This is the query plan optimisation output for the query:
SELECT fp.particleId FROM MDR1.FOFParticles AS fp WHERE fp.fofId = 85000000000

-- INPUT SQL:
SELECT fp.particleId FROM MDR1.FOFParticles AS fp WHERE fp.fofId = 85000000000

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fp.particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fp.particleId`=VALUES(`fp.particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fp.particleId AS `fp.particleId`
FROM MDR1.FOFParticles AS `fp` WHERE (  fp.fofId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `fp.particleId`
FROM `aggregation_tmp_65305809`   
ON DUPLICATE KEY UPDATE
`fp.particleId`=VALUES(`fp.particleId`)
This is the query plan for the query:
SELECT fp.particleId FROM MDR1.FOFParticles AS fp WHERE fp.fofId = 85000000000

CALL paquExec('SELECT fp.particleId AS `fp.particleId` FROM MDR1.FOFParticles AS `fp` WHERE (  fp.fofId = 85000000000 )   ', 'aggregation_tmp_65305809');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `fp.particleId`
FROM `aggregation_tmp_65305809`   ;
CALL paquDropTmp('aggregation_tmp_65305809');
This is the query plan optimisation output for the query:
SELECT webid, (CASE WHEN eigen1 >= 0.4 THEN 1 ELSE 0 END) AS num_th FROM MDR1.Vweb512 where iz=315

-- INPUT SQL:
SELECT webid, (CASE WHEN eigen1 >= 0.4 THEN 1 ELSE 0 END) AS num_th FROM MDR1.Vweb512 where iz=315

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`webid`,`num_th`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`webid`=VALUES(`webid`),
`num_th`=VALUES(`num_th`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT webid AS `webid`,CASE WHEN eigen1 >= 0.4 THEN 1 ELSE 0 END) AS num_t AS `num_th`
FROM MDR1.Vweb512 WHERE (  iz = 315 )   
)


-- AGGREGATION SQL:
SELECT `webid`,`num_th`
FROM `aggregation_tmp_30335039`   
ON DUPLICATE KEY UPDATE
`webid`=VALUES(`webid`),
`num_th`=VALUES(`num_th`)
This is the query plan for the query:
SELECT webid, (CASE WHEN eigen1 >= 0.4 THEN 1 ELSE 0 END) AS num_th FROM MDR1.Vweb512 where iz=315

CALL paquExec('SELECT webid AS `webid`,CASE WHEN eigen1 >= 0.4 THEN 1 ELSE 0 END) AS num_t AS `num_th` FROM MDR1.Vweb512 WHERE (  iz = 315 )   ', 'aggregation_tmp_30335039');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `webid`,`num_th`
FROM `aggregation_tmp_30335039`   ;
CALL paquDropTmp('aggregation_tmp_30335039');
This is the query plan optimisation output for the query:
SELECT webid, (CASE WHEN eigen1 >= 0.4 THEN 1 ELSE 0 END) AS num_th FROM MDR1.Vweb512 where iz=315 limit 10

-- INPUT SQL:
SELECT webid, (CASE WHEN eigen1 >= 0.4 THEN 1 ELSE 0 END) AS num_th FROM MDR1.Vweb512 where iz=315 limit 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`webid`,`num_th`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`webid`=VALUES(`webid`),
`num_th`=VALUES(`num_th`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT webid AS `webid`,CASE WHEN eigen1 >= 0.4 THEN 1 ELSE 0 END) AS num_t AS `num_th`
FROM MDR1.Vweb512 WHERE (  iz = 315 )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `webid`,`num_th`
FROM `aggregation_tmp_1776841`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`webid`=VALUES(`webid`),
`num_th`=VALUES(`num_th`)
This is the query plan for the query:
SELECT webid, (CASE WHEN eigen1 >= 0.4 THEN 1 ELSE 0 END) AS num_th FROM MDR1.Vweb512 where iz=315 limit 10

CALL paquExec('SELECT webid AS `webid`,CASE WHEN eigen1 >= 0.4 THEN 1 ELSE 0 END) AS num_t AS `num_th` FROM MDR1.Vweb512 WHERE (  iz = 315 )    LIMIT 0,10', 'aggregation_tmp_1776841');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `webid`,`num_th`
FROM `aggregation_tmp_1776841`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_1776841');
This is the query plan optimisation output for the query:
SELECT webid, (CASE WHEN eigen1 >= 0.4 THEN 1 ELSE 0 END) AS num_th, (2.0+i) as a FROM MDR1.Vweb512 where iz=315 limit 10

-- INPUT SQL:
SELECT webid, (CASE WHEN eigen1 >= 0.4 THEN 1 ELSE 0 END) AS num_th, (2.0+i) as a FROM MDR1.Vweb512 where iz=315 limit 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`webid`,`num_th`,`a`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`webid`=VALUES(`webid`),
`num_th`=VALUES(`num_th`),
`a`=VALUES(`a`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT webid AS `webid`,CASE WHEN eigen1 >= 0.4 THEN 1 ELSE 0 END AS `num_th`,2.0+i AS `a`
FROM MDR1.Vweb512 WHERE (  iz = 315 )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `webid`,`num_th`,`a`
FROM `aggregation_tmp_11182561`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`webid`=VALUES(`webid`),
`num_th`=VALUES(`num_th`),
`a`=VALUES(`a`)
This is the query plan for the query:
SELECT webid, (CASE WHEN eigen1 >= 0.4 THEN 1 ELSE 0 END) AS num_th, (2.0+i) as a FROM MDR1.Vweb512 where iz=315 limit 10

CALL paquExec('SELECT webid AS `webid`,CASE WHEN eigen1 >= 0.4 THEN 1 ELSE 0 END AS `num_th`,2.0+i AS `a` FROM MDR1.Vweb512 WHERE (  iz = 315 )    LIMIT 0,10', 'aggregation_tmp_11182561');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `webid`,`num_th`,`a`
FROM `aggregation_tmp_11182561`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_11182561');
This is the query plan optimisation output for the query:
SELECT webid, (CASE WHEN eigen1 >= 0.4 THEN 1 ELSE 0 END) AS num_th, (2.0+i) as a FROM MDR1.Vweb512 where iz=315 limit 10

-- INPUT SQL:
SELECT webid, (CASE WHEN eigen1 >= 0.4 THEN 1 ELSE 0 END) AS num_th, (2.0+i) as a FROM MDR1.Vweb512 where iz=315 limit 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`webid`,`num_th`,`a`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`webid`=VALUES(`webid`),
`num_th`=VALUES(`num_th`),
`a`=VALUES(`a`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT webid AS `webid`,(CASE WHEN eigen1 >= 0.4 THEN 1 ELSE 0 END)  AS `num_th`,(2.0+i)  AS `a`
FROM MDR1.Vweb512 WHERE (  iz = 315 )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `webid`,`num_th`,`a`
FROM `aggregation_tmp_79521680`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`webid`=VALUES(`webid`),
`num_th`=VALUES(`num_th`),
`a`=VALUES(`a`)
This is the query plan for the query:
SELECT webid, (CASE WHEN eigen1 >= 0.4 THEN 1 ELSE 0 END) AS num_th, (2.0+i) as a FROM MDR1.Vweb512 where iz=315 limit 10

CALL paquExec('SELECT webid AS `webid`,(CASE WHEN eigen1 >= 0.4 THEN 1 ELSE 0 END)  AS `num_th`,(2.0+i)  AS `a` FROM MDR1.Vweb512 WHERE (  iz = 315 )    LIMIT 0,10', 'aggregation_tmp_79521680');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `webid`,`num_th`,`a`
FROM `aggregation_tmp_79521680`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_79521680');
This is the query plan optimisation output for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_97208077`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np`
FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_97208077`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_19087619`  ORDER BY `p.treeSnapnum` ASC 
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)
This is the query plan for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   ', 'aggregation_tmp_97208077');
CALL paquExec('SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np` FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_97208077`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   ', 'aggregation_tmp_19087619');
CALL paquDropTmp('aggregation_tmp_97208077');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_19087619`  ORDER BY `p.treeSnapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_19087619');
This is the query plan optimisation output for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_50871341`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np`
FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_50871341`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_27829658`  ORDER BY `p.treeSnapnum` ASC 
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)
This is the query plan for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   ', 'aggregation_tmp_50871341');
CALL paquExec('SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np` FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_50871341`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   ', 'aggregation_tmp_27829658');
CALL paquDropTmp('aggregation_tmp_50871341');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_27829658`  ORDER BY `p.treeSnapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_27829658');
This is the query plan optimisation output for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_53911113`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np`
FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_53911113`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_62512733`  ORDER BY `p.treeSnapnum` ASC 
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)
This is the query plan for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   ', 'aggregation_tmp_53911113');
CALL paquExec('SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np` FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_53911113`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   ', 'aggregation_tmp_62512733');
CALL paquDropTmp('aggregation_tmp_53911113');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_62512733`  ORDER BY `p.treeSnapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_62512733');
This is the query plan optimisation output for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_2899475`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np`
FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_2899475`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_55786898`  ORDER BY `p.treeSnapnum` ASC 
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)
This is the query plan for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   ', 'aggregation_tmp_2899475');
CALL paquExec('SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np` FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_2899475`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   ', 'aggregation_tmp_55786898');
CALL paquDropTmp('aggregation_tmp_2899475');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_55786898`  ORDER BY `p.treeSnapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_55786898');
This is the query plan optimisation output for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_83957466`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np`
FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_83957466`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_53121775`  ORDER BY `p.treeSnapnum` ASC 
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)
This is the query plan for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   ', 'aggregation_tmp_83957466');
CALL paquExec('SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np` FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_83957466`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   ', 'aggregation_tmp_53121775');
CALL paquDropTmp('aggregation_tmp_83957466');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_53121775`  ORDER BY `p.treeSnapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_53121775');
This is the query plan optimisation output for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_11771806`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np`
FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_11771806`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_61473986`  ORDER BY `p.treeSnapnum` ASC 
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)
This is the query plan for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   ', 'aggregation_tmp_11771806');
CALL paquExec('SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np` FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_11771806`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   ', 'aggregation_tmp_61473986');
CALL paquDropTmp('aggregation_tmp_11771806');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_61473986`  ORDER BY `p.treeSnapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_61473986');
This is the query plan optimisation output for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_73407369`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np`
FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_73407369`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_90993250`  ORDER BY `p.treeSnapnum` ASC 
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)
This is the query plan for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   ', 'aggregation_tmp_73407369');
CALL paquExec('SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np` FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_73407369`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   ', 'aggregation_tmp_90993250');
CALL paquDropTmp('aggregation_tmp_73407369');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_90993250`  ORDER BY `p.treeSnapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_90993250');
This is the query plan optimisation output for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_86984399`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np`
FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_86984399`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_78673518`  ORDER BY `p.treeSnapnum` ASC 
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)
This is the query plan for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   ', 'aggregation_tmp_86984399');
CALL paquExec('SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np` FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_86984399`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   ', 'aggregation_tmp_78673518');
CALL paquDropTmp('aggregation_tmp_86984399');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_78673518`  ORDER BY `p.treeSnapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_78673518');
This is the query plan optimisation output for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_18739123`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np`
FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_18739123`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_81804704`  ORDER BY `p.treeSnapnum` ASC 
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)
This is the query plan for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   ', 'aggregation_tmp_18739123');
CALL paquExec('SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np` FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_18739123`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   ', 'aggregation_tmp_81804704');
CALL paquDropTmp('aggregation_tmp_18739123');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_81804704`  ORDER BY `p.treeSnapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_81804704');
This is the query plan optimisation output for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_43821738`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np`
FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_43821738`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_55248774`  ORDER BY `p.treeSnapnum` ASC 
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)
This is the query plan for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   ', 'aggregation_tmp_43821738');
CALL paquExec('SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np` FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_43821738`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   ', 'aggregation_tmp_55248774');
CALL paquDropTmp('aggregation_tmp_43821738');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_55248774`  ORDER BY `p.treeSnapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_55248774');
This is the query plan optimisation output for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_27048322`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np`
FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_27048322`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_95673708`  ORDER BY `p.treeSnapnum` ASC 
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)
This is the query plan for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   ', 'aggregation_tmp_27048322');
CALL paquExec('SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np` FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_27048322`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   ', 'aggregation_tmp_95673708');
CALL paquDropTmp('aggregation_tmp_27048322');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_95673708`  ORDER BY `p.treeSnapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_95673708');
This is the query plan optimisation output for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_14413198`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np`
FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_14413198`   ) AS `mycl`  WHERE (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` ) (  p.np > 1000 )   
)


-- AGGREGATION SQL:
SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_19929206`  ORDER BY `p.treeSnapnum` ASC 
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)
This is the query plan for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   ', 'aggregation_tmp_14413198');
CALL paquExec('SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np` FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_14413198`   ) AS `mycl`  WHERE (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` ) (  p.np > 1000 )   ', 'aggregation_tmp_19929206');
CALL paquDropTmp('aggregation_tmp_14413198');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_19929206`  ORDER BY `p.treeSnapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_19929206');
This is the query plan optimisation output for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_55924301`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np`
FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_55924301`   ) AS `mycl`  WHERE (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` ) (  p.np > 1000 )   
)


-- AGGREGATION SQL:
SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_4966715`  ORDER BY `p.treeSnapnum` ASC 
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)
This is the query plan for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   ', 'aggregation_tmp_55924301');
CALL paquExec('SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np` FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_55924301`   ) AS `mycl`  WHERE (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` ) (  p.np > 1000 )   ', 'aggregation_tmp_4966715');
CALL paquDropTmp('aggregation_tmp_55924301');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_4966715`  ORDER BY `p.treeSnapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_4966715');
This is the query plan optimisation output for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_95180289`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np`
FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_95180289`   ) AS `mycl`  WHERE and (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` ) (  p.np > 1000 )   
)


-- AGGREGATION SQL:
SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_83121071`  ORDER BY `p.treeSnapnum` ASC 
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)
This is the query plan for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   ', 'aggregation_tmp_95180289');
CALL paquExec('SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np` FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_95180289`   ) AS `mycl`  WHERE and (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` ) (  p.np > 1000 )   ', 'aggregation_tmp_83121071');
CALL paquDropTmp('aggregation_tmp_95180289');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_83121071`  ORDER BY `p.treeSnapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_83121071');
This is the query plan optimisation output for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_38417971`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np`
FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_38417971`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` ) and   
)


-- AGGREGATION SQL:
SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_55481561`  ORDER BY `p.treeSnapnum` ASC 
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)
This is the query plan for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   ', 'aggregation_tmp_38417971');
CALL paquExec('SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np` FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_38417971`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` ) and   ', 'aggregation_tmp_55481561');
CALL paquDropTmp('aggregation_tmp_38417971');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_55481561`  ORDER BY `p.treeSnapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_55481561');
This is the query plan optimisation output for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_11567285`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np`
FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_11567285`   ) AS `mycl`  WHERE (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` ) and (  p.np > 1000 )   
)


-- AGGREGATION SQL:
SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_62976849`  ORDER BY `p.treeSnapnum` ASC 
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)
This is the query plan for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   ', 'aggregation_tmp_11567285');
CALL paquExec('SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np` FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_11567285`   ) AS `mycl`  WHERE (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` ) and (  p.np > 1000 )   ', 'aggregation_tmp_62976849');
CALL paquDropTmp('aggregation_tmp_11567285');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_62976849`  ORDER BY `p.treeSnapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_62976849');
This is the query plan optimisation output for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId OR p.np > 1000 ORDER BY p.treeSnapnum

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_96277005`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId OR p.np > 1000 ORDER BY p.treeSnapnum

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np`
FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_96277005`   ) AS `mycl`  WHERE (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` ) (  p.np > 1000 )   
)


-- AGGREGATION SQL:
SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_13419451`  ORDER BY `p.treeSnapnum` ASC 
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)
This is the query plan for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId OR p.np > 1000 ORDER BY p.treeSnapnum

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   ', 'aggregation_tmp_96277005');
CALL paquExec('SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np` FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_96277005`   ) AS `mycl`  WHERE (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` ) (  p.np > 1000 )   ', 'aggregation_tmp_13419451');
CALL paquDropTmp('aggregation_tmp_96277005');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_13419451`  ORDER BY `p.treeSnapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_13419451');
This is the query plan optimisation output for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId OR p.np > 1000 ORDER BY p.treeSnapnum

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_34717660`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId OR p.np > 1000 ORDER BY p.treeSnapnum

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np`
FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_34717660`   ) AS `mycl`  WHERE (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` ) (  p.np > 1000 )   
)


-- AGGREGATION SQL:
SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_998937`  ORDER BY `p.treeSnapnum` ASC 
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)
This is the query plan for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId OR p.np > 1000 ORDER BY p.treeSnapnum

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   ', 'aggregation_tmp_34717660');
CALL paquExec('SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np` FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_34717660`   ) AS `mycl`  WHERE (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` ) (  p.np > 1000 )   ', 'aggregation_tmp_998937');
CALL paquDropTmp('aggregation_tmp_34717660');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_998937`  ORDER BY `p.treeSnapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_998937');
This is the query plan optimisation output for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId OR p.np > 1000 ORDER BY p.treeSnapnum

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_55503780`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId OR p.np > 1000 ORDER BY p.treeSnapnum

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np`
FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_55503780`   ) AS `mycl`  WHERE (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` ) OR (  p.np > 1000 )   
)


-- AGGREGATION SQL:
SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_71745814`  ORDER BY `p.treeSnapnum` ASC 
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)
This is the query plan for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId OR p.np > 1000 ORDER BY p.treeSnapnum

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   ', 'aggregation_tmp_55503780');
CALL paquExec('SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np` FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_55503780`   ) AS `mycl`  WHERE (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` ) OR (  p.np > 1000 )   ', 'aggregation_tmp_71745814');
CALL paquDropTmp('aggregation_tmp_55503780');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_71745814`  ORDER BY `p.treeSnapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_71745814');
This is the query plan optimisation output for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_87216792`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np`
FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_87216792`   ) AS `mycl`  WHERE (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` ) (  p.np > 1000 )   
)


-- AGGREGATION SQL:
SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_56930593`  ORDER BY `p.treeSnapnum` ASC 
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)
This is the query plan for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   ', 'aggregation_tmp_87216792');
CALL paquExec('SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np` FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_87216792`   ) AS `mycl`  WHERE (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` ) (  p.np > 1000 )   ', 'aggregation_tmp_56930593');
CALL paquDropTmp('aggregation_tmp_87216792');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_56930593`  ORDER BY `p.treeSnapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_56930593');
This is the query plan optimisation output for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_41942453`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np`
FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_41942453`   ) AS `mycl`  WHERE (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` ) AND (  p.np > 1000 )   
)


-- AGGREGATION SQL:
SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_92800442`  ORDER BY `p.treeSnapnum` ASC 
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)
This is the query plan for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   ', 'aggregation_tmp_41942453');
CALL paquExec('SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np` FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_41942453`   ) AS `mycl`  WHERE (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` ) AND (  p.np > 1000 )   ', 'aggregation_tmp_92800442');
CALL paquDropTmp('aggregation_tmp_41942453');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_92800442`  ORDER BY `p.treeSnapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_92800442');
This is the query plan optimisation output for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p,(SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 AND p.size > 1000 ORDER BY p.treeSnapnum

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_53249052`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p,(SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 AND p.size > 1000 ORDER BY p.treeSnapnum

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np`
FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_53249052`   ) AS `mycl`  WHERE (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` ) AND (  p.np > 1000 ) (  p.size > 1000 ) AND   
)


-- AGGREGATION SQL:
SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_51106353`  ORDER BY `p.treeSnapnum` ASC 
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)
This is the query plan for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p,(SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 AND p.size > 1000 ORDER BY p.treeSnapnum

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   ', 'aggregation_tmp_53249052');
CALL paquExec('SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np` FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_53249052`   ) AS `mycl`  WHERE (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` ) AND (  p.np > 1000 ) (  p.size > 1000 ) AND   ', 'aggregation_tmp_51106353');
CALL paquDropTmp('aggregation_tmp_53249052');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_51106353`  ORDER BY `p.treeSnapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_51106353');
This is the query plan optimisation output for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p,(SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 AND p.size > 1000 ORDER BY p.treeSnapnum

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_68463043`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p,(SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 AND p.size > 1000 ORDER BY p.treeSnapnum

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np`
FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_68463043`   ) AS `mycl`  WHERE (  p.np > 1000 ) AND (  p.size > 1000 ) AND (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_11290086`  ORDER BY `p.treeSnapnum` ASC 
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)
This is the query plan for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p,(SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 AND p.size > 1000 ORDER BY p.treeSnapnum

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   ', 'aggregation_tmp_68463043');
CALL paquExec('SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np` FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_68463043`   ) AS `mycl`  WHERE (  p.np > 1000 ) AND (  p.size > 1000 ) AND (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   ', 'aggregation_tmp_11290086');
CALL paquDropTmp('aggregation_tmp_68463043');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_11290086`  ORDER BY `p.treeSnapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_11290086');
This is the query plan optimisation output for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_50770805`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np`
FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_50770805`   ) AS `mycl`  WHERE (  p.np > 1000 ) AND (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_91798439`  ORDER BY `p.treeSnapnum` ASC 
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)
This is the query plan for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 )   ', 'aggregation_tmp_50770805');
CALL paquExec('SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np` FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_50770805`   ) AS `mycl`  WHERE (  p.np > 1000 ) AND (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   ', 'aggregation_tmp_91798439');
CALL paquDropTmp('aggregation_tmp_50770805');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_91798439`  ORDER BY `p.treeSnapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_91798439');
This is the query plan optimisation output for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000 AND x>380.0) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 ) AND (  x > 380.0 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_21328902`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000 AND x>380.0) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np`
FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_21328902`   ) AS `mycl`  WHERE (  p.np > 1000 ) AND (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_27783625`  ORDER BY `p.treeSnapnum` ASC 
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)
This is the query plan for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000 AND x>380.0) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 ) AND (  x > 380.0 )   ', 'aggregation_tmp_21328902');
CALL paquExec('SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np` FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_21328902`   ) AS `mycl`  WHERE (  p.np > 1000 ) AND (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   ', 'aggregation_tmp_27783625');
CALL paquDropTmp('aggregation_tmp_21328902');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_27783625`  ORDER BY `p.treeSnapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_27783625');
This is the query plan optimisation output for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000 AND x>380.0) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 ) AND (  x > 380.0 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_66974407`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000 AND x>380.0) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np`
FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_66974407`   ) AS `mycl`  WHERE (  p.np > 1000 ) AND (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_91490300`  ORDER BY `p.treeSnapnum` ASC 
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)
This is the query plan for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000 AND x>380.0) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 ) AND (  x > 380.0 )   ', 'aggregation_tmp_66974407');
CALL paquExec('SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np` FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_66974407`   ) AS `mycl`  WHERE (  p.np > 1000 ) AND (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   ', 'aggregation_tmp_91490300');
CALL paquDropTmp('aggregation_tmp_66974407');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_91490300`  ORDER BY `p.treeSnapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_91490300');
This is the query plan optimisation output for the query:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`mainLeafId`,`prog__fofTreeId2`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`),
`prog__fofTreeId2`=VALUES(`prog__fofTreeId2`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`,`prog__fofTreeId2` AS `prog__fofTreeId2`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`mainLeafId`,`prog__fofTreeId2`
FROM `aggregation_tmp_33947248`  ORDER BY `prog__fofTreeId2` ASC 
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`),
`prog__fofTreeId2`=VALUES(`prog__fofTreeId2`)
-- INPUT SQL:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog__fofTreeId2`=VALUES(`prog__fofTreeId2`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.fofTreeId  AS `prog__fofTreeId2`,`prog`.fofId  AS `prog__fofId`,`prog`.treeSnapnum  AS `prog__treeSnapnum`,`prog`.descendantId  AS `prog__descendantId`,`prog`.lastProgId  AS `prog__lastProgId`,`prog`.mainLeafId  AS `prog__mainLeafId`,`prog`.treeRootId  AS `prog__treeRootId`,`prog`.x  AS `prog__x`,`prog`.y  AS `prog__y`,`prog`.z  AS `prog__z`,`prog`.vx  AS `prog__vx`,`prog`.vy  AS `prog__vy`,`prog`.vz  AS `prog__vz`,`prog`.np  AS `prog__np`,`prog`.mass  AS `prog__mass`,`prog`.size  AS `prog__size`,`prog`.spin  AS `prog__spin`,`prog`.ix  AS `prog__ix`,`prog`.iy  AS `prog__iy`,`prog`.iz  AS `prog__iz`,`prog`.phkey  AS `prog__phkey`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`,`prog__fofTreeId2`
FROM `aggregation_tmp_33947248`  ORDER BY `prog__fofTreeId2` ASC ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   
)


-- AGGREGATION SQL:
SELECT `prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_88702334`  ORDER BY `prog__fofTreeId2` ASC 
ON DUPLICATE KEY UPDATE
`prog__fofTreeId2`=VALUES(`prog__fofTreeId2`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)
This is the query plan for the query:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`,`prog__fofTreeId2` AS `prog__fofTreeId2` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   ', 'aggregation_tmp_33947248');
CALL paquExec('SELECT `prog`.fofTreeId  AS `prog__fofTreeId2`,`prog`.fofId  AS `prog__fofId`,`prog`.treeSnapnum  AS `prog__treeSnapnum`,`prog`.descendantId  AS `prog__descendantId`,`prog`.lastProgId  AS `prog__lastProgId`,`prog`.mainLeafId  AS `prog__mainLeafId`,`prog`.treeRootId  AS `prog__treeRootId`,`prog`.x  AS `prog__x`,`prog`.y  AS `prog__y`,`prog`.z  AS `prog__z`,`prog`.vx  AS `prog__vx`,`prog`.vy  AS `prog__vy`,`prog`.vz  AS `prog__vz`,`prog`.np  AS `prog__np`,`prog`.mass  AS `prog__mass`,`prog`.size  AS `prog__size`,`prog`.spin  AS `prog__spin`,`prog`.ix  AS `prog__ix`,`prog`.iy  AS `prog__iy`,`prog`.iz  AS `prog__iz`,`prog`.phkey  AS `prog__phkey` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`,`prog__fofTreeId2` FROM `aggregation_tmp_33947248`  ORDER BY `prog__fofTreeId2` ASC ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   ', 'aggregation_tmp_88702334');
CALL paquDropTmp('aggregation_tmp_33947248');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_88702334`  ORDER BY `prog__fofTreeId2` ASC ;
CALL paquDropTmp('aggregation_tmp_88702334');
This is the query plan optimisation output for the query:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`mainLeafId`,`prog__fofTreeId2`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`),
`prog__fofTreeId2`=VALUES(`prog__fofTreeId2`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`,`prog__fofTreeId2` AS `prog__fofTreeId2`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`mainLeafId`,`prog__fofTreeId2`
FROM `aggregation_tmp_90982502`  ORDER BY `prog__fofTreeId2` ASC 
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`),
`prog__fofTreeId2`=VALUES(`prog__fofTreeId2`)
-- INPUT SQL:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog__fofTreeId2`=VALUES(`prog__fofTreeId2`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.fofTreeId  AS `prog__fofTreeId2`,`prog`.fofId  AS `prog__fofId`,`prog`.treeSnapnum  AS `prog__treeSnapnum`,`prog`.descendantId  AS `prog__descendantId`,`prog`.lastProgId  AS `prog__lastProgId`,`prog`.mainLeafId  AS `prog__mainLeafId`,`prog`.treeRootId  AS `prog__treeRootId`,`prog`.x  AS `prog__x`,`prog`.y  AS `prog__y`,`prog`.z  AS `prog__z`,`prog`.vx  AS `prog__vx`,`prog`.vy  AS `prog__vy`,`prog`.vz  AS `prog__vz`,`prog`.np  AS `prog__np`,`prog`.mass  AS `prog__mass`,`prog`.size  AS `prog__size`,`prog`.spin  AS `prog__spin`,`prog`.ix  AS `prog__ix`,`prog`.iy  AS `prog__iy`,`prog`.iz  AS `prog__iz`,`prog`.phkey  AS `prog__phkey`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`,`prog__fofTreeId2`
FROM `aggregation_tmp_90982502`  ORDER BY `prog__fofTreeId2` ASC ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   
)


-- AGGREGATION SQL:
SELECT `prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_18544668`  ORDER BY `prog__fofTreeId2` ASC 
ON DUPLICATE KEY UPDATE
`prog__fofTreeId2`=VALUES(`prog__fofTreeId2`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)
This is the query plan for the query:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`,`prog__fofTreeId2` AS `prog__fofTreeId2` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   ', 'aggregation_tmp_90982502');
CALL paquExec('SELECT `prog`.fofTreeId  AS `prog__fofTreeId2`,`prog`.fofId  AS `prog__fofId`,`prog`.treeSnapnum  AS `prog__treeSnapnum`,`prog`.descendantId  AS `prog__descendantId`,`prog`.lastProgId  AS `prog__lastProgId`,`prog`.mainLeafId  AS `prog__mainLeafId`,`prog`.treeRootId  AS `prog__treeRootId`,`prog`.x  AS `prog__x`,`prog`.y  AS `prog__y`,`prog`.z  AS `prog__z`,`prog`.vx  AS `prog__vx`,`prog`.vy  AS `prog__vy`,`prog`.vz  AS `prog__vz`,`prog`.np  AS `prog__np`,`prog`.mass  AS `prog__mass`,`prog`.size  AS `prog__size`,`prog`.spin  AS `prog__spin`,`prog`.ix  AS `prog__ix`,`prog`.iy  AS `prog__iy`,`prog`.iz  AS `prog__iz`,`prog`.phkey  AS `prog__phkey` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`,`prog__fofTreeId2` FROM `aggregation_tmp_90982502`  ORDER BY `prog__fofTreeId2` ASC ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   ', 'aggregation_tmp_18544668');
CALL paquDropTmp('aggregation_tmp_90982502');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_18544668`  ORDER BY `prog__fofTreeId2` ASC ;
CALL paquDropTmp('aggregation_tmp_18544668');
This is the query plan optimisation output for the query:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`mainLeafId`,`prog__fofTreeId2`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`),
`prog__fofTreeId2`=VALUES(`prog__fofTreeId2`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`,`prog__fofTreeId2` AS `prog__fofTreeId2`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`mainLeafId`,`prog__fofTreeId2`
FROM `aggregation_tmp_94640557`  ORDER BY `prog__fofTreeId2` ASC 
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`),
`prog__fofTreeId2`=VALUES(`prog__fofTreeId2`)
-- INPUT SQL:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog__fofTreeId2`=VALUES(`prog__fofTreeId2`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.fofTreeId  AS `prog__fofTreeId2`,`prog`.fofId  AS `prog__fofId`,`prog`.treeSnapnum  AS `prog__treeSnapnum`,`prog`.descendantId  AS `prog__descendantId`,`prog`.lastProgId  AS `prog__lastProgId`,`prog`.mainLeafId  AS `prog__mainLeafId`,`prog`.treeRootId  AS `prog__treeRootId`,`prog`.x  AS `prog__x`,`prog`.y  AS `prog__y`,`prog`.z  AS `prog__z`,`prog`.vx  AS `prog__vx`,`prog`.vy  AS `prog__vy`,`prog`.vz  AS `prog__vz`,`prog`.np  AS `prog__np`,`prog`.mass  AS `prog__mass`,`prog`.size  AS `prog__size`,`prog`.spin  AS `prog__spin`,`prog`.ix  AS `prog__ix`,`prog`.iy  AS `prog__iy`,`prog`.iz  AS `prog__iz`,`prog`.phkey  AS `prog__phkey`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`,`prog__fofTreeId2`
FROM `aggregation_tmp_94640557`  ORDER BY `prog__fofTreeId2` ASC ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   
)


-- AGGREGATION SQL:
SELECT `prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_55519084`  ORDER BY `prog__fofTreeId2` ASC 
ON DUPLICATE KEY UPDATE
`prog__fofTreeId2`=VALUES(`prog__fofTreeId2`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)
This is the query plan for the query:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`,`prog__fofTreeId2` AS `prog__fofTreeId2` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   ', 'aggregation_tmp_94640557');
CALL paquExec('SELECT `prog`.fofTreeId  AS `prog__fofTreeId2`,`prog`.fofId  AS `prog__fofId`,`prog`.treeSnapnum  AS `prog__treeSnapnum`,`prog`.descendantId  AS `prog__descendantId`,`prog`.lastProgId  AS `prog__lastProgId`,`prog`.mainLeafId  AS `prog__mainLeafId`,`prog`.treeRootId  AS `prog__treeRootId`,`prog`.x  AS `prog__x`,`prog`.y  AS `prog__y`,`prog`.z  AS `prog__z`,`prog`.vx  AS `prog__vx`,`prog`.vy  AS `prog__vy`,`prog`.vz  AS `prog__vz`,`prog`.np  AS `prog__np`,`prog`.mass  AS `prog__mass`,`prog`.size  AS `prog__size`,`prog`.spin  AS `prog__spin`,`prog`.ix  AS `prog__ix`,`prog`.iy  AS `prog__iy`,`prog`.iz  AS `prog__iz`,`prog`.phkey  AS `prog__phkey` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`,`prog__fofTreeId2` FROM `aggregation_tmp_94640557`  ORDER BY `prog__fofTreeId2` ASC ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   ', 'aggregation_tmp_55519084');
CALL paquDropTmp('aggregation_tmp_94640557');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_55519084`  ORDER BY `prog__fofTreeId2` ASC ;
CALL paquDropTmp('aggregation_tmp_55519084');
This is the query plan optimisation output for the query:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`mainLeafId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_2640160`  ORDER BY `prog__fofTreeId2` ASC 
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)
-- INPUT SQL:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog__fofTreeId2`=VALUES(`prog__fofTreeId2`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.fofTreeId  AS `prog__fofTreeId2`,`prog`.fofId  AS `prog__fofId`,`prog`.treeSnapnum  AS `prog__treeSnapnum`,`prog`.descendantId  AS `prog__descendantId`,`prog`.lastProgId  AS `prog__lastProgId`,`prog`.mainLeafId  AS `prog__mainLeafId`,`prog`.treeRootId  AS `prog__treeRootId`,`prog`.x  AS `prog__x`,`prog`.y  AS `prog__y`,`prog`.z  AS `prog__z`,`prog`.vx  AS `prog__vx`,`prog`.vy  AS `prog__vy`,`prog`.vz  AS `prog__vz`,`prog`.np  AS `prog__np`,`prog`.mass  AS `prog__mass`,`prog`.size  AS `prog__size`,`prog`.spin  AS `prog__spin`,`prog`.ix  AS `prog__ix`,`prog`.iy  AS `prog__iy`,`prog`.iz  AS `prog__iz`,`prog`.phkey  AS `prog__phkey`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_2640160`  ORDER BY `prog__fofTreeId2` ASC ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   
)


-- AGGREGATION SQL:
SELECT `prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_14081145`  ORDER BY `prog__fofTreeId2` ASC 
ON DUPLICATE KEY UPDATE
`prog__fofTreeId2`=VALUES(`prog__fofTreeId2`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)
This is the query plan for the query:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   ', 'aggregation_tmp_2640160');
CALL paquExec('SELECT `prog`.fofTreeId  AS `prog__fofTreeId2`,`prog`.fofId  AS `prog__fofId`,`prog`.treeSnapnum  AS `prog__treeSnapnum`,`prog`.descendantId  AS `prog__descendantId`,`prog`.lastProgId  AS `prog__lastProgId`,`prog`.mainLeafId  AS `prog__mainLeafId`,`prog`.treeRootId  AS `prog__treeRootId`,`prog`.x  AS `prog__x`,`prog`.y  AS `prog__y`,`prog`.z  AS `prog__z`,`prog`.vx  AS `prog__vx`,`prog`.vy  AS `prog__vy`,`prog`.vz  AS `prog__vz`,`prog`.np  AS `prog__np`,`prog`.mass  AS `prog__mass`,`prog`.size  AS `prog__size`,`prog`.spin  AS `prog__spin`,`prog`.ix  AS `prog__ix`,`prog`.iy  AS `prog__iy`,`prog`.iz  AS `prog__iz`,`prog`.phkey  AS `prog__phkey` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId` FROM `aggregation_tmp_2640160`  ORDER BY `prog__fofTreeId2` ASC ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   ', 'aggregation_tmp_14081145');
CALL paquDropTmp('aggregation_tmp_2640160');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_14081145`  ORDER BY `prog__fofTreeId2` ASC ;
CALL paquDropTmp('aggregation_tmp_14081145');
This is the query plan optimisation output for the query:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`mainLeafId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_96498613`  ORDER BY `prog__fofTreeId2` ASC 
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)
-- INPUT SQL:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog__fofTreeId2`=VALUES(`prog__fofTreeId2`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.fofTreeId  AS `prog__fofTreeId2`,`prog`.fofId  AS `prog__fofId`,`prog`.treeSnapnum  AS `prog__treeSnapnum`,`prog`.descendantId  AS `prog__descendantId`,`prog`.lastProgId  AS `prog__lastProgId`,`prog`.mainLeafId  AS `prog__mainLeafId`,`prog`.treeRootId  AS `prog__treeRootId`,`prog`.x  AS `prog__x`,`prog`.y  AS `prog__y`,`prog`.z  AS `prog__z`,`prog`.vx  AS `prog__vx`,`prog`.vy  AS `prog__vy`,`prog`.vz  AS `prog__vz`,`prog`.np  AS `prog__np`,`prog`.mass  AS `prog__mass`,`prog`.size  AS `prog__size`,`prog`.spin  AS `prog__spin`,`prog`.ix  AS `prog__ix`,`prog`.iy  AS `prog__iy`,`prog`.iz  AS `prog__iz`,`prog`.phkey  AS `prog__phkey`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_96498613`  ORDER BY `prog__fofTreeId2` ASC ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   
)


-- AGGREGATION SQL:
SELECT `prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_80198662`  ORDER BY `prog__fofTreeId2` ASC 
ON DUPLICATE KEY UPDATE
`prog__fofTreeId2`=VALUES(`prog__fofTreeId2`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)
This is the query plan for the query:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   ', 'aggregation_tmp_96498613');
CALL paquExec('SELECT `prog`.fofTreeId  AS `prog__fofTreeId2`,`prog`.fofId  AS `prog__fofId`,`prog`.treeSnapnum  AS `prog__treeSnapnum`,`prog`.descendantId  AS `prog__descendantId`,`prog`.lastProgId  AS `prog__lastProgId`,`prog`.mainLeafId  AS `prog__mainLeafId`,`prog`.treeRootId  AS `prog__treeRootId`,`prog`.x  AS `prog__x`,`prog`.y  AS `prog__y`,`prog`.z  AS `prog__z`,`prog`.vx  AS `prog__vx`,`prog`.vy  AS `prog__vy`,`prog`.vz  AS `prog__vz`,`prog`.np  AS `prog__np`,`prog`.mass  AS `prog__mass`,`prog`.size  AS `prog__size`,`prog`.spin  AS `prog__spin`,`prog`.ix  AS `prog__ix`,`prog`.iy  AS `prog__iy`,`prog`.iz  AS `prog__iz`,`prog`.phkey  AS `prog__phkey` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId` FROM `aggregation_tmp_96498613`  ORDER BY `prog__fofTreeId2` ASC ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   ', 'aggregation_tmp_80198662');
CALL paquDropTmp('aggregation_tmp_96498613');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_80198662`  ORDER BY `prog__fofTreeId2` ASC ;
CALL paquDropTmp('aggregation_tmp_80198662');
This is the query plan optimisation output for the query:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`mainLeafId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_57516836`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)
-- INPUT SQL:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog__fofTreeId2`=VALUES(`prog__fofTreeId2`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.fofTreeId  AS `prog__fofTreeId2`,`prog`.fofId  AS `prog__fofId`,`prog`.treeSnapnum  AS `prog__treeSnapnum`,`prog`.descendantId  AS `prog__descendantId`,`prog`.lastProgId  AS `prog__lastProgId`,`prog`.mainLeafId  AS `prog__mainLeafId`,`prog`.treeRootId  AS `prog__treeRootId`,`prog`.x  AS `prog__x`,`prog`.y  AS `prog__y`,`prog`.z  AS `prog__z`,`prog`.vx  AS `prog__vx`,`prog`.vy  AS `prog__vy`,`prog`.vz  AS `prog__vz`,`prog`.np  AS `prog__np`,`prog`.mass  AS `prog__mass`,`prog`.size  AS `prog__size`,`prog`.spin  AS `prog__spin`,`prog`.ix  AS `prog__ix`,`prog`.iy  AS `prog__iy`,`prog`.iz  AS `prog__iz`,`prog`.phkey  AS `prog__phkey`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_57516836`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   
)


-- AGGREGATION SQL:
SELECT `prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_30936152`   
ON DUPLICATE KEY UPDATE
`prog__fofTreeId2`=VALUES(`prog__fofTreeId2`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)
This is the query plan for the query:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   ', 'aggregation_tmp_57516836');
CALL paquExec('SELECT `prog`.fofTreeId  AS `prog__fofTreeId2`,`prog`.fofId  AS `prog__fofId`,`prog`.treeSnapnum  AS `prog__treeSnapnum`,`prog`.descendantId  AS `prog__descendantId`,`prog`.lastProgId  AS `prog__lastProgId`,`prog`.mainLeafId  AS `prog__mainLeafId`,`prog`.treeRootId  AS `prog__treeRootId`,`prog`.x  AS `prog__x`,`prog`.y  AS `prog__y`,`prog`.z  AS `prog__z`,`prog`.vx  AS `prog__vx`,`prog`.vy  AS `prog__vy`,`prog`.vz  AS `prog__vz`,`prog`.np  AS `prog__np`,`prog`.mass  AS `prog__mass`,`prog`.size  AS `prog__size`,`prog`.spin  AS `prog__spin`,`prog`.ix  AS `prog__ix`,`prog`.iy  AS `prog__iy`,`prog`.iz  AS `prog__iz`,`prog`.phkey  AS `prog__phkey` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId` FROM `aggregation_tmp_57516836`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   ', 'aggregation_tmp_30936152');
CALL paquDropTmp('aggregation_tmp_57516836');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_30936152`   ;
CALL paquDropTmp('aggregation_tmp_30936152');
This is the query plan optimisation output for the query:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`mainLeafId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_22565634`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)
-- INPUT SQL:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog__fofTreeId2`=VALUES(`prog__fofTreeId2`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.fofTreeId  AS `prog__fofTreeId2`,`prog`.fofId  AS `prog__fofId`,`prog`.treeSnapnum  AS `prog__treeSnapnum`,`prog`.descendantId  AS `prog__descendantId`,`prog`.lastProgId  AS `prog__lastProgId`,`prog`.mainLeafId  AS `prog__mainLeafId`,`prog`.treeRootId  AS `prog__treeRootId`,`prog`.x  AS `prog__x`,`prog`.y  AS `prog__y`,`prog`.z  AS `prog__z`,`prog`.vx  AS `prog__vx`,`prog`.vy  AS `prog__vy`,`prog`.vz  AS `prog__vz`,`prog`.np  AS `prog__np`,`prog`.mass  AS `prog__mass`,`prog`.size  AS `prog__size`,`prog`.spin  AS `prog__spin`,`prog`.ix  AS `prog__ix`,`prog`.iy  AS `prog__iy`,`prog`.iz  AS `prog__iz`,`prog`.phkey  AS `prog__phkey`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_22565634`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   
)


-- AGGREGATION SQL:
SELECT `prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_76644951`   
ON DUPLICATE KEY UPDATE
`prog__fofTreeId2`=VALUES(`prog__fofTreeId2`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)
This is the query plan for the query:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   ', 'aggregation_tmp_22565634');
CALL paquExec('SELECT `prog`.fofTreeId  AS `prog__fofTreeId2`,`prog`.fofId  AS `prog__fofId`,`prog`.treeSnapnum  AS `prog__treeSnapnum`,`prog`.descendantId  AS `prog__descendantId`,`prog`.lastProgId  AS `prog__lastProgId`,`prog`.mainLeafId  AS `prog__mainLeafId`,`prog`.treeRootId  AS `prog__treeRootId`,`prog`.x  AS `prog__x`,`prog`.y  AS `prog__y`,`prog`.z  AS `prog__z`,`prog`.vx  AS `prog__vx`,`prog`.vy  AS `prog__vy`,`prog`.vz  AS `prog__vz`,`prog`.np  AS `prog__np`,`prog`.mass  AS `prog__mass`,`prog`.size  AS `prog__size`,`prog`.spin  AS `prog__spin`,`prog`.ix  AS `prog__ix`,`prog`.iy  AS `prog__iy`,`prog`.iz  AS `prog__iz`,`prog`.phkey  AS `prog__phkey` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId` FROM `aggregation_tmp_22565634`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   ', 'aggregation_tmp_76644951');
CALL paquDropTmp('aggregation_tmp_22565634');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_76644951`   ;
CALL paquDropTmp('aggregation_tmp_76644951');
This is the query plan optimisation output for the query:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`mainLeafId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_86696261`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)
-- INPUT SQL:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog__fofTreeId2`=VALUES(`prog__fofTreeId2`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.fofTreeId  AS `prog__fofTreeId2`,`prog`.fofId  AS `prog__fofId`,`prog`.treeSnapnum  AS `prog__treeSnapnum`,`prog`.descendantId  AS `prog__descendantId`,`prog`.lastProgId  AS `prog__lastProgId`,`prog`.mainLeafId  AS `prog__mainLeafId`,`prog`.treeRootId  AS `prog__treeRootId`,`prog`.x  AS `prog__x`,`prog`.y  AS `prog__y`,`prog`.z  AS `prog__z`,`prog`.vx  AS `prog__vx`,`prog`.vy  AS `prog__vy`,`prog`.vz  AS `prog__vz`,`prog`.np  AS `prog__np`,`prog`.mass  AS `prog__mass`,`prog`.size  AS `prog__size`,`prog`.spin  AS `prog__spin`,`prog`.ix  AS `prog__ix`,`prog`.iy  AS `prog__iy`,`prog`.iz  AS `prog__iz`,`prog`.phkey  AS `prog__phkey`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_86696261`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   
)


-- AGGREGATION SQL:
SELECT `prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_26403826`   
ON DUPLICATE KEY UPDATE
`prog__fofTreeId2`=VALUES(`prog__fofTreeId2`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)
This is the query plan for the query:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   ', 'aggregation_tmp_86696261');
CALL paquExec('SELECT `prog`.fofTreeId  AS `prog__fofTreeId2`,`prog`.fofId  AS `prog__fofId`,`prog`.treeSnapnum  AS `prog__treeSnapnum`,`prog`.descendantId  AS `prog__descendantId`,`prog`.lastProgId  AS `prog__lastProgId`,`prog`.mainLeafId  AS `prog__mainLeafId`,`prog`.treeRootId  AS `prog__treeRootId`,`prog`.x  AS `prog__x`,`prog`.y  AS `prog__y`,`prog`.z  AS `prog__z`,`prog`.vx  AS `prog__vx`,`prog`.vy  AS `prog__vy`,`prog`.vz  AS `prog__vz`,`prog`.np  AS `prog__np`,`prog`.mass  AS `prog__mass`,`prog`.size  AS `prog__size`,`prog`.spin  AS `prog__spin`,`prog`.ix  AS `prog__ix`,`prog`.iy  AS `prog__iy`,`prog`.iz  AS `prog__iz`,`prog`.phkey  AS `prog__phkey` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId` FROM `aggregation_tmp_86696261`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   ', 'aggregation_tmp_26403826');
CALL paquDropTmp('aggregation_tmp_86696261');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_26403826`   ;
CALL paquDropTmp('aggregation_tmp_26403826');
This is the query plan optimisation output for the query:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`mainLeafId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_10703781`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)
-- INPUT SQL:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog__fofTreeId2`=VALUES(`prog__fofTreeId2`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.fofTreeId  AS `prog__fofTreeId2`,`prog`.fofId  AS `prog__fofId`,`prog`.treeSnapnum  AS `prog__treeSnapnum`,`prog`.descendantId  AS `prog__descendantId`,`prog`.lastProgId  AS `prog__lastProgId`,`prog`.mainLeafId  AS `prog__mainLeafId`,`prog`.treeRootId  AS `prog__treeRootId`,`prog`.x  AS `prog__x`,`prog`.y  AS `prog__y`,`prog`.z  AS `prog__z`,`prog`.vx  AS `prog__vx`,`prog`.vy  AS `prog__vy`,`prog`.vz  AS `prog__vz`,`prog`.np  AS `prog__np`,`prog`.mass  AS `prog__mass`,`prog`.size  AS `prog__size`,`prog`.spin  AS `prog__spin`,`prog`.ix  AS `prog__ix`,`prog`.iy  AS `prog__iy`,`prog`.iz  AS `prog__iz`,`prog`.phkey  AS `prog__phkey`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_10703781`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   
)


-- AGGREGATION SQL:
SELECT `prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_74624395`   
ON DUPLICATE KEY UPDATE
`prog__fofTreeId2`=VALUES(`prog__fofTreeId2`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)
This is the query plan for the query:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   ', 'aggregation_tmp_10703781');
CALL paquExec('SELECT `prog`.fofTreeId  AS `prog__fofTreeId2`,`prog`.fofId  AS `prog__fofId`,`prog`.treeSnapnum  AS `prog__treeSnapnum`,`prog`.descendantId  AS `prog__descendantId`,`prog`.lastProgId  AS `prog__lastProgId`,`prog`.mainLeafId  AS `prog__mainLeafId`,`prog`.treeRootId  AS `prog__treeRootId`,`prog`.x  AS `prog__x`,`prog`.y  AS `prog__y`,`prog`.z  AS `prog__z`,`prog`.vx  AS `prog__vx`,`prog`.vy  AS `prog__vy`,`prog`.vz  AS `prog__vz`,`prog`.np  AS `prog__np`,`prog`.mass  AS `prog__mass`,`prog`.size  AS `prog__size`,`prog`.spin  AS `prog__spin`,`prog`.ix  AS `prog__ix`,`prog`.iy  AS `prog__iy`,`prog`.iz  AS `prog__iz`,`prog`.phkey  AS `prog__phkey` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId` FROM `aggregation_tmp_10703781`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   ', 'aggregation_tmp_74624395');
CALL paquDropTmp('aggregation_tmp_10703781');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_74624395`   ;
CALL paquDropTmp('aggregation_tmp_74624395');
This is the query plan optimisation output for the query:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`mainLeafId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_96367418`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)
-- INPUT SQL:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog__fofTreeId2`=VALUES(`prog__fofTreeId2`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.fofTreeId  AS `prog__fofTreeId2`,`prog`.fofId  AS `prog__fofId`,`prog`.treeSnapnum  AS `prog__treeSnapnum`,`prog`.descendantId  AS `prog__descendantId`,`prog`.lastProgId  AS `prog__lastProgId`,`prog`.mainLeafId  AS `prog__mainLeafId`,`prog`.treeRootId  AS `prog__treeRootId`,`prog`.x  AS `prog__x`,`prog`.y  AS `prog__y`,`prog`.z  AS `prog__z`,`prog`.vx  AS `prog__vx`,`prog`.vy  AS `prog__vy`,`prog`.vz  AS `prog__vz`,`prog`.np  AS `prog__np`,`prog`.mass  AS `prog__mass`,`prog`.size  AS `prog__size`,`prog`.spin  AS `prog__spin`,`prog`.ix  AS `prog__ix`,`prog`.iy  AS `prog__iy`,`prog`.iz  AS `prog__iz`,`prog`.phkey  AS `prog__phkey`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_96367418`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   
)


-- AGGREGATION SQL:
SELECT `prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_75240364`   
ON DUPLICATE KEY UPDATE
`prog__fofTreeId2`=VALUES(`prog__fofTreeId2`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)
This is the query plan for the query:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   ', 'aggregation_tmp_96367418');
CALL paquExec('SELECT `prog`.fofTreeId  AS `prog__fofTreeId2`,`prog`.fofId  AS `prog__fofId`,`prog`.treeSnapnum  AS `prog__treeSnapnum`,`prog`.descendantId  AS `prog__descendantId`,`prog`.lastProgId  AS `prog__lastProgId`,`prog`.mainLeafId  AS `prog__mainLeafId`,`prog`.treeRootId  AS `prog__treeRootId`,`prog`.x  AS `prog__x`,`prog`.y  AS `prog__y`,`prog`.z  AS `prog__z`,`prog`.vx  AS `prog__vx`,`prog`.vy  AS `prog__vy`,`prog`.vz  AS `prog__vz`,`prog`.np  AS `prog__np`,`prog`.mass  AS `prog__mass`,`prog`.size  AS `prog__size`,`prog`.spin  AS `prog__spin`,`prog`.ix  AS `prog__ix`,`prog`.iy  AS `prog__iy`,`prog`.iz  AS `prog__iz`,`prog`.phkey  AS `prog__phkey` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId` FROM `aggregation_tmp_96367418`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   ', 'aggregation_tmp_75240364');
CALL paquDropTmp('aggregation_tmp_96367418');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_75240364`   ;
CALL paquDropTmp('aggregation_tmp_75240364');
This is the query plan optimisation output for the query:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`mainLeafId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_77313422`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)
-- INPUT SQL:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog__fofTreeId2`=VALUES(`prog__fofTreeId2`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.fofTreeId  AS `prog__fofTreeId2`,`prog`.fofId  AS `prog__fofId`,`prog`.treeSnapnum  AS `prog__treeSnapnum`,`prog`.descendantId  AS `prog__descendantId`,`prog`.lastProgId  AS `prog__lastProgId`,`prog`.mainLeafId  AS `prog__mainLeafId`,`prog`.treeRootId  AS `prog__treeRootId`,`prog`.x  AS `prog__x`,`prog`.y  AS `prog__y`,`prog`.z  AS `prog__z`,`prog`.vx  AS `prog__vx`,`prog`.vy  AS `prog__vy`,`prog`.vz  AS `prog__vz`,`prog`.np  AS `prog__np`,`prog`.mass  AS `prog__mass`,`prog`.size  AS `prog__size`,`prog`.spin  AS `prog__spin`,`prog`.ix  AS `prog__ix`,`prog`.iy  AS `prog__iy`,`prog`.iz  AS `prog__iz`,`prog`.phkey  AS `prog__phkey`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_77313422`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   
)


-- AGGREGATION SQL:
SELECT `prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_48711858`   
ON DUPLICATE KEY UPDATE
`prog__fofTreeId2`=VALUES(`prog__fofTreeId2`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)
This is the query plan for the query:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   ', 'aggregation_tmp_77313422');
CALL paquExec('SELECT `prog`.fofTreeId  AS `prog__fofTreeId2`,`prog`.fofId  AS `prog__fofId`,`prog`.treeSnapnum  AS `prog__treeSnapnum`,`prog`.descendantId  AS `prog__descendantId`,`prog`.lastProgId  AS `prog__lastProgId`,`prog`.mainLeafId  AS `prog__mainLeafId`,`prog`.treeRootId  AS `prog__treeRootId`,`prog`.x  AS `prog__x`,`prog`.y  AS `prog__y`,`prog`.z  AS `prog__z`,`prog`.vx  AS `prog__vx`,`prog`.vy  AS `prog__vy`,`prog`.vz  AS `prog__vz`,`prog`.np  AS `prog__np`,`prog`.mass  AS `prog__mass`,`prog`.size  AS `prog__size`,`prog`.spin  AS `prog__spin`,`prog`.ix  AS `prog__ix`,`prog`.iy  AS `prog__iy`,`prog`.iz  AS `prog__iz`,`prog`.phkey  AS `prog__phkey` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId` FROM `aggregation_tmp_77313422`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   ', 'aggregation_tmp_48711858');
CALL paquDropTmp('aggregation_tmp_77313422');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_48711858`   ;
CALL paquDropTmp('aggregation_tmp_48711858');
This is the query plan optimisation output for the query:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`mainLeafId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_38546329`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)
-- INPUT SQL:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog__fofTreeId2`=VALUES(`prog__fofTreeId2`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.fofTreeId  AS `prog__fofTreeId2`,`prog`.fofId  AS `prog__fofId`,`prog`.treeSnapnum  AS `prog__treeSnapnum`,`prog`.descendantId  AS `prog__descendantId`,`prog`.lastProgId  AS `prog__lastProgId`,`prog`.mainLeafId  AS `prog__mainLeafId`,`prog`.treeRootId  AS `prog__treeRootId`,`prog`.x  AS `prog__x`,`prog`.y  AS `prog__y`,`prog`.z  AS `prog__z`,`prog`.vx  AS `prog__vx`,`prog`.vy  AS `prog__vy`,`prog`.vz  AS `prog__vz`,`prog`.np  AS `prog__np`,`prog`.mass  AS `prog__mass`,`prog`.size  AS `prog__size`,`prog`.spin  AS `prog__spin`,`prog`.ix  AS `prog__ix`,`prog`.iy  AS `prog__iy`,`prog`.iz  AS `prog__iz`,`prog`.phkey  AS `prog__phkey`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_38546329`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   
)


-- AGGREGATION SQL:
SELECT `prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_58800612`   
ON DUPLICATE KEY UPDATE
`prog__fofTreeId2`=VALUES(`prog__fofTreeId2`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)
This is the query plan for the query:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   ', 'aggregation_tmp_38546329');
CALL paquExec('SELECT `prog`.fofTreeId  AS `prog__fofTreeId2`,`prog`.fofId  AS `prog__fofId`,`prog`.treeSnapnum  AS `prog__treeSnapnum`,`prog`.descendantId  AS `prog__descendantId`,`prog`.lastProgId  AS `prog__lastProgId`,`prog`.mainLeafId  AS `prog__mainLeafId`,`prog`.treeRootId  AS `prog__treeRootId`,`prog`.x  AS `prog__x`,`prog`.y  AS `prog__y`,`prog`.z  AS `prog__z`,`prog`.vx  AS `prog__vx`,`prog`.vy  AS `prog__vy`,`prog`.vz  AS `prog__vz`,`prog`.np  AS `prog__np`,`prog`.mass  AS `prog__mass`,`prog`.size  AS `prog__size`,`prog`.spin  AS `prog__spin`,`prog`.ix  AS `prog__ix`,`prog`.iy  AS `prog__iy`,`prog`.iz  AS `prog__iz`,`prog`.phkey  AS `prog__phkey` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId` FROM `aggregation_tmp_38546329`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   ', 'aggregation_tmp_58800612');
CALL paquDropTmp('aggregation_tmp_38546329');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_58800612`   ;
CALL paquDropTmp('aggregation_tmp_58800612');
This is the query plan optimisation output for the query:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`mainLeafId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_9081650`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)
-- INPUT SQL:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog__fofTreeId2`=VALUES(`prog__fofTreeId2`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.fofTreeId  AS `prog__fofTreeId2`,`prog`.fofId  AS `prog__fofId`,`prog`.treeSnapnum  AS `prog__treeSnapnum`,`prog`.descendantId  AS `prog__descendantId`,`prog`.lastProgId  AS `prog__lastProgId`,`prog`.mainLeafId  AS `prog__mainLeafId`,`prog`.treeRootId  AS `prog__treeRootId`,`prog`.x  AS `prog__x`,`prog`.y  AS `prog__y`,`prog`.z  AS `prog__z`,`prog`.vx  AS `prog__vx`,`prog`.vy  AS `prog__vy`,`prog`.vz  AS `prog__vz`,`prog`.np  AS `prog__np`,`prog`.mass  AS `prog__mass`,`prog`.size  AS `prog__size`,`prog`.spin  AS `prog__spin`,`prog`.ix  AS `prog__ix`,`prog`.iy  AS `prog__iy`,`prog`.iz  AS `prog__iz`,`prog`.phkey  AS `prog__phkey`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_9081650`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   
)


-- AGGREGATION SQL:
SELECT `prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_28520715`   
ON DUPLICATE KEY UPDATE
`prog__fofTreeId2`=VALUES(`prog__fofTreeId2`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)
This is the query plan for the query:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   ', 'aggregation_tmp_9081650');
CALL paquExec('SELECT `prog`.fofTreeId  AS `prog__fofTreeId2`,`prog`.fofId  AS `prog__fofId`,`prog`.treeSnapnum  AS `prog__treeSnapnum`,`prog`.descendantId  AS `prog__descendantId`,`prog`.lastProgId  AS `prog__lastProgId`,`prog`.mainLeafId  AS `prog__mainLeafId`,`prog`.treeRootId  AS `prog__treeRootId`,`prog`.x  AS `prog__x`,`prog`.y  AS `prog__y`,`prog`.z  AS `prog__z`,`prog`.vx  AS `prog__vx`,`prog`.vy  AS `prog__vy`,`prog`.vz  AS `prog__vz`,`prog`.np  AS `prog__np`,`prog`.mass  AS `prog__mass`,`prog`.size  AS `prog__size`,`prog`.spin  AS `prog__spin`,`prog`.ix  AS `prog__ix`,`prog`.iy  AS `prog__iy`,`prog`.iz  AS `prog__iz`,`prog`.phkey  AS `prog__phkey` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId` FROM `aggregation_tmp_9081650`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   ', 'aggregation_tmp_28520715');
CALL paquDropTmp('aggregation_tmp_9081650');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_28520715`   ;
CALL paquDropTmp('aggregation_tmp_28520715');
This is the query plan optimisation output for the query:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`mainLeafId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_9091342`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)
-- INPUT SQL:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog__fofTreeId2`=VALUES(`prog__fofTreeId2`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.fofTreeId  AS `prog__fofTreeId2`,`prog`.fofId  AS `prog__fofId`,`prog`.treeSnapnum  AS `prog__treeSnapnum`,`prog`.descendantId  AS `prog__descendantId`,`prog`.lastProgId  AS `prog__lastProgId`,`prog`.mainLeafId  AS `prog__mainLeafId`,`prog`.treeRootId  AS `prog__treeRootId`,`prog`.x  AS `prog__x`,`prog`.y  AS `prog__y`,`prog`.z  AS `prog__z`,`prog`.vx  AS `prog__vx`,`prog`.vy  AS `prog__vy`,`prog`.vz  AS `prog__vz`,`prog`.np  AS `prog__np`,`prog`.mass  AS `prog__mass`,`prog`.size  AS `prog__size`,`prog`.spin  AS `prog__spin`,`prog`.ix  AS `prog__ix`,`prog`.iy  AS `prog__iy`,`prog`.iz  AS `prog__iz`,`prog`.phkey  AS `prog__phkey`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_9091342`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   
)


-- AGGREGATION SQL:
SELECT `prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_95184983`  ORDER BY `prog__fofTreeId2` ASC 
ON DUPLICATE KEY UPDATE
`prog__fofTreeId2`=VALUES(`prog__fofTreeId2`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)
This is the query plan for the query:
SELECT `prog`.fofTreeId AS `prog__fofTreeId2`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   ', 'aggregation_tmp_9091342');
CALL paquExec('SELECT `prog`.fofTreeId  AS `prog__fofTreeId2`,`prog`.fofId  AS `prog__fofId`,`prog`.treeSnapnum  AS `prog__treeSnapnum`,`prog`.descendantId  AS `prog__descendantId`,`prog`.lastProgId  AS `prog__lastProgId`,`prog`.mainLeafId  AS `prog__mainLeafId`,`prog`.treeRootId  AS `prog__treeRootId`,`prog`.x  AS `prog__x`,`prog`.y  AS `prog__y`,`prog`.z  AS `prog__z`,`prog`.vx  AS `prog__vx`,`prog`.vy  AS `prog__vy`,`prog`.vz  AS `prog__vz`,`prog`.np  AS `prog__np`,`prog`.mass  AS `prog__mass`,`prog`.size  AS `prog__size`,`prog`.spin  AS `prog__spin`,`prog`.ix  AS `prog__ix`,`prog`.iy  AS `prog__iy`,`prog`.iz  AS `prog__iz`,`prog`.phkey  AS `prog__phkey` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId` FROM `aggregation_tmp_9091342`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   ', 'aggregation_tmp_95184983');
CALL paquDropTmp('aggregation_tmp_9091342');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `prog__fofTreeId2`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_95184983`  ORDER BY `prog__fofTreeId2` ASC ;
CALL paquDropTmp('aggregation_tmp_95184983');
This is the query plan optimisation output for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`mainLeafId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_48721824`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)
-- INPUT SQL:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.x AS `prog.x`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_48721824`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   
)


-- AGGREGATION SQL:
SELECT `prog.x`
FROM `aggregation_tmp_31862936`  ORDER BY `prog.prog__fofTreeId2` ASC 
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`)
This is the query plan for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog__fofTreeId2` ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   ', 'aggregation_tmp_48721824');
CALL paquExec('SELECT `prog`.x AS `prog.x` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId` FROM `aggregation_tmp_48721824`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   ', 'aggregation_tmp_31862936');
CALL paquDropTmp('aggregation_tmp_48721824');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `prog.x`
FROM `aggregation_tmp_31862936`  ORDER BY `prog.prog__fofTreeId2` ASC ;
CALL paquDropTmp('aggregation_tmp_31862936');
This is the query plan optimisation output for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`mainLeafId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_20910664`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)
-- INPUT SQL:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.x AS `prog.x`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_20910664`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   
)


-- AGGREGATION SQL:
SELECT `prog.x`
FROM `aggregation_tmp_33355481`   
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`)
This is the query plan for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   ', 'aggregation_tmp_20910664');
CALL paquExec('SELECT `prog`.x AS `prog.x` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId` FROM `aggregation_tmp_20910664`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   ', 'aggregation_tmp_33355481');
CALL paquDropTmp('aggregation_tmp_20910664');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `prog.x`
FROM `aggregation_tmp_33355481`   ;
CALL paquDropTmp('aggregation_tmp_33355481');
This is the query plan optimisation output for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`mainLeafId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_74139121`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)
-- INPUT SQL:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.x AS `prog.x`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_74139121`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   
)


-- AGGREGATION SQL:
SELECT `prog.x`
FROM `aggregation_tmp_47393796`   
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`)
This is the query plan for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   ', 'aggregation_tmp_74139121');
CALL paquExec('SELECT `prog`.x AS `prog.x` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId` FROM `aggregation_tmp_74139121`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   ', 'aggregation_tmp_47393796');
CALL paquDropTmp('aggregation_tmp_74139121');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `prog.x`
FROM `aggregation_tmp_47393796`   ;
CALL paquDropTmp('aggregation_tmp_47393796');
This is the query plan optimisation output for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`mainLeafId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_59424996`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)
-- INPUT SQL:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.x AS `prog.x`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_59424996`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   
)


-- AGGREGATION SQL:
SELECT `prog.x`
FROM `aggregation_tmp_22163657`   
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`)
This is the query plan for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   ', 'aggregation_tmp_59424996');
CALL paquExec('SELECT `prog`.x AS `prog.x` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId` FROM `aggregation_tmp_59424996`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   ', 'aggregation_tmp_22163657');
CALL paquDropTmp('aggregation_tmp_59424996');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `prog.x`
FROM `aggregation_tmp_22163657`   ;
CALL paquDropTmp('aggregation_tmp_22163657');
This is the query plan optimisation output for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`mainLeafId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_23179061`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)
-- INPUT SQL:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.x AS `prog.x`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_23179061`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   
)


-- AGGREGATION SQL:
SELECT `prog.x`
FROM `aggregation_tmp_48717109`   
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`)
This is the query plan for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   ', 'aggregation_tmp_23179061');
CALL paquExec('SELECT `prog`.x AS `prog.x` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId` FROM `aggregation_tmp_23179061`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   ', 'aggregation_tmp_48717109');
CALL paquDropTmp('aggregation_tmp_23179061');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `prog.x`
FROM `aggregation_tmp_48717109`   ;
CALL paquDropTmp('aggregation_tmp_48717109');
This is the query plan optimisation output for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`mainLeafId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_32101463`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)
-- INPUT SQL:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.x AS `prog.x`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_32101463`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   
)


-- AGGREGATION SQL:
SELECT `prog.x`
FROM `aggregation_tmp_57247853`  ORDER BY `prog.fofTreeId2` ASC 
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`)
This is the query plan for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   ', 'aggregation_tmp_32101463');
CALL paquExec('SELECT `prog`.x AS `prog.x` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId` FROM `aggregation_tmp_32101463`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   ', 'aggregation_tmp_57247853');
CALL paquDropTmp('aggregation_tmp_32101463');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `prog.x`
FROM `aggregation_tmp_57247853`  ORDER BY `prog.fofTreeId2` ASC ;
CALL paquDropTmp('aggregation_tmp_57247853');
This is the query plan optimisation output for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`mainLeafId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_68490174`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)
-- INPUT SQL:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.x AS `prog.x`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_68490174`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   
)


-- AGGREGATION SQL:
SELECT `prog.x`
FROM `aggregation_tmp_97199491`   
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`)
This is the query plan for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   ', 'aggregation_tmp_68490174');
CALL paquExec('SELECT `prog`.x AS `prog.x` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId` FROM `aggregation_tmp_68490174`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   ', 'aggregation_tmp_97199491');
CALL paquDropTmp('aggregation_tmp_68490174');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `prog.x`
FROM `aggregation_tmp_97199491`   ;
CALL paquDropTmp('aggregation_tmp_97199491');
This is the query plan optimisation output for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`mainLeafId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_97254323`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)
-- INPUT SQL:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.x AS `prog.x`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_97254323`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   
)


-- AGGREGATION SQL:
SELECT `prog.x`
FROM `aggregation_tmp_41395664`  ORDER BY `prog.fofTreeId2` ASC 
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`)
This is the query plan for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   ', 'aggregation_tmp_97254323');
CALL paquExec('SELECT `prog`.x AS `prog.x` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId` FROM `aggregation_tmp_97254323`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   ', 'aggregation_tmp_41395664');
CALL paquDropTmp('aggregation_tmp_97254323');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `prog.x`
FROM `aggregation_tmp_41395664`  ORDER BY `prog.fofTreeId2` ASC ;
CALL paquDropTmp('aggregation_tmp_41395664');
This is the query plan optimisation output for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`mainLeafId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_22075657`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)
-- INPUT SQL:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.x AS `prog.x`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_22075657`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   
)


-- AGGREGATION SQL:
SELECT `prog.x`
FROM `aggregation_tmp_16312092`  ORDER BY `prog.fofTreeId2` ASC 
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`)
This is the query plan for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   ', 'aggregation_tmp_22075657');
CALL paquExec('SELECT `prog`.x AS `prog.x` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId` FROM `aggregation_tmp_22075657`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   ', 'aggregation_tmp_16312092');
CALL paquDropTmp('aggregation_tmp_22075657');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `prog.x`
FROM `aggregation_tmp_16312092`  ORDER BY `prog.fofTreeId2` ASC ;
CALL paquDropTmp('aggregation_tmp_16312092');
This is the query plan optimisation output for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`mainLeafId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_65679201`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)
-- INPUT SQL:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.x AS `prog.x`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_65679201`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   
)


-- AGGREGATION SQL:
SELECT `prog.x`
FROM `aggregation_tmp_24840269`  ORDER BY `prog.fofTreeId2` ASC 
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`)
This is the query plan for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   ', 'aggregation_tmp_65679201');
CALL paquExec('SELECT `prog`.x AS `prog.x` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId` FROM `aggregation_tmp_65679201`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   ', 'aggregation_tmp_24840269');
CALL paquDropTmp('aggregation_tmp_65679201');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `prog.x`
FROM `aggregation_tmp_24840269`  ORDER BY `prog.fofTreeId2` ASC ;
CALL paquDropTmp('aggregation_tmp_24840269');
This is the query plan optimisation output for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`mainLeafId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_20436145`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)
-- INPUT SQL:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.x AS `prog.x`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_20436145`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   
)


-- AGGREGATION SQL:
SELECT `prog.x`
FROM `aggregation_tmp_22360504`  ORDER BY `prog.fofTreeId2` ASC 
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`)
This is the query plan for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   ', 'aggregation_tmp_20436145');
CALL paquExec('SELECT `prog`.x AS `prog.x` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId` FROM `aggregation_tmp_20436145`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   ', 'aggregation_tmp_22360504');
CALL paquDropTmp('aggregation_tmp_20436145');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `prog.x`
FROM `aggregation_tmp_22360504`  ORDER BY `prog.fofTreeId2` ASC ;
CALL paquDropTmp('aggregation_tmp_22360504');
This is the query plan optimisation output for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`mainLeafId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_68599237`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)
-- INPUT SQL:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.x AS `prog.x`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_68599237`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   
)


-- AGGREGATION SQL:
SELECT `prog.x`
FROM `aggregation_tmp_7416758`  ORDER BY `prog.fofTreeId2` ASC 
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`)
This is the query plan for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   ', 'aggregation_tmp_68599237');
CALL paquExec('SELECT `prog`.x AS `prog.x` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId` FROM `aggregation_tmp_68599237`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   ', 'aggregation_tmp_7416758');
CALL paquDropTmp('aggregation_tmp_68599237');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `prog.x`
FROM `aggregation_tmp_7416758`  ORDER BY `prog.fofTreeId2` ASC ;
CALL paquDropTmp('aggregation_tmp_7416758');
This is the query plan optimisation output for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`mainLeafId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_7393745`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)
-- INPUT SQL:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.x AS `prog.x`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_7393745`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   
)


-- AGGREGATION SQL:
SELECT `prog.x`
FROM `aggregation_tmp_26894636`  ORDER BY `prog.fofTreeId2` ASC 
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`)
This is the query plan for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   ', 'aggregation_tmp_7393745');
CALL paquExec('SELECT `prog`.x AS `prog.x` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId` FROM `aggregation_tmp_7393745`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   ', 'aggregation_tmp_26894636');
CALL paquDropTmp('aggregation_tmp_7393745');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `prog.x`
FROM `aggregation_tmp_26894636`  ORDER BY `prog.fofTreeId2` ASC ;
CALL paquDropTmp('aggregation_tmp_26894636');
This is the query plan optimisation output for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`mainLeafId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_27395091`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)
-- INPUT SQL:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.x AS `prog.x`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_27395091`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   
)


-- AGGREGATION SQL:
SELECT `prog.x`
FROM `aggregation_tmp_17897484`  ORDER BY `prog.fofTreeId2` ASC 
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`)
This is the query plan for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   ', 'aggregation_tmp_27395091');
CALL paquExec('SELECT `prog`.x AS `prog.x` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId` FROM `aggregation_tmp_27395091`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   ', 'aggregation_tmp_17897484');
CALL paquDropTmp('aggregation_tmp_27395091');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `prog.x`
FROM `aggregation_tmp_17897484`  ORDER BY `prog.fofTreeId2` ASC ;
CALL paquDropTmp('aggregation_tmp_17897484');
This is the query plan optimisation output for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`mainLeafId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_56254402`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)
-- INPUT SQL:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.x AS `prog.x`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_56254402`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   
)


-- AGGREGATION SQL:
SELECT `prog.x`
FROM `aggregation_tmp_2601871`  ORDER BY `prog.fofTreeId2` ASC 
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`)
This is the query plan for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   ', 'aggregation_tmp_56254402');
CALL paquExec('SELECT `prog`.x AS `prog.x` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId` FROM `aggregation_tmp_56254402`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   ', 'aggregation_tmp_2601871');
CALL paquDropTmp('aggregation_tmp_56254402');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `prog.x`
FROM `aggregation_tmp_2601871`  ORDER BY `prog.fofTreeId2` ASC ;
CALL paquDropTmp('aggregation_tmp_2601871');
This is the query plan optimisation output for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`mainLeafId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_90273595`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)
-- INPUT SQL:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.x AS `prog.x`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_90273595`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   
)


-- AGGREGATION SQL:
SELECT `prog.x`
FROM `aggregation_tmp_42113220`  ORDER BY `prog.fofTreeId2` ASC 
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`)
This is the query plan for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   ', 'aggregation_tmp_90273595');
CALL paquExec('SELECT `prog`.x AS `prog.x` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId` FROM `aggregation_tmp_90273595`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   ', 'aggregation_tmp_42113220');
CALL paquDropTmp('aggregation_tmp_90273595');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `prog.x`
FROM `aggregation_tmp_42113220`  ORDER BY `prog.fofTreeId2` ASC ;
CALL paquDropTmp('aggregation_tmp_42113220');
This is the query plan optimisation output for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`mainLeafId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_50467527`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)
-- INPUT SQL:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.x AS `prog.x`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_50467527`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   
)


-- AGGREGATION SQL:
SELECT `prog.x`
FROM `aggregation_tmp_22205064`  ORDER BY `prog.fofTreeId2` ASC 
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`)
This is the query plan for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   ', 'aggregation_tmp_50467527');
CALL paquExec('SELECT `prog`.x AS `prog.x` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId` FROM `aggregation_tmp_50467527`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   ', 'aggregation_tmp_22205064');
CALL paquDropTmp('aggregation_tmp_50467527');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `prog.x`
FROM `aggregation_tmp_22205064`  ORDER BY `prog.fofTreeId2` ASC ;
CALL paquDropTmp('aggregation_tmp_22205064');
This is the query plan optimisation output for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`mainLeafId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_1941819`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)
-- INPUT SQL:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.x`,`fofTreeId`,`prog.fofTreeId2`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`),
`fofTreeId`=VALUES(`fofTreeId`),
`prog.fofTreeId2`=VALUES(`prog.fofTreeId2`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.x AS `prog.x`,`descend`.`fofTreeId` AS `fofTreeId`,`prog`.fofTreeId2 AS `prog.fofTreeId2`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_1941819`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   
)


-- AGGREGATION SQL:
SELECT `prog.x`,`fofTreeId`,`prog.fofTreeId2`
FROM `aggregation_tmp_95968797`  ORDER BY `prog.fofTreeId2` ASC 
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`),
`fofTreeId`=VALUES(`fofTreeId`),
`prog.fofTreeId2`=VALUES(`prog.fofTreeId2`)
This is the query plan for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   ', 'aggregation_tmp_1941819');
CALL paquExec('SELECT `prog`.x AS `prog.x`,`descend`.`fofTreeId` AS `fofTreeId`,`prog`.fofTreeId2 AS `prog.fofTreeId2` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId` FROM `aggregation_tmp_1941819`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   ', 'aggregation_tmp_95968797');
CALL paquDropTmp('aggregation_tmp_1941819');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `prog.x`,`fofTreeId`,`prog.fofTreeId2`
FROM `aggregation_tmp_95968797`  ORDER BY `prog.fofTreeId2` ASC ;
CALL paquDropTmp('aggregation_tmp_95968797');
This is the query plan optimisation output for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`mainLeafId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_76972190`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)
-- INPUT SQL:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.x`,`prog.fofTreeId2`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`),
`prog.fofTreeId2`=VALUES(`prog.fofTreeId2`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.x AS `prog.x`,`prog`.fofTreeId2 AS `prog.fofTreeId2`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_76972190`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   
)


-- AGGREGATION SQL:
SELECT `prog.x`,`prog.fofTreeId2`
FROM `aggregation_tmp_64463319`  ORDER BY `prog.fofTreeId2` ASC 
ON DUPLICATE KEY UPDATE
`prog.x`=VALUES(`prog.x`),
`prog.fofTreeId2`=VALUES(`prog.fofTreeId2`)
This is the query plan for the query:
SELECT `prog`.x FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY `prog`.fofTreeId2 ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   ', 'aggregation_tmp_76972190');
CALL paquExec('SELECT `prog`.x AS `prog.x`,`prog`.fofTreeId2 AS `prog.fofTreeId2` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId` FROM `aggregation_tmp_76972190`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   ', 'aggregation_tmp_64463319');
CALL paquDropTmp('aggregation_tmp_76972190');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `prog.x`,`prog.fofTreeId2`
FROM `aggregation_tmp_64463319`  ORDER BY `prog.fofTreeId2` ASC ;
CALL paquDropTmp('aggregation_tmp_64463319');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofId`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofId AS `fofId`,particleId AS `particleId`
FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   
)


-- AGGREGATION SQL:
SELECT `fofId`,`particleId`
FROM `aggregation_tmp_7370098`   
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId`
FROM `aggregation_tmp_7370098`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_92048123`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_92048123`   ) AS `p`  WHERE AND (  `f`.`particleId` = f3.particleId )   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_91768361`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT fofId AS `fofId`,particleId AS `particleId` FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   ', 'aggregation_tmp_7370098');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId` FROM `aggregation_tmp_7370098`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   ', 'aggregation_tmp_92048123');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId` FROM `aggregation_tmp_92048123`   ) AS `p`  WHERE AND (  `f`.`particleId` = f3.particleId )   ', 'aggregation_tmp_91768361');
CALL paquDropTmp('aggregation_tmp_7370098');
CALL paquDropTmp('aggregation_tmp_92048123');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_91768361`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_91768361');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofId`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofId AS `fofId`,particleId AS `particleId`
FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   
)


-- AGGREGATION SQL:
SELECT `fofId`,`particleId`
FROM `aggregation_tmp_87266907`   
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId`
FROM `aggregation_tmp_87266907`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_19943534`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_19943534`   ) AS `p`  WHERE AND (  `f`.`particleId` = f3.particleId )   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_62240013`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT fofId AS `fofId`,particleId AS `particleId` FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   ', 'aggregation_tmp_87266907');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId` FROM `aggregation_tmp_87266907`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   ', 'aggregation_tmp_19943534');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId` FROM `aggregation_tmp_19943534`   ) AS `p`  WHERE AND (  `f`.`particleId` = f3.particleId )   ', 'aggregation_tmp_62240013');
CALL paquDropTmp('aggregation_tmp_87266907');
CALL paquDropTmp('aggregation_tmp_19943534');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_62240013`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_62240013');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofId`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofId AS `fofId`,particleId AS `particleId`
FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   
)


-- AGGREGATION SQL:
SELECT `fofId`,`particleId`
FROM `aggregation_tmp_36770906`   
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId`
FROM `aggregation_tmp_36770906`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_88996703`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_88996703`   ) AS `p`  WHERE AND (  `f`.`particleId` = f3.particleId )   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_97966639`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT fofId AS `fofId`,particleId AS `particleId` FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   ', 'aggregation_tmp_36770906');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId` FROM `aggregation_tmp_36770906`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   ', 'aggregation_tmp_88996703');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId` FROM `aggregation_tmp_88996703`   ) AS `p`  WHERE AND (  `f`.`particleId` = f3.particleId )   ', 'aggregation_tmp_97966639');
CALL paquDropTmp('aggregation_tmp_36770906');
CALL paquDropTmp('aggregation_tmp_88996703');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_97966639`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_97966639');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofId`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofId AS `fofId`,particleId AS `particleId`
FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   
)


-- AGGREGATION SQL:
SELECT `fofId`,`particleId`
FROM `aggregation_tmp_9443282`   
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId`
FROM `aggregation_tmp_9443282`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_98739006`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_98739006`   ) AS `p`  WHERE AND (  `f`.`particleId` = f3.particleId )   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_6479331`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT fofId AS `fofId`,particleId AS `particleId` FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   ', 'aggregation_tmp_9443282');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId` FROM `aggregation_tmp_9443282`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   ', 'aggregation_tmp_98739006');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId` FROM `aggregation_tmp_98739006`   ) AS `p`  WHERE AND (  `f`.`particleId` = f3.particleId )   ', 'aggregation_tmp_6479331');
CALL paquDropTmp('aggregation_tmp_9443282');
CALL paquDropTmp('aggregation_tmp_98739006');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_6479331`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_6479331');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofId`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofId AS `fofId`,particleId AS `particleId`
FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   
)


-- AGGREGATION SQL:
SELECT `fofId`,`particleId`
FROM `aggregation_tmp_83602329`   
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId`
FROM `aggregation_tmp_83602329`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_51631771`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_51631771`   ) AS `p`  WHERE AND (  `f`.`particleId` = f3.particleId )   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_1092805`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT fofId AS `fofId`,particleId AS `particleId` FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   ', 'aggregation_tmp_83602329');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId` FROM `aggregation_tmp_83602329`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   ', 'aggregation_tmp_51631771');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId` FROM `aggregation_tmp_51631771`   ) AS `p`  WHERE AND (  `f`.`particleId` = f3.particleId )   ', 'aggregation_tmp_1092805');
CALL paquDropTmp('aggregation_tmp_83602329');
CALL paquDropTmp('aggregation_tmp_51631771');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_1092805`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_1092805');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofId`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofId AS `fofId`,particleId AS `particleId`
FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   
)


-- AGGREGATION SQL:
SELECT `fofId`,`particleId`
FROM `aggregation_tmp_72506373`   
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId`
FROM `aggregation_tmp_72506373`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_57743551`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_57743551`   ) AS `p`  WHERE AND (  `f`.`particleId` = f3.particleId )   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_17172533`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT fofId AS `fofId`,particleId AS `particleId` FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   ', 'aggregation_tmp_72506373');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId` FROM `aggregation_tmp_72506373`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   ', 'aggregation_tmp_57743551');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId` FROM `aggregation_tmp_57743551`   ) AS `p`  WHERE AND (  `f`.`particleId` = f3.particleId )   ', 'aggregation_tmp_17172533');
CALL paquDropTmp('aggregation_tmp_72506373');
CALL paquDropTmp('aggregation_tmp_57743551');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_17172533`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_17172533');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofId`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofId AS `fofId`,particleId AS `particleId`
FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   
)


-- AGGREGATION SQL:
SELECT `fofId`,`particleId`
FROM `aggregation_tmp_45621061`   
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId`
FROM `aggregation_tmp_45621061`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_87898060`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_87898060`   ) AS `p`  WHERE AND (  `f`.`particleId` = f3.particleId )   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_97155372`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT fofId AS `fofId`,particleId AS `particleId` FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   ', 'aggregation_tmp_45621061');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId` FROM `aggregation_tmp_45621061`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   ', 'aggregation_tmp_87898060');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId` FROM `aggregation_tmp_87898060`   ) AS `p`  WHERE AND (  `f`.`particleId` = f3.particleId )   ', 'aggregation_tmp_97155372');
CALL paquDropTmp('aggregation_tmp_45621061');
CALL paquDropTmp('aggregation_tmp_87898060');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_97155372`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_97155372');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofId`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofId AS `fofId`,particleId AS `particleId`
FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   
)


-- AGGREGATION SQL:
SELECT `fofId`,`particleId`
FROM `aggregation_tmp_19878417`   
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId`
FROM `aggregation_tmp_19878417`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_95737588`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_95737588`   ) AS `p`  WHERE AND (  `f`.`particleId` = f3.particleId )   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_34060810`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT fofId AS `fofId`,particleId AS `particleId` FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   ', 'aggregation_tmp_19878417');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId` FROM `aggregation_tmp_19878417`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   ', 'aggregation_tmp_95737588');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId` FROM `aggregation_tmp_95737588`   ) AS `p`  WHERE AND (  `f`.`particleId` = f3.particleId )   ', 'aggregation_tmp_34060810');
CALL paquDropTmp('aggregation_tmp_19878417');
CALL paquDropTmp('aggregation_tmp_95737588');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_34060810`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_34060810');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofId`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofId AS `fofId`,particleId AS `particleId`
FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   
)


-- AGGREGATION SQL:
SELECT `fofId`,`particleId`
FROM `aggregation_tmp_45163972`   
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId`
FROM `aggregation_tmp_45163972`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_22051695`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_22051695`   ) AS `p`  WHERE AND (  `f`.`particleId` = f3.particleId )   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_56534678`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT fofId AS `fofId`,particleId AS `particleId` FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   ', 'aggregation_tmp_45163972');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId` FROM `aggregation_tmp_45163972`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   ', 'aggregation_tmp_22051695');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId` FROM `aggregation_tmp_22051695`   ) AS `p`  WHERE AND (  `f`.`particleId` = f3.particleId )   ', 'aggregation_tmp_56534678');
CALL paquDropTmp('aggregation_tmp_45163972');
CALL paquDropTmp('aggregation_tmp_22051695');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_56534678`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_56534678');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.fofId`,`f.particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.fofId`=VALUES(`f.fofId`),
`f.particleId`=VALUES(`f.particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofId AS `f.fofId`,particleId AS `f.particleId`
FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   
)


-- AGGREGATION SQL:
SELECT `f.fofId`,`f.particleId`
FROM `aggregation_tmp_19528646`   
ON DUPLICATE KEY UPDATE
`f.fofId`=VALUES(`f.fofId`),
`f.particleId`=VALUES(`f.particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`p.particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`p.particleId`=VALUES(`p.particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,particleId AS `p.particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `f.fofId`,`f.particleId`
FROM `aggregation_tmp_19528646`   ) AS `f`  WHERE (  p.particleId = `f`.`f.particleId` )   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`p.particleId`
FROM `aggregation_tmp_45646226`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`p.particleId`=VALUES(`p.particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`p.particleId`
FROM `aggregation_tmp_45646226`   ) AS `p`  WHERE AND (  `f`.`f.particleId` = f3.particleId )   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_20310546`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT fofId AS `f.fofId`,particleId AS `f.particleId` FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   ', 'aggregation_tmp_19528646');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,particleId AS `p.particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `f.fofId`,`f.particleId` FROM `aggregation_tmp_19528646`   ) AS `f`  WHERE (  p.particleId = `f`.`f.particleId` )   ', 'aggregation_tmp_45646226');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`p.particleId` FROM `aggregation_tmp_45646226`   ) AS `p`  WHERE AND (  `f`.`f.particleId` = f3.particleId )   ', 'aggregation_tmp_20310546');
CALL paquDropTmp('aggregation_tmp_19528646');
CALL paquDropTmp('aggregation_tmp_45646226');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_20310546`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_20310546');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofId`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofId AS `fofId`,particleId AS `particleId`
FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   
)


-- AGGREGATION SQL:
SELECT `fofId`,`particleId`
FROM `aggregation_tmp_20768210`   
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId`
FROM `aggregation_tmp_20768210`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_22339076`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_22339076`   ) AS `p`  WHERE AND (  `f`.`particleId` = f3.particleId )   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_94290815`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT fofId AS `fofId`,particleId AS `particleId` FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   ', 'aggregation_tmp_20768210');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId` FROM `aggregation_tmp_20768210`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   ', 'aggregation_tmp_22339076');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId` FROM `aggregation_tmp_22339076`   ) AS `p`  WHERE AND (  `f`.`particleId` = f3.particleId )   ', 'aggregation_tmp_94290815');
CALL paquDropTmp('aggregation_tmp_20768210');
CALL paquDropTmp('aggregation_tmp_22339076');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_94290815`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_94290815');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.fofId`,`f.particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.fofId`=VALUES(`f.fofId`),
`f.particleId`=VALUES(`f.particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofId AS `f.fofId`,particleId AS `f.particleId`
FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   
)


-- AGGREGATION SQL:
SELECT `f.fofId`,`f.particleId`
FROM `aggregation_tmp_79105458`   
ON DUPLICATE KEY UPDATE
`f.fofId`=VALUES(`f.fofId`),
`f.particleId`=VALUES(`f.particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`p.particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`p.particleId`=VALUES(`p.particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,particleId AS `p.particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `f.fofId`,`f.particleId`
FROM `aggregation_tmp_79105458`   ) AS `f`  WHERE (  p.particleId = `f`.`f.particleId` )   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`p.particleId`
FROM `aggregation_tmp_71570184`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`p.particleId`=VALUES(`p.particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`p.particleId`
FROM `aggregation_tmp_71570184`   ) AS `p`  WHERE AND (  `f`.`f.particleId` = f3.particleId )   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_73898405`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT fofId AS `f.fofId`,particleId AS `f.particleId` FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   ', 'aggregation_tmp_79105458');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,particleId AS `p.particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `f.fofId`,`f.particleId` FROM `aggregation_tmp_79105458`   ) AS `f`  WHERE (  p.particleId = `f`.`f.particleId` )   ', 'aggregation_tmp_71570184');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`p.particleId` FROM `aggregation_tmp_71570184`   ) AS `p`  WHERE AND (  `f`.`f.particleId` = f3.particleId )   ', 'aggregation_tmp_73898405');
CALL paquDropTmp('aggregation_tmp_79105458');
CALL paquDropTmp('aggregation_tmp_71570184');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_73898405`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_73898405');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofId`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofId AS `fofId`,particleId AS `particleId`
FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   
)


-- AGGREGATION SQL:
SELECT `fofId`,`particleId`
FROM `aggregation_tmp_25378845`   
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId`
FROM `aggregation_tmp_25378845`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_61411913`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_61411913`   ) AS `p`  WHERE AND (  `f`.`particleId` = f3.particleId )   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_5404569`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT fofId AS `fofId`,particleId AS `particleId` FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   ', 'aggregation_tmp_25378845');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId` FROM `aggregation_tmp_25378845`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   ', 'aggregation_tmp_61411913');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId` FROM `aggregation_tmp_61411913`   ) AS `p`  WHERE AND (  `f`.`particleId` = f3.particleId )   ', 'aggregation_tmp_5404569');
CALL paquDropTmp('aggregation_tmp_25378845');
CALL paquDropTmp('aggregation_tmp_61411913');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_5404569`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_5404569');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofId`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofId AS `fofId`,particleId AS `particleId`
FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   
)


-- AGGREGATION SQL:
SELECT `fofId`,`particleId`
FROM `aggregation_tmp_60078853`   
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId`
FROM `aggregation_tmp_60078853`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_54143024`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_54143024`   ) AS `p`  WHERE AND (  `f`.`particleId` = f3.particleId )   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_906126`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT fofId AS `fofId`,particleId AS `particleId` FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   ', 'aggregation_tmp_60078853');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId` FROM `aggregation_tmp_60078853`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   ', 'aggregation_tmp_54143024');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId` FROM `aggregation_tmp_54143024`   ) AS `p`  WHERE AND (  `f`.`particleId` = f3.particleId )   ', 'aggregation_tmp_906126');
CALL paquDropTmp('aggregation_tmp_60078853');
CALL paquDropTmp('aggregation_tmp_54143024');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_906126`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_906126');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofId`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofId AS `fofId`,particleId AS `particleId`
FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   
)


-- AGGREGATION SQL:
SELECT `fofId`,`particleId`
FROM `aggregation_tmp_65160773`   
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId`
FROM `aggregation_tmp_65160773`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_16527837`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_16527837`   ) AS `p`  WHERE AND (  `f`.`particleId` = f3.particleId )   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_45480857`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT fofId AS `fofId`,particleId AS `particleId` FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   ', 'aggregation_tmp_65160773');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId` FROM `aggregation_tmp_65160773`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   ', 'aggregation_tmp_16527837');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId` FROM `aggregation_tmp_16527837`   ) AS `p`  WHERE AND (  `f`.`particleId` = f3.particleId )   ', 'aggregation_tmp_45480857');
CALL paquDropTmp('aggregation_tmp_65160773');
CALL paquDropTmp('aggregation_tmp_16527837');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_45480857`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_45480857');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofId`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofId AS `fofId`,particleId AS `particleId`
FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   
)


-- AGGREGATION SQL:
SELECT `fofId`,`particleId`
FROM `aggregation_tmp_92480646`   
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId`
FROM `aggregation_tmp_92480646`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_61231315`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_61231315`   ) AS `p`  WHERE AND (  `f`.`particleId` = f3.particleId )   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_87569815`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT fofId AS `fofId`,particleId AS `particleId` FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   ', 'aggregation_tmp_92480646');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId` FROM `aggregation_tmp_92480646`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   ', 'aggregation_tmp_61231315');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId` FROM `aggregation_tmp_61231315`   ) AS `p`  WHERE AND (  `f`.`particleId` = f3.particleId )   ', 'aggregation_tmp_87569815');
CALL paquDropTmp('aggregation_tmp_92480646');
CALL paquDropTmp('aggregation_tmp_61231315');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_87569815`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_87569815');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofId`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofId AS `fofId`,particleId AS `particleId`
FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   
)


-- AGGREGATION SQL:
SELECT `fofId`,`particleId`
FROM `aggregation_tmp_34039492`   
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId`
FROM `aggregation_tmp_34039492`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_21329064`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_21329064`   ) AS `p`  WHERE (  `f`.`particleId` = f3.particleId )   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_3229195`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT fofId AS `fofId`,particleId AS `particleId` FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   ', 'aggregation_tmp_34039492');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId` FROM `aggregation_tmp_34039492`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   ', 'aggregation_tmp_21329064');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId` FROM `aggregation_tmp_21329064`   ) AS `p`  WHERE (  `f`.`particleId` = f3.particleId )   ', 'aggregation_tmp_3229195');
CALL paquDropTmp('aggregation_tmp_34039492');
CALL paquDropTmp('aggregation_tmp_21329064');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_3229195`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_3229195');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId AND f.particleId = f3.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofId`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofId AS `fofId`,particleId AS `particleId`
FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   
)


-- AGGREGATION SQL:
SELECT `fofId`,`particleId`
FROM `aggregation_tmp_15900517`   
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,`f`.`particleId` AS `particleId`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `fofId`,`particleId`
FROM `aggregation_tmp_15900517`   ) AS `f`  WHERE (  `f`.`particleId` = f3.particleId ) (  `f`.`particleId` = f3.particleId )   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`particleId`
FROM `aggregation_tmp_11117747`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId AND f.particleId = f3.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`f3.fofId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`f3.fofId`=VALUES(`f3.fofId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f3`.`f3.fofId` AS `f3.fofId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `f3.fofId`,`particleId`
FROM `aggregation_tmp_11117747`  ORDER BY `f3.fofId` ASC ) AS `f3`  WHERE (  p.particleId = `f`.`particleId` )   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`f3.fofId`
FROM `aggregation_tmp_91495903`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`f3.fofId`=VALUES(`f3.fofId`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId AND f.particleId = f3.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT fofId AS `fofId`,particleId AS `particleId` FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   ', 'aggregation_tmp_15900517');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,`f`.`particleId` AS `particleId` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `fofId`,`particleId` FROM `aggregation_tmp_15900517`   ) AS `f`  WHERE (  `f`.`particleId` = f3.particleId ) (  `f`.`particleId` = f3.particleId )   ', 'aggregation_tmp_11117747');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f3`.`f3.fofId` AS `f3.fofId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `f3.fofId`,`particleId` FROM `aggregation_tmp_11117747`  ORDER BY `f3.fofId` ASC ) AS `f3`  WHERE (  p.particleId = `f`.`particleId` )   ', 'aggregation_tmp_91495903');
CALL paquDropTmp('aggregation_tmp_15900517');
CALL paquDropTmp('aggregation_tmp_11117747');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `p.x`,`p.y`,`p.z`,`f3.fofId`
FROM `aggregation_tmp_91495903`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_91495903');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId AND f.particleId = f3.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofId`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofId AS `fofId`,particleId AS `particleId`
FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   
)


-- AGGREGATION SQL:
SELECT `fofId`,`particleId`
FROM `aggregation_tmp_63339362`   
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,`f`.`particleId` AS `particleId`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `fofId`,`particleId`
FROM `aggregation_tmp_63339362`   ) AS `f`  WHERE (  `f`.`particleId` = f3.particleId ) (  `f`.`particleId` = f3.particleId )   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`particleId`
FROM `aggregation_tmp_35540461`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId AND f.particleId = f3.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`f3.fofId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`f3.fofId`=VALUES(`f3.fofId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f3`.`f3.fofId` AS `f3.fofId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `f3.fofId`,`particleId`
FROM `aggregation_tmp_35540461`  ORDER BY `f3.fofId` ASC ) AS `f3`  WHERE (  p.particleId = `f`.`particleId` )   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`f3.fofId`
FROM `aggregation_tmp_8622560`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`f3.fofId`=VALUES(`f3.fofId`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId AND f.particleId = f3.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT fofId AS `fofId`,particleId AS `particleId` FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   ', 'aggregation_tmp_63339362');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,`f`.`particleId` AS `particleId` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `fofId`,`particleId` FROM `aggregation_tmp_63339362`   ) AS `f`  WHERE (  `f`.`particleId` = f3.particleId ) (  `f`.`particleId` = f3.particleId )   ', 'aggregation_tmp_35540461');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f3`.`f3.fofId` AS `f3.fofId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `f3.fofId`,`particleId` FROM `aggregation_tmp_35540461`  ORDER BY `f3.fofId` ASC ) AS `f3`  WHERE (  p.particleId = `f`.`particleId` )   ', 'aggregation_tmp_8622560');
CALL paquDropTmp('aggregation_tmp_63339362');
CALL paquDropTmp('aggregation_tmp_35540461');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `p.x`,`p.y`,`p.z`,`f3.fofId`
FROM `aggregation_tmp_8622560`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_8622560');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId AND f.particleId = f3.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofId`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofId AS `fofId`,particleId AS `particleId`
FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   
)


-- AGGREGATION SQL:
SELECT `fofId`,`particleId`
FROM `aggregation_tmp_90223953`   
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,`f`.`particleId` AS `particleId`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `fofId`,`particleId`
FROM `aggregation_tmp_90223953`   ) AS `f`  WHERE (  `f`.`particleId` = f3.particleId ) AND (  `f`.`particleId` = f3.particleId )   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`particleId`
FROM `aggregation_tmp_46121906`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId AND f.particleId = f3.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`f3.fofId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`f3.fofId`=VALUES(`f3.fofId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f3`.`f3.fofId` AS `f3.fofId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `f3.fofId`,`particleId`
FROM `aggregation_tmp_46121906`  ORDER BY `f3.fofId` ASC ) AS `f3`  WHERE (  p.particleId = `f`.`particleId` )   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`f3.fofId`
FROM `aggregation_tmp_71987356`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`f3.fofId`=VALUES(`f3.fofId`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId AND f.particleId = f3.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT fofId AS `fofId`,particleId AS `particleId` FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   ', 'aggregation_tmp_90223953');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,`f`.`particleId` AS `particleId` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `fofId`,`particleId` FROM `aggregation_tmp_90223953`   ) AS `f`  WHERE (  `f`.`particleId` = f3.particleId ) AND (  `f`.`particleId` = f3.particleId )   ', 'aggregation_tmp_46121906');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f3`.`f3.fofId` AS `f3.fofId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `f3.fofId`,`particleId` FROM `aggregation_tmp_46121906`  ORDER BY `f3.fofId` ASC ) AS `f3`  WHERE (  p.particleId = `f`.`particleId` )   ', 'aggregation_tmp_71987356');
CALL paquDropTmp('aggregation_tmp_90223953');
CALL paquDropTmp('aggregation_tmp_46121906');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `p.x`,`p.y`,`p.z`,`f3.fofId`
FROM `aggregation_tmp_71987356`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_71987356');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofId`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofId AS `fofId`,particleId AS `particleId`
FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   
)


-- AGGREGATION SQL:
SELECT `fofId`,`particleId`
FROM `aggregation_tmp_67052390`   
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId`
FROM `aggregation_tmp_67052390`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_2158792`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_2158792`   ) AS `p`  WHERE (  `f`.`particleId` = f3.particleId )   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_740951`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT fofId AS `fofId`,particleId AS `particleId` FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   ', 'aggregation_tmp_67052390');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId` FROM `aggregation_tmp_67052390`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   ', 'aggregation_tmp_2158792');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId` FROM `aggregation_tmp_2158792`   ) AS `p`  WHERE (  `f`.`particleId` = f3.particleId )   ', 'aggregation_tmp_740951');
CALL paquDropTmp('aggregation_tmp_67052390');
CALL paquDropTmp('aggregation_tmp_2158792');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_740951`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_740951');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.fofId`,`f.particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.fofId`=VALUES(`f.fofId`),
`f.particleId`=VALUES(`f.particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofId AS `f.fofId`,particleId AS `f.particleId`
FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   
)


-- AGGREGATION SQL:
SELECT `f.fofId`,`f.particleId`
FROM `aggregation_tmp_42191113`   
ON DUPLICATE KEY UPDATE
`f.fofId`=VALUES(`f.fofId`),
`f.particleId`=VALUES(`f.particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`p.particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`p.particleId`=VALUES(`p.particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,particleId AS `p.particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `f.fofId`,`f.particleId`
FROM `aggregation_tmp_42191113`   ) AS `f`  WHERE (  p.particleId = `f`.`f.particleId` )   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`p.particleId`
FROM `aggregation_tmp_3964388`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`p.particleId`=VALUES(`p.particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`p.particleId`
FROM `aggregation_tmp_3964388`   ) AS `p`  WHERE (  `f`.`f.particleId` = f3.particleId )   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_54487838`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT fofId AS `f.fofId`,particleId AS `f.particleId` FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   ', 'aggregation_tmp_42191113');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,particleId AS `p.particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `f.fofId`,`f.particleId` FROM `aggregation_tmp_42191113`   ) AS `f`  WHERE (  p.particleId = `f`.`f.particleId` )   ', 'aggregation_tmp_3964388');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`p.particleId` FROM `aggregation_tmp_3964388`   ) AS `p`  WHERE (  `f`.`f.particleId` = f3.particleId )   ', 'aggregation_tmp_54487838');
CALL paquDropTmp('aggregation_tmp_42191113');
CALL paquDropTmp('aggregation_tmp_3964388');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_54487838`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_54487838');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofId`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofId AS `fofId`,particleId AS `particleId`
FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   
)


-- AGGREGATION SQL:
SELECT `fofId`,`particleId`
FROM `aggregation_tmp_26554632`   
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId`
FROM `aggregation_tmp_26554632`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_96972906`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_96972906`   ) AS `p`  WHERE (  `f`.`particleId` = f3.particleId )   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_91533454`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT fofId AS `fofId`,particleId AS `particleId` FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   ', 'aggregation_tmp_26554632');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId` FROM `aggregation_tmp_26554632`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   ', 'aggregation_tmp_96972906');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId` FROM `aggregation_tmp_96972906`   ) AS `p`  WHERE (  `f`.`particleId` = f3.particleId )   ', 'aggregation_tmp_91533454');
CALL paquDropTmp('aggregation_tmp_26554632');
CALL paquDropTmp('aggregation_tmp_96972906');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_91533454`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_91533454');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofId`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofId AS `fofId`,particleId AS `particleId`
FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   
)


-- AGGREGATION SQL:
SELECT `fofId`,`particleId`
FROM `aggregation_tmp_61326476`   
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId`
FROM `aggregation_tmp_61326476`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_11358780`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_11358780`   ) AS `p`  WHERE (  `f`.`particleId` = f3.particleId )   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_44901701`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT fofId AS `fofId`,particleId AS `particleId` FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   ', 'aggregation_tmp_61326476');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId` FROM `aggregation_tmp_61326476`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   ', 'aggregation_tmp_11358780');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId` FROM `aggregation_tmp_11358780`   ) AS `p`  WHERE (  `f`.`particleId` = f3.particleId )   ', 'aggregation_tmp_44901701');
CALL paquDropTmp('aggregation_tmp_61326476');
CALL paquDropTmp('aggregation_tmp_11358780');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_44901701`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_44901701');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND p.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofId`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofId AS `fofId`,particleId AS `particleId`
FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   
)


-- AGGREGATION SQL:
SELECT `fofId`,`particleId`
FROM `aggregation_tmp_99203095`   
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId`
FROM `aggregation_tmp_99203095`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_53783636`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND p.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_53783636`   ) AS `p`  WHERE (  `p`.`particleId` = f3.particleId )   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_44814278`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND p.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT fofId AS `fofId`,particleId AS `particleId` FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   ', 'aggregation_tmp_99203095');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId` FROM `aggregation_tmp_99203095`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   ', 'aggregation_tmp_53783636');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId` FROM `aggregation_tmp_53783636`   ) AS `p`  WHERE (  `p`.`particleId` = f3.particleId )   ', 'aggregation_tmp_44814278');
CALL paquDropTmp('aggregation_tmp_99203095');
CALL paquDropTmp('aggregation_tmp_53783636');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_44814278`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_44814278');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND p.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofId`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofId AS `fofId`,particleId AS `particleId`
FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   
)


-- AGGREGATION SQL:
SELECT `fofId`,`particleId`
FROM `aggregation_tmp_78397877`   
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId`
FROM `aggregation_tmp_78397877`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_97468641`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND p.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_97468641`   ) AS `p`  WHERE (  `p`.`particleId` = f3.particleId )   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_9653479`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND p.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT fofId AS `fofId`,particleId AS `particleId` FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   ', 'aggregation_tmp_78397877');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId` FROM `aggregation_tmp_78397877`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   ', 'aggregation_tmp_97468641');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId` FROM `aggregation_tmp_97468641`   ) AS `p`  WHERE (  `p`.`particleId` = f3.particleId )   ', 'aggregation_tmp_9653479');
CALL paquDropTmp('aggregation_tmp_78397877');
CALL paquDropTmp('aggregation_tmp_97468641');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_9653479`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_9653479');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofId`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofId AS `fofId`,particleId AS `particleId`
FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   
)


-- AGGREGATION SQL:
SELECT `fofId`,`particleId`
FROM `aggregation_tmp_58399905`   
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId`
FROM `aggregation_tmp_58399905`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_85717047`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_85717047`   ) AS `p`  WHERE (  `f`.`particleId` = f3.particleId )   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_21256533`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT fofId AS `fofId`,particleId AS `particleId` FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   ', 'aggregation_tmp_58399905');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId` FROM `aggregation_tmp_58399905`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   ', 'aggregation_tmp_85717047');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId` FROM `aggregation_tmp_85717047`   ) AS `p`  WHERE (  `f`.`particleId` = f3.particleId )   ', 'aggregation_tmp_21256533');
CALL paquDropTmp('aggregation_tmp_58399905');
CALL paquDropTmp('aggregation_tmp_85717047');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_21256533`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_21256533');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofId`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofId AS `fofId`,particleId AS `particleId`
FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   
)


-- AGGREGATION SQL:
SELECT `fofId`,`particleId`
FROM `aggregation_tmp_13884718`   
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId`
FROM `aggregation_tmp_13884718`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_54673715`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_54673715`   ) AS `p`  WHERE (  `f`.`particleId` = f3.particleId )   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_59703263`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT fofId AS `fofId`,particleId AS `particleId` FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   ', 'aggregation_tmp_13884718');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId` FROM `aggregation_tmp_13884718`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   ', 'aggregation_tmp_54673715');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId` FROM `aggregation_tmp_54673715`   ) AS `p`  WHERE (  `f`.`particleId` = f3.particleId )   ', 'aggregation_tmp_59703263');
CALL paquDropTmp('aggregation_tmp_13884718');
CALL paquDropTmp('aggregation_tmp_54673715');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_59703263`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_59703263');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofId`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofId AS `fofId`,particleId AS `particleId`
FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   
)


-- AGGREGATION SQL:
SELECT `fofId`,`particleId`
FROM `aggregation_tmp_30709127`   
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId`
FROM `aggregation_tmp_30709127`   ) AS `f`  WHERE `f`.particleId = `f`.`particleId` )   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_4806649`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_4806649`   ) AS `p`  WHERE `p`.`particleId` = f3.particleId )   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_56295086`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT fofId AS `fofId`,particleId AS `particleId` FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   ', 'aggregation_tmp_30709127');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId` FROM `aggregation_tmp_30709127`   ) AS `f`  WHERE `f`.particleId = `f`.`particleId` )   ', 'aggregation_tmp_4806649');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId` FROM `aggregation_tmp_4806649`   ) AS `p`  WHERE `p`.`particleId` = f3.particleId )   ', 'aggregation_tmp_56295086');
CALL paquDropTmp('aggregation_tmp_30709127');
CALL paquDropTmp('aggregation_tmp_4806649');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_56295086`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_56295086');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofId`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofId AS `fofId`,particleId AS `particleId`
FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   
)


-- AGGREGATION SQL:
SELECT `fofId`,`particleId`
FROM `aggregation_tmp_78406931`   
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId`
FROM `aggregation_tmp_78406931`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_4660694`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_4660694`   ) AS `p`  WHERE (  `f`.`particleId` = f3.particleId )   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_82112274`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT fofId AS `fofId`,particleId AS `particleId` FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   ', 'aggregation_tmp_78406931');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId` FROM `aggregation_tmp_78406931`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   ', 'aggregation_tmp_4660694');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId` FROM `aggregation_tmp_4660694`   ) AS `p`  WHERE (  `f`.`particleId` = f3.particleId )   ', 'aggregation_tmp_82112274');
CALL paquDropTmp('aggregation_tmp_78406931');
CALL paquDropTmp('aggregation_tmp_4660694');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_82112274`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_82112274');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofId`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofId AS `fofId`,particleId AS `particleId`
FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   
)


-- AGGREGATION SQL:
SELECT `fofId`,`particleId`
FROM `aggregation_tmp_2698516`   
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId`
FROM `aggregation_tmp_2698516`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_52612167`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_52612167`   ) AS `p`  WHERE (  `f`.`particleId` = f3.particleId )   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_476095`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT fofId AS `fofId`,particleId AS `particleId` FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   ', 'aggregation_tmp_2698516');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId` FROM `aggregation_tmp_2698516`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   ', 'aggregation_tmp_52612167');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId` FROM `aggregation_tmp_52612167`   ) AS `p`  WHERE (  `f`.`particleId` = f3.particleId )   ', 'aggregation_tmp_476095');
CALL paquDropTmp('aggregation_tmp_2698516');
CALL paquDropTmp('aggregation_tmp_52612167');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_476095`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_476095');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofId`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofId AS `fofId`,particleId AS `particleId`
FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   
)


-- AGGREGATION SQL:
SELECT `fofId`,`particleId`
FROM `aggregation_tmp_55153222`   
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId`
FROM `aggregation_tmp_55153222`   ) AS `f`  WHERE `f`.particleId = `f`.`particleId` )   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_76074613`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_76074613`   ) AS `p`  WHERE `p`.`particleId` = f3.particleId )   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_81972021`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT fofId AS `fofId`,particleId AS `particleId` FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   ', 'aggregation_tmp_55153222');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId` FROM `aggregation_tmp_55153222`   ) AS `f`  WHERE `f`.particleId = `f`.`particleId` )   ', 'aggregation_tmp_76074613');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId` FROM `aggregation_tmp_76074613`   ) AS `p`  WHERE `p`.`particleId` = f3.particleId )   ', 'aggregation_tmp_81972021');
CALL paquDropTmp('aggregation_tmp_55153222');
CALL paquDropTmp('aggregation_tmp_76074613');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_81972021`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_81972021');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofId`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofId AS `fofId`,particleId AS `particleId`
FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   
)


-- AGGREGATION SQL:
SELECT `fofId`,`particleId`
FROM `aggregation_tmp_17743335`   
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId`
FROM `aggregation_tmp_17743335`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_61419741`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_61419741`   ) AS `p`  WHERE (  `f`.`particleId` = f3.particleId )   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_54732746`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT fofId AS `fofId`,particleId AS `particleId` FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   ', 'aggregation_tmp_17743335');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId` FROM `aggregation_tmp_17743335`   ) AS `f`  WHERE (  p.particleId = `f`.`particleId` )   ', 'aggregation_tmp_61419741');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId` FROM `aggregation_tmp_61419741`   ) AS `p`  WHERE (  `f`.`particleId` = f3.particleId )   ', 'aggregation_tmp_54732746');
CALL paquDropTmp('aggregation_tmp_17743335');
CALL paquDropTmp('aggregation_tmp_61419741');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_54732746`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_54732746');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofId`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofId AS `fofId`,particleId AS `particleId`
FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   
)


-- AGGREGATION SQL:
SELECT `fofId`,`particleId`
FROM `aggregation_tmp_35837495`   
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId`
FROM `aggregation_tmp_35837495`   ) AS `f`  WHERE ( p.particleId = `f`.`particleId` )   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_76901308`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`particleId`=VALUES(`particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId`
FROM `aggregation_tmp_76901308`   ) AS `p`  WHERE ( `p`.`particleId` = f3.particleId )   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_34099340`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT fofId AS `fofId`,particleId AS `particleId` FROM MDR1.FOFParticles AS `f` WHERE (  f.fofId = 85000000479 )   ', 'aggregation_tmp_35837495');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,`f`.`particleId` AS `particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `fofId`,`particleId` FROM `aggregation_tmp_35837495`   ) AS `f`  WHERE ( p.particleId = `f`.`particleId` )   ', 'aggregation_tmp_76901308');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,`p`.`p.x` AS `p.x`,`p`.`p.y` AS `p.y`,`p`.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`particleId` FROM `aggregation_tmp_76901308`   ) AS `p`  WHERE ( `p`.`particleId` = f3.particleId )   ', 'aggregation_tmp_34099340');
CALL paquDropTmp('aggregation_tmp_35837495');
CALL paquDropTmp('aggregation_tmp_76901308');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_34099340`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_34099340');
This is the query plan optimisation output for the query:
select r.* from  (select * from MDR1.FOFSub WHERE fofId = 85000000479) as r

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`
FROM MDR1.FOFSub WHERE (  fofId = 85000000479 )   
)


-- AGGREGATION SQL:
SELECT `*`
FROM `aggregation_tmp_66237378`   
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)
-- INPUT SQL:
select r.* from  (select * from MDR1.FOFSub WHERE fofId = 85000000479) as r

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`r.*`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`r.*`=VALUES(`r.*`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT r.* AS `r.*`
FROM ( SELECT `*`
FROM `aggregation_tmp_66237378`   ) AS `r` ORDER BY NULL 
)


-- AGGREGATION SQL:
SELECT `r.*`
FROM `aggregation_tmp_26796255`   
ON DUPLICATE KEY UPDATE
`r.*`=VALUES(`r.*`)
This is the query plan for the query:
select r.* from  (select * from MDR1.FOFSub WHERE fofId = 85000000479) as r

CALL paquExec('SELECT * AS `*` FROM MDR1.FOFSub WHERE (  fofId = 85000000479 )   ', 'aggregation_tmp_66237378');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_26796255 ENGINE=MyISAM SELECT r.* AS `r.*`
FROM ( SELECT `*`
FROM `aggregation_tmp_66237378`   ) AS `r` ORDER BY NULL  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_26796255 SELECT r.* AS `r.*`
FROM ( SELECT `*`
FROM `aggregation_tmp_66237378`   ) AS `r` ORDER BY NULL ;
CALL paquLinkTmp('aggregation_tmp_26796255');
CALL paquDropTmp('aggregation_tmp_66237378');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `r.*`
FROM `aggregation_tmp_26796255`   ;
CALL paquDropTmp('aggregation_tmp_26796255');
This is the query plan optimisation output for the query:
SELECT `res`.`host__fofSubId` as `res__host__fofSubId`,`res`.`host__fofId` as `res__host__fofId`,`res`.`host__level` as `res__host__level`,`res`.`host__NInFile` as `res__host__NInFile`,`res`.`host__hostId` as `res__host__hostId`,`res`.`host__lastSubId` as `res__host__lastSubId`,`res`.`host__mainLeafId` as `res__host__mainLeafId`,`res`.`host__treeRootId` as `res__host__treeRootId`,`res`.`host__nloose` as `res__host__nloose`,`res`.`host__x` as `res__host__x`,`res`.`host__y` as `res__host__y`,`res`.`host__z` as `res__host__z`,`res`.`host__vx` as `res__host__vx`,`res`.`host__vy` as `res__host__vy`,`res`.`host__vz` as `res__host__vz`,`res`.`host__np` as `res__host__np`,`res`.`host__mass` as `res__host__mass`,`res`.`host__size` as `res__host__size`,`res`.`host__spin` as `res__host__spin`,`res`.`host__ix` as `res__host__ix`,`res`.`host__iy` as `res__host__iy`,`res`.`host__iz` as `res__host__iz`,`res`.`host__phkey` as `res__host__phkey` FROM (SELECT `host`.fofSubId as `host__fofSubId`,`host`.fofId as `host__fofId`,`host`.level as `host__level`,`host`.NInFile as `host__NInFile`,`host`.hostId as `host__hostId`,`host`.lastSubId as `host__lastSubId`,`host`.mainLeafId as `host__mainLeafId`,`host`.treeRootId as `host__treeRootId`,`host`.nloose as `host__nloose`,`host`.x as `host__x`,`host`.y as `host__y`,`host`.z as `host__z`,`host`.vx as `host__vx`,`host`.vy as `host__vy`,`host`.vz as `host__vz`,`host`.np as `host__np`,`host`.mass as `host__mass`,`host`.size as `host__size`,`host`.spin as `host__spin`,`host`.ix as `host__ix`,`host`.iy as `host__iy`,`host`.iz as `host__iz`,`host`.phkey as `host__phkey` FROM MDR1.FOFSub host WHERE host.fofSubId = 85000000000000000 LIMIT 10) as res WHERE `res`.`host__np` > 50

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`host__fofSubId`=VALUES(`host__fofSubId`),
`host__fofId`=VALUES(`host__fofId`),
`host__level`=VALUES(`host__level`),
`host__NInFile`=VALUES(`host__NInFile`),
`host__hostId`=VALUES(`host__hostId`),
`host__lastSubId`=VALUES(`host__lastSubId`),
`host__mainLeafId`=VALUES(`host__mainLeafId`),
`host__treeRootId`=VALUES(`host__treeRootId`),
`host__nloose`=VALUES(`host__nloose`),
`host__x`=VALUES(`host__x`),
`host__y`=VALUES(`host__y`),
`host__z`=VALUES(`host__z`),
`host__vx`=VALUES(`host__vx`),
`host__vy`=VALUES(`host__vy`),
`host__vz`=VALUES(`host__vz`),
`host__np`=VALUES(`host__np`),
`host__mass`=VALUES(`host__mass`),
`host__size`=VALUES(`host__size`),
`host__spin`=VALUES(`host__spin`),
`host__ix`=VALUES(`host__ix`),
`host__iy`=VALUES(`host__iy`),
`host__iz`=VALUES(`host__iz`),
`host__phkey`=VALUES(`host__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `host`.fofSubId  AS `host__fofSubId`,`host`.fofId  AS `host__fofId`,`host`.level  AS `host__level`,`host`.NInFile  AS `host__NInFile`,`host`.hostId  AS `host__hostId`,`host`.lastSubId  AS `host__lastSubId`,`host`.mainLeafId  AS `host__mainLeafId`,`host`.treeRootId  AS `host__treeRootId`,`host`.nloose  AS `host__nloose`,`host`.x  AS `host__x`,`host`.y  AS `host__y`,`host`.z  AS `host__z`,`host`.vx  AS `host__vx`,`host`.vy  AS `host__vy`,`host`.vz  AS `host__vz`,`host`.np  AS `host__np`,`host`.mass  AS `host__mass`,`host`.size  AS `host__size`,`host`.spin  AS `host__spin`,`host`.ix  AS `host__ix`,`host`.iy  AS `host__iy`,`host`.iz  AS `host__iz`,`host`.phkey  AS `host__phkey`
FROM MDR1.FOFSub AS `host` WHERE (  host.fofSubId = 85000000000000000 )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`
FROM `aggregation_tmp_95159485`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`host__fofSubId`=VALUES(`host__fofSubId`),
`host__fofId`=VALUES(`host__fofId`),
`host__level`=VALUES(`host__level`),
`host__NInFile`=VALUES(`host__NInFile`),
`host__hostId`=VALUES(`host__hostId`),
`host__lastSubId`=VALUES(`host__lastSubId`),
`host__mainLeafId`=VALUES(`host__mainLeafId`),
`host__treeRootId`=VALUES(`host__treeRootId`),
`host__nloose`=VALUES(`host__nloose`),
`host__x`=VALUES(`host__x`),
`host__y`=VALUES(`host__y`),
`host__z`=VALUES(`host__z`),
`host__vx`=VALUES(`host__vx`),
`host__vy`=VALUES(`host__vy`),
`host__vz`=VALUES(`host__vz`),
`host__np`=VALUES(`host__np`),
`host__mass`=VALUES(`host__mass`),
`host__size`=VALUES(`host__size`),
`host__spin`=VALUES(`host__spin`),
`host__ix`=VALUES(`host__ix`),
`host__iy`=VALUES(`host__iy`),
`host__iz`=VALUES(`host__iz`),
`host__phkey`=VALUES(`host__phkey`)
-- INPUT SQL:
SELECT `res`.`host__fofSubId` as `res__host__fofSubId`,`res`.`host__fofId` as `res__host__fofId`,`res`.`host__level` as `res__host__level`,`res`.`host__NInFile` as `res__host__NInFile`,`res`.`host__hostId` as `res__host__hostId`,`res`.`host__lastSubId` as `res__host__lastSubId`,`res`.`host__mainLeafId` as `res__host__mainLeafId`,`res`.`host__treeRootId` as `res__host__treeRootId`,`res`.`host__nloose` as `res__host__nloose`,`res`.`host__x` as `res__host__x`,`res`.`host__y` as `res__host__y`,`res`.`host__z` as `res__host__z`,`res`.`host__vx` as `res__host__vx`,`res`.`host__vy` as `res__host__vy`,`res`.`host__vz` as `res__host__vz`,`res`.`host__np` as `res__host__np`,`res`.`host__mass` as `res__host__mass`,`res`.`host__size` as `res__host__size`,`res`.`host__spin` as `res__host__spin`,`res`.`host__ix` as `res__host__ix`,`res`.`host__iy` as `res__host__iy`,`res`.`host__iz` as `res__host__iz`,`res`.`host__phkey` as `res__host__phkey` FROM (SELECT `host`.fofSubId as `host__fofSubId`,`host`.fofId as `host__fofId`,`host`.level as `host__level`,`host`.NInFile as `host__NInFile`,`host`.hostId as `host__hostId`,`host`.lastSubId as `host__lastSubId`,`host`.mainLeafId as `host__mainLeafId`,`host`.treeRootId as `host__treeRootId`,`host`.nloose as `host__nloose`,`host`.x as `host__x`,`host`.y as `host__y`,`host`.z as `host__z`,`host`.vx as `host__vx`,`host`.vy as `host__vy`,`host`.vz as `host__vz`,`host`.np as `host__np`,`host`.mass as `host__mass`,`host`.size as `host__size`,`host`.spin as `host__spin`,`host`.ix as `host__ix`,`host`.iy as `host__iy`,`host`.iz as `host__iz`,`host`.phkey as `host__phkey` FROM MDR1.FOFSub host WHERE host.fofSubId = 85000000000000000 LIMIT 10) as res WHERE `res`.`host__np` > 50

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`res__host__fofSubId`,`res__host__fofId`,`res__host__level`,`res__host__NInFile`,`res__host__hostId`,`res__host__lastSubId`,`res__host__mainLeafId`,`res__host__treeRootId`,`res__host__nloose`,`res__host__x`,`res__host__y`,`res__host__z`,`res__host__vx`,`res__host__vy`,`res__host__vz`,`res__host__np`,`res__host__mass`,`res__host__size`,`res__host__spin`,`res__host__ix`,`res__host__iy`,`res__host__iz`,`res__host__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`res__host__fofSubId`=VALUES(`res__host__fofSubId`),
`res__host__fofId`=VALUES(`res__host__fofId`),
`res__host__level`=VALUES(`res__host__level`),
`res__host__NInFile`=VALUES(`res__host__NInFile`),
`res__host__hostId`=VALUES(`res__host__hostId`),
`res__host__lastSubId`=VALUES(`res__host__lastSubId`),
`res__host__mainLeafId`=VALUES(`res__host__mainLeafId`),
`res__host__treeRootId`=VALUES(`res__host__treeRootId`),
`res__host__nloose`=VALUES(`res__host__nloose`),
`res__host__x`=VALUES(`res__host__x`),
`res__host__y`=VALUES(`res__host__y`),
`res__host__z`=VALUES(`res__host__z`),
`res__host__vx`=VALUES(`res__host__vx`),
`res__host__vy`=VALUES(`res__host__vy`),
`res__host__vz`=VALUES(`res__host__vz`),
`res__host__np`=VALUES(`res__host__np`),
`res__host__mass`=VALUES(`res__host__mass`),
`res__host__size`=VALUES(`res__host__size`),
`res__host__spin`=VALUES(`res__host__spin`),
`res__host__ix`=VALUES(`res__host__ix`),
`res__host__iy`=VALUES(`res__host__iy`),
`res__host__iz`=VALUES(`res__host__iz`),
`res__host__phkey`=VALUES(`res__host__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `res`.`host__fofSubId`  AS `res__host__fofSubId`,`res`.`host__fofId`  AS `res__host__fofId`,`res`.`host__level`  AS `res__host__level`,`res`.`host__NInFile`  AS `res__host__NInFile`,`res`.`host__hostId`  AS `res__host__hostId`,`res`.`host__lastSubId`  AS `res__host__lastSubId`,`res`.`host__mainLeafId`  AS `res__host__mainLeafId`,`res`.`host__treeRootId`  AS `res__host__treeRootId`,`res`.`host__nloose`  AS `res__host__nloose`,`res`.`host__x`  AS `res__host__x`,`res`.`host__y`  AS `res__host__y`,`res`.`host__z`  AS `res__host__z`,`res`.`host__vx`  AS `res__host__vx`,`res`.`host__vy`  AS `res__host__vy`,`res`.`host__vz`  AS `res__host__vz`,`res`.`host__np`  AS `res__host__np`,`res`.`host__mass`  AS `res__host__mass`,`res`.`host__size`  AS `res__host__size`,`res`.`host__spin`  AS `res__host__spin`,`res`.`host__ix`  AS `res__host__ix`,`res`.`host__iy`  AS `res__host__iy`,`res`.`host__iz`  AS `res__host__iz`,`res`.`host__phkey`  AS `res__host__phkey`
FROM ( SELECT `host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`
FROM `aggregation_tmp_95159485`    LIMIT 0,10) AS `res` WHERE (  `res`.`host__np` > 50 )   
)


-- AGGREGATION SQL:
SELECT `res__host__fofSubId`,`res__host__fofId`,`res__host__level`,`res__host__NInFile`,`res__host__hostId`,`res__host__lastSubId`,`res__host__mainLeafId`,`res__host__treeRootId`,`res__host__nloose`,`res__host__x`,`res__host__y`,`res__host__z`,`res__host__vx`,`res__host__vy`,`res__host__vz`,`res__host__np`,`res__host__mass`,`res__host__size`,`res__host__spin`,`res__host__ix`,`res__host__iy`,`res__host__iz`,`res__host__phkey`
FROM `aggregation_tmp_13857471`   
ON DUPLICATE KEY UPDATE
`res__host__fofSubId`=VALUES(`res__host__fofSubId`),
`res__host__fofId`=VALUES(`res__host__fofId`),
`res__host__level`=VALUES(`res__host__level`),
`res__host__NInFile`=VALUES(`res__host__NInFile`),
`res__host__hostId`=VALUES(`res__host__hostId`),
`res__host__lastSubId`=VALUES(`res__host__lastSubId`),
`res__host__mainLeafId`=VALUES(`res__host__mainLeafId`),
`res__host__treeRootId`=VALUES(`res__host__treeRootId`),
`res__host__nloose`=VALUES(`res__host__nloose`),
`res__host__x`=VALUES(`res__host__x`),
`res__host__y`=VALUES(`res__host__y`),
`res__host__z`=VALUES(`res__host__z`),
`res__host__vx`=VALUES(`res__host__vx`),
`res__host__vy`=VALUES(`res__host__vy`),
`res__host__vz`=VALUES(`res__host__vz`),
`res__host__np`=VALUES(`res__host__np`),
`res__host__mass`=VALUES(`res__host__mass`),
`res__host__size`=VALUES(`res__host__size`),
`res__host__spin`=VALUES(`res__host__spin`),
`res__host__ix`=VALUES(`res__host__ix`),
`res__host__iy`=VALUES(`res__host__iy`),
`res__host__iz`=VALUES(`res__host__iz`),
`res__host__phkey`=VALUES(`res__host__phkey`)
This is the query plan for the query:
SELECT `res`.`host__fofSubId` as `res__host__fofSubId`,`res`.`host__fofId` as `res__host__fofId`,`res`.`host__level` as `res__host__level`,`res`.`host__NInFile` as `res__host__NInFile`,`res`.`host__hostId` as `res__host__hostId`,`res`.`host__lastSubId` as `res__host__lastSubId`,`res`.`host__mainLeafId` as `res__host__mainLeafId`,`res`.`host__treeRootId` as `res__host__treeRootId`,`res`.`host__nloose` as `res__host__nloose`,`res`.`host__x` as `res__host__x`,`res`.`host__y` as `res__host__y`,`res`.`host__z` as `res__host__z`,`res`.`host__vx` as `res__host__vx`,`res`.`host__vy` as `res__host__vy`,`res`.`host__vz` as `res__host__vz`,`res`.`host__np` as `res__host__np`,`res`.`host__mass` as `res__host__mass`,`res`.`host__size` as `res__host__size`,`res`.`host__spin` as `res__host__spin`,`res`.`host__ix` as `res__host__ix`,`res`.`host__iy` as `res__host__iy`,`res`.`host__iz` as `res__host__iz`,`res`.`host__phkey` as `res__host__phkey` FROM (SELECT `host`.fofSubId as `host__fofSubId`,`host`.fofId as `host__fofId`,`host`.level as `host__level`,`host`.NInFile as `host__NInFile`,`host`.hostId as `host__hostId`,`host`.lastSubId as `host__lastSubId`,`host`.mainLeafId as `host__mainLeafId`,`host`.treeRootId as `host__treeRootId`,`host`.nloose as `host__nloose`,`host`.x as `host__x`,`host`.y as `host__y`,`host`.z as `host__z`,`host`.vx as `host__vx`,`host`.vy as `host__vy`,`host`.vz as `host__vz`,`host`.np as `host__np`,`host`.mass as `host__mass`,`host`.size as `host__size`,`host`.spin as `host__spin`,`host`.ix as `host__ix`,`host`.iy as `host__iy`,`host`.iz as `host__iz`,`host`.phkey as `host__phkey` FROM MDR1.FOFSub host WHERE host.fofSubId = 85000000000000000 LIMIT 10) as res WHERE `res`.`host__np` > 50

CALL paquExec('SELECT `host`.fofSubId  AS `host__fofSubId`,`host`.fofId  AS `host__fofId`,`host`.level  AS `host__level`,`host`.NInFile  AS `host__NInFile`,`host`.hostId  AS `host__hostId`,`host`.lastSubId  AS `host__lastSubId`,`host`.mainLeafId  AS `host__mainLeafId`,`host`.treeRootId  AS `host__treeRootId`,`host`.nloose  AS `host__nloose`,`host`.x  AS `host__x`,`host`.y  AS `host__y`,`host`.z  AS `host__z`,`host`.vx  AS `host__vx`,`host`.vy  AS `host__vy`,`host`.vz  AS `host__vz`,`host`.np  AS `host__np`,`host`.mass  AS `host__mass`,`host`.size  AS `host__size`,`host`.spin  AS `host__spin`,`host`.ix  AS `host__ix`,`host`.iy  AS `host__iy`,`host`.iz  AS `host__iz`,`host`.phkey  AS `host__phkey` FROM MDR1.FOFSub AS `host` WHERE (  host.fofSubId = 85000000000000000 )    LIMIT 0,10', 'aggregation_tmp_95159485');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_13857471 ENGINE=MyISAM SELECT `res`.`host__fofSubId`  AS `res__host__fofSubId`,`res`.`host__fofId`  AS `res__host__fofId`,`res`.`host__level`  AS `res__host__level`,`res`.`host__NInFile`  AS `res__host__NInFile`,`res`.`host__hostId`  AS `res__host__hostId`,`res`.`host__lastSubId`  AS `res__host__lastSubId`,`res`.`host__mainLeafId`  AS `res__host__mainLeafId`,`res`.`host__treeRootId`  AS `res__host__treeRootId`,`res`.`host__nloose`  AS `res__host__nloose`,`res`.`host__x`  AS `res__host__x`,`res`.`host__y`  AS `res__host__y`,`res`.`host__z`  AS `res__host__z`,`res`.`host__vx`  AS `res__host__vx`,`res`.`host__vy`  AS `res__host__vy`,`res`.`host__vz`  AS `res__host__vz`,`res`.`host__np`  AS `res__host__np`,`res`.`host__mass`  AS `res__host__mass`,`res`.`host__size`  AS `res__host__size`,`res`.`host__spin`  AS `res__host__spin`,`res`.`host__ix`  AS `res__host__ix`,`res`.`host__iy`  AS `res__host__iy`,`res`.`host__iz`  AS `res__host__iz`,`res`.`host__phkey`  AS `res__host__phkey`
FROM ( SELECT `host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`
FROM `aggregation_tmp_95159485`     LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_13857471 SELECT `res`.`host__fofSubId`  AS `res__host__fofSubId`,`res`.`host__fofId`  AS `res__host__fofId`,`res`.`host__level`  AS `res__host__level`,`res`.`host__NInFile`  AS `res__host__NInFile`,`res`.`host__hostId`  AS `res__host__hostId`,`res`.`host__lastSubId`  AS `res__host__lastSubId`,`res`.`host__mainLeafId`  AS `res__host__mainLeafId`,`res`.`host__treeRootId`  AS `res__host__treeRootId`,`res`.`host__nloose`  AS `res__host__nloose`,`res`.`host__x`  AS `res__host__x`,`res`.`host__y`  AS `res__host__y`,`res`.`host__z`  AS `res__host__z`,`res`.`host__vx`  AS `res__host__vx`,`res`.`host__vy`  AS `res__host__vy`,`res`.`host__vz`  AS `res__host__vz`,`res`.`host__np`  AS `res__host__np`,`res`.`host__mass`  AS `res__host__mass`,`res`.`host__size`  AS `res__host__size`,`res`.`host__spin`  AS `res__host__spin`,`res`.`host__ix`  AS `res__host__ix`,`res`.`host__iy`  AS `res__host__iy`,`res`.`host__iz`  AS `res__host__iz`,`res`.`host__phkey`  AS `res__host__phkey`
FROM ( SELECT `host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`
FROM `aggregation_tmp_95159485`    LIMIT 0,10) AS `res` WHERE (  `res`.`host__np` > 50 )   ;
CALL paquLinkTmp('aggregation_tmp_13857471');
CALL paquDropTmp('aggregation_tmp_95159485');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `res__host__fofSubId`,`res__host__fofId`,`res__host__level`,`res__host__NInFile`,`res__host__hostId`,`res__host__lastSubId`,`res__host__mainLeafId`,`res__host__treeRootId`,`res__host__nloose`,`res__host__x`,`res__host__y`,`res__host__z`,`res__host__vx`,`res__host__vy`,`res__host__vz`,`res__host__np`,`res__host__mass`,`res__host__size`,`res__host__spin`,`res__host__ix`,`res__host__iy`,`res__host__iz`,`res__host__phkey`
FROM `aggregation_tmp_13857471`   ;
CALL paquDropTmp('aggregation_tmp_13857471');
This is the query plan optimisation output for the query:
SELECT `res`.`host__fofSubId` as `res__host__fofSubId`,`res`.`host__fofId` as `res__host__fofId`,`res`.`host__level` as `res__host__level`,`res`.`host__NInFile` as `res__host__NInFile`,`res`.`host__hostId` as `res__host__hostId`,`res`.`host__lastSubId` as `res__host__lastSubId`,`res`.`host__mainLeafId` as `res__host__mainLeafId`,`res`.`host__treeRootId` as `res__host__treeRootId`,`res`.`host__nloose` as `res__host__nloose`,`res`.`host__x` as `res__host__x`,`res`.`host__y` as `res__host__y`,`res`.`host__z` as `res__host__z`,`res`.`host__vx` as `res__host__vx`,`res`.`host__vy` as `res__host__vy`,`res`.`host__vz` as `res__host__vz`,`res`.`host__np` as `res__host__np`,`res`.`host__mass` as `res__host__mass`,`res`.`host__size` as `res__host__size`,`res`.`host__spin` as `res__host__spin`,`res`.`host__ix` as `res__host__ix`,`res`.`host__iy` as `res__host__iy`,`res`.`host__iz` as `res__host__iz`,`res`.`host__phkey` as `res__host__phkey` FROM (SELECT `host`.fofSubId as `host__fofSubId`,`host`.fofId as `host__fofId`,`host`.level as `host__level`,`host`.NInFile as `host__NInFile`,`host`.hostId as `host__hostId`,`host`.lastSubId as `host__lastSubId`,`host`.mainLeafId as `host__mainLeafId`,`host`.treeRootId as `host__treeRootId`,`host`.nloose as `host__nloose`,`host`.x as `host__x`,`host`.y as `host__y`,`host`.z as `host__z`,`host`.vx as `host__vx`,`host`.vy as `host__vy`,`host`.vz as `host__vz`,`host`.np as `host__np`,`host`.mass as `host__mass`,`host`.size as `host__size`,`host`.spin as `host__spin`,`host`.ix as `host__ix`,`host`.iy as `host__iy`,`host`.iz as `host__iz`,`host`.phkey as `host__phkey` FROM MDR1.FOFSub host WHERE host.fofSubId = 85000000000000000 LIMIT 10) as res WHERE `res`.`host__np` > 50

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`host__fofSubId`=VALUES(`host__fofSubId`),
`host__fofId`=VALUES(`host__fofId`),
`host__level`=VALUES(`host__level`),
`host__NInFile`=VALUES(`host__NInFile`),
`host__hostId`=VALUES(`host__hostId`),
`host__lastSubId`=VALUES(`host__lastSubId`),
`host__mainLeafId`=VALUES(`host__mainLeafId`),
`host__treeRootId`=VALUES(`host__treeRootId`),
`host__nloose`=VALUES(`host__nloose`),
`host__x`=VALUES(`host__x`),
`host__y`=VALUES(`host__y`),
`host__z`=VALUES(`host__z`),
`host__vx`=VALUES(`host__vx`),
`host__vy`=VALUES(`host__vy`),
`host__vz`=VALUES(`host__vz`),
`host__np`=VALUES(`host__np`),
`host__mass`=VALUES(`host__mass`),
`host__size`=VALUES(`host__size`),
`host__spin`=VALUES(`host__spin`),
`host__ix`=VALUES(`host__ix`),
`host__iy`=VALUES(`host__iy`),
`host__iz`=VALUES(`host__iz`),
`host__phkey`=VALUES(`host__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `host`.fofSubId  AS `host__fofSubId`,`host`.fofId  AS `host__fofId`,`host`.level  AS `host__level`,`host`.NInFile  AS `host__NInFile`,`host`.hostId  AS `host__hostId`,`host`.lastSubId  AS `host__lastSubId`,`host`.mainLeafId  AS `host__mainLeafId`,`host`.treeRootId  AS `host__treeRootId`,`host`.nloose  AS `host__nloose`,`host`.x  AS `host__x`,`host`.y  AS `host__y`,`host`.z  AS `host__z`,`host`.vx  AS `host__vx`,`host`.vy  AS `host__vy`,`host`.vz  AS `host__vz`,`host`.np  AS `host__np`,`host`.mass  AS `host__mass`,`host`.size  AS `host__size`,`host`.spin  AS `host__spin`,`host`.ix  AS `host__ix`,`host`.iy  AS `host__iy`,`host`.iz  AS `host__iz`,`host`.phkey  AS `host__phkey`
FROM MDR1.FOFSub AS `host` WHERE (  host.fofSubId = 85000000000000000 )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`
FROM `aggregation_tmp_38838646`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`host__fofSubId`=VALUES(`host__fofSubId`),
`host__fofId`=VALUES(`host__fofId`),
`host__level`=VALUES(`host__level`),
`host__NInFile`=VALUES(`host__NInFile`),
`host__hostId`=VALUES(`host__hostId`),
`host__lastSubId`=VALUES(`host__lastSubId`),
`host__mainLeafId`=VALUES(`host__mainLeafId`),
`host__treeRootId`=VALUES(`host__treeRootId`),
`host__nloose`=VALUES(`host__nloose`),
`host__x`=VALUES(`host__x`),
`host__y`=VALUES(`host__y`),
`host__z`=VALUES(`host__z`),
`host__vx`=VALUES(`host__vx`),
`host__vy`=VALUES(`host__vy`),
`host__vz`=VALUES(`host__vz`),
`host__np`=VALUES(`host__np`),
`host__mass`=VALUES(`host__mass`),
`host__size`=VALUES(`host__size`),
`host__spin`=VALUES(`host__spin`),
`host__ix`=VALUES(`host__ix`),
`host__iy`=VALUES(`host__iy`),
`host__iz`=VALUES(`host__iz`),
`host__phkey`=VALUES(`host__phkey`)
-- INPUT SQL:
SELECT `res`.`host__fofSubId` as `res__host__fofSubId`,`res`.`host__fofId` as `res__host__fofId`,`res`.`host__level` as `res__host__level`,`res`.`host__NInFile` as `res__host__NInFile`,`res`.`host__hostId` as `res__host__hostId`,`res`.`host__lastSubId` as `res__host__lastSubId`,`res`.`host__mainLeafId` as `res__host__mainLeafId`,`res`.`host__treeRootId` as `res__host__treeRootId`,`res`.`host__nloose` as `res__host__nloose`,`res`.`host__x` as `res__host__x`,`res`.`host__y` as `res__host__y`,`res`.`host__z` as `res__host__z`,`res`.`host__vx` as `res__host__vx`,`res`.`host__vy` as `res__host__vy`,`res`.`host__vz` as `res__host__vz`,`res`.`host__np` as `res__host__np`,`res`.`host__mass` as `res__host__mass`,`res`.`host__size` as `res__host__size`,`res`.`host__spin` as `res__host__spin`,`res`.`host__ix` as `res__host__ix`,`res`.`host__iy` as `res__host__iy`,`res`.`host__iz` as `res__host__iz`,`res`.`host__phkey` as `res__host__phkey` FROM (SELECT `host`.fofSubId as `host__fofSubId`,`host`.fofId as `host__fofId`,`host`.level as `host__level`,`host`.NInFile as `host__NInFile`,`host`.hostId as `host__hostId`,`host`.lastSubId as `host__lastSubId`,`host`.mainLeafId as `host__mainLeafId`,`host`.treeRootId as `host__treeRootId`,`host`.nloose as `host__nloose`,`host`.x as `host__x`,`host`.y as `host__y`,`host`.z as `host__z`,`host`.vx as `host__vx`,`host`.vy as `host__vy`,`host`.vz as `host__vz`,`host`.np as `host__np`,`host`.mass as `host__mass`,`host`.size as `host__size`,`host`.spin as `host__spin`,`host`.ix as `host__ix`,`host`.iy as `host__iy`,`host`.iz as `host__iz`,`host`.phkey as `host__phkey` FROM MDR1.FOFSub host WHERE host.fofSubId = 85000000000000000 LIMIT 10) as res WHERE `res`.`host__np` > 50

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`res__host__fofSubId`,`res__host__fofId`,`res__host__level`,`res__host__NInFile`,`res__host__hostId`,`res__host__lastSubId`,`res__host__mainLeafId`,`res__host__treeRootId`,`res__host__nloose`,`res__host__x`,`res__host__y`,`res__host__z`,`res__host__vx`,`res__host__vy`,`res__host__vz`,`res__host__np`,`res__host__mass`,`res__host__size`,`res__host__spin`,`res__host__ix`,`res__host__iy`,`res__host__iz`,`res__host__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`res__host__fofSubId`=VALUES(`res__host__fofSubId`),
`res__host__fofId`=VALUES(`res__host__fofId`),
`res__host__level`=VALUES(`res__host__level`),
`res__host__NInFile`=VALUES(`res__host__NInFile`),
`res__host__hostId`=VALUES(`res__host__hostId`),
`res__host__lastSubId`=VALUES(`res__host__lastSubId`),
`res__host__mainLeafId`=VALUES(`res__host__mainLeafId`),
`res__host__treeRootId`=VALUES(`res__host__treeRootId`),
`res__host__nloose`=VALUES(`res__host__nloose`),
`res__host__x`=VALUES(`res__host__x`),
`res__host__y`=VALUES(`res__host__y`),
`res__host__z`=VALUES(`res__host__z`),
`res__host__vx`=VALUES(`res__host__vx`),
`res__host__vy`=VALUES(`res__host__vy`),
`res__host__vz`=VALUES(`res__host__vz`),
`res__host__np`=VALUES(`res__host__np`),
`res__host__mass`=VALUES(`res__host__mass`),
`res__host__size`=VALUES(`res__host__size`),
`res__host__spin`=VALUES(`res__host__spin`),
`res__host__ix`=VALUES(`res__host__ix`),
`res__host__iy`=VALUES(`res__host__iy`),
`res__host__iz`=VALUES(`res__host__iz`),
`res__host__phkey`=VALUES(`res__host__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `res`.`host__fofSubId`  AS `res__host__fofSubId`,`res`.`host__fofId`  AS `res__host__fofId`,`res`.`host__level`  AS `res__host__level`,`res`.`host__NInFile`  AS `res__host__NInFile`,`res`.`host__hostId`  AS `res__host__hostId`,`res`.`host__lastSubId`  AS `res__host__lastSubId`,`res`.`host__mainLeafId`  AS `res__host__mainLeafId`,`res`.`host__treeRootId`  AS `res__host__treeRootId`,`res`.`host__nloose`  AS `res__host__nloose`,`res`.`host__x`  AS `res__host__x`,`res`.`host__y`  AS `res__host__y`,`res`.`host__z`  AS `res__host__z`,`res`.`host__vx`  AS `res__host__vx`,`res`.`host__vy`  AS `res__host__vy`,`res`.`host__vz`  AS `res__host__vz`,`res`.`host__np`  AS `res__host__np`,`res`.`host__mass`  AS `res__host__mass`,`res`.`host__size`  AS `res__host__size`,`res`.`host__spin`  AS `res__host__spin`,`res`.`host__ix`  AS `res__host__ix`,`res`.`host__iy`  AS `res__host__iy`,`res`.`host__iz`  AS `res__host__iz`,`res`.`host__phkey`  AS `res__host__phkey`
FROM ( SELECT `host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`
FROM `aggregation_tmp_38838646`    LIMIT 0,10) AS `res` WHERE (  `res`.`host__np` > 50 )   
)


-- AGGREGATION SQL:
SELECT `res__host__fofSubId`,`res__host__fofId`,`res__host__level`,`res__host__NInFile`,`res__host__hostId`,`res__host__lastSubId`,`res__host__mainLeafId`,`res__host__treeRootId`,`res__host__nloose`,`res__host__x`,`res__host__y`,`res__host__z`,`res__host__vx`,`res__host__vy`,`res__host__vz`,`res__host__np`,`res__host__mass`,`res__host__size`,`res__host__spin`,`res__host__ix`,`res__host__iy`,`res__host__iz`,`res__host__phkey`
FROM `aggregation_tmp_75853321`   
ON DUPLICATE KEY UPDATE
`res__host__fofSubId`=VALUES(`res__host__fofSubId`),
`res__host__fofId`=VALUES(`res__host__fofId`),
`res__host__level`=VALUES(`res__host__level`),
`res__host__NInFile`=VALUES(`res__host__NInFile`),
`res__host__hostId`=VALUES(`res__host__hostId`),
`res__host__lastSubId`=VALUES(`res__host__lastSubId`),
`res__host__mainLeafId`=VALUES(`res__host__mainLeafId`),
`res__host__treeRootId`=VALUES(`res__host__treeRootId`),
`res__host__nloose`=VALUES(`res__host__nloose`),
`res__host__x`=VALUES(`res__host__x`),
`res__host__y`=VALUES(`res__host__y`),
`res__host__z`=VALUES(`res__host__z`),
`res__host__vx`=VALUES(`res__host__vx`),
`res__host__vy`=VALUES(`res__host__vy`),
`res__host__vz`=VALUES(`res__host__vz`),
`res__host__np`=VALUES(`res__host__np`),
`res__host__mass`=VALUES(`res__host__mass`),
`res__host__size`=VALUES(`res__host__size`),
`res__host__spin`=VALUES(`res__host__spin`),
`res__host__ix`=VALUES(`res__host__ix`),
`res__host__iy`=VALUES(`res__host__iy`),
`res__host__iz`=VALUES(`res__host__iz`),
`res__host__phkey`=VALUES(`res__host__phkey`)
This is the query plan for the query:
SELECT `res`.`host__fofSubId` as `res__host__fofSubId`,`res`.`host__fofId` as `res__host__fofId`,`res`.`host__level` as `res__host__level`,`res`.`host__NInFile` as `res__host__NInFile`,`res`.`host__hostId` as `res__host__hostId`,`res`.`host__lastSubId` as `res__host__lastSubId`,`res`.`host__mainLeafId` as `res__host__mainLeafId`,`res`.`host__treeRootId` as `res__host__treeRootId`,`res`.`host__nloose` as `res__host__nloose`,`res`.`host__x` as `res__host__x`,`res`.`host__y` as `res__host__y`,`res`.`host__z` as `res__host__z`,`res`.`host__vx` as `res__host__vx`,`res`.`host__vy` as `res__host__vy`,`res`.`host__vz` as `res__host__vz`,`res`.`host__np` as `res__host__np`,`res`.`host__mass` as `res__host__mass`,`res`.`host__size` as `res__host__size`,`res`.`host__spin` as `res__host__spin`,`res`.`host__ix` as `res__host__ix`,`res`.`host__iy` as `res__host__iy`,`res`.`host__iz` as `res__host__iz`,`res`.`host__phkey` as `res__host__phkey` FROM (SELECT `host`.fofSubId as `host__fofSubId`,`host`.fofId as `host__fofId`,`host`.level as `host__level`,`host`.NInFile as `host__NInFile`,`host`.hostId as `host__hostId`,`host`.lastSubId as `host__lastSubId`,`host`.mainLeafId as `host__mainLeafId`,`host`.treeRootId as `host__treeRootId`,`host`.nloose as `host__nloose`,`host`.x as `host__x`,`host`.y as `host__y`,`host`.z as `host__z`,`host`.vx as `host__vx`,`host`.vy as `host__vy`,`host`.vz as `host__vz`,`host`.np as `host__np`,`host`.mass as `host__mass`,`host`.size as `host__size`,`host`.spin as `host__spin`,`host`.ix as `host__ix`,`host`.iy as `host__iy`,`host`.iz as `host__iz`,`host`.phkey as `host__phkey` FROM MDR1.FOFSub host WHERE host.fofSubId = 85000000000000000 LIMIT 10) as res WHERE `res`.`host__np` > 50

CALL paquExec('SELECT `host`.fofSubId  AS `host__fofSubId`,`host`.fofId  AS `host__fofId`,`host`.level  AS `host__level`,`host`.NInFile  AS `host__NInFile`,`host`.hostId  AS `host__hostId`,`host`.lastSubId  AS `host__lastSubId`,`host`.mainLeafId  AS `host__mainLeafId`,`host`.treeRootId  AS `host__treeRootId`,`host`.nloose  AS `host__nloose`,`host`.x  AS `host__x`,`host`.y  AS `host__y`,`host`.z  AS `host__z`,`host`.vx  AS `host__vx`,`host`.vy  AS `host__vy`,`host`.vz  AS `host__vz`,`host`.np  AS `host__np`,`host`.mass  AS `host__mass`,`host`.size  AS `host__size`,`host`.spin  AS `host__spin`,`host`.ix  AS `host__ix`,`host`.iy  AS `host__iy`,`host`.iz  AS `host__iz`,`host`.phkey  AS `host__phkey` FROM MDR1.FOFSub AS `host` WHERE (  host.fofSubId = 85000000000000000 )    LIMIT 0,10', 'aggregation_tmp_38838646');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_75853321 ENGINE=MyISAM SELECT `res`.`host__fofSubId`  AS `res__host__fofSubId`,`res`.`host__fofId`  AS `res__host__fofId`,`res`.`host__level`  AS `res__host__level`,`res`.`host__NInFile`  AS `res__host__NInFile`,`res`.`host__hostId`  AS `res__host__hostId`,`res`.`host__lastSubId`  AS `res__host__lastSubId`,`res`.`host__mainLeafId`  AS `res__host__mainLeafId`,`res`.`host__treeRootId`  AS `res__host__treeRootId`,`res`.`host__nloose`  AS `res__host__nloose`,`res`.`host__x`  AS `res__host__x`,`res`.`host__y`  AS `res__host__y`,`res`.`host__z`  AS `res__host__z`,`res`.`host__vx`  AS `res__host__vx`,`res`.`host__vy`  AS `res__host__vy`,`res`.`host__vz`  AS `res__host__vz`,`res`.`host__np`  AS `res__host__np`,`res`.`host__mass`  AS `res__host__mass`,`res`.`host__size`  AS `res__host__size`,`res`.`host__spin`  AS `res__host__spin`,`res`.`host__ix`  AS `res__host__ix`,`res`.`host__iy`  AS `res__host__iy`,`res`.`host__iz`  AS `res__host__iz`,`res`.`host__phkey`  AS `res__host__phkey`
FROM ( SELECT `host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`
FROM `aggregation_tmp_38838646`     LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_75853321 SELECT `res`.`host__fofSubId`  AS `res__host__fofSubId`,`res`.`host__fofId`  AS `res__host__fofId`,`res`.`host__level`  AS `res__host__level`,`res`.`host__NInFile`  AS `res__host__NInFile`,`res`.`host__hostId`  AS `res__host__hostId`,`res`.`host__lastSubId`  AS `res__host__lastSubId`,`res`.`host__mainLeafId`  AS `res__host__mainLeafId`,`res`.`host__treeRootId`  AS `res__host__treeRootId`,`res`.`host__nloose`  AS `res__host__nloose`,`res`.`host__x`  AS `res__host__x`,`res`.`host__y`  AS `res__host__y`,`res`.`host__z`  AS `res__host__z`,`res`.`host__vx`  AS `res__host__vx`,`res`.`host__vy`  AS `res__host__vy`,`res`.`host__vz`  AS `res__host__vz`,`res`.`host__np`  AS `res__host__np`,`res`.`host__mass`  AS `res__host__mass`,`res`.`host__size`  AS `res__host__size`,`res`.`host__spin`  AS `res__host__spin`,`res`.`host__ix`  AS `res__host__ix`,`res`.`host__iy`  AS `res__host__iy`,`res`.`host__iz`  AS `res__host__iz`,`res`.`host__phkey`  AS `res__host__phkey`
FROM ( SELECT `host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`
FROM `aggregation_tmp_38838646`    LIMIT 0,10) AS `res` WHERE (  `res`.`host__np` > 50 )   ;
CALL paquLinkTmp('aggregation_tmp_75853321');
CALL paquDropTmp('aggregation_tmp_38838646');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `res__host__fofSubId`,`res__host__fofId`,`res__host__level`,`res__host__NInFile`,`res__host__hostId`,`res__host__lastSubId`,`res__host__mainLeafId`,`res__host__treeRootId`,`res__host__nloose`,`res__host__x`,`res__host__y`,`res__host__z`,`res__host__vx`,`res__host__vy`,`res__host__vz`,`res__host__np`,`res__host__mass`,`res__host__size`,`res__host__spin`,`res__host__ix`,`res__host__iy`,`res__host__iz`,`res__host__phkey`
FROM `aggregation_tmp_75853321`   ;
CALL paquDropTmp('aggregation_tmp_75853321');
This is the query plan optimisation output for the query:
SELECT `res`.`host__fofSubId` as `res__host__fofSubId`,`res`.`host__fofId` as `res__host__fofId`,`res`.`host__level` as `res__host__level`,`res`.`host__NInFile` as `res__host__NInFile`,`res`.`host__hostId` as `res__host__hostId`,`res`.`host__lastSubId` as `res__host__lastSubId`,`res`.`host__mainLeafId` as `res__host__mainLeafId`,`res`.`host__treeRootId` as `res__host__treeRootId`,`res`.`host__nloose` as `res__host__nloose`,`res`.`host__x` as `res__host__x`,`res`.`host__y` as `res__host__y`,`res`.`host__z` as `res__host__z`,`res`.`host__vx` as `res__host__vx`,`res`.`host__vy` as `res__host__vy`,`res`.`host__vz` as `res__host__vz`,`res`.`host__np` as `res__host__np`,`res`.`host__mass` as `res__host__mass`,`res`.`host__size` as `res__host__size`,`res`.`host__spin` as `res__host__spin`,`res`.`host__ix` as `res__host__ix`,`res`.`host__iy` as `res__host__iy`,`res`.`host__iz` as `res__host__iz`,`res`.`host__phkey` as `res__host__phkey` FROM (SELECT `host`.fofSubId as `host__fofSubId`,`host`.fofId as `host__fofId`,`host`.level as `host__level`,`host`.NInFile as `host__NInFile`,`host`.hostId as `host__hostId`,`host`.lastSubId as `host__lastSubId`,`host`.mainLeafId as `host__mainLeafId`,`host`.treeRootId as `host__treeRootId`,`host`.nloose as `host__nloose`,`host`.x as `host__x`,`host`.y as `host__y`,`host`.z as `host__z`,`host`.vx as `host__vx`,`host`.vy as `host__vy`,`host`.vz as `host__vz`,`host`.np as `host__np`,`host`.mass as `host__mass`,`host`.size as `host__size`,`host`.spin as `host__spin`,`host`.ix as `host__ix`,`host`.iy as `host__iy`,`host`.iz as `host__iz`,`host`.phkey as `host__phkey` FROM MDR1.FOFSub host WHERE host.fofSubId = 85000000000000000 LIMIT 10) as res WHERE `res`.`host__np` > 50

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`host__fofSubId`=VALUES(`host__fofSubId`),
`host__fofId`=VALUES(`host__fofId`),
`host__level`=VALUES(`host__level`),
`host__NInFile`=VALUES(`host__NInFile`),
`host__hostId`=VALUES(`host__hostId`),
`host__lastSubId`=VALUES(`host__lastSubId`),
`host__mainLeafId`=VALUES(`host__mainLeafId`),
`host__treeRootId`=VALUES(`host__treeRootId`),
`host__nloose`=VALUES(`host__nloose`),
`host__x`=VALUES(`host__x`),
`host__y`=VALUES(`host__y`),
`host__z`=VALUES(`host__z`),
`host__vx`=VALUES(`host__vx`),
`host__vy`=VALUES(`host__vy`),
`host__vz`=VALUES(`host__vz`),
`host__np`=VALUES(`host__np`),
`host__mass`=VALUES(`host__mass`),
`host__size`=VALUES(`host__size`),
`host__spin`=VALUES(`host__spin`),
`host__ix`=VALUES(`host__ix`),
`host__iy`=VALUES(`host__iy`),
`host__iz`=VALUES(`host__iz`),
`host__phkey`=VALUES(`host__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `host`.fofSubId  AS `host__fofSubId`,`host`.fofId  AS `host__fofId`,`host`.level  AS `host__level`,`host`.NInFile  AS `host__NInFile`,`host`.hostId  AS `host__hostId`,`host`.lastSubId  AS `host__lastSubId`,`host`.mainLeafId  AS `host__mainLeafId`,`host`.treeRootId  AS `host__treeRootId`,`host`.nloose  AS `host__nloose`,`host`.x  AS `host__x`,`host`.y  AS `host__y`,`host`.z  AS `host__z`,`host`.vx  AS `host__vx`,`host`.vy  AS `host__vy`,`host`.vz  AS `host__vz`,`host`.np  AS `host__np`,`host`.mass  AS `host__mass`,`host`.size  AS `host__size`,`host`.spin  AS `host__spin`,`host`.ix  AS `host__ix`,`host`.iy  AS `host__iy`,`host`.iz  AS `host__iz`,`host`.phkey  AS `host__phkey`
FROM MDR1.FOFSub AS `host` WHERE (  host.fofSubId = 85000000000000000 )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`
FROM `aggregation_tmp_13580227`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`host__fofSubId`=VALUES(`host__fofSubId`),
`host__fofId`=VALUES(`host__fofId`),
`host__level`=VALUES(`host__level`),
`host__NInFile`=VALUES(`host__NInFile`),
`host__hostId`=VALUES(`host__hostId`),
`host__lastSubId`=VALUES(`host__lastSubId`),
`host__mainLeafId`=VALUES(`host__mainLeafId`),
`host__treeRootId`=VALUES(`host__treeRootId`),
`host__nloose`=VALUES(`host__nloose`),
`host__x`=VALUES(`host__x`),
`host__y`=VALUES(`host__y`),
`host__z`=VALUES(`host__z`),
`host__vx`=VALUES(`host__vx`),
`host__vy`=VALUES(`host__vy`),
`host__vz`=VALUES(`host__vz`),
`host__np`=VALUES(`host__np`),
`host__mass`=VALUES(`host__mass`),
`host__size`=VALUES(`host__size`),
`host__spin`=VALUES(`host__spin`),
`host__ix`=VALUES(`host__ix`),
`host__iy`=VALUES(`host__iy`),
`host__iz`=VALUES(`host__iz`),
`host__phkey`=VALUES(`host__phkey`)
-- INPUT SQL:
SELECT `res`.`host__fofSubId` as `res__host__fofSubId`,`res`.`host__fofId` as `res__host__fofId`,`res`.`host__level` as `res__host__level`,`res`.`host__NInFile` as `res__host__NInFile`,`res`.`host__hostId` as `res__host__hostId`,`res`.`host__lastSubId` as `res__host__lastSubId`,`res`.`host__mainLeafId` as `res__host__mainLeafId`,`res`.`host__treeRootId` as `res__host__treeRootId`,`res`.`host__nloose` as `res__host__nloose`,`res`.`host__x` as `res__host__x`,`res`.`host__y` as `res__host__y`,`res`.`host__z` as `res__host__z`,`res`.`host__vx` as `res__host__vx`,`res`.`host__vy` as `res__host__vy`,`res`.`host__vz` as `res__host__vz`,`res`.`host__np` as `res__host__np`,`res`.`host__mass` as `res__host__mass`,`res`.`host__size` as `res__host__size`,`res`.`host__spin` as `res__host__spin`,`res`.`host__ix` as `res__host__ix`,`res`.`host__iy` as `res__host__iy`,`res`.`host__iz` as `res__host__iz`,`res`.`host__phkey` as `res__host__phkey` FROM (SELECT `host`.fofSubId as `host__fofSubId`,`host`.fofId as `host__fofId`,`host`.level as `host__level`,`host`.NInFile as `host__NInFile`,`host`.hostId as `host__hostId`,`host`.lastSubId as `host__lastSubId`,`host`.mainLeafId as `host__mainLeafId`,`host`.treeRootId as `host__treeRootId`,`host`.nloose as `host__nloose`,`host`.x as `host__x`,`host`.y as `host__y`,`host`.z as `host__z`,`host`.vx as `host__vx`,`host`.vy as `host__vy`,`host`.vz as `host__vz`,`host`.np as `host__np`,`host`.mass as `host__mass`,`host`.size as `host__size`,`host`.spin as `host__spin`,`host`.ix as `host__ix`,`host`.iy as `host__iy`,`host`.iz as `host__iz`,`host`.phkey as `host__phkey` FROM MDR1.FOFSub host WHERE host.fofSubId = 85000000000000000 LIMIT 10) as res WHERE `res`.`host__np` > 50

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`res__host__fofSubId`,`res__host__fofId`,`res__host__level`,`res__host__NInFile`,`res__host__hostId`,`res__host__lastSubId`,`res__host__mainLeafId`,`res__host__treeRootId`,`res__host__nloose`,`res__host__x`,`res__host__y`,`res__host__z`,`res__host__vx`,`res__host__vy`,`res__host__vz`,`res__host__np`,`res__host__mass`,`res__host__size`,`res__host__spin`,`res__host__ix`,`res__host__iy`,`res__host__iz`,`res__host__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`res__host__fofSubId`=VALUES(`res__host__fofSubId`),
`res__host__fofId`=VALUES(`res__host__fofId`),
`res__host__level`=VALUES(`res__host__level`),
`res__host__NInFile`=VALUES(`res__host__NInFile`),
`res__host__hostId`=VALUES(`res__host__hostId`),
`res__host__lastSubId`=VALUES(`res__host__lastSubId`),
`res__host__mainLeafId`=VALUES(`res__host__mainLeafId`),
`res__host__treeRootId`=VALUES(`res__host__treeRootId`),
`res__host__nloose`=VALUES(`res__host__nloose`),
`res__host__x`=VALUES(`res__host__x`),
`res__host__y`=VALUES(`res__host__y`),
`res__host__z`=VALUES(`res__host__z`),
`res__host__vx`=VALUES(`res__host__vx`),
`res__host__vy`=VALUES(`res__host__vy`),
`res__host__vz`=VALUES(`res__host__vz`),
`res__host__np`=VALUES(`res__host__np`),
`res__host__mass`=VALUES(`res__host__mass`),
`res__host__size`=VALUES(`res__host__size`),
`res__host__spin`=VALUES(`res__host__spin`),
`res__host__ix`=VALUES(`res__host__ix`),
`res__host__iy`=VALUES(`res__host__iy`),
`res__host__iz`=VALUES(`res__host__iz`),
`res__host__phkey`=VALUES(`res__host__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `res`.`host__fofSubId`  AS `res__host__fofSubId`,`res`.`host__fofId`  AS `res__host__fofId`,`res`.`host__level`  AS `res__host__level`,`res`.`host__NInFile`  AS `res__host__NInFile`,`res`.`host__hostId`  AS `res__host__hostId`,`res`.`host__lastSubId`  AS `res__host__lastSubId`,`res`.`host__mainLeafId`  AS `res__host__mainLeafId`,`res`.`host__treeRootId`  AS `res__host__treeRootId`,`res`.`host__nloose`  AS `res__host__nloose`,`res`.`host__x`  AS `res__host__x`,`res`.`host__y`  AS `res__host__y`,`res`.`host__z`  AS `res__host__z`,`res`.`host__vx`  AS `res__host__vx`,`res`.`host__vy`  AS `res__host__vy`,`res`.`host__vz`  AS `res__host__vz`,`res`.`host__np`  AS `res__host__np`,`res`.`host__mass`  AS `res__host__mass`,`res`.`host__size`  AS `res__host__size`,`res`.`host__spin`  AS `res__host__spin`,`res`.`host__ix`  AS `res__host__ix`,`res`.`host__iy`  AS `res__host__iy`,`res`.`host__iz`  AS `res__host__iz`,`res`.`host__phkey`  AS `res__host__phkey`
FROM ( SELECT `host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`
FROM `aggregation_tmp_13580227`    LIMIT 0,10) AS `res` WHERE (  `res`.`host__np` > 50 )   
)


-- AGGREGATION SQL:
SELECT `res__host__fofSubId`,`res__host__fofId`,`res__host__level`,`res__host__NInFile`,`res__host__hostId`,`res__host__lastSubId`,`res__host__mainLeafId`,`res__host__treeRootId`,`res__host__nloose`,`res__host__x`,`res__host__y`,`res__host__z`,`res__host__vx`,`res__host__vy`,`res__host__vz`,`res__host__np`,`res__host__mass`,`res__host__size`,`res__host__spin`,`res__host__ix`,`res__host__iy`,`res__host__iz`,`res__host__phkey`
FROM `aggregation_tmp_62007248`   
ON DUPLICATE KEY UPDATE
`res__host__fofSubId`=VALUES(`res__host__fofSubId`),
`res__host__fofId`=VALUES(`res__host__fofId`),
`res__host__level`=VALUES(`res__host__level`),
`res__host__NInFile`=VALUES(`res__host__NInFile`),
`res__host__hostId`=VALUES(`res__host__hostId`),
`res__host__lastSubId`=VALUES(`res__host__lastSubId`),
`res__host__mainLeafId`=VALUES(`res__host__mainLeafId`),
`res__host__treeRootId`=VALUES(`res__host__treeRootId`),
`res__host__nloose`=VALUES(`res__host__nloose`),
`res__host__x`=VALUES(`res__host__x`),
`res__host__y`=VALUES(`res__host__y`),
`res__host__z`=VALUES(`res__host__z`),
`res__host__vx`=VALUES(`res__host__vx`),
`res__host__vy`=VALUES(`res__host__vy`),
`res__host__vz`=VALUES(`res__host__vz`),
`res__host__np`=VALUES(`res__host__np`),
`res__host__mass`=VALUES(`res__host__mass`),
`res__host__size`=VALUES(`res__host__size`),
`res__host__spin`=VALUES(`res__host__spin`),
`res__host__ix`=VALUES(`res__host__ix`),
`res__host__iy`=VALUES(`res__host__iy`),
`res__host__iz`=VALUES(`res__host__iz`),
`res__host__phkey`=VALUES(`res__host__phkey`)
This is the query plan for the query:
SELECT `res`.`host__fofSubId` as `res__host__fofSubId`,`res`.`host__fofId` as `res__host__fofId`,`res`.`host__level` as `res__host__level`,`res`.`host__NInFile` as `res__host__NInFile`,`res`.`host__hostId` as `res__host__hostId`,`res`.`host__lastSubId` as `res__host__lastSubId`,`res`.`host__mainLeafId` as `res__host__mainLeafId`,`res`.`host__treeRootId` as `res__host__treeRootId`,`res`.`host__nloose` as `res__host__nloose`,`res`.`host__x` as `res__host__x`,`res`.`host__y` as `res__host__y`,`res`.`host__z` as `res__host__z`,`res`.`host__vx` as `res__host__vx`,`res`.`host__vy` as `res__host__vy`,`res`.`host__vz` as `res__host__vz`,`res`.`host__np` as `res__host__np`,`res`.`host__mass` as `res__host__mass`,`res`.`host__size` as `res__host__size`,`res`.`host__spin` as `res__host__spin`,`res`.`host__ix` as `res__host__ix`,`res`.`host__iy` as `res__host__iy`,`res`.`host__iz` as `res__host__iz`,`res`.`host__phkey` as `res__host__phkey` FROM (SELECT `host`.fofSubId as `host__fofSubId`,`host`.fofId as `host__fofId`,`host`.level as `host__level`,`host`.NInFile as `host__NInFile`,`host`.hostId as `host__hostId`,`host`.lastSubId as `host__lastSubId`,`host`.mainLeafId as `host__mainLeafId`,`host`.treeRootId as `host__treeRootId`,`host`.nloose as `host__nloose`,`host`.x as `host__x`,`host`.y as `host__y`,`host`.z as `host__z`,`host`.vx as `host__vx`,`host`.vy as `host__vy`,`host`.vz as `host__vz`,`host`.np as `host__np`,`host`.mass as `host__mass`,`host`.size as `host__size`,`host`.spin as `host__spin`,`host`.ix as `host__ix`,`host`.iy as `host__iy`,`host`.iz as `host__iz`,`host`.phkey as `host__phkey` FROM MDR1.FOFSub host WHERE host.fofSubId = 85000000000000000 LIMIT 10) as res WHERE `res`.`host__np` > 50

CALL paquExec('SELECT `host`.fofSubId  AS `host__fofSubId`,`host`.fofId  AS `host__fofId`,`host`.level  AS `host__level`,`host`.NInFile  AS `host__NInFile`,`host`.hostId  AS `host__hostId`,`host`.lastSubId  AS `host__lastSubId`,`host`.mainLeafId  AS `host__mainLeafId`,`host`.treeRootId  AS `host__treeRootId`,`host`.nloose  AS `host__nloose`,`host`.x  AS `host__x`,`host`.y  AS `host__y`,`host`.z  AS `host__z`,`host`.vx  AS `host__vx`,`host`.vy  AS `host__vy`,`host`.vz  AS `host__vz`,`host`.np  AS `host__np`,`host`.mass  AS `host__mass`,`host`.size  AS `host__size`,`host`.spin  AS `host__spin`,`host`.ix  AS `host__ix`,`host`.iy  AS `host__iy`,`host`.iz  AS `host__iz`,`host`.phkey  AS `host__phkey` FROM MDR1.FOFSub AS `host` WHERE (  host.fofSubId = 85000000000000000 )    LIMIT 0,10', 'aggregation_tmp_13580227');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_62007248 ENGINE=MyISAM SELECT `res`.`host__fofSubId`  AS `res__host__fofSubId`,`res`.`host__fofId`  AS `res__host__fofId`,`res`.`host__level`  AS `res__host__level`,`res`.`host__NInFile`  AS `res__host__NInFile`,`res`.`host__hostId`  AS `res__host__hostId`,`res`.`host__lastSubId`  AS `res__host__lastSubId`,`res`.`host__mainLeafId`  AS `res__host__mainLeafId`,`res`.`host__treeRootId`  AS `res__host__treeRootId`,`res`.`host__nloose`  AS `res__host__nloose`,`res`.`host__x`  AS `res__host__x`,`res`.`host__y`  AS `res__host__y`,`res`.`host__z`  AS `res__host__z`,`res`.`host__vx`  AS `res__host__vx`,`res`.`host__vy`  AS `res__host__vy`,`res`.`host__vz`  AS `res__host__vz`,`res`.`host__np`  AS `res__host__np`,`res`.`host__mass`  AS `res__host__mass`,`res`.`host__size`  AS `res__host__size`,`res`.`host__spin`  AS `res__host__spin`,`res`.`host__ix`  AS `res__host__ix`,`res`.`host__iy`  AS `res__host__iy`,`res`.`host__iz`  AS `res__host__iz`,`res`.`host__phkey`  AS `res__host__phkey`
FROM ( SELECT `host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`
FROM `aggregation_tmp_13580227`     LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_62007248 SELECT `res`.`host__fofSubId`  AS `res__host__fofSubId`,`res`.`host__fofId`  AS `res__host__fofId`,`res`.`host__level`  AS `res__host__level`,`res`.`host__NInFile`  AS `res__host__NInFile`,`res`.`host__hostId`  AS `res__host__hostId`,`res`.`host__lastSubId`  AS `res__host__lastSubId`,`res`.`host__mainLeafId`  AS `res__host__mainLeafId`,`res`.`host__treeRootId`  AS `res__host__treeRootId`,`res`.`host__nloose`  AS `res__host__nloose`,`res`.`host__x`  AS `res__host__x`,`res`.`host__y`  AS `res__host__y`,`res`.`host__z`  AS `res__host__z`,`res`.`host__vx`  AS `res__host__vx`,`res`.`host__vy`  AS `res__host__vy`,`res`.`host__vz`  AS `res__host__vz`,`res`.`host__np`  AS `res__host__np`,`res`.`host__mass`  AS `res__host__mass`,`res`.`host__size`  AS `res__host__size`,`res`.`host__spin`  AS `res__host__spin`,`res`.`host__ix`  AS `res__host__ix`,`res`.`host__iy`  AS `res__host__iy`,`res`.`host__iz`  AS `res__host__iz`,`res`.`host__phkey`  AS `res__host__phkey`
FROM ( SELECT `host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`
FROM `aggregation_tmp_13580227`    LIMIT 0,10) AS `res` WHERE (  `res`.`host__np` > 50 )   ;
CALL paquLinkTmp('aggregation_tmp_62007248');
CALL paquDropTmp('aggregation_tmp_13580227');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `res__host__fofSubId`,`res__host__fofId`,`res__host__level`,`res__host__NInFile`,`res__host__hostId`,`res__host__lastSubId`,`res__host__mainLeafId`,`res__host__treeRootId`,`res__host__nloose`,`res__host__x`,`res__host__y`,`res__host__z`,`res__host__vx`,`res__host__vy`,`res__host__vz`,`res__host__np`,`res__host__mass`,`res__host__size`,`res__host__spin`,`res__host__ix`,`res__host__iy`,`res__host__iz`,`res__host__phkey`
FROM `aggregation_tmp_62007248`   ;
CALL paquDropTmp('aggregation_tmp_62007248');
This is the query plan optimisation output for the query:
SELECT `res`.`host__fofSubId` as `res__host__fofSubId`,`res`.`host__fofId` as `res__host__fofId`,`res`.`host__level` as `res__host__level`,`res`.`host__NInFile` as `res__host__NInFile`,`res`.`host__hostId` as `res__host__hostId`,`res`.`host__lastSubId` as `res__host__lastSubId`,`res`.`host__mainLeafId` as `res__host__mainLeafId`,`res`.`host__treeRootId` as `res__host__treeRootId`,`res`.`host__nloose` as `res__host__nloose`,`res`.`host__x` as `res__host__x`,`res`.`host__y` as `res__host__y`,`res`.`host__z` as `res__host__z`,`res`.`host__vx` as `res__host__vx`,`res`.`host__vy` as `res__host__vy`,`res`.`host__vz` as `res__host__vz`,`res`.`host__np` as `res__host__np`,`res`.`host__mass` as `res__host__mass`,`res`.`host__size` as `res__host__size`,`res`.`host__spin` as `res__host__spin`,`res`.`host__ix` as `res__host__ix`,`res`.`host__iy` as `res__host__iy`,`res`.`host__iz` as `res__host__iz`,`res`.`host__phkey` as `res__host__phkey` FROM (SELECT `host`.fofSubId as `host__fofSubId`,`host`.fofId as `host__fofId`,`host`.level as `host__level`,`host`.NInFile as `host__NInFile`,`host`.hostId as `host__hostId`,`host`.lastSubId as `host__lastSubId`,`host`.mainLeafId as `host__mainLeafId`,`host`.treeRootId as `host__treeRootId`,`host`.nloose as `host__nloose`,`host`.x as `host__x`,`host`.y as `host__y`,`host`.z as `host__z`,`host`.vx as `host__vx`,`host`.vy as `host__vy`,`host`.vz as `host__vz`,`host`.np as `host__np`,`host`.mass as `host__mass`,`host`.size as `host__size`,`host`.spin as `host__spin`,`host`.ix as `host__ix`,`host`.iy as `host__iy`,`host`.iz as `host__iz`,`host`.phkey as `host__phkey` FROM MDR1.FOFSub host WHERE host.fofSubId = 85000000000000000 LIMIT 10) as res WHERE `res`.`host__np` > 50

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`host__fofSubId`=VALUES(`host__fofSubId`),
`host__fofId`=VALUES(`host__fofId`),
`host__level`=VALUES(`host__level`),
`host__NInFile`=VALUES(`host__NInFile`),
`host__hostId`=VALUES(`host__hostId`),
`host__lastSubId`=VALUES(`host__lastSubId`),
`host__mainLeafId`=VALUES(`host__mainLeafId`),
`host__treeRootId`=VALUES(`host__treeRootId`),
`host__nloose`=VALUES(`host__nloose`),
`host__x`=VALUES(`host__x`),
`host__y`=VALUES(`host__y`),
`host__z`=VALUES(`host__z`),
`host__vx`=VALUES(`host__vx`),
`host__vy`=VALUES(`host__vy`),
`host__vz`=VALUES(`host__vz`),
`host__np`=VALUES(`host__np`),
`host__mass`=VALUES(`host__mass`),
`host__size`=VALUES(`host__size`),
`host__spin`=VALUES(`host__spin`),
`host__ix`=VALUES(`host__ix`),
`host__iy`=VALUES(`host__iy`),
`host__iz`=VALUES(`host__iz`),
`host__phkey`=VALUES(`host__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `host`.fofSubId  AS `host__fofSubId`,`host`.fofId  AS `host__fofId`,`host`.level  AS `host__level`,`host`.NInFile  AS `host__NInFile`,`host`.hostId  AS `host__hostId`,`host`.lastSubId  AS `host__lastSubId`,`host`.mainLeafId  AS `host__mainLeafId`,`host`.treeRootId  AS `host__treeRootId`,`host`.nloose  AS `host__nloose`,`host`.x  AS `host__x`,`host`.y  AS `host__y`,`host`.z  AS `host__z`,`host`.vx  AS `host__vx`,`host`.vy  AS `host__vy`,`host`.vz  AS `host__vz`,`host`.np  AS `host__np`,`host`.mass  AS `host__mass`,`host`.size  AS `host__size`,`host`.spin  AS `host__spin`,`host`.ix  AS `host__ix`,`host`.iy  AS `host__iy`,`host`.iz  AS `host__iz`,`host`.phkey  AS `host__phkey`
FROM MDR1.FOFSub AS `host` WHERE (  host.fofSubId = 85000000000000000 )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`
FROM `aggregation_tmp_25761417`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`host__fofSubId`=VALUES(`host__fofSubId`),
`host__fofId`=VALUES(`host__fofId`),
`host__level`=VALUES(`host__level`),
`host__NInFile`=VALUES(`host__NInFile`),
`host__hostId`=VALUES(`host__hostId`),
`host__lastSubId`=VALUES(`host__lastSubId`),
`host__mainLeafId`=VALUES(`host__mainLeafId`),
`host__treeRootId`=VALUES(`host__treeRootId`),
`host__nloose`=VALUES(`host__nloose`),
`host__x`=VALUES(`host__x`),
`host__y`=VALUES(`host__y`),
`host__z`=VALUES(`host__z`),
`host__vx`=VALUES(`host__vx`),
`host__vy`=VALUES(`host__vy`),
`host__vz`=VALUES(`host__vz`),
`host__np`=VALUES(`host__np`),
`host__mass`=VALUES(`host__mass`),
`host__size`=VALUES(`host__size`),
`host__spin`=VALUES(`host__spin`),
`host__ix`=VALUES(`host__ix`),
`host__iy`=VALUES(`host__iy`),
`host__iz`=VALUES(`host__iz`),
`host__phkey`=VALUES(`host__phkey`)
-- INPUT SQL:
SELECT `res`.`host__fofSubId` as `res__host__fofSubId`,`res`.`host__fofId` as `res__host__fofId`,`res`.`host__level` as `res__host__level`,`res`.`host__NInFile` as `res__host__NInFile`,`res`.`host__hostId` as `res__host__hostId`,`res`.`host__lastSubId` as `res__host__lastSubId`,`res`.`host__mainLeafId` as `res__host__mainLeafId`,`res`.`host__treeRootId` as `res__host__treeRootId`,`res`.`host__nloose` as `res__host__nloose`,`res`.`host__x` as `res__host__x`,`res`.`host__y` as `res__host__y`,`res`.`host__z` as `res__host__z`,`res`.`host__vx` as `res__host__vx`,`res`.`host__vy` as `res__host__vy`,`res`.`host__vz` as `res__host__vz`,`res`.`host__np` as `res__host__np`,`res`.`host__mass` as `res__host__mass`,`res`.`host__size` as `res__host__size`,`res`.`host__spin` as `res__host__spin`,`res`.`host__ix` as `res__host__ix`,`res`.`host__iy` as `res__host__iy`,`res`.`host__iz` as `res__host__iz`,`res`.`host__phkey` as `res__host__phkey` FROM (SELECT `host`.fofSubId as `host__fofSubId`,`host`.fofId as `host__fofId`,`host`.level as `host__level`,`host`.NInFile as `host__NInFile`,`host`.hostId as `host__hostId`,`host`.lastSubId as `host__lastSubId`,`host`.mainLeafId as `host__mainLeafId`,`host`.treeRootId as `host__treeRootId`,`host`.nloose as `host__nloose`,`host`.x as `host__x`,`host`.y as `host__y`,`host`.z as `host__z`,`host`.vx as `host__vx`,`host`.vy as `host__vy`,`host`.vz as `host__vz`,`host`.np as `host__np`,`host`.mass as `host__mass`,`host`.size as `host__size`,`host`.spin as `host__spin`,`host`.ix as `host__ix`,`host`.iy as `host__iy`,`host`.iz as `host__iz`,`host`.phkey as `host__phkey` FROM MDR1.FOFSub host WHERE host.fofSubId = 85000000000000000 LIMIT 10) as res WHERE `res`.`host__np` > 50

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`res__host__fofSubId`,`res__host__fofId`,`res__host__level`,`res__host__NInFile`,`res__host__hostId`,`res__host__lastSubId`,`res__host__mainLeafId`,`res__host__treeRootId`,`res__host__nloose`,`res__host__x`,`res__host__y`,`res__host__z`,`res__host__vx`,`res__host__vy`,`res__host__vz`,`res__host__np`,`res__host__mass`,`res__host__size`,`res__host__spin`,`res__host__ix`,`res__host__iy`,`res__host__iz`,`res__host__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`res__host__fofSubId`=VALUES(`res__host__fofSubId`),
`res__host__fofId`=VALUES(`res__host__fofId`),
`res__host__level`=VALUES(`res__host__level`),
`res__host__NInFile`=VALUES(`res__host__NInFile`),
`res__host__hostId`=VALUES(`res__host__hostId`),
`res__host__lastSubId`=VALUES(`res__host__lastSubId`),
`res__host__mainLeafId`=VALUES(`res__host__mainLeafId`),
`res__host__treeRootId`=VALUES(`res__host__treeRootId`),
`res__host__nloose`=VALUES(`res__host__nloose`),
`res__host__x`=VALUES(`res__host__x`),
`res__host__y`=VALUES(`res__host__y`),
`res__host__z`=VALUES(`res__host__z`),
`res__host__vx`=VALUES(`res__host__vx`),
`res__host__vy`=VALUES(`res__host__vy`),
`res__host__vz`=VALUES(`res__host__vz`),
`res__host__np`=VALUES(`res__host__np`),
`res__host__mass`=VALUES(`res__host__mass`),
`res__host__size`=VALUES(`res__host__size`),
`res__host__spin`=VALUES(`res__host__spin`),
`res__host__ix`=VALUES(`res__host__ix`),
`res__host__iy`=VALUES(`res__host__iy`),
`res__host__iz`=VALUES(`res__host__iz`),
`res__host__phkey`=VALUES(`res__host__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `res`.`host__fofSubId`  AS `res__host__fofSubId`,`res`.`host__fofId`  AS `res__host__fofId`,`res`.`host__level`  AS `res__host__level`,`res`.`host__NInFile`  AS `res__host__NInFile`,`res`.`host__hostId`  AS `res__host__hostId`,`res`.`host__lastSubId`  AS `res__host__lastSubId`,`res`.`host__mainLeafId`  AS `res__host__mainLeafId`,`res`.`host__treeRootId`  AS `res__host__treeRootId`,`res`.`host__nloose`  AS `res__host__nloose`,`res`.`host__x`  AS `res__host__x`,`res`.`host__y`  AS `res__host__y`,`res`.`host__z`  AS `res__host__z`,`res`.`host__vx`  AS `res__host__vx`,`res`.`host__vy`  AS `res__host__vy`,`res`.`host__vz`  AS `res__host__vz`,`res`.`host__np`  AS `res__host__np`,`res`.`host__mass`  AS `res__host__mass`,`res`.`host__size`  AS `res__host__size`,`res`.`host__spin`  AS `res__host__spin`,`res`.`host__ix`  AS `res__host__ix`,`res`.`host__iy`  AS `res__host__iy`,`res`.`host__iz`  AS `res__host__iz`,`res`.`host__phkey`  AS `res__host__phkey`
FROM ( SELECT `host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`
FROM `aggregation_tmp_25761417`    LIMIT 0,10) AS `res` WHERE (  `res`.`host__np` > 50 )   
)


-- AGGREGATION SQL:
SELECT `res__host__fofSubId`,`res__host__fofId`,`res__host__level`,`res__host__NInFile`,`res__host__hostId`,`res__host__lastSubId`,`res__host__mainLeafId`,`res__host__treeRootId`,`res__host__nloose`,`res__host__x`,`res__host__y`,`res__host__z`,`res__host__vx`,`res__host__vy`,`res__host__vz`,`res__host__np`,`res__host__mass`,`res__host__size`,`res__host__spin`,`res__host__ix`,`res__host__iy`,`res__host__iz`,`res__host__phkey`
FROM `aggregation_tmp_80196196`   
ON DUPLICATE KEY UPDATE
`res__host__fofSubId`=VALUES(`res__host__fofSubId`),
`res__host__fofId`=VALUES(`res__host__fofId`),
`res__host__level`=VALUES(`res__host__level`),
`res__host__NInFile`=VALUES(`res__host__NInFile`),
`res__host__hostId`=VALUES(`res__host__hostId`),
`res__host__lastSubId`=VALUES(`res__host__lastSubId`),
`res__host__mainLeafId`=VALUES(`res__host__mainLeafId`),
`res__host__treeRootId`=VALUES(`res__host__treeRootId`),
`res__host__nloose`=VALUES(`res__host__nloose`),
`res__host__x`=VALUES(`res__host__x`),
`res__host__y`=VALUES(`res__host__y`),
`res__host__z`=VALUES(`res__host__z`),
`res__host__vx`=VALUES(`res__host__vx`),
`res__host__vy`=VALUES(`res__host__vy`),
`res__host__vz`=VALUES(`res__host__vz`),
`res__host__np`=VALUES(`res__host__np`),
`res__host__mass`=VALUES(`res__host__mass`),
`res__host__size`=VALUES(`res__host__size`),
`res__host__spin`=VALUES(`res__host__spin`),
`res__host__ix`=VALUES(`res__host__ix`),
`res__host__iy`=VALUES(`res__host__iy`),
`res__host__iz`=VALUES(`res__host__iz`),
`res__host__phkey`=VALUES(`res__host__phkey`)
This is the query plan for the query:
SELECT `res`.`host__fofSubId` as `res__host__fofSubId`,`res`.`host__fofId` as `res__host__fofId`,`res`.`host__level` as `res__host__level`,`res`.`host__NInFile` as `res__host__NInFile`,`res`.`host__hostId` as `res__host__hostId`,`res`.`host__lastSubId` as `res__host__lastSubId`,`res`.`host__mainLeafId` as `res__host__mainLeafId`,`res`.`host__treeRootId` as `res__host__treeRootId`,`res`.`host__nloose` as `res__host__nloose`,`res`.`host__x` as `res__host__x`,`res`.`host__y` as `res__host__y`,`res`.`host__z` as `res__host__z`,`res`.`host__vx` as `res__host__vx`,`res`.`host__vy` as `res__host__vy`,`res`.`host__vz` as `res__host__vz`,`res`.`host__np` as `res__host__np`,`res`.`host__mass` as `res__host__mass`,`res`.`host__size` as `res__host__size`,`res`.`host__spin` as `res__host__spin`,`res`.`host__ix` as `res__host__ix`,`res`.`host__iy` as `res__host__iy`,`res`.`host__iz` as `res__host__iz`,`res`.`host__phkey` as `res__host__phkey` FROM (SELECT `host`.fofSubId as `host__fofSubId`,`host`.fofId as `host__fofId`,`host`.level as `host__level`,`host`.NInFile as `host__NInFile`,`host`.hostId as `host__hostId`,`host`.lastSubId as `host__lastSubId`,`host`.mainLeafId as `host__mainLeafId`,`host`.treeRootId as `host__treeRootId`,`host`.nloose as `host__nloose`,`host`.x as `host__x`,`host`.y as `host__y`,`host`.z as `host__z`,`host`.vx as `host__vx`,`host`.vy as `host__vy`,`host`.vz as `host__vz`,`host`.np as `host__np`,`host`.mass as `host__mass`,`host`.size as `host__size`,`host`.spin as `host__spin`,`host`.ix as `host__ix`,`host`.iy as `host__iy`,`host`.iz as `host__iz`,`host`.phkey as `host__phkey` FROM MDR1.FOFSub host WHERE host.fofSubId = 85000000000000000 LIMIT 10) as res WHERE `res`.`host__np` > 50

CALL paquExec('SELECT `host`.fofSubId  AS `host__fofSubId`,`host`.fofId  AS `host__fofId`,`host`.level  AS `host__level`,`host`.NInFile  AS `host__NInFile`,`host`.hostId  AS `host__hostId`,`host`.lastSubId  AS `host__lastSubId`,`host`.mainLeafId  AS `host__mainLeafId`,`host`.treeRootId  AS `host__treeRootId`,`host`.nloose  AS `host__nloose`,`host`.x  AS `host__x`,`host`.y  AS `host__y`,`host`.z  AS `host__z`,`host`.vx  AS `host__vx`,`host`.vy  AS `host__vy`,`host`.vz  AS `host__vz`,`host`.np  AS `host__np`,`host`.mass  AS `host__mass`,`host`.size  AS `host__size`,`host`.spin  AS `host__spin`,`host`.ix  AS `host__ix`,`host`.iy  AS `host__iy`,`host`.iz  AS `host__iz`,`host`.phkey  AS `host__phkey` FROM MDR1.FOFSub AS `host` WHERE (  host.fofSubId = 85000000000000000 )    LIMIT 0,10', 'aggregation_tmp_25761417');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_80196196 ENGINE=MyISAM SELECT `res`.`host__fofSubId`  AS `res__host__fofSubId`,`res`.`host__fofId`  AS `res__host__fofId`,`res`.`host__level`  AS `res__host__level`,`res`.`host__NInFile`  AS `res__host__NInFile`,`res`.`host__hostId`  AS `res__host__hostId`,`res`.`host__lastSubId`  AS `res__host__lastSubId`,`res`.`host__mainLeafId`  AS `res__host__mainLeafId`,`res`.`host__treeRootId`  AS `res__host__treeRootId`,`res`.`host__nloose`  AS `res__host__nloose`,`res`.`host__x`  AS `res__host__x`,`res`.`host__y`  AS `res__host__y`,`res`.`host__z`  AS `res__host__z`,`res`.`host__vx`  AS `res__host__vx`,`res`.`host__vy`  AS `res__host__vy`,`res`.`host__vz`  AS `res__host__vz`,`res`.`host__np`  AS `res__host__np`,`res`.`host__mass`  AS `res__host__mass`,`res`.`host__size`  AS `res__host__size`,`res`.`host__spin`  AS `res__host__spin`,`res`.`host__ix`  AS `res__host__ix`,`res`.`host__iy`  AS `res__host__iy`,`res`.`host__iz`  AS `res__host__iz`,`res`.`host__phkey`  AS `res__host__phkey`
FROM ( SELECT `host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`
FROM `aggregation_tmp_25761417`     LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_80196196 SELECT `res`.`host__fofSubId`  AS `res__host__fofSubId`,`res`.`host__fofId`  AS `res__host__fofId`,`res`.`host__level`  AS `res__host__level`,`res`.`host__NInFile`  AS `res__host__NInFile`,`res`.`host__hostId`  AS `res__host__hostId`,`res`.`host__lastSubId`  AS `res__host__lastSubId`,`res`.`host__mainLeafId`  AS `res__host__mainLeafId`,`res`.`host__treeRootId`  AS `res__host__treeRootId`,`res`.`host__nloose`  AS `res__host__nloose`,`res`.`host__x`  AS `res__host__x`,`res`.`host__y`  AS `res__host__y`,`res`.`host__z`  AS `res__host__z`,`res`.`host__vx`  AS `res__host__vx`,`res`.`host__vy`  AS `res__host__vy`,`res`.`host__vz`  AS `res__host__vz`,`res`.`host__np`  AS `res__host__np`,`res`.`host__mass`  AS `res__host__mass`,`res`.`host__size`  AS `res__host__size`,`res`.`host__spin`  AS `res__host__spin`,`res`.`host__ix`  AS `res__host__ix`,`res`.`host__iy`  AS `res__host__iy`,`res`.`host__iz`  AS `res__host__iz`,`res`.`host__phkey`  AS `res__host__phkey`
FROM ( SELECT `host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`
FROM `aggregation_tmp_25761417`    LIMIT 0,10) AS `res` WHERE (  `res`.`host__np` > 50 )   ;
CALL paquLinkTmp('aggregation_tmp_80196196');
CALL paquDropTmp('aggregation_tmp_25761417');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `res__host__fofSubId`,`res__host__fofId`,`res__host__level`,`res__host__NInFile`,`res__host__hostId`,`res__host__lastSubId`,`res__host__mainLeafId`,`res__host__treeRootId`,`res__host__nloose`,`res__host__x`,`res__host__y`,`res__host__z`,`res__host__vx`,`res__host__vy`,`res__host__vz`,`res__host__np`,`res__host__mass`,`res__host__size`,`res__host__spin`,`res__host__ix`,`res__host__iy`,`res__host__iz`,`res__host__phkey`
FROM `aggregation_tmp_80196196`   ;
CALL paquDropTmp('aggregation_tmp_80196196');
This is the query plan optimisation output for the query:
SELECT `res`.`host__fofSubId` as `res__host__fofSubId`,`res`.`host__fofId` as `res__host__fofId`,`res`.`host__level` as `res__host__level`,`res`.`host__NInFile` as `res__host__NInFile`,`res`.`host__hostId` as `res__host__hostId`,`res`.`host__lastSubId` as `res__host__lastSubId`,`res`.`host__mainLeafId` as `res__host__mainLeafId`,`res`.`host__treeRootId` as `res__host__treeRootId`,`res`.`host__nloose` as `res__host__nloose`,`res`.`host__x` as `res__host__x`,`res`.`host__y` as `res__host__y`,`res`.`host__z` as `res__host__z`,`res`.`host__vx` as `res__host__vx`,`res`.`host__vy` as `res__host__vy`,`res`.`host__vz` as `res__host__vz`,`res`.`host__np` as `res__host__np`,`res`.`host__mass` as `res__host__mass`,`res`.`host__size` as `res__host__size`,`res`.`host__spin` as `res__host__spin`,`res`.`host__ix` as `res__host__ix`,`res`.`host__iy` as `res__host__iy`,`res`.`host__iz` as `res__host__iz`,`res`.`host__phkey` as `res__host__phkey` FROM (SELECT `host`.fofSubId as `host__fofSubId`,`host`.fofId as `host__fofId`,`host`.level as `host__level`,`host`.NInFile as `host__NInFile`,`host`.hostId as `host__hostId`,`host`.lastSubId as `host__lastSubId`,`host`.mainLeafId as `host__mainLeafId`,`host`.treeRootId as `host__treeRootId`,`host`.nloose as `host__nloose`,`host`.x as `host__x`,`host`.y as `host__y`,`host`.z as `host__z`,`host`.vx as `host__vx`,`host`.vy as `host__vy`,`host`.vz as `host__vz`,`host`.np as `host__np`,`host`.mass as `host__mass`,`host`.size as `host__size`,`host`.spin as `host__spin`,`host`.ix as `host__ix`,`host`.iy as `host__iy`,`host`.iz as `host__iz`,`host`.phkey as `host__phkey` FROM MDR1.FOFSub host WHERE host.fofSubId = 85000000000000000 LIMIT 10) as res WHERE `res`.`host__np` > 50

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`host__fofSubId`=VALUES(`host__fofSubId`),
`host__fofId`=VALUES(`host__fofId`),
`host__level`=VALUES(`host__level`),
`host__NInFile`=VALUES(`host__NInFile`),
`host__hostId`=VALUES(`host__hostId`),
`host__lastSubId`=VALUES(`host__lastSubId`),
`host__mainLeafId`=VALUES(`host__mainLeafId`),
`host__treeRootId`=VALUES(`host__treeRootId`),
`host__nloose`=VALUES(`host__nloose`),
`host__x`=VALUES(`host__x`),
`host__y`=VALUES(`host__y`),
`host__z`=VALUES(`host__z`),
`host__vx`=VALUES(`host__vx`),
`host__vy`=VALUES(`host__vy`),
`host__vz`=VALUES(`host__vz`),
`host__np`=VALUES(`host__np`),
`host__mass`=VALUES(`host__mass`),
`host__size`=VALUES(`host__size`),
`host__spin`=VALUES(`host__spin`),
`host__ix`=VALUES(`host__ix`),
`host__iy`=VALUES(`host__iy`),
`host__iz`=VALUES(`host__iz`),
`host__phkey`=VALUES(`host__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `host`.fofSubId  AS `host__fofSubId`,`host`.fofId  AS `host__fofId`,`host`.level  AS `host__level`,`host`.NInFile  AS `host__NInFile`,`host`.hostId  AS `host__hostId`,`host`.lastSubId  AS `host__lastSubId`,`host`.mainLeafId  AS `host__mainLeafId`,`host`.treeRootId  AS `host__treeRootId`,`host`.nloose  AS `host__nloose`,`host`.x  AS `host__x`,`host`.y  AS `host__y`,`host`.z  AS `host__z`,`host`.vx  AS `host__vx`,`host`.vy  AS `host__vy`,`host`.vz  AS `host__vz`,`host`.np  AS `host__np`,`host`.mass  AS `host__mass`,`host`.size  AS `host__size`,`host`.spin  AS `host__spin`,`host`.ix  AS `host__ix`,`host`.iy  AS `host__iy`,`host`.iz  AS `host__iz`,`host`.phkey  AS `host__phkey`
FROM MDR1.FOFSub AS `host` WHERE (  host.fofSubId = 85000000000000000 )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`
FROM `aggregation_tmp_4393223`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`host__fofSubId`=VALUES(`host__fofSubId`),
`host__fofId`=VALUES(`host__fofId`),
`host__level`=VALUES(`host__level`),
`host__NInFile`=VALUES(`host__NInFile`),
`host__hostId`=VALUES(`host__hostId`),
`host__lastSubId`=VALUES(`host__lastSubId`),
`host__mainLeafId`=VALUES(`host__mainLeafId`),
`host__treeRootId`=VALUES(`host__treeRootId`),
`host__nloose`=VALUES(`host__nloose`),
`host__x`=VALUES(`host__x`),
`host__y`=VALUES(`host__y`),
`host__z`=VALUES(`host__z`),
`host__vx`=VALUES(`host__vx`),
`host__vy`=VALUES(`host__vy`),
`host__vz`=VALUES(`host__vz`),
`host__np`=VALUES(`host__np`),
`host__mass`=VALUES(`host__mass`),
`host__size`=VALUES(`host__size`),
`host__spin`=VALUES(`host__spin`),
`host__ix`=VALUES(`host__ix`),
`host__iy`=VALUES(`host__iy`),
`host__iz`=VALUES(`host__iz`),
`host__phkey`=VALUES(`host__phkey`)
-- INPUT SQL:
SELECT `res`.`host__fofSubId` as `res__host__fofSubId`,`res`.`host__fofId` as `res__host__fofId`,`res`.`host__level` as `res__host__level`,`res`.`host__NInFile` as `res__host__NInFile`,`res`.`host__hostId` as `res__host__hostId`,`res`.`host__lastSubId` as `res__host__lastSubId`,`res`.`host__mainLeafId` as `res__host__mainLeafId`,`res`.`host__treeRootId` as `res__host__treeRootId`,`res`.`host__nloose` as `res__host__nloose`,`res`.`host__x` as `res__host__x`,`res`.`host__y` as `res__host__y`,`res`.`host__z` as `res__host__z`,`res`.`host__vx` as `res__host__vx`,`res`.`host__vy` as `res__host__vy`,`res`.`host__vz` as `res__host__vz`,`res`.`host__np` as `res__host__np`,`res`.`host__mass` as `res__host__mass`,`res`.`host__size` as `res__host__size`,`res`.`host__spin` as `res__host__spin`,`res`.`host__ix` as `res__host__ix`,`res`.`host__iy` as `res__host__iy`,`res`.`host__iz` as `res__host__iz`,`res`.`host__phkey` as `res__host__phkey` FROM (SELECT `host`.fofSubId as `host__fofSubId`,`host`.fofId as `host__fofId`,`host`.level as `host__level`,`host`.NInFile as `host__NInFile`,`host`.hostId as `host__hostId`,`host`.lastSubId as `host__lastSubId`,`host`.mainLeafId as `host__mainLeafId`,`host`.treeRootId as `host__treeRootId`,`host`.nloose as `host__nloose`,`host`.x as `host__x`,`host`.y as `host__y`,`host`.z as `host__z`,`host`.vx as `host__vx`,`host`.vy as `host__vy`,`host`.vz as `host__vz`,`host`.np as `host__np`,`host`.mass as `host__mass`,`host`.size as `host__size`,`host`.spin as `host__spin`,`host`.ix as `host__ix`,`host`.iy as `host__iy`,`host`.iz as `host__iz`,`host`.phkey as `host__phkey` FROM MDR1.FOFSub host WHERE host.fofSubId = 85000000000000000 LIMIT 10) as res WHERE `res`.`host__np` > 50

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`res__host__fofSubId`,`res__host__fofId`,`res__host__level`,`res__host__NInFile`,`res__host__hostId`,`res__host__lastSubId`,`res__host__mainLeafId`,`res__host__treeRootId`,`res__host__nloose`,`res__host__x`,`res__host__y`,`res__host__z`,`res__host__vx`,`res__host__vy`,`res__host__vz`,`res__host__np`,`res__host__mass`,`res__host__size`,`res__host__spin`,`res__host__ix`,`res__host__iy`,`res__host__iz`,`res__host__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`res__host__fofSubId`=VALUES(`res__host__fofSubId`),
`res__host__fofId`=VALUES(`res__host__fofId`),
`res__host__level`=VALUES(`res__host__level`),
`res__host__NInFile`=VALUES(`res__host__NInFile`),
`res__host__hostId`=VALUES(`res__host__hostId`),
`res__host__lastSubId`=VALUES(`res__host__lastSubId`),
`res__host__mainLeafId`=VALUES(`res__host__mainLeafId`),
`res__host__treeRootId`=VALUES(`res__host__treeRootId`),
`res__host__nloose`=VALUES(`res__host__nloose`),
`res__host__x`=VALUES(`res__host__x`),
`res__host__y`=VALUES(`res__host__y`),
`res__host__z`=VALUES(`res__host__z`),
`res__host__vx`=VALUES(`res__host__vx`),
`res__host__vy`=VALUES(`res__host__vy`),
`res__host__vz`=VALUES(`res__host__vz`),
`res__host__np`=VALUES(`res__host__np`),
`res__host__mass`=VALUES(`res__host__mass`),
`res__host__size`=VALUES(`res__host__size`),
`res__host__spin`=VALUES(`res__host__spin`),
`res__host__ix`=VALUES(`res__host__ix`),
`res__host__iy`=VALUES(`res__host__iy`),
`res__host__iz`=VALUES(`res__host__iz`),
`res__host__phkey`=VALUES(`res__host__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `res`.`host__fofSubId`  AS `res__host__fofSubId`,`res`.`host__fofId`  AS `res__host__fofId`,`res`.`host__level`  AS `res__host__level`,`res`.`host__NInFile`  AS `res__host__NInFile`,`res`.`host__hostId`  AS `res__host__hostId`,`res`.`host__lastSubId`  AS `res__host__lastSubId`,`res`.`host__mainLeafId`  AS `res__host__mainLeafId`,`res`.`host__treeRootId`  AS `res__host__treeRootId`,`res`.`host__nloose`  AS `res__host__nloose`,`res`.`host__x`  AS `res__host__x`,`res`.`host__y`  AS `res__host__y`,`res`.`host__z`  AS `res__host__z`,`res`.`host__vx`  AS `res__host__vx`,`res`.`host__vy`  AS `res__host__vy`,`res`.`host__vz`  AS `res__host__vz`,`res`.`host__np`  AS `res__host__np`,`res`.`host__mass`  AS `res__host__mass`,`res`.`host__size`  AS `res__host__size`,`res`.`host__spin`  AS `res__host__spin`,`res`.`host__ix`  AS `res__host__ix`,`res`.`host__iy`  AS `res__host__iy`,`res`.`host__iz`  AS `res__host__iz`,`res`.`host__phkey`  AS `res__host__phkey`
FROM ( SELECT `host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`
FROM `aggregation_tmp_4393223`    LIMIT 0,10) AS `res` WHERE (  `res`.`host__np` > 50 )   
)


-- AGGREGATION SQL:
SELECT `res__host__fofSubId`,`res__host__fofId`,`res__host__level`,`res__host__NInFile`,`res__host__hostId`,`res__host__lastSubId`,`res__host__mainLeafId`,`res__host__treeRootId`,`res__host__nloose`,`res__host__x`,`res__host__y`,`res__host__z`,`res__host__vx`,`res__host__vy`,`res__host__vz`,`res__host__np`,`res__host__mass`,`res__host__size`,`res__host__spin`,`res__host__ix`,`res__host__iy`,`res__host__iz`,`res__host__phkey`
FROM `aggregation_tmp_15513523`   
ON DUPLICATE KEY UPDATE
`res__host__fofSubId`=VALUES(`res__host__fofSubId`),
`res__host__fofId`=VALUES(`res__host__fofId`),
`res__host__level`=VALUES(`res__host__level`),
`res__host__NInFile`=VALUES(`res__host__NInFile`),
`res__host__hostId`=VALUES(`res__host__hostId`),
`res__host__lastSubId`=VALUES(`res__host__lastSubId`),
`res__host__mainLeafId`=VALUES(`res__host__mainLeafId`),
`res__host__treeRootId`=VALUES(`res__host__treeRootId`),
`res__host__nloose`=VALUES(`res__host__nloose`),
`res__host__x`=VALUES(`res__host__x`),
`res__host__y`=VALUES(`res__host__y`),
`res__host__z`=VALUES(`res__host__z`),
`res__host__vx`=VALUES(`res__host__vx`),
`res__host__vy`=VALUES(`res__host__vy`),
`res__host__vz`=VALUES(`res__host__vz`),
`res__host__np`=VALUES(`res__host__np`),
`res__host__mass`=VALUES(`res__host__mass`),
`res__host__size`=VALUES(`res__host__size`),
`res__host__spin`=VALUES(`res__host__spin`),
`res__host__ix`=VALUES(`res__host__ix`),
`res__host__iy`=VALUES(`res__host__iy`),
`res__host__iz`=VALUES(`res__host__iz`),
`res__host__phkey`=VALUES(`res__host__phkey`)
This is the query plan for the query:
SELECT `res`.`host__fofSubId` as `res__host__fofSubId`,`res`.`host__fofId` as `res__host__fofId`,`res`.`host__level` as `res__host__level`,`res`.`host__NInFile` as `res__host__NInFile`,`res`.`host__hostId` as `res__host__hostId`,`res`.`host__lastSubId` as `res__host__lastSubId`,`res`.`host__mainLeafId` as `res__host__mainLeafId`,`res`.`host__treeRootId` as `res__host__treeRootId`,`res`.`host__nloose` as `res__host__nloose`,`res`.`host__x` as `res__host__x`,`res`.`host__y` as `res__host__y`,`res`.`host__z` as `res__host__z`,`res`.`host__vx` as `res__host__vx`,`res`.`host__vy` as `res__host__vy`,`res`.`host__vz` as `res__host__vz`,`res`.`host__np` as `res__host__np`,`res`.`host__mass` as `res__host__mass`,`res`.`host__size` as `res__host__size`,`res`.`host__spin` as `res__host__spin`,`res`.`host__ix` as `res__host__ix`,`res`.`host__iy` as `res__host__iy`,`res`.`host__iz` as `res__host__iz`,`res`.`host__phkey` as `res__host__phkey` FROM (SELECT `host`.fofSubId as `host__fofSubId`,`host`.fofId as `host__fofId`,`host`.level as `host__level`,`host`.NInFile as `host__NInFile`,`host`.hostId as `host__hostId`,`host`.lastSubId as `host__lastSubId`,`host`.mainLeafId as `host__mainLeafId`,`host`.treeRootId as `host__treeRootId`,`host`.nloose as `host__nloose`,`host`.x as `host__x`,`host`.y as `host__y`,`host`.z as `host__z`,`host`.vx as `host__vx`,`host`.vy as `host__vy`,`host`.vz as `host__vz`,`host`.np as `host__np`,`host`.mass as `host__mass`,`host`.size as `host__size`,`host`.spin as `host__spin`,`host`.ix as `host__ix`,`host`.iy as `host__iy`,`host`.iz as `host__iz`,`host`.phkey as `host__phkey` FROM MDR1.FOFSub host WHERE host.fofSubId = 85000000000000000 LIMIT 10) as res WHERE `res`.`host__np` > 50

CALL paquExec('SELECT `host`.fofSubId  AS `host__fofSubId`,`host`.fofId  AS `host__fofId`,`host`.level  AS `host__level`,`host`.NInFile  AS `host__NInFile`,`host`.hostId  AS `host__hostId`,`host`.lastSubId  AS `host__lastSubId`,`host`.mainLeafId  AS `host__mainLeafId`,`host`.treeRootId  AS `host__treeRootId`,`host`.nloose  AS `host__nloose`,`host`.x  AS `host__x`,`host`.y  AS `host__y`,`host`.z  AS `host__z`,`host`.vx  AS `host__vx`,`host`.vy  AS `host__vy`,`host`.vz  AS `host__vz`,`host`.np  AS `host__np`,`host`.mass  AS `host__mass`,`host`.size  AS `host__size`,`host`.spin  AS `host__spin`,`host`.ix  AS `host__ix`,`host`.iy  AS `host__iy`,`host`.iz  AS `host__iz`,`host`.phkey  AS `host__phkey` FROM MDR1.FOFSub AS `host` WHERE (  host.fofSubId = 85000000000000000 )    LIMIT 0,10', 'aggregation_tmp_4393223');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_15513523 ENGINE=MyISAM SELECT `res`.`host__fofSubId`  AS `res__host__fofSubId`,`res`.`host__fofId`  AS `res__host__fofId`,`res`.`host__level`  AS `res__host__level`,`res`.`host__NInFile`  AS `res__host__NInFile`,`res`.`host__hostId`  AS `res__host__hostId`,`res`.`host__lastSubId`  AS `res__host__lastSubId`,`res`.`host__mainLeafId`  AS `res__host__mainLeafId`,`res`.`host__treeRootId`  AS `res__host__treeRootId`,`res`.`host__nloose`  AS `res__host__nloose`,`res`.`host__x`  AS `res__host__x`,`res`.`host__y`  AS `res__host__y`,`res`.`host__z`  AS `res__host__z`,`res`.`host__vx`  AS `res__host__vx`,`res`.`host__vy`  AS `res__host__vy`,`res`.`host__vz`  AS `res__host__vz`,`res`.`host__np`  AS `res__host__np`,`res`.`host__mass`  AS `res__host__mass`,`res`.`host__size`  AS `res__host__size`,`res`.`host__spin`  AS `res__host__spin`,`res`.`host__ix`  AS `res__host__ix`,`res`.`host__iy`  AS `res__host__iy`,`res`.`host__iz`  AS `res__host__iz`,`res`.`host__phkey`  AS `res__host__phkey`
FROM ( SELECT `host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`
FROM `aggregation_tmp_4393223`     LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_15513523 SELECT `res`.`host__fofSubId`  AS `res__host__fofSubId`,`res`.`host__fofId`  AS `res__host__fofId`,`res`.`host__level`  AS `res__host__level`,`res`.`host__NInFile`  AS `res__host__NInFile`,`res`.`host__hostId`  AS `res__host__hostId`,`res`.`host__lastSubId`  AS `res__host__lastSubId`,`res`.`host__mainLeafId`  AS `res__host__mainLeafId`,`res`.`host__treeRootId`  AS `res__host__treeRootId`,`res`.`host__nloose`  AS `res__host__nloose`,`res`.`host__x`  AS `res__host__x`,`res`.`host__y`  AS `res__host__y`,`res`.`host__z`  AS `res__host__z`,`res`.`host__vx`  AS `res__host__vx`,`res`.`host__vy`  AS `res__host__vy`,`res`.`host__vz`  AS `res__host__vz`,`res`.`host__np`  AS `res__host__np`,`res`.`host__mass`  AS `res__host__mass`,`res`.`host__size`  AS `res__host__size`,`res`.`host__spin`  AS `res__host__spin`,`res`.`host__ix`  AS `res__host__ix`,`res`.`host__iy`  AS `res__host__iy`,`res`.`host__iz`  AS `res__host__iz`,`res`.`host__phkey`  AS `res__host__phkey`
FROM ( SELECT `host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`
FROM `aggregation_tmp_4393223`    LIMIT 0,10) AS `res` WHERE (  `res`.`host__np` > 50 )   ;
CALL paquLinkTmp('aggregation_tmp_15513523');
CALL paquDropTmp('aggregation_tmp_4393223');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `res__host__fofSubId`,`res__host__fofId`,`res__host__level`,`res__host__NInFile`,`res__host__hostId`,`res__host__lastSubId`,`res__host__mainLeafId`,`res__host__treeRootId`,`res__host__nloose`,`res__host__x`,`res__host__y`,`res__host__z`,`res__host__vx`,`res__host__vy`,`res__host__vz`,`res__host__np`,`res__host__mass`,`res__host__size`,`res__host__spin`,`res__host__ix`,`res__host__iy`,`res__host__iz`,`res__host__phkey`
FROM `aggregation_tmp_15513523`   ;
CALL paquDropTmp('aggregation_tmp_15513523');
This is the query plan optimisation output for the query:
SELECT `res`.`host__fofSubId` as `res__host__fofSubId`,`res`.`host__fofId` as `res__host__fofId`,`res`.`host__level` as `res__host__level`,`res`.`host__NInFile` as `res__host__NInFile`,`res`.`host__hostId` as `res__host__hostId`,`res`.`host__lastSubId` as `res__host__lastSubId`,`res`.`host__mainLeafId` as `res__host__mainLeafId`,`res`.`host__treeRootId` as `res__host__treeRootId`,`res`.`host__nloose` as `res__host__nloose`,`res`.`host__x` as `res__host__x`,`res`.`host__y` as `res__host__y`,`res`.`host__z` as `res__host__z`,`res`.`host__vx` as `res__host__vx`,`res`.`host__vy` as `res__host__vy`,`res`.`host__vz` as `res__host__vz`,`res`.`host__np` as `res__host__np`,`res`.`host__mass` as `res__host__mass`,`res`.`host__size` as `res__host__size`,`res`.`host__spin` as `res__host__spin`,`res`.`host__ix` as `res__host__ix`,`res`.`host__iy` as `res__host__iy`,`res`.`host__iz` as `res__host__iz`,`res`.`host__phkey` as `res__host__phkey` FROM (SELECT `host`.fofSubId as `host__fofSubId`,`host`.fofId as `host__fofId`,`host`.level as `host__level`,`host`.NInFile as `host__NInFile`,`host`.hostId as `host__hostId`,`host`.lastSubId as `host__lastSubId`,`host`.mainLeafId as `host__mainLeafId`,`host`.treeRootId as `host__treeRootId`,`host`.nloose as `host__nloose`,`host`.x as `host__x`,`host`.y as `host__y`,`host`.z as `host__z`,`host`.vx as `host__vx`,`host`.vy as `host__vy`,`host`.vz as `host__vz`,`host`.np as `host__np`,`host`.mass as `host__mass`,`host`.size as `host__size`,`host`.spin as `host__spin`,`host`.ix as `host__ix`,`host`.iy as `host__iy`,`host`.iz as `host__iz`,`host`.phkey as `host__phkey` FROM MDR1.FOFSub host WHERE host.fofSubId = 85000000000000000 LIMIT 10) as res WHERE `res`.`host__np` > 50

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`host__fofSubId`=VALUES(`host__fofSubId`),
`host__fofId`=VALUES(`host__fofId`),
`host__level`=VALUES(`host__level`),
`host__NInFile`=VALUES(`host__NInFile`),
`host__hostId`=VALUES(`host__hostId`),
`host__lastSubId`=VALUES(`host__lastSubId`),
`host__mainLeafId`=VALUES(`host__mainLeafId`),
`host__treeRootId`=VALUES(`host__treeRootId`),
`host__nloose`=VALUES(`host__nloose`),
`host__x`=VALUES(`host__x`),
`host__y`=VALUES(`host__y`),
`host__z`=VALUES(`host__z`),
`host__vx`=VALUES(`host__vx`),
`host__vy`=VALUES(`host__vy`),
`host__vz`=VALUES(`host__vz`),
`host__np`=VALUES(`host__np`),
`host__mass`=VALUES(`host__mass`),
`host__size`=VALUES(`host__size`),
`host__spin`=VALUES(`host__spin`),
`host__ix`=VALUES(`host__ix`),
`host__iy`=VALUES(`host__iy`),
`host__iz`=VALUES(`host__iz`),
`host__phkey`=VALUES(`host__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `host`.fofSubId  AS `host__fofSubId`,`host`.fofId  AS `host__fofId`,`host`.level  AS `host__level`,`host`.NInFile  AS `host__NInFile`,`host`.hostId  AS `host__hostId`,`host`.lastSubId  AS `host__lastSubId`,`host`.mainLeafId  AS `host__mainLeafId`,`host`.treeRootId  AS `host__treeRootId`,`host`.nloose  AS `host__nloose`,`host`.x  AS `host__x`,`host`.y  AS `host__y`,`host`.z  AS `host__z`,`host`.vx  AS `host__vx`,`host`.vy  AS `host__vy`,`host`.vz  AS `host__vz`,`host`.np  AS `host__np`,`host`.mass  AS `host__mass`,`host`.size  AS `host__size`,`host`.spin  AS `host__spin`,`host`.ix  AS `host__ix`,`host`.iy  AS `host__iy`,`host`.iz  AS `host__iz`,`host`.phkey  AS `host__phkey`
FROM MDR1.FOFSub AS `host` WHERE (  host.fofSubId = 85000000000000000 )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`
FROM `aggregation_tmp_75859595`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`host__fofSubId`=VALUES(`host__fofSubId`),
`host__fofId`=VALUES(`host__fofId`),
`host__level`=VALUES(`host__level`),
`host__NInFile`=VALUES(`host__NInFile`),
`host__hostId`=VALUES(`host__hostId`),
`host__lastSubId`=VALUES(`host__lastSubId`),
`host__mainLeafId`=VALUES(`host__mainLeafId`),
`host__treeRootId`=VALUES(`host__treeRootId`),
`host__nloose`=VALUES(`host__nloose`),
`host__x`=VALUES(`host__x`),
`host__y`=VALUES(`host__y`),
`host__z`=VALUES(`host__z`),
`host__vx`=VALUES(`host__vx`),
`host__vy`=VALUES(`host__vy`),
`host__vz`=VALUES(`host__vz`),
`host__np`=VALUES(`host__np`),
`host__mass`=VALUES(`host__mass`),
`host__size`=VALUES(`host__size`),
`host__spin`=VALUES(`host__spin`),
`host__ix`=VALUES(`host__ix`),
`host__iy`=VALUES(`host__iy`),
`host__iz`=VALUES(`host__iz`),
`host__phkey`=VALUES(`host__phkey`)
-- INPUT SQL:
SELECT `res`.`host__fofSubId` as `res__host__fofSubId`,`res`.`host__fofId` as `res__host__fofId`,`res`.`host__level` as `res__host__level`,`res`.`host__NInFile` as `res__host__NInFile`,`res`.`host__hostId` as `res__host__hostId`,`res`.`host__lastSubId` as `res__host__lastSubId`,`res`.`host__mainLeafId` as `res__host__mainLeafId`,`res`.`host__treeRootId` as `res__host__treeRootId`,`res`.`host__nloose` as `res__host__nloose`,`res`.`host__x` as `res__host__x`,`res`.`host__y` as `res__host__y`,`res`.`host__z` as `res__host__z`,`res`.`host__vx` as `res__host__vx`,`res`.`host__vy` as `res__host__vy`,`res`.`host__vz` as `res__host__vz`,`res`.`host__np` as `res__host__np`,`res`.`host__mass` as `res__host__mass`,`res`.`host__size` as `res__host__size`,`res`.`host__spin` as `res__host__spin`,`res`.`host__ix` as `res__host__ix`,`res`.`host__iy` as `res__host__iy`,`res`.`host__iz` as `res__host__iz`,`res`.`host__phkey` as `res__host__phkey` FROM (SELECT `host`.fofSubId as `host__fofSubId`,`host`.fofId as `host__fofId`,`host`.level as `host__level`,`host`.NInFile as `host__NInFile`,`host`.hostId as `host__hostId`,`host`.lastSubId as `host__lastSubId`,`host`.mainLeafId as `host__mainLeafId`,`host`.treeRootId as `host__treeRootId`,`host`.nloose as `host__nloose`,`host`.x as `host__x`,`host`.y as `host__y`,`host`.z as `host__z`,`host`.vx as `host__vx`,`host`.vy as `host__vy`,`host`.vz as `host__vz`,`host`.np as `host__np`,`host`.mass as `host__mass`,`host`.size as `host__size`,`host`.spin as `host__spin`,`host`.ix as `host__ix`,`host`.iy as `host__iy`,`host`.iz as `host__iz`,`host`.phkey as `host__phkey` FROM MDR1.FOFSub host WHERE host.fofSubId = 85000000000000000 LIMIT 10) as res WHERE `res`.`host__np` > 50

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`res__host__fofSubId`,`res__host__fofId`,`res__host__level`,`res__host__NInFile`,`res__host__hostId`,`res__host__lastSubId`,`res__host__mainLeafId`,`res__host__treeRootId`,`res__host__nloose`,`res__host__x`,`res__host__y`,`res__host__z`,`res__host__vx`,`res__host__vy`,`res__host__vz`,`res__host__np`,`res__host__mass`,`res__host__size`,`res__host__spin`,`res__host__ix`,`res__host__iy`,`res__host__iz`,`res__host__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`res__host__fofSubId`=VALUES(`res__host__fofSubId`),
`res__host__fofId`=VALUES(`res__host__fofId`),
`res__host__level`=VALUES(`res__host__level`),
`res__host__NInFile`=VALUES(`res__host__NInFile`),
`res__host__hostId`=VALUES(`res__host__hostId`),
`res__host__lastSubId`=VALUES(`res__host__lastSubId`),
`res__host__mainLeafId`=VALUES(`res__host__mainLeafId`),
`res__host__treeRootId`=VALUES(`res__host__treeRootId`),
`res__host__nloose`=VALUES(`res__host__nloose`),
`res__host__x`=VALUES(`res__host__x`),
`res__host__y`=VALUES(`res__host__y`),
`res__host__z`=VALUES(`res__host__z`),
`res__host__vx`=VALUES(`res__host__vx`),
`res__host__vy`=VALUES(`res__host__vy`),
`res__host__vz`=VALUES(`res__host__vz`),
`res__host__np`=VALUES(`res__host__np`),
`res__host__mass`=VALUES(`res__host__mass`),
`res__host__size`=VALUES(`res__host__size`),
`res__host__spin`=VALUES(`res__host__spin`),
`res__host__ix`=VALUES(`res__host__ix`),
`res__host__iy`=VALUES(`res__host__iy`),
`res__host__iz`=VALUES(`res__host__iz`),
`res__host__phkey`=VALUES(`res__host__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `res`.`host__fofSubId`  AS `res__host__fofSubId`,`res`.`host__fofId`  AS `res__host__fofId`,`res`.`host__level`  AS `res__host__level`,`res`.`host__NInFile`  AS `res__host__NInFile`,`res`.`host__hostId`  AS `res__host__hostId`,`res`.`host__lastSubId`  AS `res__host__lastSubId`,`res`.`host__mainLeafId`  AS `res__host__mainLeafId`,`res`.`host__treeRootId`  AS `res__host__treeRootId`,`res`.`host__nloose`  AS `res__host__nloose`,`res`.`host__x`  AS `res__host__x`,`res`.`host__y`  AS `res__host__y`,`res`.`host__z`  AS `res__host__z`,`res`.`host__vx`  AS `res__host__vx`,`res`.`host__vy`  AS `res__host__vy`,`res`.`host__vz`  AS `res__host__vz`,`res`.`host__np`  AS `res__host__np`,`res`.`host__mass`  AS `res__host__mass`,`res`.`host__size`  AS `res__host__size`,`res`.`host__spin`  AS `res__host__spin`,`res`.`host__ix`  AS `res__host__ix`,`res`.`host__iy`  AS `res__host__iy`,`res`.`host__iz`  AS `res__host__iz`,`res`.`host__phkey`  AS `res__host__phkey`
FROM ( SELECT `host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`
FROM `aggregation_tmp_75859595`    LIMIT 0,10) AS `res` WHERE (  `res`.`host__np` > 50 )   
)


-- AGGREGATION SQL:
SELECT `res__host__fofSubId`,`res__host__fofId`,`res__host__level`,`res__host__NInFile`,`res__host__hostId`,`res__host__lastSubId`,`res__host__mainLeafId`,`res__host__treeRootId`,`res__host__nloose`,`res__host__x`,`res__host__y`,`res__host__z`,`res__host__vx`,`res__host__vy`,`res__host__vz`,`res__host__np`,`res__host__mass`,`res__host__size`,`res__host__spin`,`res__host__ix`,`res__host__iy`,`res__host__iz`,`res__host__phkey`
FROM `aggregation_tmp_12215711`   
ON DUPLICATE KEY UPDATE
`res__host__fofSubId`=VALUES(`res__host__fofSubId`),
`res__host__fofId`=VALUES(`res__host__fofId`),
`res__host__level`=VALUES(`res__host__level`),
`res__host__NInFile`=VALUES(`res__host__NInFile`),
`res__host__hostId`=VALUES(`res__host__hostId`),
`res__host__lastSubId`=VALUES(`res__host__lastSubId`),
`res__host__mainLeafId`=VALUES(`res__host__mainLeafId`),
`res__host__treeRootId`=VALUES(`res__host__treeRootId`),
`res__host__nloose`=VALUES(`res__host__nloose`),
`res__host__x`=VALUES(`res__host__x`),
`res__host__y`=VALUES(`res__host__y`),
`res__host__z`=VALUES(`res__host__z`),
`res__host__vx`=VALUES(`res__host__vx`),
`res__host__vy`=VALUES(`res__host__vy`),
`res__host__vz`=VALUES(`res__host__vz`),
`res__host__np`=VALUES(`res__host__np`),
`res__host__mass`=VALUES(`res__host__mass`),
`res__host__size`=VALUES(`res__host__size`),
`res__host__spin`=VALUES(`res__host__spin`),
`res__host__ix`=VALUES(`res__host__ix`),
`res__host__iy`=VALUES(`res__host__iy`),
`res__host__iz`=VALUES(`res__host__iz`),
`res__host__phkey`=VALUES(`res__host__phkey`)
This is the query plan for the query:
SELECT `res`.`host__fofSubId` as `res__host__fofSubId`,`res`.`host__fofId` as `res__host__fofId`,`res`.`host__level` as `res__host__level`,`res`.`host__NInFile` as `res__host__NInFile`,`res`.`host__hostId` as `res__host__hostId`,`res`.`host__lastSubId` as `res__host__lastSubId`,`res`.`host__mainLeafId` as `res__host__mainLeafId`,`res`.`host__treeRootId` as `res__host__treeRootId`,`res`.`host__nloose` as `res__host__nloose`,`res`.`host__x` as `res__host__x`,`res`.`host__y` as `res__host__y`,`res`.`host__z` as `res__host__z`,`res`.`host__vx` as `res__host__vx`,`res`.`host__vy` as `res__host__vy`,`res`.`host__vz` as `res__host__vz`,`res`.`host__np` as `res__host__np`,`res`.`host__mass` as `res__host__mass`,`res`.`host__size` as `res__host__size`,`res`.`host__spin` as `res__host__spin`,`res`.`host__ix` as `res__host__ix`,`res`.`host__iy` as `res__host__iy`,`res`.`host__iz` as `res__host__iz`,`res`.`host__phkey` as `res__host__phkey` FROM (SELECT `host`.fofSubId as `host__fofSubId`,`host`.fofId as `host__fofId`,`host`.level as `host__level`,`host`.NInFile as `host__NInFile`,`host`.hostId as `host__hostId`,`host`.lastSubId as `host__lastSubId`,`host`.mainLeafId as `host__mainLeafId`,`host`.treeRootId as `host__treeRootId`,`host`.nloose as `host__nloose`,`host`.x as `host__x`,`host`.y as `host__y`,`host`.z as `host__z`,`host`.vx as `host__vx`,`host`.vy as `host__vy`,`host`.vz as `host__vz`,`host`.np as `host__np`,`host`.mass as `host__mass`,`host`.size as `host__size`,`host`.spin as `host__spin`,`host`.ix as `host__ix`,`host`.iy as `host__iy`,`host`.iz as `host__iz`,`host`.phkey as `host__phkey` FROM MDR1.FOFSub host WHERE host.fofSubId = 85000000000000000 LIMIT 10) as res WHERE `res`.`host__np` > 50

CALL paquExec('SELECT `host`.fofSubId  AS `host__fofSubId`,`host`.fofId  AS `host__fofId`,`host`.level  AS `host__level`,`host`.NInFile  AS `host__NInFile`,`host`.hostId  AS `host__hostId`,`host`.lastSubId  AS `host__lastSubId`,`host`.mainLeafId  AS `host__mainLeafId`,`host`.treeRootId  AS `host__treeRootId`,`host`.nloose  AS `host__nloose`,`host`.x  AS `host__x`,`host`.y  AS `host__y`,`host`.z  AS `host__z`,`host`.vx  AS `host__vx`,`host`.vy  AS `host__vy`,`host`.vz  AS `host__vz`,`host`.np  AS `host__np`,`host`.mass  AS `host__mass`,`host`.size  AS `host__size`,`host`.spin  AS `host__spin`,`host`.ix  AS `host__ix`,`host`.iy  AS `host__iy`,`host`.iz  AS `host__iz`,`host`.phkey  AS `host__phkey` FROM MDR1.FOFSub AS `host` WHERE (  host.fofSubId = 85000000000000000 )    LIMIT 0,10', 'aggregation_tmp_75859595');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_12215711 ENGINE=MyISAM SELECT `res`.`host__fofSubId`  AS `res__host__fofSubId`,`res`.`host__fofId`  AS `res__host__fofId`,`res`.`host__level`  AS `res__host__level`,`res`.`host__NInFile`  AS `res__host__NInFile`,`res`.`host__hostId`  AS `res__host__hostId`,`res`.`host__lastSubId`  AS `res__host__lastSubId`,`res`.`host__mainLeafId`  AS `res__host__mainLeafId`,`res`.`host__treeRootId`  AS `res__host__treeRootId`,`res`.`host__nloose`  AS `res__host__nloose`,`res`.`host__x`  AS `res__host__x`,`res`.`host__y`  AS `res__host__y`,`res`.`host__z`  AS `res__host__z`,`res`.`host__vx`  AS `res__host__vx`,`res`.`host__vy`  AS `res__host__vy`,`res`.`host__vz`  AS `res__host__vz`,`res`.`host__np`  AS `res__host__np`,`res`.`host__mass`  AS `res__host__mass`,`res`.`host__size`  AS `res__host__size`,`res`.`host__spin`  AS `res__host__spin`,`res`.`host__ix`  AS `res__host__ix`,`res`.`host__iy`  AS `res__host__iy`,`res`.`host__iz`  AS `res__host__iz`,`res`.`host__phkey`  AS `res__host__phkey`
FROM ( SELECT `host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`
FROM `aggregation_tmp_75859595`     LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_12215711 SELECT `res`.`host__fofSubId`  AS `res__host__fofSubId`,`res`.`host__fofId`  AS `res__host__fofId`,`res`.`host__level`  AS `res__host__level`,`res`.`host__NInFile`  AS `res__host__NInFile`,`res`.`host__hostId`  AS `res__host__hostId`,`res`.`host__lastSubId`  AS `res__host__lastSubId`,`res`.`host__mainLeafId`  AS `res__host__mainLeafId`,`res`.`host__treeRootId`  AS `res__host__treeRootId`,`res`.`host__nloose`  AS `res__host__nloose`,`res`.`host__x`  AS `res__host__x`,`res`.`host__y`  AS `res__host__y`,`res`.`host__z`  AS `res__host__z`,`res`.`host__vx`  AS `res__host__vx`,`res`.`host__vy`  AS `res__host__vy`,`res`.`host__vz`  AS `res__host__vz`,`res`.`host__np`  AS `res__host__np`,`res`.`host__mass`  AS `res__host__mass`,`res`.`host__size`  AS `res__host__size`,`res`.`host__spin`  AS `res__host__spin`,`res`.`host__ix`  AS `res__host__ix`,`res`.`host__iy`  AS `res__host__iy`,`res`.`host__iz`  AS `res__host__iz`,`res`.`host__phkey`  AS `res__host__phkey`
FROM ( SELECT `host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`
FROM `aggregation_tmp_75859595`    LIMIT 0,10) AS `res` WHERE (  `res`.`host__np` > 50 )   ;
CALL paquLinkTmp('aggregation_tmp_12215711');
CALL paquDropTmp('aggregation_tmp_75859595');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `res__host__fofSubId`,`res__host__fofId`,`res__host__level`,`res__host__NInFile`,`res__host__hostId`,`res__host__lastSubId`,`res__host__mainLeafId`,`res__host__treeRootId`,`res__host__nloose`,`res__host__x`,`res__host__y`,`res__host__z`,`res__host__vx`,`res__host__vy`,`res__host__vz`,`res__host__np`,`res__host__mass`,`res__host__size`,`res__host__spin`,`res__host__ix`,`res__host__iy`,`res__host__iz`,`res__host__phkey`
FROM `aggregation_tmp_12215711`   ;
CALL paquDropTmp('aggregation_tmp_12215711');
This is the query plan optimisation output for the query:
SELECT `res`.`host__fofSubId` as `res__host__fofSubId`,`res`.`host__fofId` as `res__host__fofId`,`res`.`host__level` as `res__host__level`,`res`.`host__NInFile` as `res__host__NInFile`,`res`.`host__hostId` as `res__host__hostId`,`res`.`host__lastSubId` as `res__host__lastSubId`,`res`.`host__mainLeafId` as `res__host__mainLeafId`,`res`.`host__treeRootId` as `res__host__treeRootId`,`res`.`host__nloose` as `res__host__nloose`,`res`.`host__x` as `res__host__x`,`res`.`host__y` as `res__host__y`,`res`.`host__z` as `res__host__z`,`res`.`host__vx` as `res__host__vx`,`res`.`host__vy` as `res__host__vy`,`res`.`host__vz` as `res__host__vz`,`res`.`host__np` as `res__host__np`,`res`.`host__mass` as `res__host__mass`,`res`.`host__size` as `res__host__size`,`res`.`host__spin` as `res__host__spin`,`res`.`host__ix` as `res__host__ix`,`res`.`host__iy` as `res__host__iy`,`res`.`host__iz` as `res__host__iz`,`res`.`host__phkey` as `res__host__phkey` FROM (SELECT `host`.fofSubId as `host__fofSubId`,`host`.fofId as `host__fofId`,`host`.level as `host__level`,`host`.NInFile as `host__NInFile`,`host`.hostId as `host__hostId`,`host`.lastSubId as `host__lastSubId`,`host`.mainLeafId as `host__mainLeafId`,`host`.treeRootId as `host__treeRootId`,`host`.nloose as `host__nloose`,`host`.x as `host__x`,`host`.y as `host__y`,`host`.z as `host__z`,`host`.vx as `host__vx`,`host`.vy as `host__vy`,`host`.vz as `host__vz`,`host`.np as `host__np`,`host`.mass as `host__mass`,`host`.size as `host__size`,`host`.spin as `host__spin`,`host`.ix as `host__ix`,`host`.iy as `host__iy`,`host`.iz as `host__iz`,`host`.phkey as `host__phkey` FROM MDR1.FOFSub host WHERE host.fofSubId = 85000000000000000 LIMIT 10) as res WHERE `res`.`host__np` > 50

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`host__fofSubId`=VALUES(`host__fofSubId`),
`host__fofId`=VALUES(`host__fofId`),
`host__level`=VALUES(`host__level`),
`host__NInFile`=VALUES(`host__NInFile`),
`host__hostId`=VALUES(`host__hostId`),
`host__lastSubId`=VALUES(`host__lastSubId`),
`host__mainLeafId`=VALUES(`host__mainLeafId`),
`host__treeRootId`=VALUES(`host__treeRootId`),
`host__nloose`=VALUES(`host__nloose`),
`host__x`=VALUES(`host__x`),
`host__y`=VALUES(`host__y`),
`host__z`=VALUES(`host__z`),
`host__vx`=VALUES(`host__vx`),
`host__vy`=VALUES(`host__vy`),
`host__vz`=VALUES(`host__vz`),
`host__np`=VALUES(`host__np`),
`host__mass`=VALUES(`host__mass`),
`host__size`=VALUES(`host__size`),
`host__spin`=VALUES(`host__spin`),
`host__ix`=VALUES(`host__ix`),
`host__iy`=VALUES(`host__iy`),
`host__iz`=VALUES(`host__iz`),
`host__phkey`=VALUES(`host__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `host`.fofSubId  AS `host__fofSubId`,`host`.fofId  AS `host__fofId`,`host`.level  AS `host__level`,`host`.NInFile  AS `host__NInFile`,`host`.hostId  AS `host__hostId`,`host`.lastSubId  AS `host__lastSubId`,`host`.mainLeafId  AS `host__mainLeafId`,`host`.treeRootId  AS `host__treeRootId`,`host`.nloose  AS `host__nloose`,`host`.x  AS `host__x`,`host`.y  AS `host__y`,`host`.z  AS `host__z`,`host`.vx  AS `host__vx`,`host`.vy  AS `host__vy`,`host`.vz  AS `host__vz`,`host`.np  AS `host__np`,`host`.mass  AS `host__mass`,`host`.size  AS `host__size`,`host`.spin  AS `host__spin`,`host`.ix  AS `host__ix`,`host`.iy  AS `host__iy`,`host`.iz  AS `host__iz`,`host`.phkey  AS `host__phkey`
FROM MDR1.FOFSub AS `host` WHERE (  host.fofSubId = 85000000000000000 )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`
FROM `aggregation_tmp_32700388`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`host__fofSubId`=VALUES(`host__fofSubId`),
`host__fofId`=VALUES(`host__fofId`),
`host__level`=VALUES(`host__level`),
`host__NInFile`=VALUES(`host__NInFile`),
`host__hostId`=VALUES(`host__hostId`),
`host__lastSubId`=VALUES(`host__lastSubId`),
`host__mainLeafId`=VALUES(`host__mainLeafId`),
`host__treeRootId`=VALUES(`host__treeRootId`),
`host__nloose`=VALUES(`host__nloose`),
`host__x`=VALUES(`host__x`),
`host__y`=VALUES(`host__y`),
`host__z`=VALUES(`host__z`),
`host__vx`=VALUES(`host__vx`),
`host__vy`=VALUES(`host__vy`),
`host__vz`=VALUES(`host__vz`),
`host__np`=VALUES(`host__np`),
`host__mass`=VALUES(`host__mass`),
`host__size`=VALUES(`host__size`),
`host__spin`=VALUES(`host__spin`),
`host__ix`=VALUES(`host__ix`),
`host__iy`=VALUES(`host__iy`),
`host__iz`=VALUES(`host__iz`),
`host__phkey`=VALUES(`host__phkey`)
-- INPUT SQL:
SELECT `res`.`host__fofSubId` as `res__host__fofSubId`,`res`.`host__fofId` as `res__host__fofId`,`res`.`host__level` as `res__host__level`,`res`.`host__NInFile` as `res__host__NInFile`,`res`.`host__hostId` as `res__host__hostId`,`res`.`host__lastSubId` as `res__host__lastSubId`,`res`.`host__mainLeafId` as `res__host__mainLeafId`,`res`.`host__treeRootId` as `res__host__treeRootId`,`res`.`host__nloose` as `res__host__nloose`,`res`.`host__x` as `res__host__x`,`res`.`host__y` as `res__host__y`,`res`.`host__z` as `res__host__z`,`res`.`host__vx` as `res__host__vx`,`res`.`host__vy` as `res__host__vy`,`res`.`host__vz` as `res__host__vz`,`res`.`host__np` as `res__host__np`,`res`.`host__mass` as `res__host__mass`,`res`.`host__size` as `res__host__size`,`res`.`host__spin` as `res__host__spin`,`res`.`host__ix` as `res__host__ix`,`res`.`host__iy` as `res__host__iy`,`res`.`host__iz` as `res__host__iz`,`res`.`host__phkey` as `res__host__phkey` FROM (SELECT `host`.fofSubId as `host__fofSubId`,`host`.fofId as `host__fofId`,`host`.level as `host__level`,`host`.NInFile as `host__NInFile`,`host`.hostId as `host__hostId`,`host`.lastSubId as `host__lastSubId`,`host`.mainLeafId as `host__mainLeafId`,`host`.treeRootId as `host__treeRootId`,`host`.nloose as `host__nloose`,`host`.x as `host__x`,`host`.y as `host__y`,`host`.z as `host__z`,`host`.vx as `host__vx`,`host`.vy as `host__vy`,`host`.vz as `host__vz`,`host`.np as `host__np`,`host`.mass as `host__mass`,`host`.size as `host__size`,`host`.spin as `host__spin`,`host`.ix as `host__ix`,`host`.iy as `host__iy`,`host`.iz as `host__iz`,`host`.phkey as `host__phkey` FROM MDR1.FOFSub host WHERE host.fofSubId = 85000000000000000 LIMIT 10) as res WHERE `res`.`host__np` > 50

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`res__host__fofSubId`,`res__host__fofId`,`res__host__level`,`res__host__NInFile`,`res__host__hostId`,`res__host__lastSubId`,`res__host__mainLeafId`,`res__host__treeRootId`,`res__host__nloose`,`res__host__x`,`res__host__y`,`res__host__z`,`res__host__vx`,`res__host__vy`,`res__host__vz`,`res__host__np`,`res__host__mass`,`res__host__size`,`res__host__spin`,`res__host__ix`,`res__host__iy`,`res__host__iz`,`res__host__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`res__host__fofSubId`=VALUES(`res__host__fofSubId`),
`res__host__fofId`=VALUES(`res__host__fofId`),
`res__host__level`=VALUES(`res__host__level`),
`res__host__NInFile`=VALUES(`res__host__NInFile`),
`res__host__hostId`=VALUES(`res__host__hostId`),
`res__host__lastSubId`=VALUES(`res__host__lastSubId`),
`res__host__mainLeafId`=VALUES(`res__host__mainLeafId`),
`res__host__treeRootId`=VALUES(`res__host__treeRootId`),
`res__host__nloose`=VALUES(`res__host__nloose`),
`res__host__x`=VALUES(`res__host__x`),
`res__host__y`=VALUES(`res__host__y`),
`res__host__z`=VALUES(`res__host__z`),
`res__host__vx`=VALUES(`res__host__vx`),
`res__host__vy`=VALUES(`res__host__vy`),
`res__host__vz`=VALUES(`res__host__vz`),
`res__host__np`=VALUES(`res__host__np`),
`res__host__mass`=VALUES(`res__host__mass`),
`res__host__size`=VALUES(`res__host__size`),
`res__host__spin`=VALUES(`res__host__spin`),
`res__host__ix`=VALUES(`res__host__ix`),
`res__host__iy`=VALUES(`res__host__iy`),
`res__host__iz`=VALUES(`res__host__iz`),
`res__host__phkey`=VALUES(`res__host__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `res`.`host__fofSubId`  AS `res__host__fofSubId`,`res`.`host__fofId`  AS `res__host__fofId`,`res`.`host__level`  AS `res__host__level`,`res`.`host__NInFile`  AS `res__host__NInFile`,`res`.`host__hostId`  AS `res__host__hostId`,`res`.`host__lastSubId`  AS `res__host__lastSubId`,`res`.`host__mainLeafId`  AS `res__host__mainLeafId`,`res`.`host__treeRootId`  AS `res__host__treeRootId`,`res`.`host__nloose`  AS `res__host__nloose`,`res`.`host__x`  AS `res__host__x`,`res`.`host__y`  AS `res__host__y`,`res`.`host__z`  AS `res__host__z`,`res`.`host__vx`  AS `res__host__vx`,`res`.`host__vy`  AS `res__host__vy`,`res`.`host__vz`  AS `res__host__vz`,`res`.`host__np`  AS `res__host__np`,`res`.`host__mass`  AS `res__host__mass`,`res`.`host__size`  AS `res__host__size`,`res`.`host__spin`  AS `res__host__spin`,`res`.`host__ix`  AS `res__host__ix`,`res`.`host__iy`  AS `res__host__iy`,`res`.`host__iz`  AS `res__host__iz`,`res`.`host__phkey`  AS `res__host__phkey`
FROM ( SELECT `host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`
FROM `aggregation_tmp_32700388`    LIMIT 0,10) AS `res` WHERE (  `res`.`host__np` > 50 )   
)


-- AGGREGATION SQL:
SELECT `res__host__fofSubId`,`res__host__fofId`,`res__host__level`,`res__host__NInFile`,`res__host__hostId`,`res__host__lastSubId`,`res__host__mainLeafId`,`res__host__treeRootId`,`res__host__nloose`,`res__host__x`,`res__host__y`,`res__host__z`,`res__host__vx`,`res__host__vy`,`res__host__vz`,`res__host__np`,`res__host__mass`,`res__host__size`,`res__host__spin`,`res__host__ix`,`res__host__iy`,`res__host__iz`,`res__host__phkey`
FROM `aggregation_tmp_63418099`   
ON DUPLICATE KEY UPDATE
`res__host__fofSubId`=VALUES(`res__host__fofSubId`),
`res__host__fofId`=VALUES(`res__host__fofId`),
`res__host__level`=VALUES(`res__host__level`),
`res__host__NInFile`=VALUES(`res__host__NInFile`),
`res__host__hostId`=VALUES(`res__host__hostId`),
`res__host__lastSubId`=VALUES(`res__host__lastSubId`),
`res__host__mainLeafId`=VALUES(`res__host__mainLeafId`),
`res__host__treeRootId`=VALUES(`res__host__treeRootId`),
`res__host__nloose`=VALUES(`res__host__nloose`),
`res__host__x`=VALUES(`res__host__x`),
`res__host__y`=VALUES(`res__host__y`),
`res__host__z`=VALUES(`res__host__z`),
`res__host__vx`=VALUES(`res__host__vx`),
`res__host__vy`=VALUES(`res__host__vy`),
`res__host__vz`=VALUES(`res__host__vz`),
`res__host__np`=VALUES(`res__host__np`),
`res__host__mass`=VALUES(`res__host__mass`),
`res__host__size`=VALUES(`res__host__size`),
`res__host__spin`=VALUES(`res__host__spin`),
`res__host__ix`=VALUES(`res__host__ix`),
`res__host__iy`=VALUES(`res__host__iy`),
`res__host__iz`=VALUES(`res__host__iz`),
`res__host__phkey`=VALUES(`res__host__phkey`)
This is the query plan for the query:
SELECT `res`.`host__fofSubId` as `res__host__fofSubId`,`res`.`host__fofId` as `res__host__fofId`,`res`.`host__level` as `res__host__level`,`res`.`host__NInFile` as `res__host__NInFile`,`res`.`host__hostId` as `res__host__hostId`,`res`.`host__lastSubId` as `res__host__lastSubId`,`res`.`host__mainLeafId` as `res__host__mainLeafId`,`res`.`host__treeRootId` as `res__host__treeRootId`,`res`.`host__nloose` as `res__host__nloose`,`res`.`host__x` as `res__host__x`,`res`.`host__y` as `res__host__y`,`res`.`host__z` as `res__host__z`,`res`.`host__vx` as `res__host__vx`,`res`.`host__vy` as `res__host__vy`,`res`.`host__vz` as `res__host__vz`,`res`.`host__np` as `res__host__np`,`res`.`host__mass` as `res__host__mass`,`res`.`host__size` as `res__host__size`,`res`.`host__spin` as `res__host__spin`,`res`.`host__ix` as `res__host__ix`,`res`.`host__iy` as `res__host__iy`,`res`.`host__iz` as `res__host__iz`,`res`.`host__phkey` as `res__host__phkey` FROM (SELECT `host`.fofSubId as `host__fofSubId`,`host`.fofId as `host__fofId`,`host`.level as `host__level`,`host`.NInFile as `host__NInFile`,`host`.hostId as `host__hostId`,`host`.lastSubId as `host__lastSubId`,`host`.mainLeafId as `host__mainLeafId`,`host`.treeRootId as `host__treeRootId`,`host`.nloose as `host__nloose`,`host`.x as `host__x`,`host`.y as `host__y`,`host`.z as `host__z`,`host`.vx as `host__vx`,`host`.vy as `host__vy`,`host`.vz as `host__vz`,`host`.np as `host__np`,`host`.mass as `host__mass`,`host`.size as `host__size`,`host`.spin as `host__spin`,`host`.ix as `host__ix`,`host`.iy as `host__iy`,`host`.iz as `host__iz`,`host`.phkey as `host__phkey` FROM MDR1.FOFSub host WHERE host.fofSubId = 85000000000000000 LIMIT 10) as res WHERE `res`.`host__np` > 50

CALL paquExec('SELECT `host`.fofSubId  AS `host__fofSubId`,`host`.fofId  AS `host__fofId`,`host`.level  AS `host__level`,`host`.NInFile  AS `host__NInFile`,`host`.hostId  AS `host__hostId`,`host`.lastSubId  AS `host__lastSubId`,`host`.mainLeafId  AS `host__mainLeafId`,`host`.treeRootId  AS `host__treeRootId`,`host`.nloose  AS `host__nloose`,`host`.x  AS `host__x`,`host`.y  AS `host__y`,`host`.z  AS `host__z`,`host`.vx  AS `host__vx`,`host`.vy  AS `host__vy`,`host`.vz  AS `host__vz`,`host`.np  AS `host__np`,`host`.mass  AS `host__mass`,`host`.size  AS `host__size`,`host`.spin  AS `host__spin`,`host`.ix  AS `host__ix`,`host`.iy  AS `host__iy`,`host`.iz  AS `host__iz`,`host`.phkey  AS `host__phkey` FROM MDR1.FOFSub AS `host` WHERE (  host.fofSubId = 85000000000000000 )    LIMIT 0,10', 'aggregation_tmp_32700388');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_63418099 ENGINE=MyISAM SELECT `res`.`host__fofSubId`  AS `res__host__fofSubId`,`res`.`host__fofId`  AS `res__host__fofId`,`res`.`host__level`  AS `res__host__level`,`res`.`host__NInFile`  AS `res__host__NInFile`,`res`.`host__hostId`  AS `res__host__hostId`,`res`.`host__lastSubId`  AS `res__host__lastSubId`,`res`.`host__mainLeafId`  AS `res__host__mainLeafId`,`res`.`host__treeRootId`  AS `res__host__treeRootId`,`res`.`host__nloose`  AS `res__host__nloose`,`res`.`host__x`  AS `res__host__x`,`res`.`host__y`  AS `res__host__y`,`res`.`host__z`  AS `res__host__z`,`res`.`host__vx`  AS `res__host__vx`,`res`.`host__vy`  AS `res__host__vy`,`res`.`host__vz`  AS `res__host__vz`,`res`.`host__np`  AS `res__host__np`,`res`.`host__mass`  AS `res__host__mass`,`res`.`host__size`  AS `res__host__size`,`res`.`host__spin`  AS `res__host__spin`,`res`.`host__ix`  AS `res__host__ix`,`res`.`host__iy`  AS `res__host__iy`,`res`.`host__iz`  AS `res__host__iz`,`res`.`host__phkey`  AS `res__host__phkey`
FROM ( SELECT `host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`
FROM `aggregation_tmp_32700388`     LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_63418099 SELECT `res`.`host__fofSubId`  AS `res__host__fofSubId`,`res`.`host__fofId`  AS `res__host__fofId`,`res`.`host__level`  AS `res__host__level`,`res`.`host__NInFile`  AS `res__host__NInFile`,`res`.`host__hostId`  AS `res__host__hostId`,`res`.`host__lastSubId`  AS `res__host__lastSubId`,`res`.`host__mainLeafId`  AS `res__host__mainLeafId`,`res`.`host__treeRootId`  AS `res__host__treeRootId`,`res`.`host__nloose`  AS `res__host__nloose`,`res`.`host__x`  AS `res__host__x`,`res`.`host__y`  AS `res__host__y`,`res`.`host__z`  AS `res__host__z`,`res`.`host__vx`  AS `res__host__vx`,`res`.`host__vy`  AS `res__host__vy`,`res`.`host__vz`  AS `res__host__vz`,`res`.`host__np`  AS `res__host__np`,`res`.`host__mass`  AS `res__host__mass`,`res`.`host__size`  AS `res__host__size`,`res`.`host__spin`  AS `res__host__spin`,`res`.`host__ix`  AS `res__host__ix`,`res`.`host__iy`  AS `res__host__iy`,`res`.`host__iz`  AS `res__host__iz`,`res`.`host__phkey`  AS `res__host__phkey`
FROM ( SELECT `host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`
FROM `aggregation_tmp_32700388`    LIMIT 0,10) AS `res` WHERE (  `res`.`host__np` > 50 )   ;
CALL paquLinkTmp('aggregation_tmp_63418099');
CALL paquDropTmp('aggregation_tmp_32700388');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `res__host__fofSubId`,`res__host__fofId`,`res__host__level`,`res__host__NInFile`,`res__host__hostId`,`res__host__lastSubId`,`res__host__mainLeafId`,`res__host__treeRootId`,`res__host__nloose`,`res__host__x`,`res__host__y`,`res__host__z`,`res__host__vx`,`res__host__vy`,`res__host__vz`,`res__host__np`,`res__host__mass`,`res__host__size`,`res__host__spin`,`res__host__ix`,`res__host__iy`,`res__host__iz`,`res__host__phkey`
FROM `aggregation_tmp_63418099`   ;
CALL paquDropTmp('aggregation_tmp_63418099');
This is the query plan optimisation output for the query:
SELECT `res`.`host__fofSubId` as `res__host__fofSubId`,`res`.`host__fofId` as `res__host__fofId`,`res`.`host__level` as `res__host__level`,`res`.`host__NInFile` as `res__host__NInFile`,`res`.`host__hostId` as `res__host__hostId`,`res`.`host__lastSubId` as `res__host__lastSubId`,`res`.`host__mainLeafId` as `res__host__mainLeafId`,`res`.`host__treeRootId` as `res__host__treeRootId`,`res`.`host__nloose` as `res__host__nloose`,`res`.`host__x` as `res__host__x`,`res`.`host__y` as `res__host__y`,`res`.`host__z` as `res__host__z`,`res`.`host__vx` as `res__host__vx`,`res`.`host__vy` as `res__host__vy`,`res`.`host__vz` as `res__host__vz`,`res`.`host__np` as `res__host__np`,`res`.`host__mass` as `res__host__mass`,`res`.`host__size` as `res__host__size`,`res`.`host__spin` as `res__host__spin`,`res`.`host__ix` as `res__host__ix`,`res`.`host__iy` as `res__host__iy`,`res`.`host__iz` as `res__host__iz`,`res`.`host__phkey` as `res__host__phkey` FROM (SELECT `host`.fofSubId as `host__fofSubId`,`host`.fofId as `host__fofId`,`host`.level as `host__level`,`host`.NInFile as `host__NInFile`,`host`.hostId as `host__hostId`,`host`.lastSubId as `host__lastSubId`,`host`.mainLeafId as `host__mainLeafId`,`host`.treeRootId as `host__treeRootId`,`host`.nloose as `host__nloose`,`host`.x as `host__x`,`host`.y as `host__y`,`host`.z as `host__z`,`host`.vx as `host__vx`,`host`.vy as `host__vy`,`host`.vz as `host__vz`,`host`.np as `host__np`,`host`.mass as `host__mass`,`host`.size as `host__size`,`host`.spin as `host__spin`,`host`.ix as `host__ix`,`host`.iy as `host__iy`,`host`.iz as `host__iz`,`host`.phkey as `host__phkey` FROM MDR1.FOFSub host WHERE host.fofSubId = 85000000000000000 LIMIT 10) as res WHERE `res`.`host__np` > 50

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`host__fofSubId`=VALUES(`host__fofSubId`),
`host__fofId`=VALUES(`host__fofId`),
`host__level`=VALUES(`host__level`),
`host__NInFile`=VALUES(`host__NInFile`),
`host__hostId`=VALUES(`host__hostId`),
`host__lastSubId`=VALUES(`host__lastSubId`),
`host__mainLeafId`=VALUES(`host__mainLeafId`),
`host__treeRootId`=VALUES(`host__treeRootId`),
`host__nloose`=VALUES(`host__nloose`),
`host__x`=VALUES(`host__x`),
`host__y`=VALUES(`host__y`),
`host__z`=VALUES(`host__z`),
`host__vx`=VALUES(`host__vx`),
`host__vy`=VALUES(`host__vy`),
`host__vz`=VALUES(`host__vz`),
`host__np`=VALUES(`host__np`),
`host__mass`=VALUES(`host__mass`),
`host__size`=VALUES(`host__size`),
`host__spin`=VALUES(`host__spin`),
`host__ix`=VALUES(`host__ix`),
`host__iy`=VALUES(`host__iy`),
`host__iz`=VALUES(`host__iz`),
`host__phkey`=VALUES(`host__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `host`.fofSubId  AS `host__fofSubId`,`host`.fofId  AS `host__fofId`,`host`.level  AS `host__level`,`host`.NInFile  AS `host__NInFile`,`host`.hostId  AS `host__hostId`,`host`.lastSubId  AS `host__lastSubId`,`host`.mainLeafId  AS `host__mainLeafId`,`host`.treeRootId  AS `host__treeRootId`,`host`.nloose  AS `host__nloose`,`host`.x  AS `host__x`,`host`.y  AS `host__y`,`host`.z  AS `host__z`,`host`.vx  AS `host__vx`,`host`.vy  AS `host__vy`,`host`.vz  AS `host__vz`,`host`.np  AS `host__np`,`host`.mass  AS `host__mass`,`host`.size  AS `host__size`,`host`.spin  AS `host__spin`,`host`.ix  AS `host__ix`,`host`.iy  AS `host__iy`,`host`.iz  AS `host__iz`,`host`.phkey  AS `host__phkey`
FROM MDR1.FOFSub AS `host` WHERE (  host.fofSubId = 85000000000000000 )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`
FROM `aggregation_tmp_4169707`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`host__fofSubId`=VALUES(`host__fofSubId`),
`host__fofId`=VALUES(`host__fofId`),
`host__level`=VALUES(`host__level`),
`host__NInFile`=VALUES(`host__NInFile`),
`host__hostId`=VALUES(`host__hostId`),
`host__lastSubId`=VALUES(`host__lastSubId`),
`host__mainLeafId`=VALUES(`host__mainLeafId`),
`host__treeRootId`=VALUES(`host__treeRootId`),
`host__nloose`=VALUES(`host__nloose`),
`host__x`=VALUES(`host__x`),
`host__y`=VALUES(`host__y`),
`host__z`=VALUES(`host__z`),
`host__vx`=VALUES(`host__vx`),
`host__vy`=VALUES(`host__vy`),
`host__vz`=VALUES(`host__vz`),
`host__np`=VALUES(`host__np`),
`host__mass`=VALUES(`host__mass`),
`host__size`=VALUES(`host__size`),
`host__spin`=VALUES(`host__spin`),
`host__ix`=VALUES(`host__ix`),
`host__iy`=VALUES(`host__iy`),
`host__iz`=VALUES(`host__iz`),
`host__phkey`=VALUES(`host__phkey`)
-- INPUT SQL:
SELECT `res`.`host__fofSubId` as `res__host__fofSubId`,`res`.`host__fofId` as `res__host__fofId`,`res`.`host__level` as `res__host__level`,`res`.`host__NInFile` as `res__host__NInFile`,`res`.`host__hostId` as `res__host__hostId`,`res`.`host__lastSubId` as `res__host__lastSubId`,`res`.`host__mainLeafId` as `res__host__mainLeafId`,`res`.`host__treeRootId` as `res__host__treeRootId`,`res`.`host__nloose` as `res__host__nloose`,`res`.`host__x` as `res__host__x`,`res`.`host__y` as `res__host__y`,`res`.`host__z` as `res__host__z`,`res`.`host__vx` as `res__host__vx`,`res`.`host__vy` as `res__host__vy`,`res`.`host__vz` as `res__host__vz`,`res`.`host__np` as `res__host__np`,`res`.`host__mass` as `res__host__mass`,`res`.`host__size` as `res__host__size`,`res`.`host__spin` as `res__host__spin`,`res`.`host__ix` as `res__host__ix`,`res`.`host__iy` as `res__host__iy`,`res`.`host__iz` as `res__host__iz`,`res`.`host__phkey` as `res__host__phkey` FROM (SELECT `host`.fofSubId as `host__fofSubId`,`host`.fofId as `host__fofId`,`host`.level as `host__level`,`host`.NInFile as `host__NInFile`,`host`.hostId as `host__hostId`,`host`.lastSubId as `host__lastSubId`,`host`.mainLeafId as `host__mainLeafId`,`host`.treeRootId as `host__treeRootId`,`host`.nloose as `host__nloose`,`host`.x as `host__x`,`host`.y as `host__y`,`host`.z as `host__z`,`host`.vx as `host__vx`,`host`.vy as `host__vy`,`host`.vz as `host__vz`,`host`.np as `host__np`,`host`.mass as `host__mass`,`host`.size as `host__size`,`host`.spin as `host__spin`,`host`.ix as `host__ix`,`host`.iy as `host__iy`,`host`.iz as `host__iz`,`host`.phkey as `host__phkey` FROM MDR1.FOFSub host WHERE host.fofSubId = 85000000000000000 LIMIT 10) as res WHERE `res`.`host__np` > 50

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`res__host__fofSubId`,`res__host__fofId`,`res__host__level`,`res__host__NInFile`,`res__host__hostId`,`res__host__lastSubId`,`res__host__mainLeafId`,`res__host__treeRootId`,`res__host__nloose`,`res__host__x`,`res__host__y`,`res__host__z`,`res__host__vx`,`res__host__vy`,`res__host__vz`,`res__host__np`,`res__host__mass`,`res__host__size`,`res__host__spin`,`res__host__ix`,`res__host__iy`,`res__host__iz`,`res__host__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`res__host__fofSubId`=VALUES(`res__host__fofSubId`),
`res__host__fofId`=VALUES(`res__host__fofId`),
`res__host__level`=VALUES(`res__host__level`),
`res__host__NInFile`=VALUES(`res__host__NInFile`),
`res__host__hostId`=VALUES(`res__host__hostId`),
`res__host__lastSubId`=VALUES(`res__host__lastSubId`),
`res__host__mainLeafId`=VALUES(`res__host__mainLeafId`),
`res__host__treeRootId`=VALUES(`res__host__treeRootId`),
`res__host__nloose`=VALUES(`res__host__nloose`),
`res__host__x`=VALUES(`res__host__x`),
`res__host__y`=VALUES(`res__host__y`),
`res__host__z`=VALUES(`res__host__z`),
`res__host__vx`=VALUES(`res__host__vx`),
`res__host__vy`=VALUES(`res__host__vy`),
`res__host__vz`=VALUES(`res__host__vz`),
`res__host__np`=VALUES(`res__host__np`),
`res__host__mass`=VALUES(`res__host__mass`),
`res__host__size`=VALUES(`res__host__size`),
`res__host__spin`=VALUES(`res__host__spin`),
`res__host__ix`=VALUES(`res__host__ix`),
`res__host__iy`=VALUES(`res__host__iy`),
`res__host__iz`=VALUES(`res__host__iz`),
`res__host__phkey`=VALUES(`res__host__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `res`.`host__fofSubId`  AS `res__host__fofSubId`,`res`.`host__fofId`  AS `res__host__fofId`,`res`.`host__level`  AS `res__host__level`,`res`.`host__NInFile`  AS `res__host__NInFile`,`res`.`host__hostId`  AS `res__host__hostId`,`res`.`host__lastSubId`  AS `res__host__lastSubId`,`res`.`host__mainLeafId`  AS `res__host__mainLeafId`,`res`.`host__treeRootId`  AS `res__host__treeRootId`,`res`.`host__nloose`  AS `res__host__nloose`,`res`.`host__x`  AS `res__host__x`,`res`.`host__y`  AS `res__host__y`,`res`.`host__z`  AS `res__host__z`,`res`.`host__vx`  AS `res__host__vx`,`res`.`host__vy`  AS `res__host__vy`,`res`.`host__vz`  AS `res__host__vz`,`res`.`host__np`  AS `res__host__np`,`res`.`host__mass`  AS `res__host__mass`,`res`.`host__size`  AS `res__host__size`,`res`.`host__spin`  AS `res__host__spin`,`res`.`host__ix`  AS `res__host__ix`,`res`.`host__iy`  AS `res__host__iy`,`res`.`host__iz`  AS `res__host__iz`,`res`.`host__phkey`  AS `res__host__phkey`
FROM ( SELECT `host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`
FROM `aggregation_tmp_4169707`    LIMIT 0,10) AS `res` WHERE (  `res`.`host__np` > 50 )   
)


-- AGGREGATION SQL:
SELECT `res__host__fofSubId`,`res__host__fofId`,`res__host__level`,`res__host__NInFile`,`res__host__hostId`,`res__host__lastSubId`,`res__host__mainLeafId`,`res__host__treeRootId`,`res__host__nloose`,`res__host__x`,`res__host__y`,`res__host__z`,`res__host__vx`,`res__host__vy`,`res__host__vz`,`res__host__np`,`res__host__mass`,`res__host__size`,`res__host__spin`,`res__host__ix`,`res__host__iy`,`res__host__iz`,`res__host__phkey`
FROM `aggregation_tmp_14444682`   
ON DUPLICATE KEY UPDATE
`res__host__fofSubId`=VALUES(`res__host__fofSubId`),
`res__host__fofId`=VALUES(`res__host__fofId`),
`res__host__level`=VALUES(`res__host__level`),
`res__host__NInFile`=VALUES(`res__host__NInFile`),
`res__host__hostId`=VALUES(`res__host__hostId`),
`res__host__lastSubId`=VALUES(`res__host__lastSubId`),
`res__host__mainLeafId`=VALUES(`res__host__mainLeafId`),
`res__host__treeRootId`=VALUES(`res__host__treeRootId`),
`res__host__nloose`=VALUES(`res__host__nloose`),
`res__host__x`=VALUES(`res__host__x`),
`res__host__y`=VALUES(`res__host__y`),
`res__host__z`=VALUES(`res__host__z`),
`res__host__vx`=VALUES(`res__host__vx`),
`res__host__vy`=VALUES(`res__host__vy`),
`res__host__vz`=VALUES(`res__host__vz`),
`res__host__np`=VALUES(`res__host__np`),
`res__host__mass`=VALUES(`res__host__mass`),
`res__host__size`=VALUES(`res__host__size`),
`res__host__spin`=VALUES(`res__host__spin`),
`res__host__ix`=VALUES(`res__host__ix`),
`res__host__iy`=VALUES(`res__host__iy`),
`res__host__iz`=VALUES(`res__host__iz`),
`res__host__phkey`=VALUES(`res__host__phkey`)
This is the query plan for the query:
SELECT `res`.`host__fofSubId` as `res__host__fofSubId`,`res`.`host__fofId` as `res__host__fofId`,`res`.`host__level` as `res__host__level`,`res`.`host__NInFile` as `res__host__NInFile`,`res`.`host__hostId` as `res__host__hostId`,`res`.`host__lastSubId` as `res__host__lastSubId`,`res`.`host__mainLeafId` as `res__host__mainLeafId`,`res`.`host__treeRootId` as `res__host__treeRootId`,`res`.`host__nloose` as `res__host__nloose`,`res`.`host__x` as `res__host__x`,`res`.`host__y` as `res__host__y`,`res`.`host__z` as `res__host__z`,`res`.`host__vx` as `res__host__vx`,`res`.`host__vy` as `res__host__vy`,`res`.`host__vz` as `res__host__vz`,`res`.`host__np` as `res__host__np`,`res`.`host__mass` as `res__host__mass`,`res`.`host__size` as `res__host__size`,`res`.`host__spin` as `res__host__spin`,`res`.`host__ix` as `res__host__ix`,`res`.`host__iy` as `res__host__iy`,`res`.`host__iz` as `res__host__iz`,`res`.`host__phkey` as `res__host__phkey` FROM (SELECT `host`.fofSubId as `host__fofSubId`,`host`.fofId as `host__fofId`,`host`.level as `host__level`,`host`.NInFile as `host__NInFile`,`host`.hostId as `host__hostId`,`host`.lastSubId as `host__lastSubId`,`host`.mainLeafId as `host__mainLeafId`,`host`.treeRootId as `host__treeRootId`,`host`.nloose as `host__nloose`,`host`.x as `host__x`,`host`.y as `host__y`,`host`.z as `host__z`,`host`.vx as `host__vx`,`host`.vy as `host__vy`,`host`.vz as `host__vz`,`host`.np as `host__np`,`host`.mass as `host__mass`,`host`.size as `host__size`,`host`.spin as `host__spin`,`host`.ix as `host__ix`,`host`.iy as `host__iy`,`host`.iz as `host__iz`,`host`.phkey as `host__phkey` FROM MDR1.FOFSub host WHERE host.fofSubId = 85000000000000000 LIMIT 10) as res WHERE `res`.`host__np` > 50

CALL paquExec('SELECT `host`.fofSubId  AS `host__fofSubId`,`host`.fofId  AS `host__fofId`,`host`.level  AS `host__level`,`host`.NInFile  AS `host__NInFile`,`host`.hostId  AS `host__hostId`,`host`.lastSubId  AS `host__lastSubId`,`host`.mainLeafId  AS `host__mainLeafId`,`host`.treeRootId  AS `host__treeRootId`,`host`.nloose  AS `host__nloose`,`host`.x  AS `host__x`,`host`.y  AS `host__y`,`host`.z  AS `host__z`,`host`.vx  AS `host__vx`,`host`.vy  AS `host__vy`,`host`.vz  AS `host__vz`,`host`.np  AS `host__np`,`host`.mass  AS `host__mass`,`host`.size  AS `host__size`,`host`.spin  AS `host__spin`,`host`.ix  AS `host__ix`,`host`.iy  AS `host__iy`,`host`.iz  AS `host__iz`,`host`.phkey  AS `host__phkey` FROM MDR1.FOFSub AS `host` WHERE (  host.fofSubId = 85000000000000000 )    LIMIT 0,10', 'aggregation_tmp_4169707');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_14444682 ENGINE=MyISAM SELECT `res`.`host__fofSubId`  AS `res__host__fofSubId`,`res`.`host__fofId`  AS `res__host__fofId`,`res`.`host__level`  AS `res__host__level`,`res`.`host__NInFile`  AS `res__host__NInFile`,`res`.`host__hostId`  AS `res__host__hostId`,`res`.`host__lastSubId`  AS `res__host__lastSubId`,`res`.`host__mainLeafId`  AS `res__host__mainLeafId`,`res`.`host__treeRootId`  AS `res__host__treeRootId`,`res`.`host__nloose`  AS `res__host__nloose`,`res`.`host__x`  AS `res__host__x`,`res`.`host__y`  AS `res__host__y`,`res`.`host__z`  AS `res__host__z`,`res`.`host__vx`  AS `res__host__vx`,`res`.`host__vy`  AS `res__host__vy`,`res`.`host__vz`  AS `res__host__vz`,`res`.`host__np`  AS `res__host__np`,`res`.`host__mass`  AS `res__host__mass`,`res`.`host__size`  AS `res__host__size`,`res`.`host__spin`  AS `res__host__spin`,`res`.`host__ix`  AS `res__host__ix`,`res`.`host__iy`  AS `res__host__iy`,`res`.`host__iz`  AS `res__host__iz`,`res`.`host__phkey`  AS `res__host__phkey`
FROM ( SELECT `host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`
FROM `aggregation_tmp_4169707`    LIMIT 0,10) AS `res` WHERE (  `res`.`host__np` > 50 )    LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_14444682 SELECT `res`.`host__fofSubId`  AS `res__host__fofSubId`,`res`.`host__fofId`  AS `res__host__fofId`,`res`.`host__level`  AS `res__host__level`,`res`.`host__NInFile`  AS `res__host__NInFile`,`res`.`host__hostId`  AS `res__host__hostId`,`res`.`host__lastSubId`  AS `res__host__lastSubId`,`res`.`host__mainLeafId`  AS `res__host__mainLeafId`,`res`.`host__treeRootId`  AS `res__host__treeRootId`,`res`.`host__nloose`  AS `res__host__nloose`,`res`.`host__x`  AS `res__host__x`,`res`.`host__y`  AS `res__host__y`,`res`.`host__z`  AS `res__host__z`,`res`.`host__vx`  AS `res__host__vx`,`res`.`host__vy`  AS `res__host__vy`,`res`.`host__vz`  AS `res__host__vz`,`res`.`host__np`  AS `res__host__np`,`res`.`host__mass`  AS `res__host__mass`,`res`.`host__size`  AS `res__host__size`,`res`.`host__spin`  AS `res__host__spin`,`res`.`host__ix`  AS `res__host__ix`,`res`.`host__iy`  AS `res__host__iy`,`res`.`host__iz`  AS `res__host__iz`,`res`.`host__phkey`  AS `res__host__phkey`
FROM ( SELECT `host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`
FROM `aggregation_tmp_4169707`    LIMIT 0,10) AS `res` WHERE (  `res`.`host__np` > 50 )   ;
CALL paquLinkTmp('aggregation_tmp_14444682');
CALL paquDropTmp('aggregation_tmp_4169707');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `res__host__fofSubId`,`res__host__fofId`,`res__host__level`,`res__host__NInFile`,`res__host__hostId`,`res__host__lastSubId`,`res__host__mainLeafId`,`res__host__treeRootId`,`res__host__nloose`,`res__host__x`,`res__host__y`,`res__host__z`,`res__host__vx`,`res__host__vy`,`res__host__vz`,`res__host__np`,`res__host__mass`,`res__host__size`,`res__host__spin`,`res__host__ix`,`res__host__iy`,`res__host__iz`,`res__host__phkey`
FROM `aggregation_tmp_14444682`   ;
CALL paquDropTmp('aggregation_tmp_14444682');
This is the query plan optimisation output for the query:
SELECT `res`.`host__fofSubId` as `res__host__fofSubId`,`res`.`host__fofId` as `res__host__fofId`,`res`.`host__level` as `res__host__level`,`res`.`host__NInFile` as `res__host__NInFile`,`res`.`host__hostId` as `res__host__hostId`,`res`.`host__lastSubId` as `res__host__lastSubId`,`res`.`host__mainLeafId` as `res__host__mainLeafId`,`res`.`host__treeRootId` as `res__host__treeRootId`,`res`.`host__nloose` as `res__host__nloose`,`res`.`host__x` as `res__host__x`,`res`.`host__y` as `res__host__y`,`res`.`host__z` as `res__host__z`,`res`.`host__vx` as `res__host__vx`,`res`.`host__vy` as `res__host__vy`,`res`.`host__vz` as `res__host__vz`,`res`.`host__np` as `res__host__np`,`res`.`host__mass` as `res__host__mass`,`res`.`host__size` as `res__host__size`,`res`.`host__spin` as `res__host__spin`,`res`.`host__ix` as `res__host__ix`,`res`.`host__iy` as `res__host__iy`,`res`.`host__iz` as `res__host__iz`,`res`.`host__phkey` as `res__host__phkey` FROM (SELECT `host`.fofSubId as `host__fofSubId`,`host`.fofId as `host__fofId`,`host`.level as `host__level`,`host`.NInFile as `host__NInFile`,`host`.hostId as `host__hostId`,`host`.lastSubId as `host__lastSubId`,`host`.mainLeafId as `host__mainLeafId`,`host`.treeRootId as `host__treeRootId`,`host`.nloose as `host__nloose`,`host`.x as `host__x`,`host`.y as `host__y`,`host`.z as `host__z`,`host`.vx as `host__vx`,`host`.vy as `host__vy`,`host`.vz as `host__vz`,`host`.np as `host__np`,`host`.mass as `host__mass`,`host`.size as `host__size`,`host`.spin as `host__spin`,`host`.ix as `host__ix`,`host`.iy as `host__iy`,`host`.iz as `host__iz`,`host`.phkey as `host__phkey` FROM MDR1.FOFSub host WHERE host.fofSubId = 85000000000000000 LIMIT 10) as res WHERE `res`.`host__np` > 50

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`host__fofSubId`=VALUES(`host__fofSubId`),
`host__fofId`=VALUES(`host__fofId`),
`host__level`=VALUES(`host__level`),
`host__NInFile`=VALUES(`host__NInFile`),
`host__hostId`=VALUES(`host__hostId`),
`host__lastSubId`=VALUES(`host__lastSubId`),
`host__mainLeafId`=VALUES(`host__mainLeafId`),
`host__treeRootId`=VALUES(`host__treeRootId`),
`host__nloose`=VALUES(`host__nloose`),
`host__x`=VALUES(`host__x`),
`host__y`=VALUES(`host__y`),
`host__z`=VALUES(`host__z`),
`host__vx`=VALUES(`host__vx`),
`host__vy`=VALUES(`host__vy`),
`host__vz`=VALUES(`host__vz`),
`host__np`=VALUES(`host__np`),
`host__mass`=VALUES(`host__mass`),
`host__size`=VALUES(`host__size`),
`host__spin`=VALUES(`host__spin`),
`host__ix`=VALUES(`host__ix`),
`host__iy`=VALUES(`host__iy`),
`host__iz`=VALUES(`host__iz`),
`host__phkey`=VALUES(`host__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `host`.fofSubId  AS `host__fofSubId`,`host`.fofId  AS `host__fofId`,`host`.level  AS `host__level`,`host`.NInFile  AS `host__NInFile`,`host`.hostId  AS `host__hostId`,`host`.lastSubId  AS `host__lastSubId`,`host`.mainLeafId  AS `host__mainLeafId`,`host`.treeRootId  AS `host__treeRootId`,`host`.nloose  AS `host__nloose`,`host`.x  AS `host__x`,`host`.y  AS `host__y`,`host`.z  AS `host__z`,`host`.vx  AS `host__vx`,`host`.vy  AS `host__vy`,`host`.vz  AS `host__vz`,`host`.np  AS `host__np`,`host`.mass  AS `host__mass`,`host`.size  AS `host__size`,`host`.spin  AS `host__spin`,`host`.ix  AS `host__ix`,`host`.iy  AS `host__iy`,`host`.iz  AS `host__iz`,`host`.phkey  AS `host__phkey`
FROM MDR1.FOFSub AS `host` WHERE (  host.fofSubId = 85000000000000000 )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`
FROM `aggregation_tmp_72230572`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`host__fofSubId`=VALUES(`host__fofSubId`),
`host__fofId`=VALUES(`host__fofId`),
`host__level`=VALUES(`host__level`),
`host__NInFile`=VALUES(`host__NInFile`),
`host__hostId`=VALUES(`host__hostId`),
`host__lastSubId`=VALUES(`host__lastSubId`),
`host__mainLeafId`=VALUES(`host__mainLeafId`),
`host__treeRootId`=VALUES(`host__treeRootId`),
`host__nloose`=VALUES(`host__nloose`),
`host__x`=VALUES(`host__x`),
`host__y`=VALUES(`host__y`),
`host__z`=VALUES(`host__z`),
`host__vx`=VALUES(`host__vx`),
`host__vy`=VALUES(`host__vy`),
`host__vz`=VALUES(`host__vz`),
`host__np`=VALUES(`host__np`),
`host__mass`=VALUES(`host__mass`),
`host__size`=VALUES(`host__size`),
`host__spin`=VALUES(`host__spin`),
`host__ix`=VALUES(`host__ix`),
`host__iy`=VALUES(`host__iy`),
`host__iz`=VALUES(`host__iz`),
`host__phkey`=VALUES(`host__phkey`)
-- INPUT SQL:
SELECT `res`.`host__fofSubId` as `res__host__fofSubId`,`res`.`host__fofId` as `res__host__fofId`,`res`.`host__level` as `res__host__level`,`res`.`host__NInFile` as `res__host__NInFile`,`res`.`host__hostId` as `res__host__hostId`,`res`.`host__lastSubId` as `res__host__lastSubId`,`res`.`host__mainLeafId` as `res__host__mainLeafId`,`res`.`host__treeRootId` as `res__host__treeRootId`,`res`.`host__nloose` as `res__host__nloose`,`res`.`host__x` as `res__host__x`,`res`.`host__y` as `res__host__y`,`res`.`host__z` as `res__host__z`,`res`.`host__vx` as `res__host__vx`,`res`.`host__vy` as `res__host__vy`,`res`.`host__vz` as `res__host__vz`,`res`.`host__np` as `res__host__np`,`res`.`host__mass` as `res__host__mass`,`res`.`host__size` as `res__host__size`,`res`.`host__spin` as `res__host__spin`,`res`.`host__ix` as `res__host__ix`,`res`.`host__iy` as `res__host__iy`,`res`.`host__iz` as `res__host__iz`,`res`.`host__phkey` as `res__host__phkey` FROM (SELECT `host`.fofSubId as `host__fofSubId`,`host`.fofId as `host__fofId`,`host`.level as `host__level`,`host`.NInFile as `host__NInFile`,`host`.hostId as `host__hostId`,`host`.lastSubId as `host__lastSubId`,`host`.mainLeafId as `host__mainLeafId`,`host`.treeRootId as `host__treeRootId`,`host`.nloose as `host__nloose`,`host`.x as `host__x`,`host`.y as `host__y`,`host`.z as `host__z`,`host`.vx as `host__vx`,`host`.vy as `host__vy`,`host`.vz as `host__vz`,`host`.np as `host__np`,`host`.mass as `host__mass`,`host`.size as `host__size`,`host`.spin as `host__spin`,`host`.ix as `host__ix`,`host`.iy as `host__iy`,`host`.iz as `host__iz`,`host`.phkey as `host__phkey` FROM MDR1.FOFSub host WHERE host.fofSubId = 85000000000000000 LIMIT 10) as res WHERE `res`.`host__np` > 50

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`res__host__fofSubId`,`res__host__fofId`,`res__host__level`,`res__host__NInFile`,`res__host__hostId`,`res__host__lastSubId`,`res__host__mainLeafId`,`res__host__treeRootId`,`res__host__nloose`,`res__host__x`,`res__host__y`,`res__host__z`,`res__host__vx`,`res__host__vy`,`res__host__vz`,`res__host__np`,`res__host__mass`,`res__host__size`,`res__host__spin`,`res__host__ix`,`res__host__iy`,`res__host__iz`,`res__host__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`res__host__fofSubId`=VALUES(`res__host__fofSubId`),
`res__host__fofId`=VALUES(`res__host__fofId`),
`res__host__level`=VALUES(`res__host__level`),
`res__host__NInFile`=VALUES(`res__host__NInFile`),
`res__host__hostId`=VALUES(`res__host__hostId`),
`res__host__lastSubId`=VALUES(`res__host__lastSubId`),
`res__host__mainLeafId`=VALUES(`res__host__mainLeafId`),
`res__host__treeRootId`=VALUES(`res__host__treeRootId`),
`res__host__nloose`=VALUES(`res__host__nloose`),
`res__host__x`=VALUES(`res__host__x`),
`res__host__y`=VALUES(`res__host__y`),
`res__host__z`=VALUES(`res__host__z`),
`res__host__vx`=VALUES(`res__host__vx`),
`res__host__vy`=VALUES(`res__host__vy`),
`res__host__vz`=VALUES(`res__host__vz`),
`res__host__np`=VALUES(`res__host__np`),
`res__host__mass`=VALUES(`res__host__mass`),
`res__host__size`=VALUES(`res__host__size`),
`res__host__spin`=VALUES(`res__host__spin`),
`res__host__ix`=VALUES(`res__host__ix`),
`res__host__iy`=VALUES(`res__host__iy`),
`res__host__iz`=VALUES(`res__host__iz`),
`res__host__phkey`=VALUES(`res__host__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `res`.`host__fofSubId`  AS `res__host__fofSubId`,`res`.`host__fofId`  AS `res__host__fofId`,`res`.`host__level`  AS `res__host__level`,`res`.`host__NInFile`  AS `res__host__NInFile`,`res`.`host__hostId`  AS `res__host__hostId`,`res`.`host__lastSubId`  AS `res__host__lastSubId`,`res`.`host__mainLeafId`  AS `res__host__mainLeafId`,`res`.`host__treeRootId`  AS `res__host__treeRootId`,`res`.`host__nloose`  AS `res__host__nloose`,`res`.`host__x`  AS `res__host__x`,`res`.`host__y`  AS `res__host__y`,`res`.`host__z`  AS `res__host__z`,`res`.`host__vx`  AS `res__host__vx`,`res`.`host__vy`  AS `res__host__vy`,`res`.`host__vz`  AS `res__host__vz`,`res`.`host__np`  AS `res__host__np`,`res`.`host__mass`  AS `res__host__mass`,`res`.`host__size`  AS `res__host__size`,`res`.`host__spin`  AS `res__host__spin`,`res`.`host__ix`  AS `res__host__ix`,`res`.`host__iy`  AS `res__host__iy`,`res`.`host__iz`  AS `res__host__iz`,`res`.`host__phkey`  AS `res__host__phkey`
FROM ( SELECT `host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`
FROM `aggregation_tmp_72230572`    LIMIT 0,10) AS `res` WHERE (  `res`.`host__np` > 50 )   
)


-- AGGREGATION SQL:
SELECT `res__host__fofSubId`,`res__host__fofId`,`res__host__level`,`res__host__NInFile`,`res__host__hostId`,`res__host__lastSubId`,`res__host__mainLeafId`,`res__host__treeRootId`,`res__host__nloose`,`res__host__x`,`res__host__y`,`res__host__z`,`res__host__vx`,`res__host__vy`,`res__host__vz`,`res__host__np`,`res__host__mass`,`res__host__size`,`res__host__spin`,`res__host__ix`,`res__host__iy`,`res__host__iz`,`res__host__phkey`
FROM `aggregation_tmp_50493134`   
ON DUPLICATE KEY UPDATE
`res__host__fofSubId`=VALUES(`res__host__fofSubId`),
`res__host__fofId`=VALUES(`res__host__fofId`),
`res__host__level`=VALUES(`res__host__level`),
`res__host__NInFile`=VALUES(`res__host__NInFile`),
`res__host__hostId`=VALUES(`res__host__hostId`),
`res__host__lastSubId`=VALUES(`res__host__lastSubId`),
`res__host__mainLeafId`=VALUES(`res__host__mainLeafId`),
`res__host__treeRootId`=VALUES(`res__host__treeRootId`),
`res__host__nloose`=VALUES(`res__host__nloose`),
`res__host__x`=VALUES(`res__host__x`),
`res__host__y`=VALUES(`res__host__y`),
`res__host__z`=VALUES(`res__host__z`),
`res__host__vx`=VALUES(`res__host__vx`),
`res__host__vy`=VALUES(`res__host__vy`),
`res__host__vz`=VALUES(`res__host__vz`),
`res__host__np`=VALUES(`res__host__np`),
`res__host__mass`=VALUES(`res__host__mass`),
`res__host__size`=VALUES(`res__host__size`),
`res__host__spin`=VALUES(`res__host__spin`),
`res__host__ix`=VALUES(`res__host__ix`),
`res__host__iy`=VALUES(`res__host__iy`),
`res__host__iz`=VALUES(`res__host__iz`),
`res__host__phkey`=VALUES(`res__host__phkey`)
This is the query plan for the query:
SELECT `res`.`host__fofSubId` as `res__host__fofSubId`,`res`.`host__fofId` as `res__host__fofId`,`res`.`host__level` as `res__host__level`,`res`.`host__NInFile` as `res__host__NInFile`,`res`.`host__hostId` as `res__host__hostId`,`res`.`host__lastSubId` as `res__host__lastSubId`,`res`.`host__mainLeafId` as `res__host__mainLeafId`,`res`.`host__treeRootId` as `res__host__treeRootId`,`res`.`host__nloose` as `res__host__nloose`,`res`.`host__x` as `res__host__x`,`res`.`host__y` as `res__host__y`,`res`.`host__z` as `res__host__z`,`res`.`host__vx` as `res__host__vx`,`res`.`host__vy` as `res__host__vy`,`res`.`host__vz` as `res__host__vz`,`res`.`host__np` as `res__host__np`,`res`.`host__mass` as `res__host__mass`,`res`.`host__size` as `res__host__size`,`res`.`host__spin` as `res__host__spin`,`res`.`host__ix` as `res__host__ix`,`res`.`host__iy` as `res__host__iy`,`res`.`host__iz` as `res__host__iz`,`res`.`host__phkey` as `res__host__phkey` FROM (SELECT `host`.fofSubId as `host__fofSubId`,`host`.fofId as `host__fofId`,`host`.level as `host__level`,`host`.NInFile as `host__NInFile`,`host`.hostId as `host__hostId`,`host`.lastSubId as `host__lastSubId`,`host`.mainLeafId as `host__mainLeafId`,`host`.treeRootId as `host__treeRootId`,`host`.nloose as `host__nloose`,`host`.x as `host__x`,`host`.y as `host__y`,`host`.z as `host__z`,`host`.vx as `host__vx`,`host`.vy as `host__vy`,`host`.vz as `host__vz`,`host`.np as `host__np`,`host`.mass as `host__mass`,`host`.size as `host__size`,`host`.spin as `host__spin`,`host`.ix as `host__ix`,`host`.iy as `host__iy`,`host`.iz as `host__iz`,`host`.phkey as `host__phkey` FROM MDR1.FOFSub host WHERE host.fofSubId = 85000000000000000 LIMIT 10) as res WHERE `res`.`host__np` > 50

CALL paquExec('SELECT `host`.fofSubId  AS `host__fofSubId`,`host`.fofId  AS `host__fofId`,`host`.level  AS `host__level`,`host`.NInFile  AS `host__NInFile`,`host`.hostId  AS `host__hostId`,`host`.lastSubId  AS `host__lastSubId`,`host`.mainLeafId  AS `host__mainLeafId`,`host`.treeRootId  AS `host__treeRootId`,`host`.nloose  AS `host__nloose`,`host`.x  AS `host__x`,`host`.y  AS `host__y`,`host`.z  AS `host__z`,`host`.vx  AS `host__vx`,`host`.vy  AS `host__vy`,`host`.vz  AS `host__vz`,`host`.np  AS `host__np`,`host`.mass  AS `host__mass`,`host`.size  AS `host__size`,`host`.spin  AS `host__spin`,`host`.ix  AS `host__ix`,`host`.iy  AS `host__iy`,`host`.iz  AS `host__iz`,`host`.phkey  AS `host__phkey` FROM MDR1.FOFSub AS `host` WHERE (  host.fofSubId = 85000000000000000 )    LIMIT 0,10', 'aggregation_tmp_72230572');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_50493134 ENGINE=MyISAM SELECT `res`.`host__fofSubId`  AS `res__host__fofSubId`,`res`.`host__fofId`  AS `res__host__fofId`,`res`.`host__level`  AS `res__host__level`,`res`.`host__NInFile`  AS `res__host__NInFile`,`res`.`host__hostId`  AS `res__host__hostId`,`res`.`host__lastSubId`  AS `res__host__lastSubId`,`res`.`host__mainLeafId`  AS `res__host__mainLeafId`,`res`.`host__treeRootId`  AS `res__host__treeRootId`,`res`.`host__nloose`  AS `res__host__nloose`,`res`.`host__x`  AS `res__host__x`,`res`.`host__y`  AS `res__host__y`,`res`.`host__z`  AS `res__host__z`,`res`.`host__vx`  AS `res__host__vx`,`res`.`host__vy`  AS `res__host__vy`,`res`.`host__vz`  AS `res__host__vz`,`res`.`host__np`  AS `res__host__np`,`res`.`host__mass`  AS `res__host__mass`,`res`.`host__size`  AS `res__host__size`,`res`.`host__spin`  AS `res__host__spin`,`res`.`host__ix`  AS `res__host__ix`,`res`.`host__iy`  AS `res__host__iy`,`res`.`host__iz`  AS `res__host__iz`,`res`.`host__phkey`  AS `res__host__phkey`
FROM ( SELECT `host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`
FROM `aggregation_tmp_72230572`    LIMIT 0,10) AS `res` WHERE (  `res`.`host__np` > 50 )    LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_50493134 SELECT `res`.`host__fofSubId`  AS `res__host__fofSubId`,`res`.`host__fofId`  AS `res__host__fofId`,`res`.`host__level`  AS `res__host__level`,`res`.`host__NInFile`  AS `res__host__NInFile`,`res`.`host__hostId`  AS `res__host__hostId`,`res`.`host__lastSubId`  AS `res__host__lastSubId`,`res`.`host__mainLeafId`  AS `res__host__mainLeafId`,`res`.`host__treeRootId`  AS `res__host__treeRootId`,`res`.`host__nloose`  AS `res__host__nloose`,`res`.`host__x`  AS `res__host__x`,`res`.`host__y`  AS `res__host__y`,`res`.`host__z`  AS `res__host__z`,`res`.`host__vx`  AS `res__host__vx`,`res`.`host__vy`  AS `res__host__vy`,`res`.`host__vz`  AS `res__host__vz`,`res`.`host__np`  AS `res__host__np`,`res`.`host__mass`  AS `res__host__mass`,`res`.`host__size`  AS `res__host__size`,`res`.`host__spin`  AS `res__host__spin`,`res`.`host__ix`  AS `res__host__ix`,`res`.`host__iy`  AS `res__host__iy`,`res`.`host__iz`  AS `res__host__iz`,`res`.`host__phkey`  AS `res__host__phkey`
FROM ( SELECT `host__fofSubId`,`host__fofId`,`host__level`,`host__NInFile`,`host__hostId`,`host__lastSubId`,`host__mainLeafId`,`host__treeRootId`,`host__nloose`,`host__x`,`host__y`,`host__z`,`host__vx`,`host__vy`,`host__vz`,`host__np`,`host__mass`,`host__size`,`host__spin`,`host__ix`,`host__iy`,`host__iz`,`host__phkey`
FROM `aggregation_tmp_72230572`    LIMIT 0,10) AS `res` WHERE (  `res`.`host__np` > 50 )   ;
CALL paquLinkTmp('aggregation_tmp_50493134');
CALL paquDropTmp('aggregation_tmp_72230572');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `res__host__fofSubId`,`res__host__fofId`,`res__host__level`,`res__host__NInFile`,`res__host__hostId`,`res__host__lastSubId`,`res__host__mainLeafId`,`res__host__treeRootId`,`res__host__nloose`,`res__host__x`,`res__host__y`,`res__host__z`,`res__host__vx`,`res__host__vy`,`res__host__vz`,`res__host__np`,`res__host__mass`,`res__host__size`,`res__host__spin`,`res__host__ix`,`res__host__iy`,`res__host__iz`,`res__host__phkey`
FROM `aggregation_tmp_50493134`   ;
CALL paquDropTmp('aggregation_tmp_50493134');
This is the query plan optimisation output for the query:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where `b`.x between a.x-25 and a.x+25 and `b`.y between a.y-25 and a.y+25 and `b`.z between a.z-25 and a.z+25

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`,`y`,`z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`,y AS `y`,z AS `z`
FROM Bolshoi.BDMV WHERE (  snapnum = 416 )    LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `x`,`y`,`z`
FROM `aggregation_tmp_31976830`    LIMIT 0,1
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`)
-- INPUT SQL:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where `b`.x between a.x-25 and a.x+25 and `b`.y between a.y-25 and a.y+25 and `b`.z between a.z-25 and a.z+25

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.vx`=VALUES(`b.vx`),
`b.vy`=VALUES(`b.vy`),
`b.vz`=VALUES(`b.vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `b`.x AS `b.x`,`b`.y AS `b.y`,`b`.z AS `b.z`,`b`.vx AS `b.vx`,`b`.vy AS `b.vy`,`b`.vz AS `b.vz`
FROM Bolshoi.particles416 AS `b` JOIN ( SELECT `x`,`y`,`z`
FROM `aggregation_tmp_31976830`    LIMIT 0,1) AS `a`  WHERE ( ``a``. `a`.`.x` between `a`.`a.x-25` and `a`.`a.x` + 25 ) ( ``a``. `a`.`.y` between `a`.`a.y-25` and `a`.`a.y` + 25 ) ( ``a``. `a`.`.z` between `a`.`a.z-25` and `a`.`a.z` + 25 )   
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`
FROM `aggregation_tmp_40673320`   
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.vx`=VALUES(`b.vx`),
`b.vy`=VALUES(`b.vy`),
`b.vz`=VALUES(`b.vz`)
This is the query plan for the query:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where `b`.x between a.x-25 and a.x+25 and `b`.y between a.y-25 and a.y+25 and `b`.z between a.z-25 and a.z+25

CALL paquExec('SELECT x AS `x`,y AS `y`,z AS `z` FROM Bolshoi.BDMV WHERE (  snapnum = 416 )    LIMIT 0,1', 'aggregation_tmp_31976830');
CALL paquExec('SELECT `b`.x AS `b.x`,`b`.y AS `b.y`,`b`.z AS `b.z`,`b`.vx AS `b.vx`,`b`.vy AS `b.vy`,`b`.vz AS `b.vz` FROM Bolshoi.particles416 AS `b` JOIN ( SELECT `x`,`y`,`z` FROM `aggregation_tmp_31976830`    LIMIT 0,1) AS `a`  WHERE ( ``a``. `a`.`.x` between `a`.`a.x-25` and `a`.`a.x` + 25 ) ( ``a``. `a`.`.y` between `a`.`a.y-25` and `a`.`a.y` + 25 ) ( ``a``. `a`.`.z` between `a`.`a.z-25` and `a`.`a.z` + 25 )   ', 'aggregation_tmp_40673320');
CALL paquDropTmp('aggregation_tmp_31976830');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`
FROM `aggregation_tmp_40673320`   ;
CALL paquDropTmp('aggregation_tmp_40673320');
This is the query plan optimisation output for the query:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where `b`.x between a.x-25 and a.x+25 and `b`.y between a.y-25 and a.y+25 and `b`.z between a.z-25 and a.z+25

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`,`y`,`z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`,y AS `y`,z AS `z`
FROM Bolshoi.BDMV WHERE (  snapnum = 416 )    LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `x`,`y`,`z`
FROM `aggregation_tmp_89913914`    LIMIT 0,1
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`)
-- INPUT SQL:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where `b`.x between a.x-25 and a.x+25 and `b`.y between a.y-25 and a.y+25 and `b`.z between a.z-25 and a.z+25

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.vx`=VALUES(`b.vx`),
`b.vy`=VALUES(`b.vy`),
`b.vz`=VALUES(`b.vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `b`.x AS `b.x`,`b`.y AS `b.y`,`b`.z AS `b.z`,`b`.vx AS `b.vx`,`b`.vy AS `b.vy`,`b`.vz AS `b.vz`
FROM Bolshoi.particles416 AS `b` JOIN ( SELECT `x`,`y`,`z`
FROM `aggregation_tmp_89913914`    LIMIT 0,1) AS `a`  WHERE ( ``a``. `a`.`.x` between `a`.`a.x-25` and `a`.`a.x` + 25 ) ( ``a``. `a`.`.y` between `a`.`a.y-25` and `a`.`a.y` + 25 ) ( ``a``. `a`.`.z` between `a`.`a.z-25` and `a`.`a.z` + 25 )   
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`
FROM `aggregation_tmp_59000699`   
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.vx`=VALUES(`b.vx`),
`b.vy`=VALUES(`b.vy`),
`b.vz`=VALUES(`b.vz`)
This is the query plan for the query:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where `b`.x between a.x-25 and a.x+25 and `b`.y between a.y-25 and a.y+25 and `b`.z between a.z-25 and a.z+25

CALL paquExec('SELECT x AS `x`,y AS `y`,z AS `z` FROM Bolshoi.BDMV WHERE (  snapnum = 416 )    LIMIT 0,1', 'aggregation_tmp_89913914');
CALL paquExec('SELECT `b`.x AS `b.x`,`b`.y AS `b.y`,`b`.z AS `b.z`,`b`.vx AS `b.vx`,`b`.vy AS `b.vy`,`b`.vz AS `b.vz` FROM Bolshoi.particles416 AS `b` JOIN ( SELECT `x`,`y`,`z` FROM `aggregation_tmp_89913914`    LIMIT 0,1) AS `a`  WHERE ( ``a``. `a`.`.x` between `a`.`a.x-25` and `a`.`a.x` + 25 ) ( ``a``. `a`.`.y` between `a`.`a.y-25` and `a`.`a.y` + 25 ) ( ``a``. `a`.`.z` between `a`.`a.z-25` and `a`.`a.z` + 25 )   ', 'aggregation_tmp_59000699');
CALL paquDropTmp('aggregation_tmp_89913914');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`
FROM `aggregation_tmp_59000699`   ;
CALL paquDropTmp('aggregation_tmp_59000699');
This is the query plan optimisation output for the query:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where `b`.x between a.x-25 and a.x+25 and `b`.y between a.y-25 and a.y+25 and `b`.z between a.z-25 and a.z+25

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`,`y`,`z`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`Mvir`=VALUES(`Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`,y AS `y`,z AS `z`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `x`,`y`,`z`,`Mvir`
FROM `aggregation_tmp_80867780`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`Mvir`=VALUES(`Mvir`)
-- INPUT SQL:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where `b`.x between a.x-25 and a.x+25 and `b`.y between a.y-25 and a.y+25 and `b`.z between a.z-25 and a.z+25

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.vx`=VALUES(`b.vx`),
`b.vy`=VALUES(`b.vy`),
`b.vz`=VALUES(`b.vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `b`.x AS `b.x`,`b`.y AS `b.y`,`b`.z AS `b.z`,`b`.vx AS `b.vx`,`b`.vy AS `b.vy`,`b`.vz AS `b.vz`
FROM Bolshoi.particles416 AS `b` JOIN ( SELECT `x`,`y`,`z`,`Mvir`
FROM `aggregation_tmp_80867780`  ORDER BY `Mvir` DESC  LIMIT 0,1) AS `a`  WHERE ( ``a``. `a`.`.x` between `a`.`a.x-25` and `a`.`a.x` + 25 ) ( ``a``. `a`.`.y` between `a`.`a.y-25` and `a`.`a.y` + 25 ) ( ``a``. `a`.`.z` between `a`.`a.z-25` and `a`.`a.z` + 25 )   
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`
FROM `aggregation_tmp_18915935`   
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.vx`=VALUES(`b.vx`),
`b.vy`=VALUES(`b.vy`),
`b.vz`=VALUES(`b.vz`)
This is the query plan for the query:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where `b`.x between a.x-25 and a.x+25 and `b`.y between a.y-25 and a.y+25 and `b`.z between a.z-25 and a.z+25

CALL paquExec('SELECT x AS `x`,y AS `y`,z AS `z`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_80867780');
CALL paquExec('SELECT `b`.x AS `b.x`,`b`.y AS `b.y`,`b`.z AS `b.z`,`b`.vx AS `b.vx`,`b`.vy AS `b.vy`,`b`.vz AS `b.vz` FROM Bolshoi.particles416 AS `b` JOIN ( SELECT `x`,`y`,`z`,`Mvir` FROM `aggregation_tmp_80867780`  ORDER BY `Mvir` DESC  LIMIT 0,1) AS `a`  WHERE ( ``a``. `a`.`.x` between `a`.`a.x-25` and `a`.`a.x` + 25 ) ( ``a``. `a`.`.y` between `a`.`a.y-25` and `a`.`a.y` + 25 ) ( ``a``. `a`.`.z` between `a`.`a.z-25` and `a`.`a.z` + 25 )   ', 'aggregation_tmp_18915935');
CALL paquDropTmp('aggregation_tmp_80867780');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`
FROM `aggregation_tmp_18915935`   ;
CALL paquDropTmp('aggregation_tmp_18915935');
This is the query plan optimisation output for the query:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where `b`.x between a.x-25 and a.x+25 and `b`.y between a.y-25 and a.y+25 and `b`.z between a.z-25 and a.z+25

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`,`y`,`z`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`Mvir`=VALUES(`Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`,y AS `y`,z AS `z`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `x`,`y`,`z`,`Mvir`
FROM `aggregation_tmp_64409051`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`Mvir`=VALUES(`Mvir`)
-- INPUT SQL:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where `b`.x between a.x-25 and a.x+25 and `b`.y between a.y-25 and a.y+25 and `b`.z between a.z-25 and a.z+25

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.vx`=VALUES(`b.vx`),
`b.vy`=VALUES(`b.vy`),
`b.vz`=VALUES(`b.vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `b`.x AS `b.x`,`b`.y AS `b.y`,`b`.z AS `b.z`,`b`.vx AS `b.vx`,`b`.vy AS `b.vy`,`b`.vz AS `b.vz`
FROM Bolshoi.particles416 AS `b` JOIN ( SELECT `x`,`y`,`z`,`Mvir`
FROM `aggregation_tmp_64409051`  ORDER BY `Mvir` DESC  LIMIT 0,1) AS `a`  WHERE ( ``a``. `a`.`.x` between `a`.`a.x-25` and `a`.`a.x` + 25 ) ( ``a``. `a`.`.y` between `a`.`a.y-25` and `a`.`a.y` + 25 ) ( ``a``. `a`.`.z` between `a`.`a.z-25` and `a`.`a.z` + 25 )   
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`
FROM `aggregation_tmp_97078976`   
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.vx`=VALUES(`b.vx`),
`b.vy`=VALUES(`b.vy`),
`b.vz`=VALUES(`b.vz`)
This is the query plan for the query:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where `b`.x between a.x-25 and a.x+25 and `b`.y between a.y-25 and a.y+25 and `b`.z between a.z-25 and a.z+25

CALL paquExec('SELECT x AS `x`,y AS `y`,z AS `z`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_64409051');
CALL paquExec('SELECT `b`.x AS `b.x`,`b`.y AS `b.y`,`b`.z AS `b.z`,`b`.vx AS `b.vx`,`b`.vy AS `b.vy`,`b`.vz AS `b.vz` FROM Bolshoi.particles416 AS `b` JOIN ( SELECT `x`,`y`,`z`,`Mvir` FROM `aggregation_tmp_64409051`  ORDER BY `Mvir` DESC  LIMIT 0,1) AS `a`  WHERE ( ``a``. `a`.`.x` between `a`.`a.x-25` and `a`.`a.x` + 25 ) ( ``a``. `a`.`.y` between `a`.`a.y-25` and `a`.`a.y` + 25 ) ( ``a``. `a`.`.z` between `a`.`a.z-25` and `a`.`a.z` + 25 )   ', 'aggregation_tmp_97078976');
CALL paquDropTmp('aggregation_tmp_64409051');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`
FROM `aggregation_tmp_97078976`   ;
CALL paquDropTmp('aggregation_tmp_97078976');
This is the query plan optimisation output for the query:
SELECT `prog`.fofTreeId AS `prog__fofTreeId`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS  `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`mainLeafId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_5756454`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`mainLeafId`=VALUES(`mainLeafId`)
-- INPUT SQL:
SELECT `prog`.fofTreeId AS `prog__fofTreeId`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS  `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog__fofTreeId`=VALUES(`prog__fofTreeId`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.fofTreeId  AS `prog__fofTreeId`,`prog`.fofId  AS `prog__fofId`,`prog`.treeSnapnum  AS `prog__treeSnapnum`,`prog`.descendantId  AS `prog__descendantId`,`prog`.lastProgId  AS `prog__lastProgId`,`prog`.mainLeafId  AS `prog__mainLeafId`,`prog`.treeRootId  AS `prog__treeRootId`,`prog`.x  AS `prog__x`,`prog`.y  AS `prog__y`,`prog`.z  AS `prog__z`,`prog`.vx  AS `prog__vx`,`prog`.vy  AS `prog__vy`,`prog`.vz  AS `prog__vz`,`prog`.np  AS `prog__np`,`prog`.mass  AS `prog__mass`,`prog`.size  AS `prog__size`,`prog`.spin  AS `prog__spin`,`prog`.ix  AS `prog__ix`,`prog`.iy  AS `prog__iy`,`prog`.iz  AS `prog__iz`,`prog`.phkey  AS `prog__phkey`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId`
FROM `aggregation_tmp_5756454`   ) AS `descend`  WHERE ( prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   
)


-- AGGREGATION SQL:
SELECT `prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`,`prog.fofTreeId`
FROM `aggregation_tmp_90881668`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog__fofTreeId`=VALUES(`prog__fofTreeId`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT `prog`.fofTreeId AS `prog__fofTreeId`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS  `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 100000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.mainLeafId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,mainLeafId AS `mainLeafId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 100000000 )   ', 'aggregation_tmp_5756454');
CALL paquExec('SELECT `prog`.fofTreeId  AS `prog__fofTreeId`,`prog`.fofId  AS `prog__fofId`,`prog`.treeSnapnum  AS `prog__treeSnapnum`,`prog`.descendantId  AS `prog__descendantId`,`prog`.lastProgId  AS `prog__lastProgId`,`prog`.mainLeafId  AS `prog__mainLeafId`,`prog`.treeRootId  AS `prog__treeRootId`,`prog`.x  AS `prog__x`,`prog`.y  AS `prog__y`,`prog`.z  AS `prog__z`,`prog`.vx  AS `prog__vx`,`prog`.vy  AS `prog__vy`,`prog`.vz  AS `prog__vz`,`prog`.np  AS `prog__np`,`prog`.mass  AS `prog__mass`,`prog`.size  AS `prog__size`,`prog`.spin  AS `prog__spin`,`prog`.ix  AS `prog__ix`,`prog`.iy  AS `prog__iy`,`prog`.iz  AS `prog__iz`,`prog`.phkey  AS `prog__phkey`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`mainLeafId` FROM `aggregation_tmp_5756454`   ) AS `descend`  WHERE ( prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`mainLeafId` )   ', 'aggregation_tmp_90881668');
CALL paquDropTmp('aggregation_tmp_5756454');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`,`prog.fofTreeId`
FROM `aggregation_tmp_90881668`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_90881668');
This is the query plan optimisation output for the query:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where `b`.x between a.x-25 and a.x+25 and `b`.y between a.y-25 and a.y+25 and `b`.z between a.z-25 and a.z+25

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`,`y`,`z`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`Mvir`=VALUES(`Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`,y AS `y`,z AS `z`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `x`,`y`,`z`,`Mvir`
FROM `aggregation_tmp_24352833`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`Mvir`=VALUES(`Mvir`)
-- INPUT SQL:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where `b`.x between a.x-25 and a.x+25 and `b`.y between a.y-25 and a.y+25 and `b`.z between a.z-25 and a.z+25

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.vx`=VALUES(`b.vx`),
`b.vy`=VALUES(`b.vy`),
`b.vz`=VALUES(`b.vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `b`.x AS `b.x`,`b`.y AS `b.y`,`b`.z AS `b.z`,`b`.vx AS `b.vx`,`b`.vy AS `b.vy`,`b`.vz AS `b.vz`
FROM Bolshoi.particles416 AS `b` JOIN ( SELECT `x`,`y`,`z`,`Mvir`
FROM `aggregation_tmp_24352833`  ORDER BY `Mvir` DESC  LIMIT 0,1) AS `a`  WHERE ( ``a``. `a`.`.x` between `a`.`a.x-25` and `a`.`a.x` + 25 ) ( ``a``. `a`.`.y` between `a`.`a.y-25` and `a`.`a.y` + 25 ) ( ``a``. `a`.`.z` between `a`.`a.z-25` and `a`.`a.z` + 25 )   
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`
FROM `aggregation_tmp_61200521`   
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.vx`=VALUES(`b.vx`),
`b.vy`=VALUES(`b.vy`),
`b.vz`=VALUES(`b.vz`)
This is the query plan for the query:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where `b`.x between a.x-25 and a.x+25 and `b`.y between a.y-25 and a.y+25 and `b`.z between a.z-25 and a.z+25

CALL paquExec('SELECT x AS `x`,y AS `y`,z AS `z`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_24352833');
CALL paquExec('SELECT `b`.x AS `b.x`,`b`.y AS `b.y`,`b`.z AS `b.z`,`b`.vx AS `b.vx`,`b`.vy AS `b.vy`,`b`.vz AS `b.vz` FROM Bolshoi.particles416 AS `b` JOIN ( SELECT `x`,`y`,`z`,`Mvir` FROM `aggregation_tmp_24352833`  ORDER BY `Mvir` DESC  LIMIT 0,1) AS `a`  WHERE ( ``a``. `a`.`.x` between `a`.`a.x-25` and `a`.`a.x` + 25 ) ( ``a``. `a`.`.y` between `a`.`a.y-25` and `a`.`a.y` + 25 ) ( ``a``. `a`.`.z` between `a`.`a.z-25` and `a`.`a.z` + 25 )   ', 'aggregation_tmp_61200521');
CALL paquDropTmp('aggregation_tmp_24352833');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`
FROM `aggregation_tmp_61200521`   ;
CALL paquDropTmp('aggregation_tmp_61200521');
This is the query plan optimisation output for the query:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where `b`.x between a.x-25 and a.x+25 and `b`.y between a.y-25 and a.y+25 and `b`.z between a.z-25 and a.z+25

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`,`y`,`z`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`Mvir`=VALUES(`Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`,y AS `y`,z AS `z`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `x`,`y`,`z`,`Mvir`
FROM `aggregation_tmp_70923277`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`Mvir`=VALUES(`Mvir`)
-- INPUT SQL:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where `b`.x between a.x-25 and a.x+25 and `b`.y between a.y-25 and a.y+25 and `b`.z between a.z-25 and a.z+25

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.vx`=VALUES(`b.vx`),
`b.vy`=VALUES(`b.vy`),
`b.vz`=VALUES(`b.vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `b`.x AS `b.x`,`b`.y AS `b.y`,`b`.z AS `b.z`,`b`.vx AS `b.vx`,`b`.vy AS `b.vy`,`b`.vz AS `b.vz`
FROM Bolshoi.particles416 AS `b` JOIN ( SELECT `x`,`y`,`z`,`Mvir`
FROM `aggregation_tmp_70923277`  ORDER BY `Mvir` DESC  LIMIT 0,1) AS `a`  WHERE ( ``a``. `a`.`.x` between `a`.`a.x-25` and `a`.`a.x` + 25 ) ( ``a``. `a`.`.y` between `a`.`a.y-25` and `a`.`a.y` + 25 ) ( ``a``. `a`.`.z` between `a`.`a.z-25` and `a`.`a.z` + 25 )   
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`
FROM `aggregation_tmp_15396183`   
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.vx`=VALUES(`b.vx`),
`b.vy`=VALUES(`b.vy`),
`b.vz`=VALUES(`b.vz`)
This is the query plan for the query:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where `b`.x between a.x-25 and a.x+25 and `b`.y between a.y-25 and a.y+25 and `b`.z between a.z-25 and a.z+25

CALL paquExec('SELECT x AS `x`,y AS `y`,z AS `z`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_70923277');
CALL paquExec('SELECT `b`.x AS `b.x`,`b`.y AS `b.y`,`b`.z AS `b.z`,`b`.vx AS `b.vx`,`b`.vy AS `b.vy`,`b`.vz AS `b.vz` FROM Bolshoi.particles416 AS `b` JOIN ( SELECT `x`,`y`,`z`,`Mvir` FROM `aggregation_tmp_70923277`  ORDER BY `Mvir` DESC  LIMIT 0,1) AS `a`  WHERE ( ``a``. `a`.`.x` between `a`.`a.x-25` and `a`.`a.x` + 25 ) ( ``a``. `a`.`.y` between `a`.`a.y-25` and `a`.`a.y` + 25 ) ( ``a``. `a`.`.z` between `a`.`a.z-25` and `a`.`a.z` + 25 )   ', 'aggregation_tmp_15396183');
CALL paquDropTmp('aggregation_tmp_70923277');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`
FROM `aggregation_tmp_15396183`   ;
CALL paquDropTmp('aggregation_tmp_15396183');
This is the query plan optimisation output for the query:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where `b`.x between a.x-25 and a.x+25 and `b`.y between a.y-25 and a.y+25 and `b`.z between a.z-25 and a.z+25

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`,`y`,`z`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`Mvir`=VALUES(`Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`,y AS `y`,z AS `z`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `x`,`y`,`z`,`Mvir`
FROM `aggregation_tmp_18858833`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`Mvir`=VALUES(`Mvir`)
-- INPUT SQL:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where `b`.x between a.x-25 and a.x+25 and `b`.y between a.y-25 and a.y+25 and `b`.z between a.z-25 and a.z+25

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.vx`=VALUES(`b.vx`),
`b.vy`=VALUES(`b.vy`),
`b.vz`=VALUES(`b.vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `b`.x AS `b.x`,`b`.y AS `b.y`,`b`.z AS `b.z`,`b`.vx AS `b.vx`,`b`.vy AS `b.vy`,`b`.vz AS `b.vz`
FROM Bolshoi.particles416 AS `b` JOIN ( SELECT `x`,`y`,`z`,`Mvir`
FROM `aggregation_tmp_18858833`  ORDER BY `Mvir` DESC  LIMIT 0,1) AS `a`  WHERE ( ``a``. `a`.`.x` between `a`.`a.x-25` and `a`.`a.x` + 25 ) ( ``a``. `a`.`.y` between `a`.`a.y-25` and `a`.`a.y` + 25 ) ( ``a``. `a`.`.z` between `a`.`a.z-25` and `a`.`a.z` + 25 )   
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`
FROM `aggregation_tmp_9197860`   
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.vx`=VALUES(`b.vx`),
`b.vy`=VALUES(`b.vy`),
`b.vz`=VALUES(`b.vz`)
This is the query plan for the query:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where `b`.x between a.x-25 and a.x+25 and `b`.y between a.y-25 and a.y+25 and `b`.z between a.z-25 and a.z+25

CALL paquExec('SELECT x AS `x`,y AS `y`,z AS `z`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_18858833');
CALL paquExec('SELECT `b`.x AS `b.x`,`b`.y AS `b.y`,`b`.z AS `b.z`,`b`.vx AS `b.vx`,`b`.vy AS `b.vy`,`b`.vz AS `b.vz` FROM Bolshoi.particles416 AS `b` JOIN ( SELECT `x`,`y`,`z`,`Mvir` FROM `aggregation_tmp_18858833`  ORDER BY `Mvir` DESC  LIMIT 0,1) AS `a`  WHERE ( ``a``. `a`.`.x` between `a`.`a.x-25` and `a`.`a.x` + 25 ) ( ``a``. `a`.`.y` between `a`.`a.y-25` and `a`.`a.y` + 25 ) ( ``a``. `a`.`.z` between `a`.`a.z-25` and `a`.`a.z` + 25 )   ', 'aggregation_tmp_9197860');
CALL paquDropTmp('aggregation_tmp_18858833');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`
FROM `aggregation_tmp_9197860`   ;
CALL paquDropTmp('aggregation_tmp_9197860');
This is the query plan optimisation output for the query:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where b.x between a.x-25 and a.x+25 and `b`.y between a.y-25 and a.y+25 and b.z between a.z-25 and a.z+25

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`,`y`,`z`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`Mvir`=VALUES(`Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`,y AS `y`,z AS `z`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `x`,`y`,`z`,`Mvir`
FROM `aggregation_tmp_4359676`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`Mvir`=VALUES(`Mvir`)
-- INPUT SQL:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where b.x between a.x-25 and a.x+25 and `b`.y between a.y-25 and a.y+25 and b.z between a.z-25 and a.z+25

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.vx`=VALUES(`b.vx`),
`b.vy`=VALUES(`b.vy`),
`b.vz`=VALUES(`b.vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `b`.x AS `b.x`,`b`.y AS `b.y`,`b`.z AS `b.z`,`b`.vx AS `b.vx`,`b`.vy AS `b.vy`,`b`.vz AS `b.vz`
FROM Bolshoi.particles416 AS `b` JOIN ( SELECT `x`,`y`,`z`,`Mvir`
FROM `aggregation_tmp_4359676`  ORDER BY `Mvir` DESC  LIMIT 0,1) AS `a`  WHERE ( ``a``. `a`.`.y` between `a`.`a.y-25` and `a`.`a.y` + 25 )   
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`
FROM `aggregation_tmp_82658435`   
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.vx`=VALUES(`b.vx`),
`b.vy`=VALUES(`b.vy`),
`b.vz`=VALUES(`b.vz`)
This is the query plan for the query:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where b.x between a.x-25 and a.x+25 and `b`.y between a.y-25 and a.y+25 and b.z between a.z-25 and a.z+25

CALL paquExec('SELECT x AS `x`,y AS `y`,z AS `z`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_4359676');
CALL paquExec('SELECT `b`.x AS `b.x`,`b`.y AS `b.y`,`b`.z AS `b.z`,`b`.vx AS `b.vx`,`b`.vy AS `b.vy`,`b`.vz AS `b.vz` FROM Bolshoi.particles416 AS `b` JOIN ( SELECT `x`,`y`,`z`,`Mvir` FROM `aggregation_tmp_4359676`  ORDER BY `Mvir` DESC  LIMIT 0,1) AS `a`  WHERE ( ``a``. `a`.`.y` between `a`.`a.y-25` and `a`.`a.y` + 25 )   ', 'aggregation_tmp_82658435');
CALL paquDropTmp('aggregation_tmp_4359676');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`
FROM `aggregation_tmp_82658435`   ;
CALL paquDropTmp('aggregation_tmp_82658435');
This is the query plan optimisation output for the query:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where b.x between a.x - 25 and a.x + 25 and b.y between a.y - 25 and a.y + 25 and b.z > a.z-25

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`,`y`,`z`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`Mvir`=VALUES(`Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`,y AS `y`,z AS `z`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `x`,`y`,`z`,`Mvir`
FROM `aggregation_tmp_65507751`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`Mvir`=VALUES(`Mvir`)
-- INPUT SQL:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where b.x between a.x - 25 and a.x + 25 and b.y between a.y - 25 and a.y + 25 and b.z > a.z-25

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.vx`=VALUES(`b.vx`),
`b.vy`=VALUES(`b.vy`),
`b.vz`=VALUES(`b.vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `b`.x AS `b.x`,`b`.y AS `b.y`,`b`.z AS `b.z`,`b`.vx AS `b.vx`,`b`.vy AS `b.vy`,`b`.vz AS `b.vz`
FROM Bolshoi.particles416 AS `b` JOIN ( SELECT `x`,`y`,`z`,`Mvir`
FROM `aggregation_tmp_65507751`  ORDER BY `Mvir` DESC  LIMIT 0,1) AS `a`  WHERE (  b.x between `a`.`a.x` - 25 and `a`.`a.x` + 25 ) and (  b.y between `a`.`a.y` - 25 and `a`.`a.y` + 25 ) and (  b.z > `a`.`a.z-25` )   
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`
FROM `aggregation_tmp_2069874`   
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.vx`=VALUES(`b.vx`),
`b.vy`=VALUES(`b.vy`),
`b.vz`=VALUES(`b.vz`)
This is the query plan for the query:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where b.x between a.x - 25 and a.x + 25 and b.y between a.y - 25 and a.y + 25 and b.z > a.z-25

CALL paquExec('SELECT x AS `x`,y AS `y`,z AS `z`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_65507751');
CALL paquExec('SELECT `b`.x AS `b.x`,`b`.y AS `b.y`,`b`.z AS `b.z`,`b`.vx AS `b.vx`,`b`.vy AS `b.vy`,`b`.vz AS `b.vz` FROM Bolshoi.particles416 AS `b` JOIN ( SELECT `x`,`y`,`z`,`Mvir` FROM `aggregation_tmp_65507751`  ORDER BY `Mvir` DESC  LIMIT 0,1) AS `a`  WHERE (  b.x between `a`.`a.x` - 25 and `a`.`a.x` + 25 ) and (  b.y between `a`.`a.y` - 25 and `a`.`a.y` + 25 ) and (  b.z > `a`.`a.z-25` )   ', 'aggregation_tmp_2069874');
CALL paquDropTmp('aggregation_tmp_65507751');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`
FROM `aggregation_tmp_2069874`   ;
CALL paquDropTmp('aggregation_tmp_2069874');
This is the query plan optimisation output for the query:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where b.x between a.x - 25 and a.x + 25 and b.y between a.y - 25 and a.y + 25 and b.z > a.z-25

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`,`y`,`z`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`Mvir`=VALUES(`Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`,y AS `y`,z AS `z`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `x`,`y`,`z`,`Mvir`
FROM `aggregation_tmp_41313097`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`Mvir`=VALUES(`Mvir`)
-- INPUT SQL:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where b.x between a.x - 25 and a.x + 25 and b.y between a.y - 25 and a.y + 25 and b.z > a.z-25

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.vx`=VALUES(`b.vx`),
`b.vy`=VALUES(`b.vy`),
`b.vz`=VALUES(`b.vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `b`.x AS `b.x`,`b`.y AS `b.y`,`b`.z AS `b.z`,`b`.vx AS `b.vx`,`b`.vy AS `b.vy`,`b`.vz AS `b.vz`
FROM Bolshoi.particles416 AS `b` JOIN ( SELECT `x`,`y`,`z`,`Mvir`
FROM `aggregation_tmp_41313097`  ORDER BY `Mvir` DESC  LIMIT 0,1) AS `a`  WHERE (  b.x between `a`.`x` - 25 and `a`.`x` + 25 ) and (  b.y between `a`.`y` - 25 and `a`.`y` + 25 ) and (  b.z > `a`.`a.z-25` )   
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`
FROM `aggregation_tmp_19820138`   
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.vx`=VALUES(`b.vx`),
`b.vy`=VALUES(`b.vy`),
`b.vz`=VALUES(`b.vz`)
This is the query plan for the query:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where b.x between a.x - 25 and a.x + 25 and b.y between a.y - 25 and a.y + 25 and b.z > a.z-25

CALL paquExec('SELECT x AS `x`,y AS `y`,z AS `z`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_41313097');
CALL paquExec('SELECT `b`.x AS `b.x`,`b`.y AS `b.y`,`b`.z AS `b.z`,`b`.vx AS `b.vx`,`b`.vy AS `b.vy`,`b`.vz AS `b.vz` FROM Bolshoi.particles416 AS `b` JOIN ( SELECT `x`,`y`,`z`,`Mvir` FROM `aggregation_tmp_41313097`  ORDER BY `Mvir` DESC  LIMIT 0,1) AS `a`  WHERE (  b.x between `a`.`x` - 25 and `a`.`x` + 25 ) and (  b.y between `a`.`y` - 25 and `a`.`y` + 25 ) and (  b.z > `a`.`a.z-25` )   ', 'aggregation_tmp_19820138');
CALL paquDropTmp('aggregation_tmp_41313097');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`
FROM `aggregation_tmp_19820138`   ;
CALL paquDropTmp('aggregation_tmp_19820138');
This is the query plan optimisation output for the query:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where b.x between a.x - 25 and a.x + 25 and b.y between a.y - 25 and a.y + 25 and b.z > a.z-25

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`,`y`,`z`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`Mvir`=VALUES(`Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`,y AS `y`,z AS `z`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `x`,`y`,`z`,`Mvir`
FROM `aggregation_tmp_13886896`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`Mvir`=VALUES(`Mvir`)
-- INPUT SQL:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where b.x between a.x - 25 and a.x + 25 and b.y between a.y - 25 and a.y + 25 and b.z > a.z-25

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.vx`=VALUES(`b.vx`),
`b.vy`=VALUES(`b.vy`),
`b.vz`=VALUES(`b.vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `b`.x AS `b.x`,`b`.y AS `b.y`,`b`.z AS `b.z`,`b`.vx AS `b.vx`,`b`.vy AS `b.vy`,`b`.vz AS `b.vz`
FROM Bolshoi.particles416 AS `b` JOIN ( SELECT `x`,`y`,`z`,`Mvir`
FROM `aggregation_tmp_13886896`  ORDER BY `Mvir` DESC  LIMIT 0,1) AS `a`  WHERE (  b.x between `a`.`x` - 25 and `a`.`x` + 25 ) and (  b.y between `a`.`y` - 25 and `a`.`y` + 25 ) and (  b.z > `a`.`a.z-25` )   
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`
FROM `aggregation_tmp_86032861`   
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.vx`=VALUES(`b.vx`),
`b.vy`=VALUES(`b.vy`),
`b.vz`=VALUES(`b.vz`)
This is the query plan for the query:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where b.x between a.x - 25 and a.x + 25 and b.y between a.y - 25 and a.y + 25 and b.z > a.z-25

CALL paquExec('SELECT x AS `x`,y AS `y`,z AS `z`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_13886896');
CALL paquExec('SELECT `b`.x AS `b.x`,`b`.y AS `b.y`,`b`.z AS `b.z`,`b`.vx AS `b.vx`,`b`.vy AS `b.vy`,`b`.vz AS `b.vz` FROM Bolshoi.particles416 AS `b` JOIN ( SELECT `x`,`y`,`z`,`Mvir` FROM `aggregation_tmp_13886896`  ORDER BY `Mvir` DESC  LIMIT 0,1) AS `a`  WHERE (  b.x between `a`.`x` - 25 and `a`.`x` + 25 ) and (  b.y between `a`.`y` - 25 and `a`.`y` + 25 ) and (  b.z > `a`.`a.z-25` )   ', 'aggregation_tmp_86032861');
CALL paquDropTmp('aggregation_tmp_13886896');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`
FROM `aggregation_tmp_86032861`   ;
CALL paquDropTmp('aggregation_tmp_86032861');
This is the query plan optimisation output for the query:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where b.x between a.x - 25 and a.x + 25 and b.y between a.y - 25 and a.y + 25 and b.z > a.z-25

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`,`y`,`z`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`Mvir`=VALUES(`Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`,y AS `y`,z AS `z`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `x`,`y`,`z`,`Mvir`
FROM `aggregation_tmp_49008363`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`Mvir`=VALUES(`Mvir`)
-- INPUT SQL:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where b.x between a.x - 25 and a.x + 25 and b.y between a.y - 25 and a.y + 25 and b.z > a.z-25

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.vx`=VALUES(`b.vx`),
`b.vy`=VALUES(`b.vy`),
`b.vz`=VALUES(`b.vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `b`.x AS `b.x`,`b`.y AS `b.y`,`b`.z AS `b.z`,`b`.vx AS `b.vx`,`b`.vy AS `b.vy`,`b`.vz AS `b.vz`
FROM Bolshoi.particles416 AS `b` JOIN ( SELECT `x`,`y`,`z`,`Mvir`
FROM `aggregation_tmp_49008363`  ORDER BY `Mvir` DESC  LIMIT 0,1) AS `a`  WHERE (  b.x between `a`.`x` - 25 and `a`.`x` + 25 ) and (  b.y between `a`.`y` - 25 and `a`.`y` + 25 ) and (  b.z > `a`.`a.z-25` )   
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`
FROM `aggregation_tmp_23426680`   
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.vx`=VALUES(`b.vx`),
`b.vy`=VALUES(`b.vy`),
`b.vz`=VALUES(`b.vz`)
This is the query plan for the query:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where b.x between a.x - 25 and a.x + 25 and b.y between a.y - 25 and a.y + 25 and b.z > a.z-25

CALL paquExec('SELECT x AS `x`,y AS `y`,z AS `z`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_49008363');
CALL paquExec('SELECT `b`.x AS `b.x`,`b`.y AS `b.y`,`b`.z AS `b.z`,`b`.vx AS `b.vx`,`b`.vy AS `b.vy`,`b`.vz AS `b.vz` FROM Bolshoi.particles416 AS `b` JOIN ( SELECT `x`,`y`,`z`,`Mvir` FROM `aggregation_tmp_49008363`  ORDER BY `Mvir` DESC  LIMIT 0,1) AS `a`  WHERE (  b.x between `a`.`x` - 25 and `a`.`x` + 25 ) and (  b.y between `a`.`y` - 25 and `a`.`y` + 25 ) and (  b.z > `a`.`a.z-25` )   ', 'aggregation_tmp_23426680');
CALL paquDropTmp('aggregation_tmp_49008363');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`
FROM `aggregation_tmp_23426680`   ;
CALL paquDropTmp('aggregation_tmp_23426680');
This is the query plan optimisation output for the query:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where `b`.x between a.x-25 and a.x+25 and `b`.y between a.y-25 and a.y+25 and `b`.z between a.z-25 and a.z+25

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`,`y`,`z`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`Mvir`=VALUES(`Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`,y AS `y`,z AS `z`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `x`,`y`,`z`,`Mvir`
FROM `aggregation_tmp_818985`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`Mvir`=VALUES(`Mvir`)
-- INPUT SQL:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where `b`.x between a.x-25 and a.x+25 and `b`.y between a.y-25 and a.y+25 and `b`.z between a.z-25 and a.z+25

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.vx`=VALUES(`b.vx`),
`b.vy`=VALUES(`b.vy`),
`b.vz`=VALUES(`b.vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `b`.x AS `b.x`,`b`.y AS `b.y`,`b`.z AS `b.z`,`b`.vx AS `b.vx`,`b`.vy AS `b.vy`,`b`.vz AS `b.vz`
FROM Bolshoi.particles416 AS `b` JOIN ( SELECT `x`,`y`,`z`,`Mvir`
FROM `aggregation_tmp_818985`  ORDER BY `Mvir` DESC  LIMIT 0,1) AS `a`  WHERE (  `b` `a`.`x` between `a`.`a.x-25` and `a`.`x` + 25 ) (  `b` `a`.`y` between `a`.`a.y-25` and `a`.`y` + 25 ) (  `b` `a`.`z` between `a`.`a.z-25` and `a`.`z` + 25 )   
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`
FROM `aggregation_tmp_67678294`   
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.vx`=VALUES(`b.vx`),
`b.vy`=VALUES(`b.vy`),
`b.vz`=VALUES(`b.vz`)
This is the query plan for the query:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where `b`.x between a.x-25 and a.x+25 and `b`.y between a.y-25 and a.y+25 and `b`.z between a.z-25 and a.z+25

CALL paquExec('SELECT x AS `x`,y AS `y`,z AS `z`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_818985');
CALL paquExec('SELECT `b`.x AS `b.x`,`b`.y AS `b.y`,`b`.z AS `b.z`,`b`.vx AS `b.vx`,`b`.vy AS `b.vy`,`b`.vz AS `b.vz` FROM Bolshoi.particles416 AS `b` JOIN ( SELECT `x`,`y`,`z`,`Mvir` FROM `aggregation_tmp_818985`  ORDER BY `Mvir` DESC  LIMIT 0,1) AS `a`  WHERE (  `b` `a`.`x` between `a`.`a.x-25` and `a`.`x` + 25 ) (  `b` `a`.`y` between `a`.`a.y-25` and `a`.`y` + 25 ) (  `b` `a`.`z` between `a`.`a.z-25` and `a`.`z` + 25 )   ', 'aggregation_tmp_67678294');
CALL paquDropTmp('aggregation_tmp_818985');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`
FROM `aggregation_tmp_67678294`   ;
CALL paquDropTmp('aggregation_tmp_67678294');
This is the query plan optimisation output for the query:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where `b`.x between a.x - 25 and a.x + 25 and `b`.y between a.y - 25 and a.y + 25 and `b`.z between a.z - 25 and a.z + 25

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`,`y`,`z`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`Mvir`=VALUES(`Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`,y AS `y`,z AS `z`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `x`,`y`,`z`,`Mvir`
FROM `aggregation_tmp_86201805`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`Mvir`=VALUES(`Mvir`)
-- INPUT SQL:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where `b`.x between a.x - 25 and a.x + 25 and `b`.y between a.y - 25 and a.y + 25 and `b`.z between a.z - 25 and a.z + 25

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.vx`=VALUES(`b.vx`),
`b.vy`=VALUES(`b.vy`),
`b.vz`=VALUES(`b.vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `b`.x AS `b.x`,`b`.y AS `b.y`,`b`.z AS `b.z`,`b`.vx AS `b.vx`,`b`.vy AS `b.vy`,`b`.vz AS `b.vz`
FROM Bolshoi.particles416 AS `b` JOIN ( SELECT `x`,`y`,`z`,`Mvir`
FROM `aggregation_tmp_86201805`  ORDER BY `Mvir` DESC  LIMIT 0,1) AS `a`  WHERE (  `b` `a`.`x` between `a`.`x` - 25 and `a`.`x` + 25 ) (  `b` `a`.`y` between `a`.`y` - 25 and `a`.`y` + 25 ) (  `b` `a`.`z` between `a`.`z` - 25 and `a`.`z` + 25 )   
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`
FROM `aggregation_tmp_31100205`   
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.vx`=VALUES(`b.vx`),
`b.vy`=VALUES(`b.vy`),
`b.vz`=VALUES(`b.vz`)
This is the query plan for the query:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where `b`.x between a.x - 25 and a.x + 25 and `b`.y between a.y - 25 and a.y + 25 and `b`.z between a.z - 25 and a.z + 25

CALL paquExec('SELECT x AS `x`,y AS `y`,z AS `z`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_86201805');
CALL paquExec('SELECT `b`.x AS `b.x`,`b`.y AS `b.y`,`b`.z AS `b.z`,`b`.vx AS `b.vx`,`b`.vy AS `b.vy`,`b`.vz AS `b.vz` FROM Bolshoi.particles416 AS `b` JOIN ( SELECT `x`,`y`,`z`,`Mvir` FROM `aggregation_tmp_86201805`  ORDER BY `Mvir` DESC  LIMIT 0,1) AS `a`  WHERE (  `b` `a`.`x` between `a`.`x` - 25 and `a`.`x` + 25 ) (  `b` `a`.`y` between `a`.`y` - 25 and `a`.`y` + 25 ) (  `b` `a`.`z` between `a`.`z` - 25 and `a`.`z` + 25 )   ', 'aggregation_tmp_31100205');
CALL paquDropTmp('aggregation_tmp_86201805');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`
FROM `aggregation_tmp_31100205`   ;
CALL paquDropTmp('aggregation_tmp_31100205');
This is the query plan optimisation output for the query:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where b.x between a.x - 25 and a.x + 25 and b.y between a.y - 25 and a.y + 25 and b.z between a.z - 25 and a.z + 25

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`,`y`,`z`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`Mvir`=VALUES(`Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`,y AS `y`,z AS `z`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `x`,`y`,`z`,`Mvir`
FROM `aggregation_tmp_32686860`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`Mvir`=VALUES(`Mvir`)
-- INPUT SQL:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where b.x between a.x - 25 and a.x + 25 and b.y between a.y - 25 and a.y + 25 and b.z between a.z - 25 and a.z + 25

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.vx`=VALUES(`b.vx`),
`b.vy`=VALUES(`b.vy`),
`b.vz`=VALUES(`b.vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `b`.x AS `b.x`,`b`.y AS `b.y`,`b`.z AS `b.z`,`b`.vx AS `b.vx`,`b`.vy AS `b.vy`,`b`.vz AS `b.vz`
FROM Bolshoi.particles416 AS `b` JOIN ( SELECT `x`,`y`,`z`,`Mvir`
FROM `aggregation_tmp_32686860`  ORDER BY `Mvir` DESC  LIMIT 0,1) AS `a`  WHERE (  b.x between `a`.`x` - 25 and `a`.`x` + 25 ) and (  b.y between `a`.`y` - 25 and `a`.`y` + 25 ) and (  b.z between `a`.`z` - 25 and `a`.`z` + 25 )   
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`
FROM `aggregation_tmp_61077589`   
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.vx`=VALUES(`b.vx`),
`b.vy`=VALUES(`b.vy`),
`b.vz`=VALUES(`b.vz`)
This is the query plan for the query:
select `b`.x, `b`.y, `b`.z, `b`.vx, `b`.vy, `b`.vz from Bolshoi.particles416 as `b`, (select x, y, z from Bolshoi.BDMV where snapnum=416 order by Mvir desc limit 1) as `a` where b.x between a.x - 25 and a.x + 25 and b.y between a.y - 25 and a.y + 25 and b.z between a.z - 25 and a.z + 25

CALL paquExec('SELECT x AS `x`,y AS `y`,z AS `z`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_32686860');
CALL paquExec('SELECT `b`.x AS `b.x`,`b`.y AS `b.y`,`b`.z AS `b.z`,`b`.vx AS `b.vx`,`b`.vy AS `b.vy`,`b`.vz AS `b.vz` FROM Bolshoi.particles416 AS `b` JOIN ( SELECT `x`,`y`,`z`,`Mvir` FROM `aggregation_tmp_32686860`  ORDER BY `Mvir` DESC  LIMIT 0,1) AS `a`  WHERE (  b.x between `a`.`x` - 25 and `a`.`x` + 25 ) and (  b.y between `a`.`y` - 25 and `a`.`y` + 25 ) and (  b.z between `a`.`z` - 25 and `a`.`z` + 25 )   ', 'aggregation_tmp_61077589');
CALL paquDropTmp('aggregation_tmp_32686860');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `b.x`,`b.y`,`b.z`,`b.vx`,`b.vy`,`b.vz`
FROM `aggregation_tmp_61077589`   ;
CALL paquDropTmp('aggregation_tmp_61077589');
This is the query plan optimisation output for the query:
SELECT MDR1.redshifts.snapnum  AS `MDR1__redshifts__snapnum`,MDR1.redshifts.aexp  AS `MDR1__redshifts__aexp`,MDR1.redshifts.zred  AS `MDR1__redshifts__zred` FROM MDR1.redshifts

-- INPUT SQL:
SELECT MDR1.redshifts.snapnum  AS `MDR1__redshifts__snapnum`,MDR1.redshifts.aexp  AS `MDR1__redshifts__aexp`,MDR1.redshifts.zred  AS `MDR1__redshifts__zred` FROM MDR1.redshifts

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`MDR1__redshifts__snapnum`,`MDR1__redshifts__aexp`,`MDR1__redshifts__zred`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`MDR1__redshifts__snapnum`=VALUES(`MDR1__redshifts__snapnum`),
`MDR1__redshifts__aexp`=VALUES(`MDR1__redshifts__aexp`),
`MDR1__redshifts__zred`=VALUES(`MDR1__redshifts__zred`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT MDR1.redshifts.snapnum  AS `MDR1__redshifts__snapnum`,MDR1.redshifts.aexp  AS `MDR1__redshifts__aexp`,MDR1.redshifts.zred  AS `MDR1__redshifts__zred`
FROM MDR1.redshifts ORDER BY NULL 
)


-- AGGREGATION SQL:
SELECT `MDR1__redshifts__snapnum`,`MDR1__redshifts__aexp`,`MDR1__redshifts__zred`
FROM `aggregation_tmp_84371331`   
ON DUPLICATE KEY UPDATE
`MDR1__redshifts__snapnum`=VALUES(`MDR1__redshifts__snapnum`),
`MDR1__redshifts__aexp`=VALUES(`MDR1__redshifts__aexp`),
`MDR1__redshifts__zred`=VALUES(`MDR1__redshifts__zred`)
This is the query plan for the query:
SELECT MDR1.redshifts.snapnum  AS `MDR1__redshifts__snapnum`,MDR1.redshifts.aexp  AS `MDR1__redshifts__aexp`,MDR1.redshifts.zred  AS `MDR1__redshifts__zred` FROM MDR1.redshifts

CALL paquExec('SELECT MDR1.redshifts.snapnum  AS `MDR1__redshifts__snapnum`,MDR1.redshifts.aexp  AS `MDR1__redshifts__aexp`,MDR1.redshifts.zred  AS `MDR1__redshifts__zred` FROM MDR1.redshifts ORDER BY NULL ', 'aggregation_tmp_84371331');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `MDR1__redshifts__snapnum`,`MDR1__redshifts__aexp`,`MDR1__redshifts__zred`
FROM `aggregation_tmp_84371331`   ;
CALL paquDropTmp('aggregation_tmp_84371331');
This is the query plan optimisation output for the query:
SELECT DISTINCT MDR1.redshifts.snapnum  AS `MDR1__redshifts__snapnum`,MDR1.redshifts.aexp  AS `MDR1__redshifts__aexp`,MDR1.redshifts.zred  AS `MDR1__redshifts__zred` FROM MDR1.redshifts

-- INPUT SQL:
SELECT DISTINCT MDR1.redshifts.snapnum  AS `MDR1__redshifts__snapnum`,MDR1.redshifts.aexp  AS `MDR1__redshifts__aexp`,MDR1.redshifts.zred  AS `MDR1__redshifts__zred` FROM MDR1.redshifts

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`MDR1__redshifts__snapnum`,`MDR1__redshifts__aexp`,`MDR1__redshifts__zred`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`MDR1__redshifts__snapnum`=VALUES(`MDR1__redshifts__snapnum`),
`MDR1__redshifts__aexp`=VALUES(`MDR1__redshifts__aexp`),
`MDR1__redshifts__zred`=VALUES(`MDR1__redshifts__zred`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT DISTINCT MDR1.redshifts.snapnum  AS `MDR1__redshifts__snapnum`,MDR1.redshifts.aexp  AS `MDR1__redshifts__aexp`,MDR1.redshifts.zred  AS `MDR1__redshifts__zred`
FROM MDR1.redshifts ORDER BY NULL 
)


-- AGGREGATION SQL:
SELECT DISTINCT `MDR1__redshifts__snapnum`,`MDR1__redshifts__aexp`,`MDR1__redshifts__zred`
FROM `aggregation_tmp_97731689`   
ON DUPLICATE KEY UPDATE
`MDR1__redshifts__snapnum`=VALUES(`MDR1__redshifts__snapnum`),
`MDR1__redshifts__aexp`=VALUES(`MDR1__redshifts__aexp`),
`MDR1__redshifts__zred`=VALUES(`MDR1__redshifts__zred`)
This is the query plan for the query:
SELECT DISTINCT MDR1.redshifts.snapnum  AS `MDR1__redshifts__snapnum`,MDR1.redshifts.aexp  AS `MDR1__redshifts__aexp`,MDR1.redshifts.zred  AS `MDR1__redshifts__zred` FROM MDR1.redshifts

CALL paquExec('SELECT DISTINCT MDR1.redshifts.snapnum  AS `MDR1__redshifts__snapnum`,MDR1.redshifts.aexp  AS `MDR1__redshifts__aexp`,MDR1.redshifts.zred  AS `MDR1__redshifts__zred` FROM MDR1.redshifts ORDER BY NULL ', 'aggregation_tmp_97731689');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT DISTINCT `MDR1__redshifts__snapnum`,`MDR1__redshifts__aexp`,`MDR1__redshifts__zred`
FROM `aggregation_tmp_97731689`   ;
CALL paquDropTmp('aggregation_tmp_97731689');
This is the query plan optimisation output for the query:
select `a`.`fp.fofId` from `multidark_user_kristin`.`check-fp52` as a limit 10

-- INPUT SQL:
select `a`.`fp.fofId` from `multidark_user_kristin`.`check-fp52` as a limit 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`a.fp.fofId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`a.fp.fofId`=VALUES(`a.fp.fofId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `a`.`fp.fofId` AS `a.fp.fofId`
FROM `multidark_user_kristin`.`check-fp52` AS `a` ORDER BY NULL  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `a.fp.fofId`
FROM `aggregation_tmp_69007358`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`a.fp.fofId`=VALUES(`a.fp.fofId`)
This is the query plan for the query:
select `a`.`fp.fofId` from `multidark_user_kristin`.`check-fp52` as a limit 10

CALL paquExec('SELECT `a`.`fp.fofId` AS `a.fp.fofId` FROM `multidark_user_kristin`.`check-fp52` AS `a` ORDER BY NULL  LIMIT 0,10', 'aggregation_tmp_69007358');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `a.fp.fofId`
FROM `aggregation_tmp_69007358`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_69007358');
This is the query plan optimisation output for the query:
select `fp.fofId` from `multidark_user_kristin`.`check-fp52` limit 10

-- INPUT SQL:
select `fp.fofId` from `multidark_user_kristin`.`check-fp52` limit 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fp.fofId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fp.fofId`=VALUES(`fp.fofId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `fp.fofId` AS `fp.fofId`
FROM `multidark_user_kristin`.`check-fp52` ORDER BY NULL  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `fp.fofId`
FROM `aggregation_tmp_39523305`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`fp.fofId`=VALUES(`fp.fofId`)
This is the query plan for the query:
select `fp.fofId` from `multidark_user_kristin`.`check-fp52` limit 10

CALL paquExec('SELECT `fp.fofId` AS `fp.fofId` FROM `multidark_user_kristin`.`check-fp52` ORDER BY NULL  LIMIT 0,10', 'aggregation_tmp_39523305');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `fp.fofId`
FROM `aggregation_tmp_39523305`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_39523305');
This is the query plan optimisation output for the query:
select `a`.`fp.fofId` from `multidark_user_kristin`.`check-fp52` as a limit 10

-- INPUT SQL:
select `a`.`fp.fofId` from `multidark_user_kristin`.`check-fp52` as a limit 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`a.fp.fofId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`a.fp.fofId`=VALUES(`a.fp.fofId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `a`.`fp.fofId` AS `a.fp.fofId`
FROM `multidark_user_kristin`.`check-fp52` AS `a` ORDER BY NULL  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `a.fp.fofId`
FROM `aggregation_tmp_90266260`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`a.fp.fofId`=VALUES(`a.fp.fofId`)
This is the query plan for the query:
select `a`.`fp.fofId` from `multidark_user_kristin`.`check-fp52` as a limit 10

CALL paquExec('SELECT `a`.`fp.fofId` AS `a.fp.fofId` FROM `multidark_user_kristin`.`check-fp52` AS `a` ORDER BY NULL  LIMIT 0,10', 'aggregation_tmp_90266260');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `a.fp.fofId`
FROM `aggregation_tmp_90266260`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_90266260');
This is the query plan optimisation output for the query:
select `a`.`MDR1__FOF__snapnum` from `multidark_user_guest`.`tmp2` as a

-- INPUT SQL:
select `a`.`MDR1__FOF__snapnum` from `multidark_user_guest`.`tmp2` as a

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`a.MDR1__FOF__snapnum`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`a.MDR1__FOF__snapnum`=VALUES(`a.MDR1__FOF__snapnum`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `a`.`MDR1__FOF__snapnum` AS `a.MDR1__FOF__snapnum`
FROM `multidark_user_guest`.`tmp2` AS `a` ORDER BY NULL 
)


-- AGGREGATION SQL:
SELECT `a.MDR1__FOF__snapnum`
FROM `aggregation_tmp_54155037`   
ON DUPLICATE KEY UPDATE
`a.MDR1__FOF__snapnum`=VALUES(`a.MDR1__FOF__snapnum`)
This is the query plan for the query:
select `a`.`MDR1__FOF__snapnum` from `multidark_user_guest`.`tmp2` as a

CALL paquExec('SELECT `a`.`MDR1__FOF__snapnum` AS `a.MDR1__FOF__snapnum` FROM `multidark_user_guest`.`tmp2` AS `a` ORDER BY NULL ', 'aggregation_tmp_54155037');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `a.MDR1__FOF__snapnum`
FROM `aggregation_tmp_54155037`   ;
CALL paquDropTmp('aggregation_tmp_54155037');
This is the query plan optimisation output for the query:
SELECT LOG10(YX*SQRT(2)) AS logYX FROM MDR1.BDMWMfreq WHERE snapnum=74

-- INPUT SQL:
SELECT LOG10(YX*SQRT(2)) AS logYX FROM MDR1.BDMWMfreq WHERE snapnum=74

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`logYX`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`logYX`=VALUES(`logYX`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT LOG10(YX*SQRT(2))  AS `logYX`
FROM MDR1.BDMWMfreq WHERE (  snapnum = 74 )   
)


-- AGGREGATION SQL:
SELECT `logYX`
FROM `aggregation_tmp_26847159`   
ON DUPLICATE KEY UPDATE
`logYX`=VALUES(`logYX`)
This is the query plan for the query:
SELECT LOG10(YX*SQRT(2)) AS logYX FROM MDR1.BDMWMfreq WHERE snapnum=74

CALL paquExec('SELECT LOG10(YX*SQRT(2))  AS `logYX` FROM MDR1.BDMWMfreq WHERE (  snapnum = 74 )   ', 'aggregation_tmp_26847159');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `logYX`
FROM `aggregation_tmp_26847159`   ;
CALL paquDropTmp('aggregation_tmp_26847159');
This is the query plan optimisation output for the query:
select * from `GUMS10`.`MW` where magG >= 15.0 and magG <= 15.01 ORDER BY magG ASC

-- INPUT SQL:
select * from `GUMS10`.`MW` where magG >= 15.0 and magG <= 15.01 ORDER BY magG ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`,`magG`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`magG`=VALUES(`magG`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,magG AS `magG`
FROM `GUMS10`.`MW` WHERE (  magG >= 15.0 ) (  magG <= 15.01 )   
)


-- AGGREGATION SQL:
SELECT `*`,`magG`
FROM `aggregation_tmp_41218478`  ORDER BY `magG` ASC 
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`magG`=VALUES(`magG`)
This is the query plan for the query:
select * from `GUMS10`.`MW` where magG >= 15.0 and magG <= 15.01 ORDER BY magG ASC

CALL paquExec('SELECT * AS `*`,magG AS `magG` FROM `GUMS10`.`MW` WHERE (  magG >= 15.0 ) (  magG <= 15.01 )   ', 'aggregation_tmp_41218478');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `*`,`magG`
FROM `aggregation_tmp_41218478`  ORDER BY `magG` ASC ;
CALL paquDropTmp('aggregation_tmp_41218478');
This is the query plan optimisation output for the query:
select * from `GUMS10`.`MW` where magG >= 15.0 and magG <= 15.01 ORDER BY magG ASC

-- INPUT SQL:
select * from `GUMS10`.`MW` where magG >= 15.0 and magG <= 15.01 ORDER BY magG ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`,`magG`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`magG`=VALUES(`magG`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,magG AS `magG`
FROM `GUMS10`.`MW` WHERE (  magG >= 15.0 ) and (  magG <= 15.01 )   
)


-- AGGREGATION SQL:
SELECT `*`,`magG`
FROM `aggregation_tmp_67101377`  ORDER BY `magG` ASC 
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`magG`=VALUES(`magG`)
This is the query plan for the query:
select * from `GUMS10`.`MW` where magG >= 15.0 and magG <= 15.01 ORDER BY magG ASC

CALL paquExec('SELECT * AS `*`,magG AS `magG` FROM `GUMS10`.`MW` WHERE (  magG >= 15.0 ) and (  magG <= 15.01 )   ', 'aggregation_tmp_67101377');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `*`,`magG`
FROM `aggregation_tmp_67101377`  ORDER BY `magG` ASC ;
CALL paquDropTmp('aggregation_tmp_67101377');
This is the query plan optimisation output for the query:
select * from `GUMS10`.`MW` where magG >= 15.0 or magG <= 15.01 ORDER BY magG ASC

-- INPUT SQL:
select * from `GUMS10`.`MW` where magG >= 15.0 or magG <= 15.01 ORDER BY magG ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`,`magG`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`magG`=VALUES(`magG`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,magG AS `magG`
FROM `GUMS10`.`MW` WHERE (  magG >= 15.0 ) or (  magG <= 15.01 )   
)


-- AGGREGATION SQL:
SELECT `*`,`magG`
FROM `aggregation_tmp_94621594`  ORDER BY `magG` ASC 
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`magG`=VALUES(`magG`)
This is the query plan for the query:
select * from `GUMS10`.`MW` where magG >= 15.0 or magG <= 15.01 ORDER BY magG ASC

CALL paquExec('SELECT * AS `*`,magG AS `magG` FROM `GUMS10`.`MW` WHERE (  magG >= 15.0 ) or (  magG <= 15.01 )   ', 'aggregation_tmp_94621594');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `*`,`magG`
FROM `aggregation_tmp_94621594`  ORDER BY `magG` ASC ;
CALL paquDropTmp('aggregation_tmp_94621594');
This is the query plan optimisation output for the query:
select * from `GUMS10`.`MW` where magG >= 15.0 and magG <= 15.01 ORDER BY magG ASC

-- INPUT SQL:
select * from `GUMS10`.`MW` where magG >= 15.0 and magG <= 15.01 ORDER BY magG ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`,`magG`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`magG`=VALUES(`magG`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,magG AS `magG`
FROM `GUMS10`.`MW` WHERE (  magG >= 15.0 ) and (  magG <= 15.01 )   
)


-- AGGREGATION SQL:
SELECT `*`,`magG`
FROM `aggregation_tmp_45703820`  ORDER BY `magG` ASC 
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`magG`=VALUES(`magG`)
This is the query plan for the query:
select * from `GUMS10`.`MW` where magG >= 15.0 and magG <= 15.01 ORDER BY magG ASC

CALL paquExec('SELECT * AS `*`,magG AS `magG` FROM `GUMS10`.`MW` WHERE (  magG >= 15.0 ) and (  magG <= 15.01 )   ', 'aggregation_tmp_45703820');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `*`,`magG`
FROM `aggregation_tmp_45703820`  ORDER BY `magG` ASC ;
CALL paquDropTmp('aggregation_tmp_45703820');
This is the query plan optimisation output for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000 AND x>380.0) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 ) AND (  x > 380.0 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_80497625`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000 AND x>380.0) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np`
FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_80497625`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_33055146`  ORDER BY `p.treeSnapnum` ASC 
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)
This is the query plan for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000 AND x>380.0) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 ) AND (  x > 380.0 )   ', 'aggregation_tmp_80497625');
CALL paquExec('SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np` FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_80497625`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   ', 'aggregation_tmp_33055146');
CALL paquDropTmp('aggregation_tmp_80497625');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_33055146`  ORDER BY `p.treeSnapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_33055146');
This is the query plan optimisation output for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000 AND x>380.0) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 ) AND (  x > 380.0 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_97068323`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000 AND x>380.0) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np`
FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_97068323`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_53903328`  ORDER BY `p.treeSnapnum` ASC 
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)
This is the query plan for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000 AND x>380.0) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 ) AND (  x > 380.0 )   ', 'aggregation_tmp_97068323');
CALL paquExec('SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np` FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_97068323`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   ', 'aggregation_tmp_53903328');
CALL paquDropTmp('aggregation_tmp_97068323');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_53903328`  ORDER BY `p.treeSnapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_53903328');
This is the query plan optimisation output for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000 AND x>380.0) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 ) AND (  x > 380.0 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_50391627`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000 AND x>380.0) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np`
FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_50391627`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_96108371`  ORDER BY `p.treeSnapnum` ASC 
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)
This is the query plan for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000 AND x>380.0) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 ) AND (  x > 380.0 )   ', 'aggregation_tmp_50391627');
CALL paquExec('SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np` FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_50391627`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   ', 'aggregation_tmp_96108371');
CALL paquDropTmp('aggregation_tmp_50391627');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_96108371`  ORDER BY `p.treeSnapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_96108371');
This is the query plan optimisation output for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000 AND x>380.0) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 ) AND (  x > 380.0 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_94821001`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000 AND x>380.0) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np`
FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_94821001`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_83727953`  ORDER BY `p.treeSnapnum` ASC 
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)
This is the query plan for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000 AND x>380.0) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 ) AND (  x > 380.0 )   ', 'aggregation_tmp_94821001');
CALL paquExec('SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np` FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_94821001`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   ', 'aggregation_tmp_83727953');
CALL paquDropTmp('aggregation_tmp_94821001');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_83727953`  ORDER BY `p.treeSnapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_83727953');
This is the query plan optimisation output for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000 AND x>380.0) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 ) AND (  x > 380.0 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_3223758`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000 AND x>380.0) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np`
FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_3223758`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_77565594`  ORDER BY `p.treeSnapnum` ASC 
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)
This is the query plan for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000 AND x>380.0) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 ) AND (  x > 380.0 )   ', 'aggregation_tmp_3223758');
CALL paquExec('SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np` FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_3223758`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   ', 'aggregation_tmp_77565594');
CALL paquDropTmp('aggregation_tmp_3223758');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_77565594`  ORDER BY `p.treeSnapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_77565594');
This is the query plan optimisation output for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000 AND x>380.0) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 ) AND (  x > 380.0 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_50384430`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000 AND x>380.0) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np`
FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_50384430`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_8428036`  ORDER BY `p.treeSnapnum` ASC 
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)
This is the query plan for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000 AND x>380.0) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 ) AND (  x > 380.0 )   ', 'aggregation_tmp_50384430');
CALL paquExec('SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np` FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_50384430`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   ', 'aggregation_tmp_8428036');
CALL paquDropTmp('aggregation_tmp_50384430');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_8428036`  ORDER BY `p.treeSnapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_8428036');
This is the query plan optimisation output for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000 AND x>380.0) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 ) AND (  x > 380.0 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_33489839`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000 AND x>380.0) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np`
FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_33489839`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_1679200`  ORDER BY `p.treeSnapnum` ASC 
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)
This is the query plan for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000 AND x>380.0) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 ) AND (  x > 380.0 )   ', 'aggregation_tmp_33489839');
CALL paquExec('SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np` FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_33489839`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   ', 'aggregation_tmp_1679200');
CALL paquDropTmp('aggregation_tmp_33489839');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_1679200`  ORDER BY `p.treeSnapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_1679200');
This is the query plan optimisation output for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000 AND x>380.0) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 ) AND (  x > 380.0 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_62897316`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000 AND x>380.0) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np`
FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_62897316`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_57597831`  ORDER BY `p.treeSnapnum` ASC 
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)
This is the query plan for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000 AND x>380.0) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 ) AND (  x > 380.0 )   ', 'aggregation_tmp_62897316');
CALL paquExec('SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np` FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_62897316`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   ', 'aggregation_tmp_57597831');
CALL paquDropTmp('aggregation_tmp_62897316');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_57597831`  ORDER BY `p.treeSnapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_57597831');
This is the query plan optimisation output for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000 AND x>380.0) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 ) AND (  x > 380.0 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_86787818`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000 AND x>380.0) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np`
FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_86787818`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_13682820`  ORDER BY `p.treeSnapnum` ASC 
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)
This is the query plan for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000 AND x>380.0) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 ) AND (  x > 380.0 )   ', 'aggregation_tmp_86787818');
CALL paquExec('SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np` FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_86787818`   ) AS `mycl`  WHERE (  p.np > 1000 ) (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   ', 'aggregation_tmp_13682820');
CALL paquDropTmp('aggregation_tmp_86787818');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_13682820`  ORDER BY `p.treeSnapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_13682820');
This is the query plan optimisation output for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000 AND x>380.0) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 ) AND (  x > 380.0 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_39195813`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000 AND x>380.0) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np`
FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_39195813`   ) AS `mycl`  WHERE (  p.np > 1000 ) AND (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_78160957`  ORDER BY `p.treeSnapnum` ASC 
ON DUPLICATE KEY UPDATE
`p.fofTreeId`=VALUES(`p.fofTreeId`),
`p.treeSnapnum`=VALUES(`p.treeSnapnum`),
`p.mass`=VALUES(`p.mass`),
`p.np`=VALUES(`p.np`)
This is the query plan for the query:
SELECT p.fofTreeId, p.treeSnapnum, p.mass, p.np FROM MDR1.FOFMtree AS p, (SELECT fofTreeId, lastProgId FROM MDR1.FOFMtree WHERE fofId=85000000000 AND x>380.0) AS mycl WHERE p.fofTreeId BETWEEN mycl.fofTreeId AND mycl.lastProgId AND p.np > 1000 ORDER BY p.treeSnapnum

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree WHERE (  fofId = 85000000000 ) AND (  x > 380.0 )   ', 'aggregation_tmp_39195813');
CALL paquExec('SELECT p.fofTreeId AS `p.fofTreeId`,p.treeSnapnum AS `p.treeSnapnum`,p.mass AS `p.mass`,p.np AS `p.np` FROM MDR1.FOFMtree AS `p` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_39195813`   ) AS `mycl`  WHERE (  p.np > 1000 ) AND (  p.fofTreeId BETWEEN `mycl`.`fofTreeId` AND `mycl`.`lastProgId` )   ', 'aggregation_tmp_78160957');
CALL paquDropTmp('aggregation_tmp_39195813');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `p.fofTreeId`,`p.treeSnapnum`,`p.mass`,`p.np`
FROM `aggregation_tmp_78160957`  ORDER BY `p.treeSnapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_78160957');
This is the query plan optimisation output for the query:
select * from `GUMS10`.`MW` where magG >= 15.0 and magG <= 15.01 ORDER BY magG ASC

-- INPUT SQL:
select * from `GUMS10`.`MW` where magG >= 15.0 and magG <= 15.01 ORDER BY magG ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`,`magG`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`magG`=VALUES(`magG`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,magG AS `magG`
FROM `GUMS10`.`MW` WHERE (  magG >= 15.0 ) and (  magG <= 15.01 )   
)


-- AGGREGATION SQL:
SELECT `*`,`magG`
FROM `aggregation_tmp_55269260`  ORDER BY `magG` ASC 
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`magG`=VALUES(`magG`)
This is the query plan for the query:
select * from `GUMS10`.`MW` where magG >= 15.0 and magG <= 15.01 ORDER BY magG ASC

CALL paquExec('SELECT * AS `*`,magG AS `magG` FROM `GUMS10`.`MW` WHERE (  magG >= 15.0 ) and (  magG <= 15.01 )   ', 'aggregation_tmp_55269260');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `*`,`magG`
FROM `aggregation_tmp_55269260`  ORDER BY `magG` ASC ;
CALL paquDropTmp('aggregation_tmp_55269260');
This is the query plan optimisation output for the query:
SELECT * FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY Rbin

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`
FROM `aggregation_tmp_20720203`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT * FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY Rbin

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`,`Rbin`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`Rbin`=VALUES(`Rbin`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,Rbin AS `Rbin`
FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId`
FROM `aggregation_tmp_20720203`  ORDER BY `Mvir` DESC  LIMIT 0,1)    
)


-- AGGREGATION SQL:
SELECT `*`,`Rbin`
FROM `aggregation_tmp_35232282`  ORDER BY `Rbin` ASC 
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`Rbin`=VALUES(`Rbin`)
This is the query plan for the query:
SELECT * FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY Rbin

CALL paquExec('SELECT bdmId AS `bdmId`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_20720203');
CALL paquExec('SELECT * AS `*`,Rbin AS `Rbin` FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId` FROM `aggregation_tmp_20720203`  ORDER BY `Mvir` DESC  LIMIT 0,1)    ', 'aggregation_tmp_35232282');
CALL paquDropTmp('aggregation_tmp_20720203');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `*`,`Rbin`
FROM `aggregation_tmp_35232282`  ORDER BY `Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_35232282');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree AS `descend` ORDER BY NULL 
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_30567491`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.*() AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_30567491`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_45908099`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree AS `descend` ORDER BY NULL ', 'aggregation_tmp_30567491');
CALL paquExec('SELECT prog.*() AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_30567491`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`lastProgId` )   ', 'aggregation_tmp_45908099');
CALL paquDropTmp('aggregation_tmp_30567491');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_45908099`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_45908099');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree AS `descend` ORDER BY NULL 
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_41545710`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.*() AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_41545710`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_20849413`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree AS `descend` ORDER BY NULL ', 'aggregation_tmp_41545710');
CALL paquExec('SELECT prog.*() AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_41545710`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`lastProgId` )   ', 'aggregation_tmp_20849413');
CALL paquDropTmp('aggregation_tmp_41545710');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_20849413`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_20849413');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree AS `descend` ORDER BY NULL 
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_35693117`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.*() AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_35693117`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_24718899`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree AS `descend` ORDER BY NULL ', 'aggregation_tmp_35693117');
CALL paquExec('SELECT prog.*() AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_35693117`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`lastProgId` )   ', 'aggregation_tmp_24718899');
CALL paquDropTmp('aggregation_tmp_35693117');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_24718899`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_24718899');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.*() AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_31042321`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT prog.*() AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_31042321');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_31042321`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_31042321');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.*() AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_14453633`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT prog.*() AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_14453633');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_14453633`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_14453633');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.*() AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_37542535`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT prog.*() AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_37542535');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_37542535`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_37542535');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.*() AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_73169083`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT prog.*() AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_73169083');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_73169083`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_73169083');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_8396416`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.*() AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_8396416`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_84148504`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   ', 'aggregation_tmp_8396416');
CALL paquExec('SELECT prog.*() AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_8396416`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`lastProgId` )   ', 'aggregation_tmp_84148504');
CALL paquDropTmp('aggregation_tmp_8396416');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_84148504`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_84148504');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_38636130`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.*() AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_38636130`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_11838328`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   ', 'aggregation_tmp_38636130');
CALL paquExec('SELECT prog.*() AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_38636130`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`lastProgId` )   ', 'aggregation_tmp_11838328');
CALL paquDropTmp('aggregation_tmp_38636130');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_11838328`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_11838328');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_20219340`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.*() AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_20219340`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_55918708`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   ', 'aggregation_tmp_20219340');
CALL paquExec('SELECT prog.*() AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_20219340`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`lastProgId` )   ', 'aggregation_tmp_55918708');
CALL paquDropTmp('aggregation_tmp_20219340');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_55918708`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_55918708');
This is the query plan optimisation output for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`fofTreeId`=VALUES(`fofTreeId`),
`mass`=VALUES(`mass`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,fofTreeId AS `fofTreeId`,mass AS `mass`
FROM MDR1.FOFMtree AS `PROG` WHERE (  PROG.mass > 1.e13 )   
)


-- AGGREGATION SQL:
SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass`
FROM `aggregation_tmp_60128896`   
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`fofTreeId`=VALUES(`fofTreeId`),
`mass`=VALUES(`mass`)
-- INPUT SQL:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,`PROG`.`PROG.mass` AS `PROG.mass`,`PROG`.`PROG.treeSnapnum` AS `PROG.treeSnapnum`,`PROG`.`PROG.fofId` AS `PROG.fofId`
FROM MDR1.FOFMtree AS `DES` JOIN ( SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass`
FROM `aggregation_tmp_60128896`   ) AS `PROG`  WHERE (  DES.treeSnapnum = 39 ) AND AND (  `PROG`.`fofTreeId` BETWEEN DES.fofTreeId AND DES.lastProgId )   
)


-- AGGREGATION SQL:
SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`
FROM `aggregation_tmp_89690914`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`)
This is the query plan for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

CALL paquExec('SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,fofTreeId AS `fofTreeId`,mass AS `mass` FROM MDR1.FOFMtree AS `PROG` WHERE (  PROG.mass > 1.e13 )   ', 'aggregation_tmp_60128896');
CALL paquExec('SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,`PROG`.`PROG.mass` AS `PROG.mass`,`PROG`.`PROG.treeSnapnum` AS `PROG.treeSnapnum`,`PROG`.`PROG.fofId` AS `PROG.fofId` FROM MDR1.FOFMtree AS `DES` JOIN ( SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass` FROM `aggregation_tmp_60128896`   ) AS `PROG`  WHERE (  DES.treeSnapnum = 39 ) AND AND (  `PROG`.`fofTreeId` BETWEEN DES.fofTreeId AND DES.lastProgId )   ', 'aggregation_tmp_89690914');
CALL paquDropTmp('aggregation_tmp_60128896');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`
FROM `aggregation_tmp_89690914`  ORDER BY `DES.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_89690914');
This is the query plan optimisation output for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`fofTreeId`=VALUES(`fofTreeId`),
`mass`=VALUES(`mass`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,fofTreeId AS `fofTreeId`,mass AS `mass`
FROM MDR1.FOFMtree AS `PROG` WHERE (  PROG.mass > 1.e13 )   
)


-- AGGREGATION SQL:
SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass`
FROM `aggregation_tmp_75682197`   
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`fofTreeId`=VALUES(`fofTreeId`),
`mass`=VALUES(`mass`)
-- INPUT SQL:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,`PROG`.`PROG.mass` AS `PROG.mass`,`PROG`.`PROG.treeSnapnum` AS `PROG.treeSnapnum`,`PROG`.`PROG.fofId` AS `PROG.fofId`
FROM MDR1.FOFMtree AS `DES` JOIN ( SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass`
FROM `aggregation_tmp_75682197`   ) AS `PROG`  WHERE (  DES.treeSnapnum = 39 ) AND AND (  `PROG`.`fofTreeId` BETWEEN DES.fofTreeId AND DES.lastProgId )   
)


-- AGGREGATION SQL:
SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`
FROM `aggregation_tmp_85212422`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`)
This is the query plan for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

CALL paquExec('SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,fofTreeId AS `fofTreeId`,mass AS `mass` FROM MDR1.FOFMtree AS `PROG` WHERE (  PROG.mass > 1.e13 )   ', 'aggregation_tmp_75682197');
CALL paquExec('SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,`PROG`.`PROG.mass` AS `PROG.mass`,`PROG`.`PROG.treeSnapnum` AS `PROG.treeSnapnum`,`PROG`.`PROG.fofId` AS `PROG.fofId` FROM MDR1.FOFMtree AS `DES` JOIN ( SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass` FROM `aggregation_tmp_75682197`   ) AS `PROG`  WHERE (  DES.treeSnapnum = 39 ) AND AND (  `PROG`.`fofTreeId` BETWEEN DES.fofTreeId AND DES.lastProgId )   ', 'aggregation_tmp_85212422');
CALL paquDropTmp('aggregation_tmp_75682197');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`
FROM `aggregation_tmp_85212422`  ORDER BY `DES.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_85212422');
This is the query plan optimisation output for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`fofTreeId`=VALUES(`fofTreeId`),
`mass`=VALUES(`mass`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,fofTreeId AS `fofTreeId`,mass AS `mass`
FROM MDR1.FOFMtree AS `PROG` WHERE (  PROG.mass > 1.e13 )   
)


-- AGGREGATION SQL:
SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass`
FROM `aggregation_tmp_47377509`   
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`fofTreeId`=VALUES(`fofTreeId`),
`mass`=VALUES(`mass`)
-- INPUT SQL:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,`PROG`.`PROG.mass` AS `PROG.mass`,`PROG`.`PROG.treeSnapnum` AS `PROG.treeSnapnum`,`PROG`.`PROG.fofId` AS `PROG.fofId`
FROM MDR1.FOFMtree AS `DES` JOIN ( SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass`
FROM `aggregation_tmp_47377509`   ) AS `PROG`  WHERE (  DES.treeSnapnum = 39 ) AND AND (  `PROG`.`fofTreeId` BETWEEN DES.fofTreeId AND DES.lastProgId )   
)


-- AGGREGATION SQL:
SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`
FROM `aggregation_tmp_26692177`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`)
This is the query plan for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

CALL paquExec('SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,fofTreeId AS `fofTreeId`,mass AS `mass` FROM MDR1.FOFMtree AS `PROG` WHERE (  PROG.mass > 1.e13 )   ', 'aggregation_tmp_47377509');
CALL paquExec('SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,`PROG`.`PROG.mass` AS `PROG.mass`,`PROG`.`PROG.treeSnapnum` AS `PROG.treeSnapnum`,`PROG`.`PROG.fofId` AS `PROG.fofId` FROM MDR1.FOFMtree AS `DES` JOIN ( SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass` FROM `aggregation_tmp_47377509`   ) AS `PROG`  WHERE (  DES.treeSnapnum = 39 ) AND AND (  `PROG`.`fofTreeId` BETWEEN DES.fofTreeId AND DES.lastProgId )   ', 'aggregation_tmp_26692177');
CALL paquDropTmp('aggregation_tmp_47377509');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`
FROM `aggregation_tmp_26692177`  ORDER BY `DES.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_26692177');
This is the query plan optimisation output for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`fofTreeId`=VALUES(`fofTreeId`),
`mass`=VALUES(`mass`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,fofTreeId AS `fofTreeId`,mass AS `mass`
FROM MDR1.FOFMtree AS `PROG` WHERE (  PROG.mass > 1.e13 )   
)


-- AGGREGATION SQL:
SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass`
FROM `aggregation_tmp_16916763`   
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`fofTreeId`=VALUES(`fofTreeId`),
`mass`=VALUES(`mass`)
-- INPUT SQL:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,`PROG`.`PROG.mass` AS `PROG.mass`,`PROG`.`PROG.treeSnapnum` AS `PROG.treeSnapnum`,`PROG`.`PROG.fofId` AS `PROG.fofId`
FROM MDR1.FOFMtree AS `DES` JOIN ( SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass`
FROM `aggregation_tmp_16916763`   ) AS `PROG`  WHERE (  DES.treeSnapnum = 39 ) AND AND (  `PROG`.`fofTreeId` BETWEEN DES.fofTreeId AND DES.lastProgId )   
)


-- AGGREGATION SQL:
SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`
FROM `aggregation_tmp_20545906`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`)
This is the query plan for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

CALL paquExec('SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,fofTreeId AS `fofTreeId`,mass AS `mass` FROM MDR1.FOFMtree AS `PROG` WHERE (  PROG.mass > 1.e13 )   ', 'aggregation_tmp_16916763');
CALL paquExec('SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,`PROG`.`PROG.mass` AS `PROG.mass`,`PROG`.`PROG.treeSnapnum` AS `PROG.treeSnapnum`,`PROG`.`PROG.fofId` AS `PROG.fofId` FROM MDR1.FOFMtree AS `DES` JOIN ( SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass` FROM `aggregation_tmp_16916763`   ) AS `PROG`  WHERE (  DES.treeSnapnum = 39 ) AND AND (  `PROG`.`fofTreeId` BETWEEN DES.fofTreeId AND DES.lastProgId )   ', 'aggregation_tmp_20545906');
CALL paquDropTmp('aggregation_tmp_16916763');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`
FROM `aggregation_tmp_20545906`  ORDER BY `DES.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_20545906');
This is the query plan optimisation output for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`fofTreeId`=VALUES(`fofTreeId`),
`mass`=VALUES(`mass`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,fofTreeId AS `fofTreeId`,mass AS `mass`
FROM MDR1.FOFMtree AS `PROG` WHERE (  PROG.mass > 1.e13 )   
)


-- AGGREGATION SQL:
SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass`
FROM `aggregation_tmp_83644745`   
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`fofTreeId`=VALUES(`fofTreeId`),
`mass`=VALUES(`mass`)
-- INPUT SQL:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,`PROG`.`PROG.mass` AS `PROG.mass`,`PROG`.`PROG.treeSnapnum` AS `PROG.treeSnapnum`,`PROG`.`PROG.fofId` AS `PROG.fofId`
FROM MDR1.FOFMtree AS `DES` JOIN ( SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass`
FROM `aggregation_tmp_83644745`   ) AS `PROG`  WHERE (  DES.treeSnapnum = 39 ) AND AND (  `PROG`.`fofTreeId` BETWEEN DES.fofTreeId AND DES.lastProgId )   
)


-- AGGREGATION SQL:
SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`
FROM `aggregation_tmp_29432374`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`)
This is the query plan for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

CALL paquExec('SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,fofTreeId AS `fofTreeId`,mass AS `mass` FROM MDR1.FOFMtree AS `PROG` WHERE (  PROG.mass > 1.e13 )   ', 'aggregation_tmp_83644745');
CALL paquExec('SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,`PROG`.`PROG.mass` AS `PROG.mass`,`PROG`.`PROG.treeSnapnum` AS `PROG.treeSnapnum`,`PROG`.`PROG.fofId` AS `PROG.fofId` FROM MDR1.FOFMtree AS `DES` JOIN ( SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass` FROM `aggregation_tmp_83644745`   ) AS `PROG`  WHERE (  DES.treeSnapnum = 39 ) AND AND (  `PROG`.`fofTreeId` BETWEEN DES.fofTreeId AND DES.lastProgId )   ', 'aggregation_tmp_29432374');
CALL paquDropTmp('aggregation_tmp_83644745');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`
FROM `aggregation_tmp_29432374`  ORDER BY `DES.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_29432374');
This is the query plan optimisation output for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`fofTreeId`=VALUES(`fofTreeId`),
`mass`=VALUES(`mass`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,fofTreeId AS `fofTreeId`,mass AS `mass`
FROM MDR1.FOFMtree AS `PROG` WHERE (  PROG.mass > 1.e13 )   
)


-- AGGREGATION SQL:
SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass`
FROM `aggregation_tmp_86105367`   
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`fofTreeId`=VALUES(`fofTreeId`),
`mass`=VALUES(`mass`)
-- INPUT SQL:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,`PROG`.`PROG.mass` AS `PROG.mass`,`PROG`.`PROG.treeSnapnum` AS `PROG.treeSnapnum`,`PROG`.`PROG.fofId` AS `PROG.fofId`
FROM MDR1.FOFMtree AS `DES` JOIN ( SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass`
FROM `aggregation_tmp_86105367`   ) AS `PROG`  WHERE (  DES.treeSnapnum = 39 ) AND AND (  `PROG`.`fofTreeId` BETWEEN DES.fofTreeId AND DES.lastProgId )   
)


-- AGGREGATION SQL:
SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`
FROM `aggregation_tmp_19138888`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`)
This is the query plan for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

CALL paquExec('SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,fofTreeId AS `fofTreeId`,mass AS `mass` FROM MDR1.FOFMtree AS `PROG` WHERE (  PROG.mass > 1.e13 )   ', 'aggregation_tmp_86105367');
CALL paquExec('SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,`PROG`.`PROG.mass` AS `PROG.mass`,`PROG`.`PROG.treeSnapnum` AS `PROG.treeSnapnum`,`PROG`.`PROG.fofId` AS `PROG.fofId` FROM MDR1.FOFMtree AS `DES` JOIN ( SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass` FROM `aggregation_tmp_86105367`   ) AS `PROG`  WHERE (  DES.treeSnapnum = 39 ) AND AND (  `PROG`.`fofTreeId` BETWEEN DES.fofTreeId AND DES.lastProgId )   ', 'aggregation_tmp_19138888');
CALL paquDropTmp('aggregation_tmp_86105367');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`
FROM `aggregation_tmp_19138888`  ORDER BY `DES.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_19138888');
This is the query plan optimisation output for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`fofTreeId`=VALUES(`fofTreeId`),
`mass`=VALUES(`mass`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,fofTreeId AS `fofTreeId`,mass AS `mass`
FROM MDR1.FOFMtree AS `PROG` WHERE (  PROG.mass > 1.e13 )   
)


-- AGGREGATION SQL:
SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass`
FROM `aggregation_tmp_6477108`   
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`fofTreeId`=VALUES(`fofTreeId`),
`mass`=VALUES(`mass`)
-- INPUT SQL:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,`PROG`.`PROG.mass` AS `PROG.mass`,`PROG`.`PROG.treeSnapnum` AS `PROG.treeSnapnum`,`PROG`.`PROG.fofId` AS `PROG.fofId`
FROM MDR1.FOFMtree AS `DES` JOIN ( SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass`
FROM `aggregation_tmp_6477108`   ) AS `PROG`  WHERE (  DES.treeSnapnum = 39 ) AND AND (  `PROG`.`fofTreeId` BETWEEN DES.fofTreeId AND DES.lastProgId )   
)


-- AGGREGATION SQL:
SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`
FROM `aggregation_tmp_49268069`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`)
This is the query plan for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

CALL paquExec('SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,fofTreeId AS `fofTreeId`,mass AS `mass` FROM MDR1.FOFMtree AS `PROG` WHERE (  PROG.mass > 1.e13 )   ', 'aggregation_tmp_6477108');
CALL paquExec('SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,`PROG`.`PROG.mass` AS `PROG.mass`,`PROG`.`PROG.treeSnapnum` AS `PROG.treeSnapnum`,`PROG`.`PROG.fofId` AS `PROG.fofId` FROM MDR1.FOFMtree AS `DES` JOIN ( SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass` FROM `aggregation_tmp_6477108`   ) AS `PROG`  WHERE (  DES.treeSnapnum = 39 ) AND AND (  `PROG`.`fofTreeId` BETWEEN DES.fofTreeId AND DES.lastProgId )   ', 'aggregation_tmp_49268069');
CALL paquDropTmp('aggregation_tmp_6477108');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`
FROM `aggregation_tmp_49268069`  ORDER BY `DES.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_49268069');
This is the query plan optimisation output for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`fofTreeId`=VALUES(`fofTreeId`),
`mass`=VALUES(`mass`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,fofTreeId AS `fofTreeId`,mass AS `mass`
FROM MDR1.FOFMtree AS `PROG` WHERE (  PROG.mass > 1.e13 )   
)


-- AGGREGATION SQL:
SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass`
FROM `aggregation_tmp_50647201`   
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`fofTreeId`=VALUES(`fofTreeId`),
`mass`=VALUES(`mass`)
-- INPUT SQL:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,`PROG`.`PROG.mass` AS `PROG.mass`,`PROG`.`PROG.treeSnapnum` AS `PROG.treeSnapnum`,`PROG`.`PROG.fofId` AS `PROG.fofId`
FROM MDR1.FOFMtree AS `DES` JOIN ( SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass`
FROM `aggregation_tmp_50647201`   ) AS `PROG`  WHERE (  DES.treeSnapnum = 39 ) AND AND (  `PROG`.`fofTreeId` BETWEEN DES.fofTreeId AND DES.lastProgId )   
)


-- AGGREGATION SQL:
SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`
FROM `aggregation_tmp_24147778`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`)
This is the query plan for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

CALL paquExec('SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,fofTreeId AS `fofTreeId`,mass AS `mass` FROM MDR1.FOFMtree AS `PROG` WHERE (  PROG.mass > 1.e13 )   ', 'aggregation_tmp_50647201');
CALL paquExec('SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,`PROG`.`PROG.mass` AS `PROG.mass`,`PROG`.`PROG.treeSnapnum` AS `PROG.treeSnapnum`,`PROG`.`PROG.fofId` AS `PROG.fofId` FROM MDR1.FOFMtree AS `DES` JOIN ( SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass` FROM `aggregation_tmp_50647201`   ) AS `PROG`  WHERE (  DES.treeSnapnum = 39 ) AND AND (  `PROG`.`fofTreeId` BETWEEN DES.fofTreeId AND DES.lastProgId )   ', 'aggregation_tmp_24147778');
CALL paquDropTmp('aggregation_tmp_50647201');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`
FROM `aggregation_tmp_24147778`  ORDER BY `DES.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_24147778');
This is the query plan optimisation output for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`fofTreeId`=VALUES(`fofTreeId`),
`mass`=VALUES(`mass`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,fofTreeId AS `fofTreeId`,mass AS `mass`
FROM MDR1.FOFMtree AS `PROG` WHERE (  PROG.mass > 1.e13 )   
)


-- AGGREGATION SQL:
SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass`
FROM `aggregation_tmp_19726008`   
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`fofTreeId`=VALUES(`fofTreeId`),
`mass`=VALUES(`mass`)
-- INPUT SQL:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,`PROG`.`PROG.mass` AS `PROG.mass`,`PROG`.`PROG.treeSnapnum` AS `PROG.treeSnapnum`,`PROG`.`PROG.fofId` AS `PROG.fofId`
FROM MDR1.FOFMtree AS `DES` JOIN ( SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass`
FROM `aggregation_tmp_19726008`   ) AS `PROG`  WHERE (  DES.treeSnapnum = 39 ) AND AND (  `PROG`.`fofTreeId` BETWEEN DES.fofTreeId AND DES.lastProgId )   
)


-- AGGREGATION SQL:
SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`
FROM `aggregation_tmp_66755496`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`)
This is the query plan for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

CALL paquExec('SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,fofTreeId AS `fofTreeId`,mass AS `mass` FROM MDR1.FOFMtree AS `PROG` WHERE (  PROG.mass > 1.e13 )   ', 'aggregation_tmp_19726008');
CALL paquExec('SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,`PROG`.`PROG.mass` AS `PROG.mass`,`PROG`.`PROG.treeSnapnum` AS `PROG.treeSnapnum`,`PROG`.`PROG.fofId` AS `PROG.fofId` FROM MDR1.FOFMtree AS `DES` JOIN ( SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass` FROM `aggregation_tmp_19726008`   ) AS `PROG`  WHERE (  DES.treeSnapnum = 39 ) AND AND (  `PROG`.`fofTreeId` BETWEEN DES.fofTreeId AND DES.lastProgId )   ', 'aggregation_tmp_66755496');
CALL paquDropTmp('aggregation_tmp_19726008');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`
FROM `aggregation_tmp_66755496`  ORDER BY `DES.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_66755496');
This is the query plan optimisation output for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`fofTreeId`=VALUES(`fofTreeId`),
`mass`=VALUES(`mass`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,fofTreeId AS `fofTreeId`,mass AS `mass`
FROM MDR1.FOFMtree AS `PROG` WHERE (  PROG.mass > 1.e13 )   
)


-- AGGREGATION SQL:
SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass`
FROM `aggregation_tmp_31224111`   
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`fofTreeId`=VALUES(`fofTreeId`),
`mass`=VALUES(`mass`)
-- INPUT SQL:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,`PROG`.`PROG.mass` AS `PROG.mass`,`PROG`.`PROG.treeSnapnum` AS `PROG.treeSnapnum`,`PROG`.`PROG.fofId` AS `PROG.fofId`
FROM MDR1.FOFMtree AS `DES` JOIN ( SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass`
FROM `aggregation_tmp_31224111`   ) AS `PROG`  WHERE (  DES.treeSnapnum = 39 ) AND AND (  `PROG`.`fofTreeId` BETWEEN DES.fofTreeId AND DES.lastProgId )   
)


-- AGGREGATION SQL:
SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`
FROM `aggregation_tmp_26768401`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`)
This is the query plan for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

CALL paquExec('SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,fofTreeId AS `fofTreeId`,mass AS `mass` FROM MDR1.FOFMtree AS `PROG` WHERE (  PROG.mass > 1.e13 )   ', 'aggregation_tmp_31224111');
CALL paquExec('SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,`PROG`.`PROG.mass` AS `PROG.mass`,`PROG`.`PROG.treeSnapnum` AS `PROG.treeSnapnum`,`PROG`.`PROG.fofId` AS `PROG.fofId` FROM MDR1.FOFMtree AS `DES` JOIN ( SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass` FROM `aggregation_tmp_31224111`   ) AS `PROG`  WHERE (  DES.treeSnapnum = 39 ) AND AND (  `PROG`.`fofTreeId` BETWEEN DES.fofTreeId AND DES.lastProgId )   ', 'aggregation_tmp_26768401');
CALL paquDropTmp('aggregation_tmp_31224111');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`
FROM `aggregation_tmp_26768401`  ORDER BY `DES.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_26768401');
This is the query plan optimisation output for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`fofTreeId`=VALUES(`fofTreeId`),
`mass`=VALUES(`mass`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,fofTreeId AS `fofTreeId`,mass AS `mass`
FROM MDR1.FOFMtree AS `PROG` WHERE (  PROG.mass > 1.e13 )   
)


-- AGGREGATION SQL:
SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass`
FROM `aggregation_tmp_88727579`   
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`fofTreeId`=VALUES(`fofTreeId`),
`mass`=VALUES(`mass`)
-- INPUT SQL:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,`PROG`.`PROG.mass` AS `PROG.mass`,`PROG`.`PROG.treeSnapnum` AS `PROG.treeSnapnum`,`PROG`.`PROG.fofId` AS `PROG.fofId`
FROM MDR1.FOFMtree AS `DES` JOIN ( SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass`
FROM `aggregation_tmp_88727579`   ) AS `PROG`  WHERE (  DES.treeSnapnum = 39 ) AND (  `PROG`.`fofTreeId` BETWEEN DES.fofTreeId AND DES.lastProgId )   
)


-- AGGREGATION SQL:
SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`
FROM `aggregation_tmp_8396293`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`)
This is the query plan for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

CALL paquExec('SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,fofTreeId AS `fofTreeId`,mass AS `mass` FROM MDR1.FOFMtree AS `PROG` WHERE (  PROG.mass > 1.e13 )   ', 'aggregation_tmp_88727579');
CALL paquExec('SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,`PROG`.`PROG.mass` AS `PROG.mass`,`PROG`.`PROG.treeSnapnum` AS `PROG.treeSnapnum`,`PROG`.`PROG.fofId` AS `PROG.fofId` FROM MDR1.FOFMtree AS `DES` JOIN ( SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`fofTreeId`,`mass` FROM `aggregation_tmp_88727579`   ) AS `PROG`  WHERE (  DES.treeSnapnum = 39 ) AND (  `PROG`.`fofTreeId` BETWEEN DES.fofTreeId AND DES.lastProgId )   ', 'aggregation_tmp_8396293');
CALL paquDropTmp('aggregation_tmp_88727579');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`
FROM `aggregation_tmp_8396293`  ORDER BY `DES.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_8396293');
This is the query plan optimisation output for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`treeSnapnum`,`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`treeSnapnum`=VALUES(`treeSnapnum`),
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,treeSnapnum AS `treeSnapnum`,fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree AS `DES` WHERE (  DES.treeSnapnum = 39 )   
)


-- AGGREGATION SQL:
SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`treeSnapnum`,`fofTreeId`,`lastProgId`
FROM `aggregation_tmp_12666997`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`treeSnapnum`=VALUES(`treeSnapnum`),
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,`DES`.`DES.mass` AS `DES.mass`,`DES`.`DES.treeSnapnum` AS `DES.treeSnapnum`,`DES`.`DES.fofId` AS `DES.fofId`,`DES`.`DES.lastProgId` AS `DES.lastProgId`
FROM MDR1.FOFMtree AS `PROG` JOIN ( SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`treeSnapnum`,`fofTreeId`,`lastProgId`
FROM `aggregation_tmp_12666997`  ORDER BY `DES.fofId` ASC ) AS `DES`  WHERE (  PROG.mass > 1.e13 ) AND (  PROG.fofTreeId BETWEEN `DES`.`fofTreeId` AND `DES`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`
FROM `aggregation_tmp_56666873`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`)
This is the query plan for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

CALL paquExec('SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,treeSnapnum AS `treeSnapnum`,fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree AS `DES` WHERE (  DES.treeSnapnum = 39 )   ', 'aggregation_tmp_12666997');
CALL paquExec('SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,`DES`.`DES.mass` AS `DES.mass`,`DES`.`DES.treeSnapnum` AS `DES.treeSnapnum`,`DES`.`DES.fofId` AS `DES.fofId`,`DES`.`DES.lastProgId` AS `DES.lastProgId` FROM MDR1.FOFMtree AS `PROG` JOIN ( SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`treeSnapnum`,`fofTreeId`,`lastProgId` FROM `aggregation_tmp_12666997`  ORDER BY `DES.fofId` ASC ) AS `DES`  WHERE (  PROG.mass > 1.e13 ) AND (  PROG.fofTreeId BETWEEN `DES`.`fofTreeId` AND `DES`.`lastProgId` )   ', 'aggregation_tmp_56666873');
CALL paquDropTmp('aggregation_tmp_12666997');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`
FROM `aggregation_tmp_56666873`  ORDER BY `DES.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_56666873');
This is the query plan optimisation output for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`treeSnapnum`,`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`treeSnapnum`=VALUES(`treeSnapnum`),
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,treeSnapnum AS `treeSnapnum`,fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree AS `DES` WHERE (  DES.treeSnapnum = 39 )   
)


-- AGGREGATION SQL:
SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`treeSnapnum`,`fofTreeId`,`lastProgId`
FROM `aggregation_tmp_23557387`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`treeSnapnum`=VALUES(`treeSnapnum`),
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,`DES`.`DES.mass` AS `DES.mass`,`DES`.`DES.treeSnapnum` AS `DES.treeSnapnum`,`DES`.`DES.fofId` AS `DES.fofId`,`DES`.`DES.lastProgId` AS `DES.lastProgId`
FROM MDR1.FOFMtree AS `PROG` JOIN ( SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`treeSnapnum`,`fofTreeId`,`lastProgId`
FROM `aggregation_tmp_23557387`  ORDER BY `DES.fofId` ASC ) AS `DES`  WHERE (  PROG.mass > 1.e13 ) AND (  PROG.fofTreeId BETWEEN `DES`.`fofTreeId` AND `DES`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`
FROM `aggregation_tmp_73218564`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`)
This is the query plan for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

CALL paquExec('SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,treeSnapnum AS `treeSnapnum`,fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree AS `DES` WHERE (  DES.treeSnapnum = 39 )   ', 'aggregation_tmp_23557387');
CALL paquExec('SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,`DES`.`DES.mass` AS `DES.mass`,`DES`.`DES.treeSnapnum` AS `DES.treeSnapnum`,`DES`.`DES.fofId` AS `DES.fofId`,`DES`.`DES.lastProgId` AS `DES.lastProgId` FROM MDR1.FOFMtree AS `PROG` JOIN ( SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`treeSnapnum`,`fofTreeId`,`lastProgId` FROM `aggregation_tmp_23557387`  ORDER BY `DES.fofId` ASC ) AS `DES`  WHERE (  PROG.mass > 1.e13 ) AND (  PROG.fofTreeId BETWEEN `DES`.`fofTreeId` AND `DES`.`lastProgId` )   ', 'aggregation_tmp_73218564');
CALL paquDropTmp('aggregation_tmp_23557387');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`
FROM `aggregation_tmp_73218564`  ORDER BY `DES.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_73218564');
This is the query plan optimisation output for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`treeSnapnum`,`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`treeSnapnum`=VALUES(`treeSnapnum`),
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,treeSnapnum AS `treeSnapnum`,fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree AS `DES` WHERE (  DES.treeSnapnum = 39 )   
)


-- AGGREGATION SQL:
SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`treeSnapnum`,`fofTreeId`,`lastProgId`
FROM `aggregation_tmp_46665401`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`treeSnapnum`=VALUES(`treeSnapnum`),
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,`DES`.`DES.mass` AS `DES.mass`,`DES`.`DES.treeSnapnum` AS `DES.treeSnapnum`,`DES`.`DES.fofId` AS `DES.fofId`,`DES`.`DES.lastProgId` AS `DES.lastProgId`
FROM MDR1.FOFMtree AS `PROG` JOIN ( SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`treeSnapnum`,`fofTreeId`,`lastProgId`
FROM `aggregation_tmp_46665401`  ORDER BY `DES.fofId` ASC ) AS `DES`  WHERE (  PROG.mass > 1.e13 ) AND (  PROG.fofTreeId BETWEEN `DES`.`fofTreeId` AND `DES`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`
FROM `aggregation_tmp_48563653`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`)
This is the query plan for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

CALL paquExec('SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,treeSnapnum AS `treeSnapnum`,fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree AS `DES` WHERE (  DES.treeSnapnum = 39 )   ', 'aggregation_tmp_46665401');
CALL paquExec('SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,`DES`.`DES.mass` AS `DES.mass`,`DES`.`DES.treeSnapnum` AS `DES.treeSnapnum`,`DES`.`DES.fofId` AS `DES.fofId`,`DES`.`DES.lastProgId` AS `DES.lastProgId` FROM MDR1.FOFMtree AS `PROG` JOIN ( SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`treeSnapnum`,`fofTreeId`,`lastProgId` FROM `aggregation_tmp_46665401`  ORDER BY `DES.fofId` ASC ) AS `DES`  WHERE (  PROG.mass > 1.e13 ) AND (  PROG.fofTreeId BETWEEN `DES`.`fofTreeId` AND `DES`.`lastProgId` )   ', 'aggregation_tmp_48563653');
CALL paquDropTmp('aggregation_tmp_46665401');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`
FROM `aggregation_tmp_48563653`  ORDER BY `DES.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_48563653');
This is the query plan optimisation output for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`treeSnapnum`,`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`treeSnapnum`=VALUES(`treeSnapnum`),
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,treeSnapnum AS `treeSnapnum`,fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId`
FROM MDR1.FOFMtree AS `DES` WHERE (  DES.treeSnapnum = 39 )   
)


-- AGGREGATION SQL:
SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`treeSnapnum`,`fofTreeId`,`lastProgId`
FROM `aggregation_tmp_8213250`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`treeSnapnum`=VALUES(`treeSnapnum`),
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,`DES`.`DES.mass` AS `DES.mass`,`DES`.`DES.treeSnapnum` AS `DES.treeSnapnum`,`DES`.`DES.fofId` AS `DES.fofId`,`DES`.`DES.lastProgId` AS `DES.lastProgId`
FROM MDR1.FOFMtree AS `PROG` JOIN ( SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`treeSnapnum`,`fofTreeId`,`lastProgId`
FROM `aggregation_tmp_8213250`  ORDER BY `DES.fofId` ASC ) AS `DES`  WHERE (  PROG.mass > 1.e13 ) AND (  PROG.fofTreeId BETWEEN `DES`.`fofTreeId` AND `DES`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`
FROM `aggregation_tmp_81069542`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`)
This is the query plan for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

CALL paquExec('SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,treeSnapnum AS `treeSnapnum`,fofTreeId AS `fofTreeId`,lastProgId AS `lastProgId` FROM MDR1.FOFMtree AS `DES` WHERE (  DES.treeSnapnum = 39 )   ', 'aggregation_tmp_8213250');
CALL paquExec('SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,`DES`.`DES.mass` AS `DES.mass`,`DES`.`DES.treeSnapnum` AS `DES.treeSnapnum`,`DES`.`DES.fofId` AS `DES.fofId`,`DES`.`DES.lastProgId` AS `DES.lastProgId` FROM MDR1.FOFMtree AS `PROG` JOIN ( SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`treeSnapnum`,`fofTreeId`,`lastProgId` FROM `aggregation_tmp_8213250`  ORDER BY `DES.fofId` ASC ) AS `DES`  WHERE (  PROG.mass > 1.e13 ) AND (  PROG.fofTreeId BETWEEN `DES`.`fofTreeId` AND `DES`.`lastProgId` )   ', 'aggregation_tmp_81069542');
CALL paquDropTmp('aggregation_tmp_8213250');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`
FROM `aggregation_tmp_81069542`  ORDER BY `DES.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_81069542');
This is the query plan optimisation output for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`DES.fofTreeId`=VALUES(`DES.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,DES.fofTreeId AS `DES.fofTreeId`
FROM MDR1.FOFMtree AS `DES` WHERE (  DES.treeSnapnum = 39 )   
)


-- AGGREGATION SQL:
SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId`
FROM `aggregation_tmp_47446542`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`DES.fofTreeId`=VALUES(`DES.fofTreeId`)
-- INPUT SQL:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,`DES`.`DES.mass` AS `DES.mass`,`DES`.`DES.treeSnapnum` AS `DES.treeSnapnum`,`DES`.`DES.fofId` AS `DES.fofId`,`DES`.`DES.lastProgId` AS `DES.lastProgId`
FROM MDR1.FOFMtree AS `PROG` JOIN ( SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId`
FROM `aggregation_tmp_47446542`  ORDER BY `DES.fofId` ASC ) AS `DES`  WHERE (  PROG.mass > 1.e13 ) AND (  PROG.fofTreeId BETWEEN `DES`.`DES.fofTreeId` AND `DES`.`DES.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`
FROM `aggregation_tmp_90700880`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`)
This is the query plan for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

CALL paquExec('SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,DES.fofTreeId AS `DES.fofTreeId` FROM MDR1.FOFMtree AS `DES` WHERE (  DES.treeSnapnum = 39 )   ', 'aggregation_tmp_47446542');
CALL paquExec('SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,`DES`.`DES.mass` AS `DES.mass`,`DES`.`DES.treeSnapnum` AS `DES.treeSnapnum`,`DES`.`DES.fofId` AS `DES.fofId`,`DES`.`DES.lastProgId` AS `DES.lastProgId` FROM MDR1.FOFMtree AS `PROG` JOIN ( SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId` FROM `aggregation_tmp_47446542`  ORDER BY `DES.fofId` ASC ) AS `DES`  WHERE (  PROG.mass > 1.e13 ) AND (  PROG.fofTreeId BETWEEN `DES`.`DES.fofTreeId` AND `DES`.`DES.lastProgId` )   ', 'aggregation_tmp_90700880');
CALL paquDropTmp('aggregation_tmp_47446542');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`
FROM `aggregation_tmp_90700880`  ORDER BY `DES.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_90700880');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR`
FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_71722775`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_71722775`   ) AS `h`  WHERE (  POWER (  `h`.`h.haloX` - p.x, 2 ) + POWER (  `h`.`h.haloY` - p.y, 2 ) + POWER (  `h`.`h.haloZ` - p.z, 2 ) <= `h`.`h.hR` * `h`.`h.hR` )   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_63083787`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR` FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   ', 'aggregation_tmp_71722775');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_71722775`   ) AS `h`  WHERE (  POWER (  `h`.`h.haloX` - p.x, 2 ) + POWER (  `h`.`h.haloY` - p.y, 2 ) + POWER (  `h`.`h.haloZ` - p.z, 2 ) <= `h`.`h.hR` * `h`.`h.hR` )   ', 'aggregation_tmp_63083787');
CALL paquDropTmp('aggregation_tmp_71722775');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_63083787`   ;
CALL paquDropTmp('aggregation_tmp_63083787');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR`
FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_15516052`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_15516052`   ) AS `h`  WHERE (  POWER (  `h`.`h.haloX` - p.x, 2 ) + POWER (  `h`.`h.haloY` - p.y, 2 ) + POWER (  `h`.`h.haloZ` - p.z, 2 ) <= `h`.`h.hR` * `h`.`h.hR` )   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_57660175`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR` FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   ', 'aggregation_tmp_15516052');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_15516052`   ) AS `h`  WHERE (  POWER (  `h`.`h.haloX` - p.x, 2 ) + POWER (  `h`.`h.haloY` - p.y, 2 ) + POWER (  `h`.`h.haloZ` - p.z, 2 ) <= `h`.`h.hR` * `h`.`h.hR` )   ', 'aggregation_tmp_57660175');
CALL paquDropTmp('aggregation_tmp_15516052');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_57660175`   ;
CALL paquDropTmp('aggregation_tmp_57660175');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR`
FROM MDR1.BDMV WHERE ( bdmId = 6200000001 )   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_65214265`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_65214265`   ) AS `h`  WHERE ( POWER() (h.haloX-p.x,2) + POWER() (h.haloY-p.y,2) + POWER() (h.haloZ-p.z,2) <= h.hR * h.hR )   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_69147014`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR` FROM MDR1.BDMV WHERE ( bdmId = 6200000001 )   ', 'aggregation_tmp_65214265');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_65214265`   ) AS `h`  WHERE ( POWER() (h.haloX-p.x,2) + POWER() (h.haloY-p.y,2) + POWER() (h.haloZ-p.z,2) <= h.hR * h.hR )   ', 'aggregation_tmp_69147014');
CALL paquDropTmp('aggregation_tmp_65214265');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_69147014`   ;
CALL paquDropTmp('aggregation_tmp_69147014');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR`
FROM MDR1.BDMV WHERE ( bdmId = 6200000001 )   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_46283105`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_46283105`   ) AS `h`  WHERE ( POWER() (h.haloX-p.x,2) + POWER() (h.haloY-p.y,2) + POWER() (h.haloZ-p.z,2) <= h.hR * h.hR )   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_26778814`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR` FROM MDR1.BDMV WHERE ( bdmId = 6200000001 )   ', 'aggregation_tmp_46283105');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_46283105`   ) AS `h`  WHERE ( POWER() (h.haloX-p.x,2) + POWER() (h.haloY-p.y,2) + POWER() (h.haloZ-p.z,2) <= h.hR * h.hR )   ', 'aggregation_tmp_26778814');
CALL paquDropTmp('aggregation_tmp_46283105');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_26778814`   ;
CALL paquDropTmp('aggregation_tmp_26778814');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR`
FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_40867324`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_40867324`   ) AS `h`  WHERE (  POWER (  `h`.`h.haloX` - p.x, 2 ) + POWER (  `h`.`h.haloY` - p.y, 2 ) + POWER (  `h`.`h.haloZ` - p.z, 2 ) <= `h`.`h.hR` * `h`.`h.hR` )   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_20783247`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR` FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   ', 'aggregation_tmp_40867324');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_40867324`   ) AS `h`  WHERE (  POWER (  `h`.`h.haloX` - p.x, 2 ) + POWER (  `h`.`h.haloY` - p.y, 2 ) + POWER (  `h`.`h.haloZ` - p.z, 2 ) <= `h`.`h.hR` * `h`.`h.hR` )   ', 'aggregation_tmp_20783247');
CALL paquDropTmp('aggregation_tmp_40867324');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_20783247`   ;
CALL paquDropTmp('aggregation_tmp_20783247');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR`
FROM MDR1.BDMV WHERE ( bdmId = 6200000001 )   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_25856473`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_25856473`   ) AS `h`  WHERE ( POWER() (h.haloX-p.x,2) + POWER() (h.haloY-p.y,2) + POWER() (h.haloZ-p.z,2) <= h.hR * h.hR )   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_91031480`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR` FROM MDR1.BDMV WHERE ( bdmId = 6200000001 )   ', 'aggregation_tmp_25856473');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_25856473`   ) AS `h`  WHERE ( POWER() (h.haloX-p.x,2) + POWER() (h.haloY-p.y,2) + POWER() (h.haloZ-p.z,2) <= h.hR * h.hR )   ', 'aggregation_tmp_91031480');
CALL paquDropTmp('aggregation_tmp_25856473');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_91031480`   ;
CALL paquDropTmp('aggregation_tmp_91031480');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR`
FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_45762405`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_45762405`   ) AS `h`  WHERE (  POWER (  `h`.`h.haloX` - p.x, 2 ) + POWER (  `h`.`h.haloY` - p.y, 2 ) + POWER (  `h`.`h.haloZ` - p.z, 2 ) <= `h`.`h.hR` * `h`.`h.hR` )   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_50979683`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR` FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   ', 'aggregation_tmp_45762405');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_45762405`   ) AS `h`  WHERE (  POWER (  `h`.`h.haloX` - p.x, 2 ) + POWER (  `h`.`h.haloY` - p.y, 2 ) + POWER (  `h`.`h.haloZ` - p.z, 2 ) <= `h`.`h.hR` * `h`.`h.hR` )   ', 'aggregation_tmp_50979683');
CALL paquDropTmp('aggregation_tmp_45762405');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_50979683`   ;
CALL paquDropTmp('aggregation_tmp_50979683');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR`
FROM MDR1.BDMV WHERE ( bdmId = 6200000001 )   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_65331322`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_65331322`   ) AS `h`  WHERE ( POWER() (h.haloX-p.x,2) + POWER() (h.haloY-p.y,2) + POWER() (h.haloZ-p.z,2) <= h.hR * h.hR )   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_59285815`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR` FROM MDR1.BDMV WHERE ( bdmId = 6200000001 )   ', 'aggregation_tmp_65331322');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_65331322`   ) AS `h`  WHERE ( POWER() (h.haloX-p.x,2) + POWER() (h.haloY-p.y,2) + POWER() (h.haloZ-p.z,2) <= h.hR * h.hR )   ', 'aggregation_tmp_59285815');
CALL paquDropTmp('aggregation_tmp_65331322');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_59285815`   ;
CALL paquDropTmp('aggregation_tmp_59285815');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR`
FROM MDR1.BDMV WHERE ( bdmId = 6200000001 )   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_30685311`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_30685311`   ) AS `h`  WHERE ( POWER() (h.haloX-p.x,2) + POWER() (h.haloY-p.y,2) + POWER() (h.haloZ-p.z,2) <= h.hR * h.hR )   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_42047032`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR` FROM MDR1.BDMV WHERE ( bdmId = 6200000001 )   ', 'aggregation_tmp_30685311');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_30685311`   ) AS `h`  WHERE ( POWER() (h.haloX-p.x,2) + POWER() (h.haloY-p.y,2) + POWER() (h.haloZ-p.z,2) <= h.hR * h.hR )   ', 'aggregation_tmp_42047032');
CALL paquDropTmp('aggregation_tmp_30685311');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_42047032`   ;
CALL paquDropTmp('aggregation_tmp_42047032');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR`
FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_13272373`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_13272373`   ) AS `h`  WHERE (  POWER (  `h`.`h.haloX` - p.x, 2 ) + POWER (  `h`.`h.haloY` - p.y, 2 ) + POWER (  `h`.`h.haloZ` - p.z, 2 ) <= `h`.`h.hR` * `h`.`h.hR` )   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_47884729`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR` FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   ', 'aggregation_tmp_13272373');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_13272373`   ) AS `h`  WHERE (  POWER (  `h`.`h.haloX` - p.x, 2 ) + POWER (  `h`.`h.haloY` - p.y, 2 ) + POWER (  `h`.`h.haloZ` - p.z, 2 ) <= `h`.`h.hR` * `h`.`h.hR` )   ', 'aggregation_tmp_47884729');
CALL paquDropTmp('aggregation_tmp_13272373');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_47884729`   ;
CALL paquDropTmp('aggregation_tmp_47884729');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR`
FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_90083238`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_90083238`   ) AS `h`  WHERE (  POWER (  `h`.`h.haloX` - p.x, 2 ) + POWER (  `h`.`h.haloY` - p.y, 2 ) + POWER (  `h`.`h.haloZ` - p.z, 2 ) <= `h`.`h.hR` * `h`.`h.hR` )   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_31658326`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR` FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   ', 'aggregation_tmp_90083238');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_90083238`   ) AS `h`  WHERE (  POWER (  `h`.`h.haloX` - p.x, 2 ) + POWER (  `h`.`h.haloY` - p.y, 2 ) + POWER (  `h`.`h.haloZ` - p.z, 2 ) <= `h`.`h.hR` * `h`.`h.hR` )   ', 'aggregation_tmp_31658326');
CALL paquDropTmp('aggregation_tmp_90083238');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_31658326`   ;
CALL paquDropTmp('aggregation_tmp_31658326');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR`
FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_8227599`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_8227599`   ) AS `h`  WHERE (  POWER (  `h`.`h.haloX` - p.x, 2 ) + POWER (  `h`.`h.haloY` - p.y, 2 ) + POWER (  `h`.`h.haloZ` - p.z, 2 ) <= `h`.`h.hR` * `h`.`h.hR` )   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_13434055`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR` FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   ', 'aggregation_tmp_8227599');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_8227599`   ) AS `h`  WHERE (  POWER (  `h`.`h.haloX` - p.x, 2 ) + POWER (  `h`.`h.haloY` - p.y, 2 ) + POWER (  `h`.`h.haloZ` - p.z, 2 ) <= `h`.`h.hR` * `h`.`h.hR` )   ', 'aggregation_tmp_13434055');
CALL paquDropTmp('aggregation_tmp_8227599');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_13434055`   ;
CALL paquDropTmp('aggregation_tmp_13434055');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR`
FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_81148437`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_81148437`   ) AS `h`  WHERE (  POWER (  `h`.`h.haloX` - p.x, 2 ) + POWER (  `h`.`h.haloY` - p.y, 2 ) + POWER (  `h`.`h.haloZ` - p.z, 2 ) <= `h`.`h.hR` * `h`.`h.hR` )   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_41911590`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR` FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   ', 'aggregation_tmp_81148437');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_81148437`   ) AS `h`  WHERE (  POWER (  `h`.`h.haloX` - p.x, 2 ) + POWER (  `h`.`h.haloY` - p.y, 2 ) + POWER (  `h`.`h.haloZ` - p.z, 2 ) <= `h`.`h.hR` * `h`.`h.hR` )   ', 'aggregation_tmp_41911590');
CALL paquDropTmp('aggregation_tmp_81148437');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_41911590`   ;
CALL paquDropTmp('aggregation_tmp_41911590');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR`
FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_30329696`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_30329696`   ) AS `h`  WHERE (  POWER (  `h`.`h.haloX` - p.x, 2 ) + POWER (  `h`.`h.haloY` - p.y, 2 ) + POWER (  `h`.`h.haloZ` - p.z, 2 ) <= `h`.`h.hR` * `h`.`h.hR` )   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_68586708`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR` FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   ', 'aggregation_tmp_30329696');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_30329696`   ) AS `h`  WHERE (  POWER (  `h`.`h.haloX` - p.x, 2 ) + POWER (  `h`.`h.haloY` - p.y, 2 ) + POWER (  `h`.`h.haloZ` - p.z, 2 ) <= `h`.`h.hR` * `h`.`h.hR` )   ', 'aggregation_tmp_68586708');
CALL paquDropTmp('aggregation_tmp_30329696');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_68586708`   ;
CALL paquDropTmp('aggregation_tmp_68586708');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR`
FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_83993249`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_83993249`   ) AS `h`  WHERE (  POWER (  `h`.`h.haloX` - p.x, 2 ) + POWER (  `h`.`h.haloY` - p.y, 2 ) + POWER (  `h`.`h.haloZ` - p.z, 2 ) <= `h`.`h.hR` * `h`.`h.hR` )   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_34883067`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR` FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   ', 'aggregation_tmp_83993249');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_83993249`   ) AS `h`  WHERE (  POWER (  `h`.`h.haloX` - p.x, 2 ) + POWER (  `h`.`h.haloY` - p.y, 2 ) + POWER (  `h`.`h.haloZ` - p.z, 2 ) <= `h`.`h.hR` * `h`.`h.hR` )   ', 'aggregation_tmp_34883067');
CALL paquDropTmp('aggregation_tmp_83993249');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_34883067`   ;
CALL paquDropTmp('aggregation_tmp_34883067');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR`
FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_3010593`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_3010593`   ) AS `h`  WHERE (  POWER (  `h`.`h.haloX` - p.x, 2 ) + POWER (  `h`.`h.haloY` - p.y, 2 ) + POWER (  `h`.`h.haloZ` - p.z, 2 ) <= `h`.`h.hR` * `h`.`h.hR` )   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_35727947`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR` FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   ', 'aggregation_tmp_3010593');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_3010593`   ) AS `h`  WHERE (  POWER (  `h`.`h.haloX` - p.x, 2 ) + POWER (  `h`.`h.haloY` - p.y, 2 ) + POWER (  `h`.`h.haloZ` - p.z, 2 ) <= `h`.`h.hR` * `h`.`h.hR` )   ', 'aggregation_tmp_35727947');
CALL paquDropTmp('aggregation_tmp_3010593');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_35727947`   ;
CALL paquDropTmp('aggregation_tmp_35727947');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR`
FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_96035598`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_96035598`   ) AS `h`  WHERE (  POWER (  `h.haloX` - p.x, 2 ) + POWER (  `h.haloY` - p.y, 2 ) + POWER (  `h.haloZ` - p.z, 2 ) <= `h.hR` * `h.hR` )   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_31071038`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR` FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   ', 'aggregation_tmp_96035598');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_96035598`   ) AS `h`  WHERE (  POWER (  `h.haloX` - p.x, 2 ) + POWER (  `h.haloY` - p.y, 2 ) + POWER (  `h.haloZ` - p.z, 2 ) <= `h.hR` * `h.hR` )   ', 'aggregation_tmp_31071038');
CALL paquDropTmp('aggregation_tmp_96035598');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_31071038`   ;
CALL paquDropTmp('aggregation_tmp_31071038');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR`
FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_77606761`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_77606761`   ) AS `h`  WHERE (  POWER (  `h.haloX` - p.x, 2 ) + POWER (  `h.haloY` - p.y, 2 ) + POWER (  `h.haloZ` - p.z, 2 ) <= `h.hR` * `h.hR` )   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_63488172`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR` FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   ', 'aggregation_tmp_77606761');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_77606761`   ) AS `h`  WHERE (  POWER (  `h.haloX` - p.x, 2 ) + POWER (  `h.haloY` - p.y, 2 ) + POWER (  `h.haloZ` - p.z, 2 ) <= `h.hR` * `h.hR` )   ', 'aggregation_tmp_63488172');
CALL paquDropTmp('aggregation_tmp_77606761');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_63488172`   ;
CALL paquDropTmp('aggregation_tmp_63488172');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR`
FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_90339479`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_90339479`   ) AS `h`  WHERE (  POWER (  `h.haloX` - p.x, 2 ) + POWER (  `h.haloY` - p.y, 2 ) + POWER (  `h.haloZ` - p.z, 2 ) <= `h.hR` * `h.hR` )   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_72653471`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR` FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   ', 'aggregation_tmp_90339479');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_90339479`   ) AS `h`  WHERE (  POWER (  `h.haloX` - p.x, 2 ) + POWER (  `h.haloY` - p.y, 2 ) + POWER (  `h.haloZ` - p.z, 2 ) <= `h.hR` * `h.hR` )   ', 'aggregation_tmp_72653471');
CALL paquDropTmp('aggregation_tmp_90339479');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_72653471`   ;
CALL paquDropTmp('aggregation_tmp_72653471');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR`
FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_49265018`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_49265018`   ) AS `h`  WHERE (  POWER (  h.haloX - p.x, 2 ) + POWER (  h.haloY - p.y, 2 ) + POWER (  h.haloZ - p.z, 2 ) <= h.hR * h.hR )   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_93468269`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR` FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   ', 'aggregation_tmp_49265018');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_49265018`   ) AS `h`  WHERE (  POWER (  h.haloX - p.x, 2 ) + POWER (  h.haloY - p.y, 2 ) + POWER (  h.haloZ - p.z, 2 ) <= h.hR * h.hR )   ', 'aggregation_tmp_93468269');
CALL paquDropTmp('aggregation_tmp_49265018');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_93468269`   ;
CALL paquDropTmp('aggregation_tmp_93468269');
This is the query plan optimisation output for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`DES.fofTreeId`=VALUES(`DES.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,DES.fofTreeId AS `DES.fofTreeId`
FROM MDR1.FOFMtree AS `DES` WHERE (  DES.treeSnapnum = 39 )   
)


-- AGGREGATION SQL:
SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId`
FROM `aggregation_tmp_94532204`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`DES.fofTreeId`=VALUES(`DES.fofTreeId`)
-- INPUT SQL:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,`DES`.`DES.mass` AS `DES.mass`,`DES`.`DES.treeSnapnum` AS `DES.treeSnapnum`,`DES`.`DES.fofId` AS `DES.fofId`,`DES`.`DES.lastProgId` AS `DES.lastProgId`
FROM MDR1.FOFMtree AS `PROG` JOIN ( SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId`
FROM `aggregation_tmp_94532204`  ORDER BY `DES.fofId` ASC ) AS `DES`  WHERE (  PROG.mass > 1.e13 ) AND (  PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId )   
)


-- AGGREGATION SQL:
SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`
FROM `aggregation_tmp_76796491`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`)
This is the query plan for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

CALL paquExec('SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,DES.fofTreeId AS `DES.fofTreeId` FROM MDR1.FOFMtree AS `DES` WHERE (  DES.treeSnapnum = 39 )   ', 'aggregation_tmp_94532204');
CALL paquExec('SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,`DES`.`DES.mass` AS `DES.mass`,`DES`.`DES.treeSnapnum` AS `DES.treeSnapnum`,`DES`.`DES.fofId` AS `DES.fofId`,`DES`.`DES.lastProgId` AS `DES.lastProgId` FROM MDR1.FOFMtree AS `PROG` JOIN ( SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId` FROM `aggregation_tmp_94532204`  ORDER BY `DES.fofId` ASC ) AS `DES`  WHERE (  PROG.mass > 1.e13 ) AND (  PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId )   ', 'aggregation_tmp_76796491');
CALL paquDropTmp('aggregation_tmp_94532204');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`
FROM `aggregation_tmp_76796491`  ORDER BY `DES.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_76796491');
This is the query plan optimisation output for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`DES.fofTreeId`=VALUES(`DES.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,DES.fofTreeId AS `DES.fofTreeId`
FROM MDR1.FOFMtree AS `DES` WHERE (  DES.treeSnapnum = 39 )   
)


-- AGGREGATION SQL:
SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId`
FROM `aggregation_tmp_20983493`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`DES.fofTreeId`=VALUES(`DES.fofTreeId`)
-- INPUT SQL:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,`DES`.`DES.mass` AS `DES.mass`,`DES`.`DES.treeSnapnum` AS `DES.treeSnapnum`,`DES`.`DES.fofId` AS `DES.fofId`,`DES`.`DES.lastProgId` AS `DES.lastProgId`
FROM MDR1.FOFMtree AS `PROG` JOIN ( SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId`
FROM `aggregation_tmp_20983493`  ORDER BY `DES.fofId` ASC ) AS `DES`  WHERE (  PROG.mass > 1.e13 ) AND (  PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId )   
)


-- AGGREGATION SQL:
SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`
FROM `aggregation_tmp_73453217`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`)
This is the query plan for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

CALL paquExec('SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,DES.fofTreeId AS `DES.fofTreeId` FROM MDR1.FOFMtree AS `DES` WHERE (  DES.treeSnapnum = 39 )   ', 'aggregation_tmp_20983493');
CALL paquExec('SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,`DES`.`DES.mass` AS `DES.mass`,`DES`.`DES.treeSnapnum` AS `DES.treeSnapnum`,`DES`.`DES.fofId` AS `DES.fofId`,`DES`.`DES.lastProgId` AS `DES.lastProgId` FROM MDR1.FOFMtree AS `PROG` JOIN ( SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId` FROM `aggregation_tmp_20983493`  ORDER BY `DES.fofId` ASC ) AS `DES`  WHERE (  PROG.mass > 1.e13 ) AND (  PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId )   ', 'aggregation_tmp_73453217');
CALL paquDropTmp('aggregation_tmp_20983493');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`
FROM `aggregation_tmp_73453217`  ORDER BY `DES.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_73453217');
This is the query plan optimisation output for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`DES.fofTreeId`=VALUES(`DES.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,DES.fofTreeId AS `DES.fofTreeId`
FROM MDR1.FOFMtree AS `DES` WHERE (  DES.treeSnapnum = 39 )   
)


-- AGGREGATION SQL:
SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId`
FROM `aggregation_tmp_82102295`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`DES.fofTreeId`=VALUES(`DES.fofTreeId`)
-- INPUT SQL:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,`DES`.`DES.mass` AS `DES.mass`,`DES`.`DES.treeSnapnum` AS `DES.treeSnapnum`,`DES`.`DES.fofId` AS `DES.fofId`,`DES`.`DES.lastProgId` AS `DES.lastProgId`
FROM MDR1.FOFMtree AS `PROG` JOIN ( SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId`
FROM `aggregation_tmp_82102295`  ORDER BY `DES.fofId` ASC ) AS `DES`  WHERE (  PROG.mass > 1.e13 ) AND (  PROG.fofTreeId BETWEEN `DES.fofTreeId` AND `DES.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`
FROM `aggregation_tmp_28844069`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`)
This is the query plan for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

CALL paquExec('SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,DES.fofTreeId AS `DES.fofTreeId` FROM MDR1.FOFMtree AS `DES` WHERE (  DES.treeSnapnum = 39 )   ', 'aggregation_tmp_82102295');
CALL paquExec('SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,`DES`.`DES.mass` AS `DES.mass`,`DES`.`DES.treeSnapnum` AS `DES.treeSnapnum`,`DES`.`DES.fofId` AS `DES.fofId`,`DES`.`DES.lastProgId` AS `DES.lastProgId` FROM MDR1.FOFMtree AS `PROG` JOIN ( SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId` FROM `aggregation_tmp_82102295`  ORDER BY `DES.fofId` ASC ) AS `DES`  WHERE (  PROG.mass > 1.e13 ) AND (  PROG.fofTreeId BETWEEN `DES.fofTreeId` AND `DES.lastProgId` )   ', 'aggregation_tmp_28844069');
CALL paquDropTmp('aggregation_tmp_82102295');
USE spider_tmp_shard; CREATE TABLE tmp.tmp ENGINE=MyISAM SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`
FROM `aggregation_tmp_28844069`  ORDER BY `DES.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_28844069');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR`
FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_94094558`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_94094558`   ) AS `h`  WHERE (  POWER (  `h.haloX` - p.x, 2 ) + POWER (  `h.haloY` - p.y, 2 ) + POWER (  `h.haloZ` - p.z, 2 ) <= `h.hR` * `h.hR` )   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_57865155`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR` FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   ', 'aggregation_tmp_94094558');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_94094558`   ) AS `h`  WHERE (  POWER (  `h.haloX` - p.x, 2 ) + POWER (  `h.haloY` - p.y, 2 ) + POWER (  `h.haloZ` - p.z, 2 ) <= `h.hR` * `h.hR` )   ', 'aggregation_tmp_57865155');
CALL paquDropTmp('aggregation_tmp_94094558');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_57865155`   ;
CALL paquDropTmp('aggregation_tmp_57865155');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR`
FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_37331927`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_37331927`   ) AS `h`  WHERE (  POWER (  `h.haloX` - p.x, 2 ) + POWER (  `h.haloY` - p.y, 2 ) + POWER (  `h.haloZ` - p.z, 2 ) <= `h.hR` * `h.hR` )   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_8700185`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR` FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   ', 'aggregation_tmp_37331927');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_37331927`   ) AS `h`  WHERE (  POWER (  `h.haloX` - p.x, 2 ) + POWER (  `h.haloY` - p.y, 2 ) + POWER (  `h.haloZ` - p.z, 2 ) <= `h.hR` * `h.hR` )   ', 'aggregation_tmp_8700185');
CALL paquDropTmp('aggregation_tmp_37331927');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_8700185`   ;
CALL paquDropTmp('aggregation_tmp_8700185');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR`
FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_76371286`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_76371286`   ) AS `h`  WHERE (  POWER (  `h.haloX` - p.x, 2 ) + POWER (  `h.haloY` - p.y, 2 ) + POWER (  `h.haloZ` - p.z, 2 ) <= `h.hR` * `h.hR` )   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_19316778`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR` FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   ', 'aggregation_tmp_76371286');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_76371286`   ) AS `h`  WHERE (  POWER (  `h.haloX` - p.x, 2 ) + POWER (  `h.haloY` - p.y, 2 ) + POWER (  `h.haloZ` - p.z, 2 ) <= `h.hR` * `h.hR` )   ', 'aggregation_tmp_19316778');
CALL paquDropTmp('aggregation_tmp_76371286');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_19316778`   ;
CALL paquDropTmp('aggregation_tmp_19316778');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR`
FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_37904074`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_37904074`   ) AS `h`  WHERE (  POWER (  `h`.`h.haloX` - p.x, 2 ) + POWER (  `h`.`h.haloY` - p.y, 2 ) + POWER (  `h`.`h.haloZ` - p.z, 2 ) <= `h`.`h.hR` * `h`.`h.hR` )   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_15343697`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR` FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   ', 'aggregation_tmp_37904074');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_37904074`   ) AS `h`  WHERE (  POWER (  `h`.`h.haloX` - p.x, 2 ) + POWER (  `h`.`h.haloY` - p.y, 2 ) + POWER (  `h`.`h.haloZ` - p.z, 2 ) <= `h`.`h.hR` * `h`.`h.hR` )   ', 'aggregation_tmp_15343697');
CALL paquDropTmp('aggregation_tmp_37904074');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_15343697`   ;
CALL paquDropTmp('aggregation_tmp_15343697');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR`
FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_45942171`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_45942171`   ) AS `h`  WHERE (  POWER (  `h`.`h.haloX` - p.x, 2 ) + POWER (  `h`.`h.haloY` - p.y, 2 ) + POWER (  `h`.`h.haloZ` - p.z, 2 ) <= `h`.`h.hR` * `h`.`h.hR` )   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_90014565`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR` FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   ', 'aggregation_tmp_45942171');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_45942171`   ) AS `h`  WHERE (  POWER (  `h`.`h.haloX` - p.x, 2 ) + POWER (  `h`.`h.haloY` - p.y, 2 ) + POWER (  `h`.`h.haloZ` - p.z, 2 ) <= `h`.`h.hR` * `h`.`h.hR` )   ', 'aggregation_tmp_90014565');
CALL paquDropTmp('aggregation_tmp_45942171');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_90014565`   ;
CALL paquDropTmp('aggregation_tmp_90014565');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR`
FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_21907370`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_21907370`   ) AS `h`  WHERE (  POWER (  `h`.`h.haloX` - p.x, 2 ) + POWER (  `h`.`h.haloY` - p.y, 2 ) + POWER (  `h`.`h.haloZ` - p.z, 2 ) <= `h`.`h.hR` * `h`.`h.hR` )   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_32925316`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR` FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   ', 'aggregation_tmp_21907370');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_21907370`   ) AS `h`  WHERE (  POWER (  `h`.`h.haloX` - p.x, 2 ) + POWER (  `h`.`h.haloY` - p.y, 2 ) + POWER (  `h`.`h.haloZ` - p.z, 2 ) <= `h`.`h.hR` * `h`.`h.hR` )   ', 'aggregation_tmp_32925316');
CALL paquDropTmp('aggregation_tmp_21907370');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_32925316`   ;
CALL paquDropTmp('aggregation_tmp_32925316');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR`
FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_84820839`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_84820839`   ) AS `h`  WHERE (  POWER (  `h`.`h.haloX` - p.x, 2 ) + POWER (  `h`.`h.haloY` - p.y, 2 ) + POWER (  `h`.`h.haloZ` - p.z, 2 ) <= `h`.`h.hR` * `h`.`h.hR` )   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_94795658`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR` FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   ', 'aggregation_tmp_84820839');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_84820839`   ) AS `h`  WHERE (  POWER (  `h`.`h.haloX` - p.x, 2 ) + POWER (  `h`.`h.haloY` - p.y, 2 ) + POWER (  `h`.`h.haloZ` - p.z, 2 ) <= `h`.`h.hR` * `h`.`h.hR` )   ', 'aggregation_tmp_94795658');
CALL paquDropTmp('aggregation_tmp_84820839');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_94795658`   ;
CALL paquDropTmp('aggregation_tmp_94795658');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR`
FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_67990050`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_67990050`   ) AS `h`  WHERE (  POWER (  `h`.`h.haloX` - p.x, 2 ) + POWER (  `h`.`h.haloY` - p.y, 2 ) + POWER (  `h`.`h.haloZ` - p.z, 2 ) <= `h`.`h.hR` * `h`.`h.hR` )   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_41960002`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR` FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   ', 'aggregation_tmp_67990050');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_67990050`   ) AS `h`  WHERE (  POWER (  `h`.`h.haloX` - p.x, 2 ) + POWER (  `h`.`h.haloY` - p.y, 2 ) + POWER (  `h`.`h.haloZ` - p.z, 2 ) <= `h`.`h.hR` * `h`.`h.hR` )   ', 'aggregation_tmp_41960002');
CALL paquDropTmp('aggregation_tmp_67990050');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_41960002`   ;
CALL paquDropTmp('aggregation_tmp_41960002');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR`
FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_41320401`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_41320401`   ) AS `h`  WHERE (  POWER (  `h`.`h.haloX` - p.x, 2 ) + POWER (  `h`.`h.haloY` - p.y, 2 ) + POWER (  `h`.`h.haloZ` - p.z, 2 ) <= `h`.`h.hR` * `h`.`h.hR` )   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_67934701`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR` FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   ', 'aggregation_tmp_41320401');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_41320401`   ) AS `h`  WHERE (  POWER (  `h`.`h.haloX` - p.x, 2 ) + POWER (  `h`.`h.haloY` - p.y, 2 ) + POWER (  `h`.`h.haloZ` - p.z, 2 ) <= `h`.`h.hR` * `h`.`h.hR` )   ', 'aggregation_tmp_67934701');
CALL paquDropTmp('aggregation_tmp_41320401');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_67934701`   ;
CALL paquDropTmp('aggregation_tmp_67934701');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR`
FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_84993487`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_84993487`   ) AS `h`  WHERE (  POWER (  `h`.`h.haloX` - p.x, 2 ) + POWER (  `h`.`h.haloY` - p.y, 2 ) + POWER (  `h`.`h.haloZ` - p.z, 2 ) <= `h`.`h.hR` * `h`.`h.hR` )   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_2109252`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR` FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   ', 'aggregation_tmp_84993487');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_84993487`   ) AS `h`  WHERE (  POWER (  `h`.`h.haloX` - p.x, 2 ) + POWER (  `h`.`h.haloY` - p.y, 2 ) + POWER (  `h`.`h.haloZ` - p.z, 2 ) <= `h`.`h.hR` * `h`.`h.hR` )   ', 'aggregation_tmp_2109252');
CALL paquDropTmp('aggregation_tmp_84993487');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_2109252`   ;
CALL paquDropTmp('aggregation_tmp_2109252');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR`
FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_31557359`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_31557359`   ) AS `h`  WHERE (  POWER (  `h`.`haloX` - p.x, 2 ) + POWER (  `h`.`haloY` - p.y, 2 ) + POWER (  `h`.`haloZ` - p.z, 2 ) <= `h`.`hR` * `h`.`hR` )   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_43875042`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x  AS `haloX`,y  AS `haloY`,z  AS `haloZ`,Rvir  AS `hR` FROM MDR1.BDMV WHERE (  bdmId = 6200000001 )   ', 'aggregation_tmp_31557359');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_31557359`   ) AS `h`  WHERE (  POWER (  `h`.`haloX` - p.x, 2 ) + POWER (  `h`.`haloY` - p.y, 2 ) + POWER (  `h`.`haloZ` - p.z, 2 ) <= `h`.`hR` * `h`.`hR` )   ', 'aggregation_tmp_43875042');
CALL paquDropTmp('aggregation_tmp_31557359');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_43875042`   ;
CALL paquDropTmp('aggregation_tmp_43875042');
This is the query plan optimisation output for the query:
SELECT * from barbar;

-- INPUT SQL:
SELECT * from barbar;

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`
FROM barbar ORDER BY NULL 
)


-- AGGREGATION SQL:
SELECT `*`
FROM `aggregation_tmp_75050795`   
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)
This is the query plan for the query:
SELECT * from barbar;

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_75050795 ENGINE=MyISAM SELECT * AS `*`
FROM barbar ORDER BY NULL  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_75050795 SELECT * AS `*`
FROM barbar ORDER BY NULL ;
CALL paquLinkTmp('aggregation_tmp_75050795');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`
FROM `aggregation_tmp_75050795`   ;
CALL paquDropTmp('aggregation_tmp_75050795');
This is the query plan optimisation output for the query:
SELECT * from barbar;

-- INPUT SQL:
SELECT * from barbar;

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`
FROM barbar ORDER BY NULL 
)


-- AGGREGATION SQL:
SELECT `*`
FROM `aggregation_tmp_86819940`   
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)
This is the query plan for the query:
SELECT * from barbar;

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_86819940 ENGINE=MyISAM SELECT * AS `*`
FROM barbar ORDER BY NULL  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_86819940 SELECT * AS `*`
FROM barbar ORDER BY NULL ;
CALL paquLinkTmp('aggregation_tmp_86819940');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`
FROM `aggregation_tmp_86819940`   ;
CALL paquDropTmp('aggregation_tmp_86819940');
This is the query plan optimisation output for the query:
SELECT * from barbar;

-- INPUT SQL:
SELECT * from barbar;

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`
FROM barbar ORDER BY NULL 
)


-- AGGREGATION SQL:
SELECT `*`
FROM `aggregation_tmp_95210410`   
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)
This is the query plan for the query:
SELECT * from barbar;

CALL paquExec('SELECT * AS `*` FROM barbar ORDER BY NULL ', 'aggregation_tmp_95210410');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`
FROM `aggregation_tmp_95210410`   ;
CALL paquDropTmp('aggregation_tmp_95210410');
This is the query plan optimisation output for the query:
SELECT * from barbar;

-- INPUT SQL:
SELECT * from barbar;

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`
FROM barbar ORDER BY NULL 
)


-- AGGREGATION SQL:
SELECT `*`
FROM `aggregation_tmp_77693380`   
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)
This is the query plan for the query:
SELECT * from barbar;

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_77693380 ENGINE=MyISAM SELECT * AS `*`
FROM barbar ORDER BY NULL  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_77693380 SELECT * AS `*`
FROM barbar ORDER BY NULL ;
CALL paquLinkTmp('aggregation_tmp_77693380');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`
FROM `aggregation_tmp_77693380`   ;
CALL paquDropTmp('aggregation_tmp_77693380');
This is the query plan optimisation output for the query:
SELECT * from barbar;

-- INPUT SQL:
SELECT * from barbar;

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`
FROM barbar ORDER BY NULL 
)


-- AGGREGATION SQL:
SELECT `*`
FROM `aggregation_tmp_23986911`   
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)
This is the query plan for the query:
SELECT * from barbar;

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_23986911 ENGINE=MyISAM SELECT * AS `*`
FROM barbar ORDER BY NULL  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_23986911 SELECT * AS `*`
FROM barbar ORDER BY NULL ;
CALL paquLinkTmp('aggregation_tmp_23986911');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`
FROM `aggregation_tmp_23986911`   ;
CALL paquDropTmp('aggregation_tmp_23986911');
This is the query plan optimisation output for the query:
SELECT * from barbar;

-- INPUT SQL:
SELECT * from barbar;

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`
FROM barbar ORDER BY NULL 
)


-- AGGREGATION SQL:
SELECT `*`
FROM `aggregation_tmp_55218499`   
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)
This is the query plan for the query:
SELECT * from barbar;

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_55218499 ENGINE=MyISAM SELECT * AS `*`
FROM barbar ORDER BY NULL  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_55218499 SELECT * AS `*`
FROM barbar ORDER BY NULL ;
CALL paquLinkTmp('aggregation_tmp_55218499');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`
FROM `aggregation_tmp_55218499`   ;
CALL paquDropTmp('aggregation_tmp_55218499');
This is the query plan optimisation output for the query:
SELECT * from barbar;

-- INPUT SQL:
SELECT * from barbar;

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`
FROM barbar ORDER BY NULL 
)


-- AGGREGATION SQL:
SELECT `*`
FROM `aggregation_tmp_49140657`   
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)
This is the query plan for the query:
SELECT * from barbar;

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_49140657 ENGINE=MyISAM SELECT * AS `*`
FROM barbar ORDER BY NULL  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_49140657 SELECT * AS `*`
FROM barbar ORDER BY NULL ;
CALL paquLinkTmp('aggregation_tmp_49140657');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`
FROM `aggregation_tmp_49140657`   ;
CALL paquDropTmp('aggregation_tmp_49140657');
This is the query plan optimisation output for the query:
SELECT * from barbar;

-- INPUT SQL:
SELECT * from barbar;

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`
FROM barbar ORDER BY NULL 
)


-- AGGREGATION SQL:
SELECT `*`
FROM `aggregation_tmp_21275034`   
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)
This is the query plan for the query:
SELECT * from barbar;

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_21275034 ENGINE=MyISAM SELECT * AS `*`
FROM barbar ORDER BY NULL  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_21275034 SELECT * AS `*`
FROM barbar ORDER BY NULL ;
CALL paquLinkTmp('aggregation_tmp_21275034');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`
FROM `aggregation_tmp_21275034`   ;
CALL paquDropTmp('aggregation_tmp_21275034');
This is the query plan optimisation output for the query:
SELECT * from barbar;

-- INPUT SQL:
SELECT * from barbar;

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`
FROM barbar ORDER BY NULL 
)


-- AGGREGATION SQL:
SELECT `*`
FROM `aggregation_tmp_28834447`   
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)
This is the query plan for the query:
SELECT * from barbar;

CALL paquExec('SELECT * AS `*` FROM barbar ORDER BY NULL ', 'aggregation_tmp_28834447');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`
FROM `aggregation_tmp_28834447`   ;
CALL paquDropTmp('aggregation_tmp_28834447');
This is the query plan optimisation output for the query:
SELECT * from bar WHERE i=1;

-- INPUT SQL:
SELECT * from bar WHERE i=1;

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`
FROM bar WHERE (  i = 1 )   
)


-- AGGREGATION SQL:
SELECT `*`
FROM `aggregation_tmp_12349054`   
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)
This is the query plan for the query:
SELECT * from bar WHERE i=1;

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_12349054 ENGINE=MyISAM SELECT * AS `*`
FROM bar WHERE (  i = 1 )    LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_12349054 SELECT * AS `*`
FROM bar WHERE (  i = 1 )   ;
CALL paquLinkTmp('aggregation_tmp_12349054');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`
FROM `aggregation_tmp_12349054`   ;
CALL paquDropTmp('aggregation_tmp_12349054');
This is the query plan optimisation output for the query:
SELECT * from barbar WHERE i=1;

-- INPUT SQL:
SELECT * from barbar WHERE i=1;

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`
FROM barbar WHERE (  i = 1 )   
)


-- AGGREGATION SQL:
SELECT `*`
FROM `aggregation_tmp_74992953`   
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)
This is the query plan for the query:
SELECT * from barbar WHERE i=1;

CALL paquExec('SELECT * AS `*` FROM barbar WHERE (  i = 1 )   ', 'aggregation_tmp_74992953');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`
FROM `aggregation_tmp_74992953`   ;
CALL paquDropTmp('aggregation_tmp_74992953');
This is the query plan optimisation output for the query:
SELECT i from barbar WHERE i=1;

-- INPUT SQL:
SELECT i from barbar WHERE i=1;

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`i`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`i`=VALUES(`i`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT i AS `i`
FROM barbar WHERE (  i = 1 )   
)


-- AGGREGATION SQL:
SELECT `i`
FROM `aggregation_tmp_36724740`   
ON DUPLICATE KEY UPDATE
`i`=VALUES(`i`)
This is the query plan for the query:
SELECT i from barbar WHERE i=1;

CALL paquExec('SELECT i AS `i` FROM barbar WHERE (  i = 1 )   ', 'aggregation_tmp_36724740');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `i`
FROM `aggregation_tmp_36724740`   ;
CALL paquDropTmp('aggregation_tmp_36724740');
This is the query plan optimisation output for the query:
SELECT i from barbar WHERE i=1;

-- INPUT SQL:
SELECT i from barbar WHERE i=1;

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`i`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`i`=VALUES(`i`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT i AS `i`
FROM barbar WHERE (  i = 1 )   
)


-- AGGREGATION SQL:
SELECT `i`
FROM `aggregation_tmp_29801183`   
ON DUPLICATE KEY UPDATE
`i`=VALUES(`i`)
This is the query plan for the query:
SELECT i from barbar WHERE i=1;

CALL paquExec('SELECT i AS `i` FROM barbar WHERE (  i = 1 )   ', 'aggregation_tmp_29801183');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `i`
FROM `aggregation_tmp_29801183`   ;
CALL paquDropTmp('aggregation_tmp_29801183');
This is the query plan optimisation output for the query:
SELECT i from bar WHERE i=1;

-- INPUT SQL:
SELECT i from bar WHERE i=1;

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`i`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`i`=VALUES(`i`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT i AS `i`
FROM bar WHERE (  i = 1 )   
)


-- AGGREGATION SQL:
SELECT `i`
FROM `aggregation_tmp_11967387`   
ON DUPLICATE KEY UPDATE
`i`=VALUES(`i`)
This is the query plan for the query:
SELECT i from bar WHERE i=1;

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_11967387 ENGINE=MyISAM SELECT i AS `i`
FROM bar WHERE (  i = 1 )    LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_11967387 SELECT i AS `i`
FROM bar WHERE (  i = 1 )   ;
CALL paquLinkTmp('aggregation_tmp_11967387');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `i`
FROM `aggregation_tmp_11967387`   ;
CALL paquDropTmp('aggregation_tmp_11967387');
This is the query plan optimisation output for the query:
SELECT i from bar WHERE i=1;

-- INPUT SQL:
SELECT i from bar WHERE i=1;

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`i`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`i`=VALUES(`i`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT i AS `i`
FROM bar WHERE (  i = 1 )   
)


-- AGGREGATION SQL:
SELECT `i`
FROM `aggregation_tmp_8188346`   
ON DUPLICATE KEY UPDATE
`i`=VALUES(`i`)
This is the query plan for the query:
SELECT i from bar WHERE i=1;

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_8188346 ENGINE=MyISAM SELECT i AS `i`
FROM bar WHERE (  i = 1 )    LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_8188346 SELECT i AS `i`
FROM bar WHERE (  i = 1 )   ;
CALL paquLinkTmp('aggregation_tmp_8188346');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `i`
FROM `aggregation_tmp_8188346`   ;
CALL paquDropTmp('aggregation_tmp_8188346');
This is the query plan optimisation output for the query:
SELECT i from bar WHERE i>1;

-- INPUT SQL:
SELECT i from bar WHERE i>1;

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`i`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`i`=VALUES(`i`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT i AS `i`
FROM bar WHERE (  i > 1 )   
)


-- AGGREGATION SQL:
SELECT `i`
FROM `aggregation_tmp_59503829`   
ON DUPLICATE KEY UPDATE
`i`=VALUES(`i`)
This is the query plan for the query:
SELECT i from bar WHERE i>1;

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_59503829 ENGINE=MyISAM SELECT i AS `i`
FROM bar WHERE (  i > 1 )    LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_59503829 SELECT i AS `i`
FROM bar WHERE (  i > 1 )   ;
CALL paquLinkTmp('aggregation_tmp_59503829');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `i`
FROM `aggregation_tmp_59503829`   ;
CALL paquDropTmp('aggregation_tmp_59503829');
This is the query plan optimisation output for the query:
SELECT i from . WHERE i>1;

-- INPUT SQL:
SELECT i from . WHERE i>1;

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`i`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`i`=VALUES(`i`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT i AS `i`
FROM . WHERE (  i > 1 )   
)


-- AGGREGATION SQL:
SELECT `i`
FROM `aggregation_tmp_3682043`   
ON DUPLICATE KEY UPDATE
`i`=VALUES(`i`)
This is the query plan for the query:
SELECT i from . WHERE i>1;

CALL paquExec('SELECT i AS `i` FROM . WHERE (  i > 1 )   ', 'aggregation_tmp_3682043');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `i`
FROM `aggregation_tmp_3682043`   ;
CALL paquDropTmp('aggregation_tmp_3682043');
This is the query plan optimisation output for the query:
SELECT i from `TEST`.`bar` WHERE i>1;

-- INPUT SQL:
SELECT i from `TEST`.`bar` WHERE i>1;

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`i`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`i`=VALUES(`i`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT i AS `i`
FROM `TEST`.`bar` WHERE (  i > 1 )   
)


-- AGGREGATION SQL:
SELECT `i`
FROM `aggregation_tmp_74394144`   
ON DUPLICATE KEY UPDATE
`i`=VALUES(`i`)
This is the query plan for the query:
SELECT i from `TEST`.`bar` WHERE i>1;

CALL paquExec('SELECT i AS `i` FROM `TEST`.`bar` WHERE (  i > 1 )   ', 'aggregation_tmp_74394144');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `i`
FROM `aggregation_tmp_74394144`   ;
CALL paquDropTmp('aggregation_tmp_74394144');
This is the query plan optimisation output for the query:
SELECT i from `TEST`.`bar` WHERE i>1;

-- INPUT SQL:
SELECT i from `TEST`.`bar` WHERE i>1;

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`i`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`i`=VALUES(`i`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT i AS `i`
FROM `TEST`.`bar` WHERE (  i > 1 )   
)


-- AGGREGATION SQL:
SELECT `i`
FROM `aggregation_tmp_35069038`   
ON DUPLICATE KEY UPDATE
`i`=VALUES(`i`)
This is the query plan for the query:
SELECT i from `TEST`.`bar` WHERE i>1;

CALL paquExec('SELECT i AS `i` FROM `TEST`.`bar` WHERE (  i > 1 )   ', 'aggregation_tmp_35069038');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `i`
FROM `aggregation_tmp_35069038`   ;
CALL paquDropTmp('aggregation_tmp_35069038');
This is the query plan optimisation output for the query:
SELECT i from `TEST`.`bar` WHERE i>1;

-- INPUT SQL:
SELECT i from `TEST`.`bar` WHERE i>1;

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`i`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`i`=VALUES(`i`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT i AS `i`
FROM `TEST`.`bar` WHERE (  i > 1 )   
)


-- AGGREGATION SQL:
SELECT `i`
FROM `aggregation_tmp_80740631`   
ON DUPLICATE KEY UPDATE
`i`=VALUES(`i`)
This is the query plan for the query:
SELECT i from `TEST`.`bar` WHERE i>1;

CALL paquExec('SELECT i AS `i` FROM `TEST`.`bar` WHERE (  i > 1 )   ', 'aggregation_tmp_80740631');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `i`
FROM `aggregation_tmp_80740631`   ;
CALL paquDropTmp('aggregation_tmp_80740631');
This is the query plan optimisation output for the query:
SELECT i from `TEST`.`bar` WHERE i>1;

-- INPUT SQL:
SELECT i from `TEST`.`bar` WHERE i>1;

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`i`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`i`=VALUES(`i`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT i AS `i`
FROM `TEST`.`bar` WHERE (  i > 1 )   
)


-- AGGREGATION SQL:
SELECT `i`
FROM `aggregation_tmp_24704167`   
ON DUPLICATE KEY UPDATE
`i`=VALUES(`i`)
This is the query plan for the query:
SELECT i from `TEST`.`bar` WHERE i>1;

CALL paquExec('SELECT i AS `i` FROM `TEST`.`bar` WHERE (  i > 1 )   ', 'aggregation_tmp_24704167');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `i`
FROM `aggregation_tmp_24704167`   ;
CALL paquDropTmp('aggregation_tmp_24704167');
This is the query plan optimisation output for the query:
SELECT i from `TEST`.`bar` WHERE i>1;

-- INPUT SQL:
SELECT i from `TEST`.`bar` WHERE i>1;

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`i`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`i`=VALUES(`i`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT i AS `i`
FROM `TEST`.`bar` WHERE (  i > 1 )   
)


-- AGGREGATION SQL:
SELECT `i`
FROM `aggregation_tmp_46012940`   
ON DUPLICATE KEY UPDATE
`i`=VALUES(`i`)
This is the query plan for the query:
SELECT i from `TEST`.`bar` WHERE i>1;

CALL paquExec('SELECT i AS `i` FROM `TEST`.`bar` WHERE (  i > 1 )   ', 'aggregation_tmp_46012940');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `i`
FROM `aggregation_tmp_46012940`   ;
CALL paquDropTmp('aggregation_tmp_46012940');
This is the query plan optimisation output for the query:
SELECT i from `TEST`.`bar` WHERE i>1;

-- INPUT SQL:
SELECT i from `TEST`.`bar` WHERE i>1;

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`i`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`i`=VALUES(`i`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT i AS `i`
FROM `TEST`.`bar` WHERE (  i > 1 )   
)


-- AGGREGATION SQL:
SELECT `i`
FROM `aggregation_tmp_31560716`   
ON DUPLICATE KEY UPDATE
`i`=VALUES(`i`)
This is the query plan for the query:
SELECT i from `TEST`.`bar` WHERE i>1;

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_31560716 ENGINE=MyISAM SELECT i AS `i`
FROM `TEST`.`bar` WHERE (  i > 1 )    LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_31560716 SELECT i AS `i`
FROM `TEST`.`bar` WHERE (  i > 1 )   ;
CALL paquLinkTmp('aggregation_tmp_31560716');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `i`
FROM `aggregation_tmp_31560716`   ;
CALL paquDropTmp('aggregation_tmp_31560716');
This is the query plan optimisation output for the query:
SELECT i from `bar`.`barbar` WHERE i>1;

-- INPUT SQL:
SELECT i from `bar`.`barbar` WHERE i>1;

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`i`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`i`=VALUES(`i`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT i AS `i`
FROM `bar`.`barbar` WHERE (  i > 1 )   
)


-- AGGREGATION SQL:
SELECT `i`
FROM `aggregation_tmp_50769884`   
ON DUPLICATE KEY UPDATE
`i`=VALUES(`i`)
This is the query plan for the query:
SELECT i from `bar`.`barbar` WHERE i>1;

CALL paquExec('SELECT i AS `i` FROM `bar`.`barbar` WHERE (  i > 1 )   ', 'aggregation_tmp_50769884');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `i`
FROM `aggregation_tmp_50769884`   ;
CALL paquDropTmp('aggregation_tmp_50769884');
This is the query plan optimisation output for the query:
SELECT i from `TEST`.`bar` WHERE i>1;

-- INPUT SQL:
SELECT i from `TEST`.`bar` WHERE i>1;

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`i`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`i`=VALUES(`i`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT i AS `i`
FROM `TEST`.`bar` WHERE (  i > 1 )   
)


-- AGGREGATION SQL:
SELECT `i`
FROM `aggregation_tmp_77419293`   
ON DUPLICATE KEY UPDATE
`i`=VALUES(`i`)
This is the query plan for the query:
SELECT i from `TEST`.`bar` WHERE i>1;

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_77419293 ENGINE=MyISAM SELECT i AS `i`
FROM `TEST`.`bar` WHERE (  i > 1 )    LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_77419293 SELECT i AS `i`
FROM `TEST`.`bar` WHERE (  i > 1 )   ;
CALL paquLinkTmp('aggregation_tmp_77419293');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `i`
FROM `aggregation_tmp_77419293`   ;
CALL paquDropTmp('aggregation_tmp_77419293');
This is the query plan optimisation output for the query:
SELECT i from `bar`.`barbar` WHERE i>1;

-- INPUT SQL:
SELECT i from `bar`.`barbar` WHERE i>1;

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`i`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`i`=VALUES(`i`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT i AS `i`
FROM `bar`.`barbar` WHERE (  i > 1 )   
)


-- AGGREGATION SQL:
SELECT `i`
FROM `aggregation_tmp_84743582`   
ON DUPLICATE KEY UPDATE
`i`=VALUES(`i`)
This is the query plan for the query:
SELECT i from `bar`.`barbar` WHERE i>1;

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_84743582 ENGINE=MyISAM SELECT i AS `i`
FROM `bar`.`barbar` WHERE (  i > 1 )    LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_84743582 SELECT i AS `i`
FROM `bar`.`barbar` WHERE (  i > 1 )   ;
CALL paquLinkTmp('aggregation_tmp_84743582');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `i`
FROM `aggregation_tmp_84743582`   ;
CALL paquDropTmp('aggregation_tmp_84743582');
This is the query plan optimisation output for the query:
SELECT `D.treeRootId`, `D.x`,`D.y`,`D.z`,`D.mass`, `P.x`,`P.y`,`P.z`, `P.mass` FROM `bar`.`bar` WHERE `P.x` BETWEEN 515 and 516

-- INPUT SQL:
SELECT `D.treeRootId`, `D.x`,`D.y`,`D.z`,`D.mass`, `P.x`,`P.y`,`P.z`, `P.mass` FROM `bar`.`bar` WHERE `P.x` BETWEEN 515 and 516

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`D.treeRootId`,`D.x`,`D.y`,`D.z`,`D.mass`,`P.x`,`P.y`,`P.z`,`P.mass`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`D.treeRootId`=VALUES(`D.treeRootId`),
`D.x`=VALUES(`D.x`),
`D.y`=VALUES(`D.y`),
`D.z`=VALUES(`D.z`),
`D.mass`=VALUES(`D.mass`),
`P.x`=VALUES(`P.x`),
`P.y`=VALUES(`P.y`),
`P.z`=VALUES(`P.z`),
`P.mass`=VALUES(`P.mass`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `D.treeRootId` AS `D.treeRootId`,`D.x` AS `D.x`,`D.y` AS `D.y`,`D.z` AS `D.z`,`D.mass` AS `D.mass`,`P.x` AS `P.x`,`P.y` AS `P.y`,`P.z` AS `P.z`,`P.mass` AS `P.mass`
FROM `bar`.`bar` ORDER BY NULL 
)


-- AGGREGATION SQL:
SELECT `D.treeRootId`,`D.x`,`D.y`,`D.z`,`D.mass`,`P.x`,`P.y`,`P.z`,`P.mass`
FROM `aggregation_tmp_58289658`   
ON DUPLICATE KEY UPDATE
`D.treeRootId`=VALUES(`D.treeRootId`),
`D.x`=VALUES(`D.x`),
`D.y`=VALUES(`D.y`),
`D.z`=VALUES(`D.z`),
`D.mass`=VALUES(`D.mass`),
`P.x`=VALUES(`P.x`),
`P.y`=VALUES(`P.y`),
`P.z`=VALUES(`P.z`),
`P.mass`=VALUES(`P.mass`)
This is the query plan for the query:
SELECT `D.treeRootId`, `D.x`,`D.y`,`D.z`,`D.mass`, `P.x`,`P.y`,`P.z`, `P.mass` FROM `bar`.`bar` WHERE `P.x` BETWEEN 515 and 516

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_58289658 ENGINE=MyISAM SELECT `D.treeRootId` AS `D.treeRootId`,`D.x` AS `D.x`,`D.y` AS `D.y`,`D.z` AS `D.z`,`D.mass` AS `D.mass`,`P.x` AS `P.x`,`P.y` AS `P.y`,`P.z` AS `P.z`,`P.mass` AS `P.mass`
FROM `bar`.`bar` ORDER BY NULL  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_58289658 SELECT `D.treeRootId` AS `D.treeRootId`,`D.x` AS `D.x`,`D.y` AS `D.y`,`D.z` AS `D.z`,`D.mass` AS `D.mass`,`P.x` AS `P.x`,`P.y` AS `P.y`,`P.z` AS `P.z`,`P.mass` AS `P.mass`
FROM `bar`.`bar` ORDER BY NULL ;
CALL paquLinkTmp('aggregation_tmp_58289658');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `D.treeRootId`,`D.x`,`D.y`,`D.z`,`D.mass`,`P.x`,`P.y`,`P.z`,`P.mass`
FROM `aggregation_tmp_58289658`   ;
CALL paquDropTmp('aggregation_tmp_58289658');
This is the query plan optimisation output for the query:
SELECT `D.treeRootId`, `D.x`,`D.y`,`D.z`,`D.mass`, `P.x`,`P.y`,`P.z`, `P.mass` FROM `bar`.`bar` WHERE `P.x` > 515 and `P.x`<516

-- INPUT SQL:
SELECT `D.treeRootId`, `D.x`,`D.y`,`D.z`,`D.mass`, `P.x`,`P.y`,`P.z`, `P.mass` FROM `bar`.`bar` WHERE `P.x` > 515 and `P.x`<516

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`D.treeRootId`,`D.x`,`D.y`,`D.z`,`D.mass`,`P.x`,`P.y`,`P.z`,`P.mass`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`D.treeRootId`=VALUES(`D.treeRootId`),
`D.x`=VALUES(`D.x`),
`D.y`=VALUES(`D.y`),
`D.z`=VALUES(`D.z`),
`D.mass`=VALUES(`D.mass`),
`P.x`=VALUES(`P.x`),
`P.y`=VALUES(`P.y`),
`P.z`=VALUES(`P.z`),
`P.mass`=VALUES(`P.mass`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `D.treeRootId` AS `D.treeRootId`,`D.x` AS `D.x`,`D.y` AS `D.y`,`D.z` AS `D.z`,`D.mass` AS `D.mass`,`P.x` AS `P.x`,`P.y` AS `P.y`,`P.z` AS `P.z`,`P.mass` AS `P.mass`
FROM `bar`.`bar` ORDER BY NULL 
)


-- AGGREGATION SQL:
SELECT `D.treeRootId`,`D.x`,`D.y`,`D.z`,`D.mass`,`P.x`,`P.y`,`P.z`,`P.mass`
FROM `aggregation_tmp_15732836`   
ON DUPLICATE KEY UPDATE
`D.treeRootId`=VALUES(`D.treeRootId`),
`D.x`=VALUES(`D.x`),
`D.y`=VALUES(`D.y`),
`D.z`=VALUES(`D.z`),
`D.mass`=VALUES(`D.mass`),
`P.x`=VALUES(`P.x`),
`P.y`=VALUES(`P.y`),
`P.z`=VALUES(`P.z`),
`P.mass`=VALUES(`P.mass`)
This is the query plan for the query:
SELECT `D.treeRootId`, `D.x`,`D.y`,`D.z`,`D.mass`, `P.x`,`P.y`,`P.z`, `P.mass` FROM `bar`.`bar` WHERE `P.x` > 515 and `P.x`<516

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_15732836 ENGINE=MyISAM SELECT `D.treeRootId` AS `D.treeRootId`,`D.x` AS `D.x`,`D.y` AS `D.y`,`D.z` AS `D.z`,`D.mass` AS `D.mass`,`P.x` AS `P.x`,`P.y` AS `P.y`,`P.z` AS `P.z`,`P.mass` AS `P.mass`
FROM `bar`.`bar` ORDER BY NULL  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_15732836 SELECT `D.treeRootId` AS `D.treeRootId`,`D.x` AS `D.x`,`D.y` AS `D.y`,`D.z` AS `D.z`,`D.mass` AS `D.mass`,`P.x` AS `P.x`,`P.y` AS `P.y`,`P.z` AS `P.z`,`P.mass` AS `P.mass`
FROM `bar`.`bar` ORDER BY NULL ;
CALL paquLinkTmp('aggregation_tmp_15732836');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `D.treeRootId`,`D.x`,`D.y`,`D.z`,`D.mass`,`P.x`,`P.y`,`P.z`,`P.mass`
FROM `aggregation_tmp_15732836`   ;
CALL paquDropTmp('aggregation_tmp_15732836');
This is the query plan optimisation output for the query:
SELECT `D.treeRootId`, `D.x`,`D.y`,`D.z`,`D.mass`, `P.x`,`P.y`,`P.z`, `P.mass` FROM `bar`.`bar` WHERE `x` BETWEEN 515 and 516

-- INPUT SQL:
SELECT `D.treeRootId`, `D.x`,`D.y`,`D.z`,`D.mass`, `P.x`,`P.y`,`P.z`, `P.mass` FROM `bar`.`bar` WHERE `x` BETWEEN 515 and 516

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`D.treeRootId`,`D.x`,`D.y`,`D.z`,`D.mass`,`P.x`,`P.y`,`P.z`,`P.mass`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`D.treeRootId`=VALUES(`D.treeRootId`),
`D.x`=VALUES(`D.x`),
`D.y`=VALUES(`D.y`),
`D.z`=VALUES(`D.z`),
`D.mass`=VALUES(`D.mass`),
`P.x`=VALUES(`P.x`),
`P.y`=VALUES(`P.y`),
`P.z`=VALUES(`P.z`),
`P.mass`=VALUES(`P.mass`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `D.treeRootId` AS `D.treeRootId`,`D.x` AS `D.x`,`D.y` AS `D.y`,`D.z` AS `D.z`,`D.mass` AS `D.mass`,`P.x` AS `P.x`,`P.y` AS `P.y`,`P.z` AS `P.z`,`P.mass` AS `P.mass`
FROM `bar`.`bar` WHERE (  `x` BETWEEN 515 and 516 )   
)


-- AGGREGATION SQL:
SELECT `D.treeRootId`,`D.x`,`D.y`,`D.z`,`D.mass`,`P.x`,`P.y`,`P.z`,`P.mass`
FROM `aggregation_tmp_22978724`   
ON DUPLICATE KEY UPDATE
`D.treeRootId`=VALUES(`D.treeRootId`),
`D.x`=VALUES(`D.x`),
`D.y`=VALUES(`D.y`),
`D.z`=VALUES(`D.z`),
`D.mass`=VALUES(`D.mass`),
`P.x`=VALUES(`P.x`),
`P.y`=VALUES(`P.y`),
`P.z`=VALUES(`P.z`),
`P.mass`=VALUES(`P.mass`)
This is the query plan for the query:
SELECT `D.treeRootId`, `D.x`,`D.y`,`D.z`,`D.mass`, `P.x`,`P.y`,`P.z`, `P.mass` FROM `bar`.`bar` WHERE `x` BETWEEN 515 and 516

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_22978724 ENGINE=MyISAM SELECT `D.treeRootId` AS `D.treeRootId`,`D.x` AS `D.x`,`D.y` AS `D.y`,`D.z` AS `D.z`,`D.mass` AS `D.mass`,`P.x` AS `P.x`,`P.y` AS `P.y`,`P.z` AS `P.z`,`P.mass` AS `P.mass`
FROM `bar`.`bar` WHERE (  `x` BETWEEN 515 and 516 )    LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_22978724 SELECT `D.treeRootId` AS `D.treeRootId`,`D.x` AS `D.x`,`D.y` AS `D.y`,`D.z` AS `D.z`,`D.mass` AS `D.mass`,`P.x` AS `P.x`,`P.y` AS `P.y`,`P.z` AS `P.z`,`P.mass` AS `P.mass`
FROM `bar`.`bar` WHERE (  `x` BETWEEN 515 and 516 )   ;
CALL paquLinkTmp('aggregation_tmp_22978724');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `D.treeRootId`,`D.x`,`D.y`,`D.z`,`D.mass`,`P.x`,`P.y`,`P.z`,`P.mass`
FROM `aggregation_tmp_22978724`   ;
CALL paquDropTmp('aggregation_tmp_22978724');
This is the query plan optimisation output for the query:
SELECT `D.treeRootId`, `D.x`,`D.y`,`D.z`,`D.mass`, `P.x`,`P.y`,`P.z`, `P.mass` FROM `bar`.`bar` WHERE `P.x` > 515 and `P.x`<516

-- INPUT SQL:
SELECT `D.treeRootId`, `D.x`,`D.y`,`D.z`,`D.mass`, `P.x`,`P.y`,`P.z`, `P.mass` FROM `bar`.`bar` WHERE `P.x` > 515 and `P.x`<516

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`D.treeRootId`,`D.x`,`D.y`,`D.z`,`D.mass`,`P.x`,`P.y`,`P.z`,`P.mass`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`D.treeRootId`=VALUES(`D.treeRootId`),
`D.x`=VALUES(`D.x`),
`D.y`=VALUES(`D.y`),
`D.z`=VALUES(`D.z`),
`D.mass`=VALUES(`D.mass`),
`P.x`=VALUES(`P.x`),
`P.y`=VALUES(`P.y`),
`P.z`=VALUES(`P.z`),
`P.mass`=VALUES(`P.mass`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `D.treeRootId` AS `D.treeRootId`,`D.x` AS `D.x`,`D.y` AS `D.y`,`D.z` AS `D.z`,`D.mass` AS `D.mass`,`P.x` AS `P.x`,`P.y` AS `P.y`,`P.z` AS `P.z`,`P.mass` AS `P.mass`
FROM `bar`.`bar` ORDER BY NULL 
)


-- AGGREGATION SQL:
SELECT `D.treeRootId`,`D.x`,`D.y`,`D.z`,`D.mass`,`P.x`,`P.y`,`P.z`,`P.mass`
FROM `aggregation_tmp_20672188`   
ON DUPLICATE KEY UPDATE
`D.treeRootId`=VALUES(`D.treeRootId`),
`D.x`=VALUES(`D.x`),
`D.y`=VALUES(`D.y`),
`D.z`=VALUES(`D.z`),
`D.mass`=VALUES(`D.mass`),
`P.x`=VALUES(`P.x`),
`P.y`=VALUES(`P.y`),
`P.z`=VALUES(`P.z`),
`P.mass`=VALUES(`P.mass`)
This is the query plan for the query:
SELECT `D.treeRootId`, `D.x`,`D.y`,`D.z`,`D.mass`, `P.x`,`P.y`,`P.z`, `P.mass` FROM `bar`.`bar` WHERE `P.x` > 515 and `P.x`<516

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_20672188 ENGINE=MyISAM SELECT `D.treeRootId` AS `D.treeRootId`,`D.x` AS `D.x`,`D.y` AS `D.y`,`D.z` AS `D.z`,`D.mass` AS `D.mass`,`P.x` AS `P.x`,`P.y` AS `P.y`,`P.z` AS `P.z`,`P.mass` AS `P.mass`
FROM `bar`.`bar` ORDER BY NULL  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_20672188 SELECT `D.treeRootId` AS `D.treeRootId`,`D.x` AS `D.x`,`D.y` AS `D.y`,`D.z` AS `D.z`,`D.mass` AS `D.mass`,`P.x` AS `P.x`,`P.y` AS `P.y`,`P.z` AS `P.z`,`P.mass` AS `P.mass`
FROM `bar`.`bar` ORDER BY NULL ;
CALL paquLinkTmp('aggregation_tmp_20672188');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `D.treeRootId`,`D.x`,`D.y`,`D.z`,`D.mass`,`P.x`,`P.y`,`P.z`,`P.mass`
FROM `aggregation_tmp_20672188`   ;
CALL paquDropTmp('aggregation_tmp_20672188');
This is the query plan optimisation output for the query:
SELECT `D.treeRootId`, `D.x`,`D.y`,`D.z`,`D.mass`, `P.x`,`P.y`,`P.z`, `P.mass` FROM `bar`.`bar` WHERE `P.x` > 515 and `P.x`<516

-- INPUT SQL:
SELECT `D.treeRootId`, `D.x`,`D.y`,`D.z`,`D.mass`, `P.x`,`P.y`,`P.z`, `P.mass` FROM `bar`.`bar` WHERE `P.x` > 515 and `P.x`<516

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`D.treeRootId`,`D.x`,`D.y`,`D.z`,`D.mass`,`P.x`,`P.y`,`P.z`,`P.mass`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`D.treeRootId`=VALUES(`D.treeRootId`),
`D.x`=VALUES(`D.x`),
`D.y`=VALUES(`D.y`),
`D.z`=VALUES(`D.z`),
`D.mass`=VALUES(`D.mass`),
`P.x`=VALUES(`P.x`),
`P.y`=VALUES(`P.y`),
`P.z`=VALUES(`P.z`),
`P.mass`=VALUES(`P.mass`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `D.treeRootId` AS `D.treeRootId`,`D.x` AS `D.x`,`D.y` AS `D.y`,`D.z` AS `D.z`,`D.mass` AS `D.mass`,`P.x` AS `P.x`,`P.y` AS `P.y`,`P.z` AS `P.z`,`P.mass` AS `P.mass`
FROM `bar`.`bar` ORDER BY NULL 
)


-- AGGREGATION SQL:
SELECT `D.treeRootId`,`D.x`,`D.y`,`D.z`,`D.mass`,`P.x`,`P.y`,`P.z`,`P.mass`
FROM `aggregation_tmp_1545232`   
ON DUPLICATE KEY UPDATE
`D.treeRootId`=VALUES(`D.treeRootId`),
`D.x`=VALUES(`D.x`),
`D.y`=VALUES(`D.y`),
`D.z`=VALUES(`D.z`),
`D.mass`=VALUES(`D.mass`),
`P.x`=VALUES(`P.x`),
`P.y`=VALUES(`P.y`),
`P.z`=VALUES(`P.z`),
`P.mass`=VALUES(`P.mass`)
This is the query plan for the query:
SELECT `D.treeRootId`, `D.x`,`D.y`,`D.z`,`D.mass`, `P.x`,`P.y`,`P.z`, `P.mass` FROM `bar`.`bar` WHERE `P.x` > 515 and `P.x`<516

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_1545232 ENGINE=MyISAM SELECT `D.treeRootId` AS `D.treeRootId`,`D.x` AS `D.x`,`D.y` AS `D.y`,`D.z` AS `D.z`,`D.mass` AS `D.mass`,`P.x` AS `P.x`,`P.y` AS `P.y`,`P.z` AS `P.z`,`P.mass` AS `P.mass`
FROM `bar`.`bar` ORDER BY NULL  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_1545232 SELECT `D.treeRootId` AS `D.treeRootId`,`D.x` AS `D.x`,`D.y` AS `D.y`,`D.z` AS `D.z`,`D.mass` AS `D.mass`,`P.x` AS `P.x`,`P.y` AS `P.y`,`P.z` AS `P.z`,`P.mass` AS `P.mass`
FROM `bar`.`bar` ORDER BY NULL ;
CALL paquLinkTmp('aggregation_tmp_1545232');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `D.treeRootId`,`D.x`,`D.y`,`D.z`,`D.mass`,`P.x`,`P.y`,`P.z`,`P.mass`
FROM `aggregation_tmp_1545232`   ;
CALL paquDropTmp('aggregation_tmp_1545232');
This is the query plan optimisation output for the query:
SELECT `D.treeRootId`, `D.x`,`D.y`,`D.z`,`D.mass`, `P.x`,`P.y`,`P.z`, `P.mass` FROM `bar`.`bar` WHERE `P.x` > 515 and `P.x`<516

-- INPUT SQL:
SELECT `D.treeRootId`, `D.x`,`D.y`,`D.z`,`D.mass`, `P.x`,`P.y`,`P.z`, `P.mass` FROM `bar`.`bar` WHERE `P.x` > 515 and `P.x`<516

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`D.treeRootId`,`D.x`,`D.y`,`D.z`,`D.mass`,`P.x`,`P.y`,`P.z`,`P.mass`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`D.treeRootId`=VALUES(`D.treeRootId`),
`D.x`=VALUES(`D.x`),
`D.y`=VALUES(`D.y`),
`D.z`=VALUES(`D.z`),
`D.mass`=VALUES(`D.mass`),
`P.x`=VALUES(`P.x`),
`P.y`=VALUES(`P.y`),
`P.z`=VALUES(`P.z`),
`P.mass`=VALUES(`P.mass`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `D.treeRootId` AS `D.treeRootId`,`D.x` AS `D.x`,`D.y` AS `D.y`,`D.z` AS `D.z`,`D.mass` AS `D.mass`,`P.x` AS `P.x`,`P.y` AS `P.y`,`P.z` AS `P.z`,`P.mass` AS `P.mass`
FROM `bar`.`bar` WHERE (  `P.x` > 515 ) and (  `P.x` < 516 )   
)


-- AGGREGATION SQL:
SELECT `D.treeRootId`,`D.x`,`D.y`,`D.z`,`D.mass`,`P.x`,`P.y`,`P.z`,`P.mass`
FROM `aggregation_tmp_73495269`   
ON DUPLICATE KEY UPDATE
`D.treeRootId`=VALUES(`D.treeRootId`),
`D.x`=VALUES(`D.x`),
`D.y`=VALUES(`D.y`),
`D.z`=VALUES(`D.z`),
`D.mass`=VALUES(`D.mass`),
`P.x`=VALUES(`P.x`),
`P.y`=VALUES(`P.y`),
`P.z`=VALUES(`P.z`),
`P.mass`=VALUES(`P.mass`)
This is the query plan for the query:
SELECT `D.treeRootId`, `D.x`,`D.y`,`D.z`,`D.mass`, `P.x`,`P.y`,`P.z`, `P.mass` FROM `bar`.`bar` WHERE `P.x` > 515 and `P.x`<516

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_73495269 ENGINE=MyISAM SELECT `D.treeRootId` AS `D.treeRootId`,`D.x` AS `D.x`,`D.y` AS `D.y`,`D.z` AS `D.z`,`D.mass` AS `D.mass`,`P.x` AS `P.x`,`P.y` AS `P.y`,`P.z` AS `P.z`,`P.mass` AS `P.mass`
FROM `bar`.`bar` WHERE (  `P.x` > 515 ) and (  `P.x` < 516 )    LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_73495269 SELECT `D.treeRootId` AS `D.treeRootId`,`D.x` AS `D.x`,`D.y` AS `D.y`,`D.z` AS `D.z`,`D.mass` AS `D.mass`,`P.x` AS `P.x`,`P.y` AS `P.y`,`P.z` AS `P.z`,`P.mass` AS `P.mass`
FROM `bar`.`bar` WHERE (  `P.x` > 515 ) and (  `P.x` < 516 )   ;
CALL paquLinkTmp('aggregation_tmp_73495269');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `D.treeRootId`,`D.x`,`D.y`,`D.z`,`D.mass`,`P.x`,`P.y`,`P.z`,`P.mass`
FROM `aggregation_tmp_73495269`   ;
CALL paquDropTmp('aggregation_tmp_73495269');
This is the query plan optimisation output for the query:
SELECT `D.treeRootId`, `D.x`,`D.y`,`D.z`,`D.mass`, `P.x`,`P.y`,`P.z`, `P.mass` FROM `bar`.`bar` WHERE `P.x` BETWEEN 515 and 516

-- INPUT SQL:
SELECT `D.treeRootId`, `D.x`,`D.y`,`D.z`,`D.mass`, `P.x`,`P.y`,`P.z`, `P.mass` FROM `bar`.`bar` WHERE `P.x` BETWEEN 515 and 516

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`D.treeRootId`,`D.x`,`D.y`,`D.z`,`D.mass`,`P.x`,`P.y`,`P.z`,`P.mass`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`D.treeRootId`=VALUES(`D.treeRootId`),
`D.x`=VALUES(`D.x`),
`D.y`=VALUES(`D.y`),
`D.z`=VALUES(`D.z`),
`D.mass`=VALUES(`D.mass`),
`P.x`=VALUES(`P.x`),
`P.y`=VALUES(`P.y`),
`P.z`=VALUES(`P.z`),
`P.mass`=VALUES(`P.mass`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `D.treeRootId` AS `D.treeRootId`,`D.x` AS `D.x`,`D.y` AS `D.y`,`D.z` AS `D.z`,`D.mass` AS `D.mass`,`P.x` AS `P.x`,`P.y` AS `P.y`,`P.z` AS `P.z`,`P.mass` AS `P.mass`
FROM `bar`.`bar` WHERE (  `P.x` BETWEEN 515 and 516 )   
)


-- AGGREGATION SQL:
SELECT `D.treeRootId`,`D.x`,`D.y`,`D.z`,`D.mass`,`P.x`,`P.y`,`P.z`,`P.mass`
FROM `aggregation_tmp_84273164`   
ON DUPLICATE KEY UPDATE
`D.treeRootId`=VALUES(`D.treeRootId`),
`D.x`=VALUES(`D.x`),
`D.y`=VALUES(`D.y`),
`D.z`=VALUES(`D.z`),
`D.mass`=VALUES(`D.mass`),
`P.x`=VALUES(`P.x`),
`P.y`=VALUES(`P.y`),
`P.z`=VALUES(`P.z`),
`P.mass`=VALUES(`P.mass`)
This is the query plan for the query:
SELECT `D.treeRootId`, `D.x`,`D.y`,`D.z`,`D.mass`, `P.x`,`P.y`,`P.z`, `P.mass` FROM `bar`.`bar` WHERE `P.x` BETWEEN 515 and 516

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_84273164 ENGINE=MyISAM SELECT `D.treeRootId` AS `D.treeRootId`,`D.x` AS `D.x`,`D.y` AS `D.y`,`D.z` AS `D.z`,`D.mass` AS `D.mass`,`P.x` AS `P.x`,`P.y` AS `P.y`,`P.z` AS `P.z`,`P.mass` AS `P.mass`
FROM `bar`.`bar` WHERE (  `P.x` BETWEEN 515 and 516 )    LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_84273164 SELECT `D.treeRootId` AS `D.treeRootId`,`D.x` AS `D.x`,`D.y` AS `D.y`,`D.z` AS `D.z`,`D.mass` AS `D.mass`,`P.x` AS `P.x`,`P.y` AS `P.y`,`P.z` AS `P.z`,`P.mass` AS `P.mass`
FROM `bar`.`bar` WHERE (  `P.x` BETWEEN 515 and 516 )   ;
CALL paquLinkTmp('aggregation_tmp_84273164');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `D.treeRootId`,`D.x`,`D.y`,`D.z`,`D.mass`,`P.x`,`P.y`,`P.z`,`P.mass`
FROM `aggregation_tmp_84273164`   ;
CALL paquDropTmp('aggregation_tmp_84273164');
This is the query plan optimisation output for the query:
SELECT `D.treeRootId`, `D.x`,`D.y`,`D.z`,`D.mass`, `P.x`,`P.y`,`P.z`, `P.mass` FROM `bar`.`bar` WHERE `P.x` BETWEEN 515 and 516

-- INPUT SQL:
SELECT `D.treeRootId`, `D.x`,`D.y`,`D.z`,`D.mass`, `P.x`,`P.y`,`P.z`, `P.mass` FROM `bar`.`bar` WHERE `P.x` BETWEEN 515 and 516

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`D.treeRootId`,`D.x`,`D.y`,`D.z`,`D.mass`,`P.x`,`P.y`,`P.z`,`P.mass`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`D.treeRootId`=VALUES(`D.treeRootId`),
`D.x`=VALUES(`D.x`),
`D.y`=VALUES(`D.y`),
`D.z`=VALUES(`D.z`),
`D.mass`=VALUES(`D.mass`),
`P.x`=VALUES(`P.x`),
`P.y`=VALUES(`P.y`),
`P.z`=VALUES(`P.z`),
`P.mass`=VALUES(`P.mass`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `D.treeRootId` AS `D.treeRootId`,`D.x` AS `D.x`,`D.y` AS `D.y`,`D.z` AS `D.z`,`D.mass` AS `D.mass`,`P.x` AS `P.x`,`P.y` AS `P.y`,`P.z` AS `P.z`,`P.mass` AS `P.mass`
FROM `bar`.`bar` WHERE (  `P.x` BETWEEN 515 and 516 )   
)


-- AGGREGATION SQL:
SELECT `D.treeRootId`,`D.x`,`D.y`,`D.z`,`D.mass`,`P.x`,`P.y`,`P.z`,`P.mass`
FROM `aggregation_tmp_93490301`   
ON DUPLICATE KEY UPDATE
`D.treeRootId`=VALUES(`D.treeRootId`),
`D.x`=VALUES(`D.x`),
`D.y`=VALUES(`D.y`),
`D.z`=VALUES(`D.z`),
`D.mass`=VALUES(`D.mass`),
`P.x`=VALUES(`P.x`),
`P.y`=VALUES(`P.y`),
`P.z`=VALUES(`P.z`),
`P.mass`=VALUES(`P.mass`)
This is the query plan for the query:
SELECT `D.treeRootId`, `D.x`,`D.y`,`D.z`,`D.mass`, `P.x`,`P.y`,`P.z`, `P.mass` FROM `bar`.`bar` WHERE `P.x` BETWEEN 515 and 516

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_93490301 ENGINE=MyISAM SELECT `D.treeRootId` AS `D.treeRootId`,`D.x` AS `D.x`,`D.y` AS `D.y`,`D.z` AS `D.z`,`D.mass` AS `D.mass`,`P.x` AS `P.x`,`P.y` AS `P.y`,`P.z` AS `P.z`,`P.mass` AS `P.mass`
FROM `bar`.`bar` WHERE (  `P.x` BETWEEN 515 and 516 )    LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_93490301 SELECT `D.treeRootId` AS `D.treeRootId`,`D.x` AS `D.x`,`D.y` AS `D.y`,`D.z` AS `D.z`,`D.mass` AS `D.mass`,`P.x` AS `P.x`,`P.y` AS `P.y`,`P.z` AS `P.z`,`P.mass` AS `P.mass`
FROM `bar`.`bar` WHERE (  `P.x` BETWEEN 515 and 516 )   ;
CALL paquLinkTmp('aggregation_tmp_93490301');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `D.treeRootId`,`D.x`,`D.y`,`D.z`,`D.mass`,`P.x`,`P.y`,`P.z`,`P.mass`
FROM `aggregation_tmp_93490301`   ;
CALL paquDropTmp('aggregation_tmp_93490301');
This is the query plan optimisation output for the query:
SELECT x,y,z FROM MDR1.Particles85 WHERE RAND(154321) <= 2.91e-5

-- INPUT SQL:
SELECT x,y,z FROM MDR1.Particles85 WHERE RAND(154321) <= 2.91e-5

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`,`y`,`z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`,y AS `y`,z AS `z`
FROM MDR1.Particles85 ORDER BY NULL 
)


-- AGGREGATION SQL:
SELECT `x`,`y`,`z`
FROM `aggregation_tmp_59580435`   
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`)
This is the query plan for the query:
SELECT x,y,z FROM MDR1.Particles85 WHERE RAND(154321) <= 2.91e-5

CALL paquExec('SELECT x AS `x`,y AS `y`,z AS `z` FROM MDR1.Particles85 ORDER BY NULL ', 'aggregation_tmp_59580435');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `x`,`y`,`z`
FROM `aggregation_tmp_59580435`   ;
CALL paquDropTmp('aggregation_tmp_59580435');
This is the query plan optimisation output for the query:
SELECT x,y,z FROM MDR1.Particles85 WHERE RAND(154321) <= 2.91E-5

-- INPUT SQL:
SELECT x,y,z FROM MDR1.Particles85 WHERE RAND(154321) <= 2.91E-5

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`,`y`,`z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`,y AS `y`,z AS `z`
FROM MDR1.Particles85 WHERE (  RAND (154321) <= 2.91E-5 )   
)


-- AGGREGATION SQL:
SELECT `x`,`y`,`z`
FROM `aggregation_tmp_43215833`   
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`)
This is the query plan for the query:
SELECT x,y,z FROM MDR1.Particles85 WHERE RAND(154321) <= 2.91E-5

CALL paquExec('SELECT x AS `x`,y AS `y`,z AS `z` FROM MDR1.Particles85 WHERE (  RAND (154321) <= 2.91E-5 )   ', 'aggregation_tmp_43215833');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `x`,`y`,`z`
FROM `aggregation_tmp_43215833`   ;
CALL paquDropTmp('aggregation_tmp_43215833');
This is the query plan optimisation output for the query:
SELECT x,y,z FROM MDR1.Particles85 WHERE RAND(154321) <= 2.91E-5

-- INPUT SQL:
SELECT x,y,z FROM MDR1.Particles85 WHERE RAND(154321) <= 2.91E-5

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`,`y`,`z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`,y AS `y`,z AS `z`
FROM MDR1.Particles85 WHERE (  RAND (154321) <= 2.91E-5 )   
)


-- AGGREGATION SQL:
SELECT `x`,`y`,`z`
FROM `aggregation_tmp_14122906`   
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`)
This is the query plan for the query:
SELECT x,y,z FROM MDR1.Particles85 WHERE RAND(154321) <= 2.91E-5

CALL paquExec('SELECT x AS `x`,y AS `y`,z AS `z` FROM MDR1.Particles85 WHERE (  RAND (154321) <= 2.91E-5 )   ', 'aggregation_tmp_14122906');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `x`,`y`,`z`
FROM `aggregation_tmp_14122906`   ;
CALL paquDropTmp('aggregation_tmp_14122906');
This is the query plan optimisation output for the query:
SELECT sprng_make_seed();

-- INPUT SQL:
SELECT sprng_make_seed();

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`sprng_make_seed`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`sprng_make_seed`=VALUES(`sprng_make_seed`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT sprng_make_seed AS `sprng_make_seed` ORDER BY NULL 
)


-- AGGREGATION SQL:
SELECT `sprng_make_seed`   
ON DUPLICATE KEY UPDATE
`sprng_make_seed`=VALUES(`sprng_make_seed`)
This is the query plan for the query:
SELECT sprng_make_seed();

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard. ENGINE=MyISAM SELECT sprng_make_seed AS `sprng_make_seed` ORDER BY NULL  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard. SELECT sprng_make_seed AS `sprng_make_seed` ORDER BY NULL ;
CALL paquLinkTmp('');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `sprng_make_seed`   ;
CALL paquDropTmp('');
This is the query plan optimisation output for the query:
SELECT sprng_make_seed();

-- INPUT SQL:
SELECT sprng_make_seed();

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`sprng_make_seed`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`sprng_make_seed`=VALUES(`sprng_make_seed`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT sprng_make_seed AS `sprng_make_seed`
FROM  ORDER BY NULL 
)


-- AGGREGATION SQL:
SELECT `sprng_make_seed`
FROM `aggregation_tmp_35486483`   
ON DUPLICATE KEY UPDATE
`sprng_make_seed`=VALUES(`sprng_make_seed`)
This is the query plan for the query:
SELECT sprng_make_seed();

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_35486483 ENGINE=MyISAM SELECT sprng_make_seed AS `sprng_make_seed`
FROM  ORDER BY NULL  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_35486483 SELECT sprng_make_seed AS `sprng_make_seed`
FROM  ORDER BY NULL ;
CALL paquLinkTmp('aggregation_tmp_35486483');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `sprng_make_seed`
FROM `aggregation_tmp_35486483`   ;
CALL paquDropTmp('aggregation_tmp_35486483');
This is the query plan optimisation output for the query:
SELECT sprng_make_seed();

-- INPUT SQL:
SELECT sprng_make_seed();

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`sprng_make_seed`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`sprng_make_seed`=VALUES(`sprng_make_seed`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT sprng_make_seed AS `sprng_make_seed` ORDER BY NULL 
)


-- AGGREGATION SQL:
SELECT `sprng_make_seed`   
ON DUPLICATE KEY UPDATE
`sprng_make_seed`=VALUES(`sprng_make_seed`)
This is the query plan for the query:
SELECT sprng_make_seed();

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard. ENGINE=MyISAM SELECT sprng_make_seed AS `sprng_make_seed` ORDER BY NULL  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard. SELECT sprng_make_seed AS `sprng_make_seed` ORDER BY NULL ;
CALL paquLinkTmp('');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `sprng_make_seed`   ;
CALL paquDropTmp('');
This is the query plan optimisation output for the query:
SELECT sprng_make_seed();

-- INPUT SQL:
SELECT sprng_make_seed();

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`sprng_make_seed`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`sprng_make_seed`=VALUES(`sprng_make_seed`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT sprng_make_seed AS `sprng_make_seed` ORDER BY NULL 
)


-- AGGREGATION SQL:
SELECT `sprng_make_seed`   
ON DUPLICATE KEY UPDATE
`sprng_make_seed`=VALUES(`sprng_make_seed`)
This is the query plan for the query:
SELECT sprng_make_seed();

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard. ENGINE=MyISAM SELECT sprng_make_seed AS `sprng_make_seed` ORDER BY NULL  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard. SELECT sprng_make_seed AS `sprng_make_seed` ORDER BY NULL ;
CALL paquLinkTmp('');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `sprng_make_seed`   ;
CALL paquDropTmp('');
This is the query plan optimisation output for the query:
SELECT sprng_make_seed( );

-- INPUT SQL:
SELECT sprng_make_seed( );

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`sprng_make_seed( )`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`sprng_make_seed( )`=VALUES(`sprng_make_seed( )`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT sprng_make_seed( ) AS `sprng_make_seed( )` ORDER BY NULL 
)


-- AGGREGATION SQL:
SELECT `sprng_make_seed( )`   
ON DUPLICATE KEY UPDATE
`sprng_make_seed( )`=VALUES(`sprng_make_seed( )`)
This is the query plan for the query:
SELECT sprng_make_seed( );

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard. ENGINE=MyISAM SELECT sprng_make_seed( ) AS `sprng_make_seed( )` ORDER BY NULL  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard. SELECT sprng_make_seed( ) AS `sprng_make_seed( )` ORDER BY NULL ;
CALL paquLinkTmp('');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `sprng_make_seed( )`   ;
CALL paquDropTmp('');
This is the query plan optimisation output for the query:
SELECT sprng_make_seed( );

-- INPUT SQL:
SELECT sprng_make_seed( );

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`sprng_make_seed( )`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`sprng_make_seed( )`=VALUES(`sprng_make_seed( )`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT sprng_make_seed( ) AS `sprng_make_seed( )` ORDER BY NULL 
)


-- AGGREGATION SQL:
SELECT `sprng_make_seed( )`   
ON DUPLICATE KEY UPDATE
`sprng_make_seed( )`=VALUES(`sprng_make_seed( )`)
This is the query plan for the query:
SELECT sprng_make_seed( );

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard. ENGINE=MyISAM SELECT sprng_make_seed( ) AS `sprng_make_seed( )` ORDER BY NULL  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard. SELECT sprng_make_seed( ) AS `sprng_make_seed( )` ORDER BY NULL ;
CALL paquLinkTmp('');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `sprng_make_seed( )`   ;
CALL paquDropTmp('');
This is the query plan optimisation output for the query:
SELECT sprng_make_seed(a );

-- INPUT SQL:
SELECT sprng_make_seed(a );

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`sprng_make_seed(a )`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`sprng_make_seed(a )`=VALUES(`sprng_make_seed(a )`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT sprng_make_seed(a ) AS `sprng_make_seed(a )` ORDER BY NULL 
)


-- AGGREGATION SQL:
SELECT `sprng_make_seed(a )`   
ON DUPLICATE KEY UPDATE
`sprng_make_seed(a )`=VALUES(`sprng_make_seed(a )`)
This is the query plan for the query:
SELECT sprng_make_seed(a );

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard. ENGINE=MyISAM SELECT sprng_make_seed(a ) AS `sprng_make_seed(a )` ORDER BY NULL  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard. SELECT sprng_make_seed(a ) AS `sprng_make_seed(a )` ORDER BY NULL ;
CALL paquLinkTmp('');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `sprng_make_seed(a )`   ;
CALL paquDropTmp('');
This is the query plan optimisation output for the query:
SELECT sprng_make_seed( );

-- INPUT SQL:
SELECT sprng_make_seed( );

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`sprng_make_seed( )`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`sprng_make_seed( )`=VALUES(`sprng_make_seed( )`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT sprng_make_seed( ) AS `sprng_make_seed( )` ORDER BY NULL 
)


-- AGGREGATION SQL:
SELECT `sprng_make_seed( )`   
ON DUPLICATE KEY UPDATE
`sprng_make_seed( )`=VALUES(`sprng_make_seed( )`)
This is the query plan for the query:
SELECT sprng_make_seed( );

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard. ENGINE=MyISAM SELECT sprng_make_seed( ) AS `sprng_make_seed( )` ORDER BY NULL  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard. SELECT sprng_make_seed( ) AS `sprng_make_seed( )` ORDER BY NULL ;
CALL paquLinkTmp('');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `sprng_make_seed( )`   ;
CALL paquDropTmp('');
This is the query plan optimisation output for the query:
SELECT sprng_make_seed( );

-- INPUT SQL:
SELECT sprng_make_seed( );

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`sprng_make_seed( )`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`sprng_make_seed( )`=VALUES(`sprng_make_seed( )`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT sprng_make_seed( ) AS `sprng_make_seed( )` ORDER BY NULL 
)


-- AGGREGATION SQL:
SELECT `sprng_make_seed( )`   
ON DUPLICATE KEY UPDATE
`sprng_make_seed( )`=VALUES(`sprng_make_seed( )`)
This is the query plan for the query:
SELECT sprng_make_seed( );

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard. ENGINE=MyISAM SELECT sprng_make_seed( ) AS `sprng_make_seed( )` ORDER BY NULL  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard. SELECT sprng_make_seed( ) AS `sprng_make_seed( )` ORDER BY NULL ;
CALL paquLinkTmp('');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `sprng_make_seed( )`   ;
CALL paquDropTmp('');
This is the query plan optimisation output for the query:
SELECT sprng_make_seed();

-- INPUT SQL:
SELECT sprng_make_seed();

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`sprng_make_seed()`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`sprng_make_seed()`=VALUES(`sprng_make_seed()`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT sprng_make_seed() AS `sprng_make_seed()` ORDER BY NULL 
)


-- AGGREGATION SQL:
SELECT `sprng_make_seed()`   
ON DUPLICATE KEY UPDATE
`sprng_make_seed()`=VALUES(`sprng_make_seed()`)
This is the query plan for the query:
SELECT sprng_make_seed();

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard. ENGINE=MyISAM SELECT sprng_make_seed() AS `sprng_make_seed()` ORDER BY NULL  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard. SELECT sprng_make_seed() AS `sprng_make_seed()` ORDER BY NULL ;
CALL paquLinkTmp('');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `sprng_make_seed()`   ;
CALL paquDropTmp('');
This is the query plan optimisation output for the query:
SELECT sprng_make_seed(), count(*);

-- INPUT SQL:
SELECT sprng_make_seed(), count(*);

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`sprng_make_seed()`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`sprng_make_seed()`=VALUES(`sprng_make_seed()`),
`_count_*__`=`_count_*__` +  VALUES(`_count_*__`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT sprng_make_seed() AS `sprng_make_seed()`,COUNT(*) AS `_count_*__` ORDER BY NULL 
)


-- AGGREGATION SQL:
SELECT `sprng_make_seed()`,SUM(`_count_*__`) AS `_count_*__`   
ON DUPLICATE KEY UPDATE
`sprng_make_seed()`=VALUES(`sprng_make_seed()`),
`_count_*__`=`_count_*__` +  VALUES(`_count_*__`)
This is the query plan for the query:
SELECT sprng_make_seed(), count(*);

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard. ENGINE=MyISAM SELECT sprng_make_seed() AS `sprng_make_seed()`,COUNT(*) AS `_count_*__` ORDER BY NULL  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard. SELECT sprng_make_seed() AS `sprng_make_seed()`,COUNT(*) AS `_count_*__` ORDER BY NULL ;
CALL paquLinkTmp('');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `sprng_make_seed()`,SUM(`_count_*__`) AS `_count_*__`   ;
CALL paquDropTmp('');
This is the query plan optimisation output for the query:
SELECT sprng_make_seed(), count(*);

-- INPUT SQL:
SELECT sprng_make_seed(), count(*);

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_sprng_make_seed___`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_sprng_make_seed___`=VALUES(`_sprng_make_seed___`),
`_count_*__`=`_count_*__` +  VALUES(`_count_*__`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT sprng_make_seed() AS `_sprng_make_seed___`,COUNT(*) AS `_count_*__` ORDER BY NULL 
)


-- AGGREGATION SQL:
SELECT `_sprng_make_seed___`,SUM(`_count_*__`) AS `_count_*__`   
ON DUPLICATE KEY UPDATE
`_sprng_make_seed___`=VALUES(`_sprng_make_seed___`),
`_count_*__`=`_count_*__` +  VALUES(`_count_*__`)
This is the query plan for the query:
SELECT sprng_make_seed(), count(*);

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard. ENGINE=MyISAM SELECT sprng_make_seed() AS `_sprng_make_seed___`,COUNT(*) AS `_count_*__` ORDER BY NULL  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard. SELECT sprng_make_seed() AS `_sprng_make_seed___`,COUNT(*) AS `_count_*__` ORDER BY NULL ;
CALL paquLinkTmp('');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_sprng_make_seed___`,SUM(`_count_*__`) AS `_count_*__`   ;
CALL paquDropTmp('');
This is the query plan optimisation output for the query:
SELECT sprng_make_seed( );

-- INPUT SQL:
SELECT sprng_make_seed( );

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_sprng_make_seed____`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_sprng_make_seed____`=VALUES(`_sprng_make_seed____`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT sprng_make_seed( ) AS `_sprng_make_seed____` ORDER BY NULL 
)


-- AGGREGATION SQL:
SELECT `_sprng_make_seed____`   
ON DUPLICATE KEY UPDATE
`_sprng_make_seed____`=VALUES(`_sprng_make_seed____`)
This is the query plan for the query:
SELECT sprng_make_seed( );

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard. ENGINE=MyISAM SELECT sprng_make_seed( ) AS `_sprng_make_seed____` ORDER BY NULL  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard. SELECT sprng_make_seed( ) AS `_sprng_make_seed____` ORDER BY NULL ;
CALL paquLinkTmp('');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_sprng_make_seed____`   ;
CALL paquDropTmp('');
This is the query plan optimisation output for the query:
SELECT sprng_make_seed( );

-- INPUT SQL:
SELECT sprng_make_seed( );

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_sprng_make_seed____`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_sprng_make_seed____`=VALUES(`_sprng_make_seed____`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT sprng_make_seed( ) AS `_sprng_make_seed____` ORDER BY NULL 
)


-- AGGREGATION SQL:
SELECT `_sprng_make_seed____`   
ON DUPLICATE KEY UPDATE
`_sprng_make_seed____`=VALUES(`_sprng_make_seed____`)
This is the query plan for the query:
SELECT sprng_make_seed( );

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_6575547 ENGINE=MyISAM SELECT sprng_make_seed( ) AS `_sprng_make_seed____` ORDER BY NULL  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_6575547 SELECT sprng_make_seed( ) AS `_sprng_make_seed____` ORDER BY NULL ;
CALL paquLinkTmp('aggregation_tmp_6575547');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_sprng_make_seed____`   ;
CALL paquDropTmp('aggregation_tmp_6575547');
This is the query plan optimisation output for the query:
SELECT sprng_make_seed( );

-- INPUT SQL:
SELECT sprng_make_seed( );

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_sprng_make_seed____`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_sprng_make_seed____`=VALUES(`_sprng_make_seed____`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT sprng_make_seed( ) AS `_sprng_make_seed____` 
)


-- AGGREGATION SQL:
SELECT `_sprng_make_seed____`   
ON DUPLICATE KEY UPDATE
`_sprng_make_seed____`=VALUES(`_sprng_make_seed____`)
This is the query plan for the query:
SELECT sprng_make_seed( );

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_6117986 ENGINE=MyISAM SELECT sprng_make_seed( ) AS `_sprng_make_seed____`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_6117986 SELECT sprng_make_seed( ) AS `_sprng_make_seed____` ;
CALL paquLinkTmp('aggregation_tmp_6117986');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_sprng_make_seed____`   ;
CALL paquDropTmp('aggregation_tmp_6117986');
This is the query plan optimisation output for the query:
SELECT sprng_make_seed( );

-- INPUT SQL:
SELECT sprng_make_seed( );

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_sprng_make_seed____`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_sprng_make_seed____`=VALUES(`_sprng_make_seed____`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT sprng_make_seed( ) AS `_sprng_make_seed____` 
)


-- AGGREGATION SQL:
SELECT `_sprng_make_seed____`
FROM `aggregation_tmp_47124159`   
ON DUPLICATE KEY UPDATE
`_sprng_make_seed____`=VALUES(`_sprng_make_seed____`)
This is the query plan for the query:
SELECT sprng_make_seed( );

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_47124159 ENGINE=MyISAM SELECT sprng_make_seed( ) AS `_sprng_make_seed____`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_47124159 SELECT sprng_make_seed( ) AS `_sprng_make_seed____` ;
CALL paquLinkTmp('aggregation_tmp_47124159');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_sprng_make_seed____`
FROM `aggregation_tmp_47124159`   ;
CALL paquDropTmp('aggregation_tmp_47124159');
This is the query plan optimisation output for the query:
select * from a

-- INPUT SQL:
select * from a

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`
FROM a 
)


-- AGGREGATION SQL:
SELECT `*`
FROM `aggregation_tmp_60922332`   
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)
This is the query plan for the query:
select * from a

CALL paquExec('SELECT * AS `*` FROM a ', 'aggregation_tmp_60922332');
USE spider_tmp_shard; CREATE TABLE test.test ENGINE=MyISAM SELECT `*`
FROM `aggregation_tmp_60922332`   ;
CALL paquDropTmp('aggregation_tmp_60922332');
This is the query plan optimisation output for the query:
select a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by a

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`a`,`t3.id`,`id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`a`=VALUES(`a`),
`_count_*__`=`_count_*__` +  VALUES(`_count_*__`),
`t3.id`=VALUES(`t3.id`),
`id`=VALUES(`id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT a AS `a`,COUNT(*) AS `_count_*__`,t3.id AS `t3.id`,id AS `id`
FROM t3 GROUP BY a 
)


-- AGGREGATION SQL:
SELECT `a`,SUM(`_count_*__`) AS `_count_*__`,`t3.id`,`id`
FROM `aggregation_tmp_14911862`  GROUP BY `a`  
ON DUPLICATE KEY UPDATE
`a`=VALUES(`a`),
`_count_*__`=`_count_*__` +  VALUES(`_count_*__`),
`t3.id`=VALUES(`t3.id`),
`id`=VALUES(`id`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t2.t1_id`,`t2.date_id`,`t1_id`,`date_id`,`a`,`_count_*__`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t2.t1_id`=VALUES(`t2.t1_id`),
`t2.date_id`=VALUES(`t2.date_id`),
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`),
`a`=VALUES(`a`),
`_count_*__`=VALUES(`_count_*__`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t2.t1_id AS `t2.t1_id`,t2.date_id AS `t2.date_id`,t1_id AS `t1_id`,date_id AS `date_id`,.`a` AS `a`,.`_count_*__` AS `_count_*__`
FROM t2 JOIN ( SELECT `a`,SUM(`_count_*__`) AS `_count_*__`,`t3.id`,`id`
FROM `aggregation_tmp_14911862`  GROUP BY `a`  ) AS `t3`  WHERE (  `t3`.`id` = t2.date_id )   
)


-- AGGREGATION SQL:
SELECT `t2.t1_id`,`t2.date_id`,`t1_id`,`date_id`,`a`,`_count_*__`
FROM `aggregation_tmp_51443229`   
ON DUPLICATE KEY UPDATE
`t2.t1_id`=VALUES(`t2.t1_id`),
`t2.date_id`=VALUES(`t2.date_id`),
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`),
`a`=VALUES(`a`),
`_count_*__`=VALUES(`_count_*__`)
-- INPUT SQL:
select a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by a

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`a`,`_count_*__`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`a`=VALUES(`a`),
`_count_*__`=VALUES(`_count_*__`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT .`a` AS `a`,.`_count_*__` AS `_count_*__`
FROM t1 JOIN ( SELECT `t2.t1_id`,`t2.date_id`,`t1_id`,`date_id`,`a`,`_count_*__`
FROM `aggregation_tmp_51443229`   ) AS `t2`  WHERE (  t1.id = `t2`.`t1_id` )   
)


-- AGGREGATION SQL:
SELECT `a`,`_count_*__`
FROM `aggregation_tmp_16065598`   
ON DUPLICATE KEY UPDATE
`a`=VALUES(`a`),
`_count_*__`=VALUES(`_count_*__`)
This is the query plan for the query:
select a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by a

CALL paquExec('SELECT a AS `a`,COUNT(*) AS `_count_*__`,t3.id AS `t3.id`,id AS `id` FROM t3 GROUP BY a ', 'aggregation_tmp_14911862');
CALL paquExec('SELECT t2.t1_id AS `t2.t1_id`,t2.date_id AS `t2.date_id`,t1_id AS `t1_id`,date_id AS `date_id`,.`a` AS `a`,.`_count_*__` AS `_count_*__` FROM t2 JOIN ( SELECT `a`,SUM(`_count_*__`) AS `_count_*__`,`t3.id`,`id` FROM `aggregation_tmp_14911862`  GROUP BY `a`  ) AS `t3`  WHERE (  `t3`.`id` = t2.date_id )   ', 'aggregation_tmp_51443229');
CALL paquExec('SELECT .`a` AS `a`,.`_count_*__` AS `_count_*__` FROM t1 JOIN ( SELECT `t2.t1_id`,`t2.date_id`,`t1_id`,`date_id`,`a`,`_count_*__` FROM `aggregation_tmp_51443229`   ) AS `t2`  WHERE (  t1.id = `t2`.`t1_id` )   ', 'aggregation_tmp_16065598');
CALL paquDropTmp('aggregation_tmp_14911862');
CALL paquDropTmp('aggregation_tmp_51443229');
USE spider_tmp_shard; CREATE TABLE test.test ENGINE=MyISAM SELECT `a`,`_count_*__`
FROM `aggregation_tmp_16065598`   ;
CALL paquDropTmp('aggregation_tmp_16065598');
This is the query plan optimisation output for the query:
select t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t3.id`,`id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t3.id`=VALUES(`t3.id`),
`id`=VALUES(`id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t3.id AS `t3.id`,id AS `id`
FROM t3 
)


-- AGGREGATION SQL:
SELECT `t3.id`,`id`
FROM `aggregation_tmp_70987790`   
ON DUPLICATE KEY UPDATE
`t3.id`=VALUES(`t3.id`),
`id`=VALUES(`id`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t2.t1_id`,`t2.date_id`,`t1_id`,`date_id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t2.t1_id`=VALUES(`t2.t1_id`),
`t2.date_id`=VALUES(`t2.date_id`),
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t2.t1_id AS `t2.t1_id`,t2.date_id AS `t2.date_id`,t1_id AS `t1_id`,date_id AS `date_id`
FROM t2 JOIN ( SELECT `t3.id`,`id`
FROM `aggregation_tmp_70987790`   ) AS `t3`  WHERE (  `t3`.`id` = t2.date_id )   
)


-- AGGREGATION SQL:
SELECT `t2.t1_id`,`t2.date_id`,`t1_id`,`date_id`
FROM `aggregation_tmp_97778250`   
ON DUPLICATE KEY UPDATE
`t2.t1_id`=VALUES(`t2.t1_id`),
`t2.date_id`=VALUES(`t2.date_id`),
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)
-- INPUT SQL:
select t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1.a`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*__`=`_count_*__` +  VALUES(`_count_*__`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*__`
FROM t1 JOIN ( SELECT `t2.t1_id`,`t2.date_id`,`t1_id`,`date_id`
FROM `aggregation_tmp_97778250`   ) AS `t2`  WHERE (  t1.id = `t2`.`t1_id` )  GROUP BY t1.a  
)


-- AGGREGATION SQL:
SELECT `t1.a`,SUM(`_count_*__`) AS `_count_*__`
FROM `aggregation_tmp_37833810`  GROUP BY `t1.a`  
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*__`=`_count_*__` +  VALUES(`_count_*__`)
This is the query plan for the query:
select t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

CALL paquExec('SELECT t3.id AS `t3.id`,id AS `id` FROM t3 ', 'aggregation_tmp_70987790');
CALL paquExec('SELECT t2.t1_id AS `t2.t1_id`,t2.date_id AS `t2.date_id`,t1_id AS `t1_id`,date_id AS `date_id` FROM t2 JOIN ( SELECT `t3.id`,`id` FROM `aggregation_tmp_70987790`   ) AS `t3`  WHERE (  `t3`.`id` = t2.date_id )   ', 'aggregation_tmp_97778250');
CALL paquExec('SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*__` FROM t1 JOIN ( SELECT `t2.t1_id`,`t2.date_id`,`t1_id`,`date_id` FROM `aggregation_tmp_97778250`   ) AS `t2`  WHERE (  t1.id = `t2`.`t1_id` )  GROUP BY t1.a  ', 'aggregation_tmp_37833810');
CALL paquDropTmp('aggregation_tmp_70987790');
CALL paquDropTmp('aggregation_tmp_97778250');
USE spider_tmp_shard; CREATE TABLE test.test ENGINE=MyISAM SELECT `t1.a`,SUM(`_count_*__`) AS `_count_*__`
FROM `aggregation_tmp_37833810`  GROUP BY `t1.a`  ;
CALL paquDropTmp('aggregation_tmp_37833810');
This is the query plan optimisation output for the query:
select t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t3.id`,`id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t3.id`=VALUES(`t3.id`),
`id`=VALUES(`id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t3.id AS `t3.id`,id AS `id`
FROM t3 
)


-- AGGREGATION SQL:
SELECT `t3.id`,`id`
FROM `aggregation_tmp_29352004`   
ON DUPLICATE KEY UPDATE
`t3.id`=VALUES(`t3.id`),
`id`=VALUES(`id`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t2.t1_id`,`t2.date_id`,`t1_id`,`date_id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t2.t1_id`=VALUES(`t2.t1_id`),
`t2.date_id`=VALUES(`t2.date_id`),
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t2.t1_id AS `t2.t1_id`,t2.date_id AS `t2.date_id`,t1_id AS `t1_id`,date_id AS `date_id`
FROM t2 JOIN ( SELECT `t3.id`,`id`
FROM `aggregation_tmp_29352004`   ) AS `t3`  WHERE (  `t3`.`id` = t2.date_id )   
)


-- AGGREGATION SQL:
SELECT `t2.t1_id`,`t2.date_id`,`t1_id`,`date_id`
FROM `aggregation_tmp_95709328`   
ON DUPLICATE KEY UPDATE
`t2.t1_id`=VALUES(`t2.t1_id`),
`t2.date_id`=VALUES(`t2.date_id`),
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)
-- INPUT SQL:
select t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1.a`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*__`=`_count_*__` +  VALUES(`_count_*__`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*__`
FROM t1 JOIN ( SELECT `t2.t1_id`,`t2.date_id`,`t1_id`,`date_id`
FROM `aggregation_tmp_95709328`   ) AS `t2`  WHERE (  t1.id = `t2`.`t1_id` )  GROUP BY t1.a  
)


-- AGGREGATION SQL:
SELECT `t1.a`,SUM(`_count_*__`) AS `_count_*__`
FROM `aggregation_tmp_97314199`  GROUP BY `t1.a`  
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*__`=`_count_*__` +  VALUES(`_count_*__`)
This is the query plan for the query:
select t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

CALL paquExec('SELECT t3.id AS `t3.id`,id AS `id` FROM t3 ', 'aggregation_tmp_29352004');
CALL paquExec('SELECT t2.t1_id AS `t2.t1_id`,t2.date_id AS `t2.date_id`,t1_id AS `t1_id`,date_id AS `date_id` FROM t2 JOIN ( SELECT `t3.id`,`id` FROM `aggregation_tmp_29352004`   ) AS `t3`  WHERE (  `t3`.`id` = t2.date_id )   ', 'aggregation_tmp_95709328');
CALL paquExec('SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*__` FROM t1 JOIN ( SELECT `t2.t1_id`,`t2.date_id`,`t1_id`,`date_id` FROM `aggregation_tmp_95709328`   ) AS `t2`  WHERE (  t1.id = `t2`.`t1_id` )  GROUP BY t1.a  ', 'aggregation_tmp_97314199');
CALL paquDropTmp('aggregation_tmp_29352004');
CALL paquDropTmp('aggregation_tmp_95709328');
USE spider_tmp_shard; CREATE TABLE test.test ENGINE=MyISAM SELECT `t1.a`,SUM(`_count_*__`) AS `_count_*__`
FROM `aggregation_tmp_97314199`  GROUP BY `t1.a`  ;
CALL paquDropTmp('aggregation_tmp_97314199');
This is the query plan optimisation output for the query:
select t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by a

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t3.id`,`id`,`a`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t3.id`=VALUES(`t3.id`),
`id`=VALUES(`id`),
`a`=VALUES(`a`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t3.id AS `t3.id`,id AS `id`,a AS `a`
FROM t3 GROUP BY a 
)


-- AGGREGATION SQL:
SELECT `t3.id`,`id`,`a`
FROM `aggregation_tmp_1697981`  GROUP BY `a`  
ON DUPLICATE KEY UPDATE
`t3.id`=VALUES(`t3.id`),
`id`=VALUES(`id`),
`a`=VALUES(`a`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t2.t1_id`,`t2.date_id`,`t1_id`,`date_id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t2.t1_id`=VALUES(`t2.t1_id`),
`t2.date_id`=VALUES(`t2.date_id`),
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t2.t1_id AS `t2.t1_id`,t2.date_id AS `t2.date_id`,t1_id AS `t1_id`,date_id AS `date_id`
FROM t2 JOIN ( SELECT `t3.id`,`id`,`a`
FROM `aggregation_tmp_1697981`  GROUP BY `a`  ) AS `t3`  WHERE (  `t3`.`id` = t2.date_id )   
)


-- AGGREGATION SQL:
SELECT `t2.t1_id`,`t2.date_id`,`t1_id`,`date_id`
FROM `aggregation_tmp_53383468`   
ON DUPLICATE KEY UPDATE
`t2.t1_id`=VALUES(`t2.t1_id`),
`t2.date_id`=VALUES(`t2.date_id`),
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)
-- INPUT SQL:
select t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by a

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1.a`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*__`=`_count_*__` +  VALUES(`_count_*__`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*__`
FROM t1 JOIN ( SELECT `t2.t1_id`,`t2.date_id`,`t1_id`,`date_id`
FROM `aggregation_tmp_53383468`   ) AS `t2`  WHERE (  t1.id = `t2`.`t1_id` )   
)


-- AGGREGATION SQL:
SELECT `t1.a`,SUM(`_count_*__`) AS `_count_*__`
FROM `aggregation_tmp_53124429`   
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*__`=`_count_*__` +  VALUES(`_count_*__`)
This is the query plan for the query:
select t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by a

CALL paquExec('SELECT t3.id AS `t3.id`,id AS `id`,a AS `a` FROM t3 GROUP BY a ', 'aggregation_tmp_1697981');
CALL paquExec('SELECT t2.t1_id AS `t2.t1_id`,t2.date_id AS `t2.date_id`,t1_id AS `t1_id`,date_id AS `date_id` FROM t2 JOIN ( SELECT `t3.id`,`id`,`a` FROM `aggregation_tmp_1697981`  GROUP BY `a`  ) AS `t3`  WHERE (  `t3`.`id` = t2.date_id )   ', 'aggregation_tmp_53383468');
CALL paquExec('SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*__` FROM t1 JOIN ( SELECT `t2.t1_id`,`t2.date_id`,`t1_id`,`date_id` FROM `aggregation_tmp_53383468`   ) AS `t2`  WHERE (  t1.id = `t2`.`t1_id` )   ', 'aggregation_tmp_53124429');
CALL paquDropTmp('aggregation_tmp_1697981');
CALL paquDropTmp('aggregation_tmp_53383468');
USE spider_tmp_shard; CREATE TABLE test.test ENGINE=MyISAM SELECT `t1.a`,SUM(`_count_*__`) AS `_count_*__`
FROM `aggregation_tmp_53124429`   ;
CALL paquDropTmp('aggregation_tmp_53124429');
This is the query plan optimisation output for the query:
select t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by a

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t3.id`,`id`,`a`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t3.id`=VALUES(`t3.id`),
`id`=VALUES(`id`),
`a`=VALUES(`a`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t3.id AS `t3.id`,id AS `id`,a AS `a`
FROM t3 GROUP BY a 
)


-- AGGREGATION SQL:
SELECT `t3.id`,`id`,`a`
FROM `aggregation_tmp_12330558`  GROUP BY `a`  
ON DUPLICATE KEY UPDATE
`t3.id`=VALUES(`t3.id`),
`id`=VALUES(`id`),
`a`=VALUES(`a`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t2.t1_id`,`t2.date_id`,`t1_id`,`date_id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t2.t1_id`=VALUES(`t2.t1_id`),
`t2.date_id`=VALUES(`t2.date_id`),
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t2.t1_id AS `t2.t1_id`,t2.date_id AS `t2.date_id`,t1_id AS `t1_id`,date_id AS `date_id`
FROM t2 JOIN ( SELECT `t3.id`,`id`,`a`
FROM `aggregation_tmp_12330558`  GROUP BY `a`  ) AS `t3`  WHERE (  `t3`.`id` = t2.date_id )   
)


-- AGGREGATION SQL:
SELECT `t2.t1_id`,`t2.date_id`,`t1_id`,`date_id`
FROM `aggregation_tmp_93700697`   
ON DUPLICATE KEY UPDATE
`t2.t1_id`=VALUES(`t2.t1_id`),
`t2.date_id`=VALUES(`t2.date_id`),
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)
-- INPUT SQL:
select t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by a

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1.a`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*__`=`_count_*__` +  VALUES(`_count_*__`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*__`
FROM t1 JOIN ( SELECT `t2.t1_id`,`t2.date_id`,`t1_id`,`date_id`
FROM `aggregation_tmp_93700697`   ) AS `t2`  WHERE (  t1.id = `t2`.`t1_id` )   
)


-- AGGREGATION SQL:
SELECT `t1.a`,SUM(`_count_*__`) AS `_count_*__`
FROM `aggregation_tmp_50211991`   
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*__`=`_count_*__` +  VALUES(`_count_*__`)
This is the query plan for the query:
select t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by a

CALL paquExec('SELECT t3.id AS `t3.id`,id AS `id`,a AS `a` FROM t3 GROUP BY a ', 'aggregation_tmp_12330558');
CALL paquExec('SELECT t2.t1_id AS `t2.t1_id`,t2.date_id AS `t2.date_id`,t1_id AS `t1_id`,date_id AS `date_id` FROM t2 JOIN ( SELECT `t3.id`,`id`,`a` FROM `aggregation_tmp_12330558`  GROUP BY `a`  ) AS `t3`  WHERE (  `t3`.`id` = t2.date_id )   ', 'aggregation_tmp_93700697');
CALL paquExec('SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*__` FROM t1 JOIN ( SELECT `t2.t1_id`,`t2.date_id`,`t1_id`,`date_id` FROM `aggregation_tmp_93700697`   ) AS `t2`  WHERE (  t1.id = `t2`.`t1_id` )   ', 'aggregation_tmp_50211991');
CALL paquDropTmp('aggregation_tmp_12330558');
CALL paquDropTmp('aggregation_tmp_93700697');
USE spider_tmp_shard; CREATE TABLE test.test ENGINE=MyISAM SELECT `t1.a`,SUM(`_count_*__`) AS `_count_*__`
FROM `aggregation_tmp_50211991`   ;
CALL paquDropTmp('aggregation_tmp_50211991');
This is the query plan optimisation output for the query:
select a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by a

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`a`,`t3.id`,`id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`a`=VALUES(`a`),
`_count_*__`=`_count_*__` +  VALUES(`_count_*__`),
`t3.id`=VALUES(`t3.id`),
`id`=VALUES(`id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT a AS `a`,COUNT(*) AS `_count_*__`,t3.id AS `t3.id`,id AS `id`
FROM t3 GROUP BY a 
)


-- AGGREGATION SQL:
SELECT `a`,SUM(`_count_*__`) AS `_count_*__`,`t3.id`,`id`
FROM `aggregation_tmp_31476699`  GROUP BY `a`  
ON DUPLICATE KEY UPDATE
`a`=VALUES(`a`),
`_count_*__`=`_count_*__` +  VALUES(`_count_*__`),
`t3.id`=VALUES(`t3.id`),
`id`=VALUES(`id`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t2.t1_id`,`t2.date_id`,`t1_id`,`date_id`,`a`,`_count_*__`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t2.t1_id`=VALUES(`t2.t1_id`),
`t2.date_id`=VALUES(`t2.date_id`),
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`),
`a`=VALUES(`a`),
`_count_*__`=VALUES(`_count_*__`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t2.t1_id AS `t2.t1_id`,t2.date_id AS `t2.date_id`,t1_id AS `t1_id`,date_id AS `date_id`,.`a` AS `a`,.`_count_*__` AS `_count_*__`
FROM t2 JOIN ( SELECT `a`,SUM(`_count_*__`) AS `_count_*__`,`t3.id`,`id`
FROM `aggregation_tmp_31476699`  GROUP BY `a`  ) AS `t3`  WHERE (  `t3`.`id` = t2.date_id )   
)


-- AGGREGATION SQL:
SELECT `t2.t1_id`,`t2.date_id`,`t1_id`,`date_id`,`a`,`_count_*__`
FROM `aggregation_tmp_60670228`   
ON DUPLICATE KEY UPDATE
`t2.t1_id`=VALUES(`t2.t1_id`),
`t2.date_id`=VALUES(`t2.date_id`),
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`),
`a`=VALUES(`a`),
`_count_*__`=VALUES(`_count_*__`)
-- INPUT SQL:
select a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by a

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`a`,`_count_*__`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`a`=VALUES(`a`),
`_count_*__`=VALUES(`_count_*__`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT .`a` AS `a`,.`_count_*__` AS `_count_*__`
FROM t1 JOIN ( SELECT `t2.t1_id`,`t2.date_id`,`t1_id`,`date_id`,`a`,`_count_*__`
FROM `aggregation_tmp_60670228`   ) AS `t2`  WHERE (  t1.id = `t2`.`t1_id` )   
)


-- AGGREGATION SQL:
SELECT `a`,`_count_*__`
FROM `aggregation_tmp_68597026`   
ON DUPLICATE KEY UPDATE
`a`=VALUES(`a`),
`_count_*__`=VALUES(`_count_*__`)
This is the query plan for the query:
select a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by a

CALL paquExec('SELECT a AS `a`,COUNT(*) AS `_count_*__`,t3.id AS `t3.id`,id AS `id` FROM t3 GROUP BY a ', 'aggregation_tmp_31476699');
CALL paquExec('SELECT t2.t1_id AS `t2.t1_id`,t2.date_id AS `t2.date_id`,t1_id AS `t1_id`,date_id AS `date_id`,.`a` AS `a`,.`_count_*__` AS `_count_*__` FROM t2 JOIN ( SELECT `a`,SUM(`_count_*__`) AS `_count_*__`,`t3.id`,`id` FROM `aggregation_tmp_31476699`  GROUP BY `a`  ) AS `t3`  WHERE (  `t3`.`id` = t2.date_id )   ', 'aggregation_tmp_60670228');
CALL paquExec('SELECT .`a` AS `a`,.`_count_*__` AS `_count_*__` FROM t1 JOIN ( SELECT `t2.t1_id`,`t2.date_id`,`t1_id`,`date_id`,`a`,`_count_*__` FROM `aggregation_tmp_60670228`   ) AS `t2`  WHERE (  t1.id = `t2`.`t1_id` )   ', 'aggregation_tmp_68597026');
CALL paquDropTmp('aggregation_tmp_31476699');
CALL paquDropTmp('aggregation_tmp_60670228');
USE spider_tmp_shard; CREATE TABLE test.test ENGINE=MyISAM SELECT `a`,`_count_*__`
FROM `aggregation_tmp_68597026`   ;
CALL paquDropTmp('aggregation_tmp_68597026');
This is the query plan optimisation output for the query:
select t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t3.id`,`id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t3.id`=VALUES(`t3.id`),
`id`=VALUES(`id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t3.id AS `t3.id`,id AS `id`
FROM t3 
)


-- AGGREGATION SQL:
SELECT `t3.id`,`id`
FROM `aggregation_tmp_50548816`   
ON DUPLICATE KEY UPDATE
`t3.id`=VALUES(`t3.id`),
`id`=VALUES(`id`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t2.t1_id`,`t2.date_id`,`t1_id`,`date_id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t2.t1_id`=VALUES(`t2.t1_id`),
`t2.date_id`=VALUES(`t2.date_id`),
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t2.t1_id AS `t2.t1_id`,t2.date_id AS `t2.date_id`,t1_id AS `t1_id`,date_id AS `date_id`
FROM t2 JOIN ( SELECT `t3.id`,`id`
FROM `aggregation_tmp_50548816`   ) AS `t3`  WHERE (  `t3`.`id` = t2.date_id )   
)


-- AGGREGATION SQL:
SELECT `t2.t1_id`,`t2.date_id`,`t1_id`,`date_id`
FROM `aggregation_tmp_75255232`   
ON DUPLICATE KEY UPDATE
`t2.t1_id`=VALUES(`t2.t1_id`),
`t2.date_id`=VALUES(`t2.date_id`),
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)
-- INPUT SQL:
select t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1.a`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*__`=`_count_*__` +  VALUES(`_count_*__`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*__`
FROM t1 JOIN ( SELECT `t2.t1_id`,`t2.date_id`,`t1_id`,`date_id`
FROM `aggregation_tmp_75255232`   ) AS `t2`  WHERE (  t1.id = `t2`.`t1_id` )  GROUP BY t1.a  
)


-- AGGREGATION SQL:
SELECT `t1.a`,SUM(`_count_*__`) AS `_count_*__`
FROM `aggregation_tmp_32351266`  GROUP BY `t1.a`  
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*__`=`_count_*__` +  VALUES(`_count_*__`)
This is the query plan for the query:
select t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

CALL paquExec('SELECT t3.id AS `t3.id`,id AS `id` FROM t3 ', 'aggregation_tmp_50548816');
CALL paquExec('SELECT t2.t1_id AS `t2.t1_id`,t2.date_id AS `t2.date_id`,t1_id AS `t1_id`,date_id AS `date_id` FROM t2 JOIN ( SELECT `t3.id`,`id` FROM `aggregation_tmp_50548816`   ) AS `t3`  WHERE (  `t3`.`id` = t2.date_id )   ', 'aggregation_tmp_75255232');
CALL paquExec('SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*__` FROM t1 JOIN ( SELECT `t2.t1_id`,`t2.date_id`,`t1_id`,`date_id` FROM `aggregation_tmp_75255232`   ) AS `t2`  WHERE (  t1.id = `t2`.`t1_id` )  GROUP BY t1.a  ', 'aggregation_tmp_32351266');
CALL paquDropTmp('aggregation_tmp_50548816');
CALL paquDropTmp('aggregation_tmp_75255232');
USE spider_tmp_shard; CREATE TABLE test.test ENGINE=MyISAM SELECT `t1.a`,SUM(`_count_*__`) AS `_count_*__`
FROM `aggregation_tmp_32351266`  GROUP BY `t1.a`  ;
CALL paquDropTmp('aggregation_tmp_32351266');
This is the query plan optimisation output for the query:
select t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t3.id`,`id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t3.id`=VALUES(`t3.id`),
`id`=VALUES(`id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t3.id AS `t3.id`,id AS `id`
FROM t3 
)


-- AGGREGATION SQL:
SELECT `t3.id`,`id`
FROM `aggregation_tmp_77553618`   
ON DUPLICATE KEY UPDATE
`t3.id`=VALUES(`t3.id`),
`id`=VALUES(`id`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t2.t1_id`,`t2.date_id`,`t1_id`,`date_id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t2.t1_id`=VALUES(`t2.t1_id`),
`t2.date_id`=VALUES(`t2.date_id`),
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t2.t1_id AS `t2.t1_id`,t2.date_id AS `t2.date_id`,t1_id AS `t1_id`,date_id AS `date_id`
FROM t2 JOIN ( SELECT `t3.id`,`id`
FROM `aggregation_tmp_77553618`   ) AS `t3`  WHERE (  `t3`.`id` = t2.date_id )   
)


-- AGGREGATION SQL:
SELECT `t2.t1_id`,`t2.date_id`,`t1_id`,`date_id`
FROM `aggregation_tmp_1262894`   
ON DUPLICATE KEY UPDATE
`t2.t1_id`=VALUES(`t2.t1_id`),
`t2.date_id`=VALUES(`t2.date_id`),
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)
-- INPUT SQL:
select t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1.a`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*__`=`_count_*__` +  VALUES(`_count_*__`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*__`
FROM t1 JOIN ( SELECT `t2.t1_id`,`t2.date_id`,`t1_id`,`date_id`
FROM `aggregation_tmp_1262894`   ) AS `t2`  WHERE (  t1.id = `t2`.`t1_id` )  GROUP BY t1.a  
)


-- AGGREGATION SQL:
SELECT `t1.a`,SUM(`_count_*__`) AS `_count_*__`
FROM `aggregation_tmp_36620418`  GROUP BY `t1.a`  
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*__`=`_count_*__` +  VALUES(`_count_*__`)
This is the query plan for the query:
select t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

CALL paquExec('SELECT t3.id AS `t3.id`,id AS `id` FROM t3 ', 'aggregation_tmp_77553618');
CALL paquExec('SELECT t2.t1_id AS `t2.t1_id`,t2.date_id AS `t2.date_id`,t1_id AS `t1_id`,date_id AS `date_id` FROM t2 JOIN ( SELECT `t3.id`,`id` FROM `aggregation_tmp_77553618`   ) AS `t3`  WHERE (  `t3`.`id` = t2.date_id )   ', 'aggregation_tmp_1262894');
CALL paquExec('SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*__` FROM t1 JOIN ( SELECT `t2.t1_id`,`t2.date_id`,`t1_id`,`date_id` FROM `aggregation_tmp_1262894`   ) AS `t2`  WHERE (  t1.id = `t2`.`t1_id` )  GROUP BY t1.a  ', 'aggregation_tmp_36620418');
CALL paquDropTmp('aggregation_tmp_77553618');
CALL paquDropTmp('aggregation_tmp_1262894');
USE spider_tmp_shard; CREATE TABLE test.test ENGINE=MyISAM SELECT `t1.a`,SUM(`_count_*__`) AS `_count_*__`
FROM `aggregation_tmp_36620418`  GROUP BY `t1.a`  ;
CALL paquDropTmp('aggregation_tmp_36620418');
This is the query plan optimisation output for the query:
select t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t3.id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t3.id`=VALUES(`t3.id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t3.id AS `t3.id`
FROM t3 
)


-- AGGREGATION SQL:
SELECT `t3.id`
FROM `aggregation_tmp_50785454`   
ON DUPLICATE KEY UPDATE
`t3.id`=VALUES(`t3.id`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t2.t1_id`,`t2.date_id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t2.t1_id`=VALUES(`t2.t1_id`),
`t2.date_id`=VALUES(`t2.date_id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t2.t1_id AS `t2.t1_id`,t2.date_id AS `t2.date_id`
FROM t2 JOIN ( SELECT `t3.id`
FROM `aggregation_tmp_50785454`   ) AS `t3`  WHERE (  `t3`.`t3.id` = t2.date_id )   
)


-- AGGREGATION SQL:
SELECT `t2.t1_id`,`t2.date_id`
FROM `aggregation_tmp_27701461`   
ON DUPLICATE KEY UPDATE
`t2.t1_id`=VALUES(`t2.t1_id`),
`t2.date_id`=VALUES(`t2.date_id`)
-- INPUT SQL:
select t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1.a`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*__`=`_count_*__` +  VALUES(`_count_*__`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*__`
FROM t1 JOIN ( SELECT `t2.t1_id`,`t2.date_id`
FROM `aggregation_tmp_27701461`   ) AS `t2`  WHERE (  t1.id = `t2`.`t2.t1_id` )  GROUP BY t1.a  
)


-- AGGREGATION SQL:
SELECT `t1.a`,SUM(`_count_*__`) AS `_count_*__`
FROM `aggregation_tmp_56139094`  GROUP BY `t1.a`  
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*__`=`_count_*__` +  VALUES(`_count_*__`)
This is the query plan for the query:
select t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

CALL paquExec('SELECT t3.id AS `t3.id` FROM t3 ', 'aggregation_tmp_50785454');
CALL paquExec('SELECT t2.t1_id AS `t2.t1_id`,t2.date_id AS `t2.date_id` FROM t2 JOIN ( SELECT `t3.id` FROM `aggregation_tmp_50785454`   ) AS `t3`  WHERE (  `t3`.`t3.id` = t2.date_id )   ', 'aggregation_tmp_27701461');
CALL paquExec('SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*__` FROM t1 JOIN ( SELECT `t2.t1_id`,`t2.date_id` FROM `aggregation_tmp_27701461`   ) AS `t2`  WHERE (  t1.id = `t2`.`t2.t1_id` )  GROUP BY t1.a  ', 'aggregation_tmp_56139094');
CALL paquDropTmp('aggregation_tmp_50785454');
CALL paquDropTmp('aggregation_tmp_27701461');
USE spider_tmp_shard; CREATE TABLE test.test ENGINE=MyISAM SELECT `t1.a`,SUM(`_count_*__`) AS `_count_*__`
FROM `aggregation_tmp_56139094`  GROUP BY `t1.a`  ;
CALL paquDropTmp('aggregation_tmp_56139094');
This is the query plan optimisation output for the query:
SELECT sprng_make_seed(), count(abs(*));

-- INPUT SQL:
SELECT sprng_make_seed(), count(abs(*));

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_sprng_make_seed___`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_sprng_make_seed___`=VALUES(`_sprng_make_seed___`),
`_count_abs_*___`=`_count_abs_*___` +  VALUES(`_count_abs_*___`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT sprng_make_seed() AS `_sprng_make_seed___`,COUNT(abs(*)) AS `_count_abs_*___` 
)


-- AGGREGATION SQL:
SELECT `_sprng_make_seed___`,SUM(`_count_abs_*___`) AS `_count_abs_*___`
FROM `aggregation_tmp_83241140`   
ON DUPLICATE KEY UPDATE
`_sprng_make_seed___`=VALUES(`_sprng_make_seed___`),
`_count_abs_*___`=`_count_abs_*___` +  VALUES(`_count_abs_*___`)
This is the query plan for the query:
SELECT sprng_make_seed(), count(abs(*));

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_83241140 ENGINE=MyISAM SELECT sprng_make_seed() AS `_sprng_make_seed___`,COUNT(abs(*)) AS `_count_abs_*___`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_83241140 SELECT sprng_make_seed() AS `_sprng_make_seed___`,COUNT(abs(*)) AS `_count_abs_*___` ;
CALL paquLinkTmp('aggregation_tmp_83241140');
USE spider_tmp_shard; CREATE TABLE test.test ENGINE=MyISAM SELECT `_sprng_make_seed___`,SUM(`_count_abs_*___`) AS `_count_abs_*___`
FROM `aggregation_tmp_83241140`   ;
CALL paquDropTmp('aggregation_tmp_83241140');
This is the query plan optimisation output for the query:
SELECT sprng_make_seed(), count(abs(*));

-- INPUT SQL:
SELECT sprng_make_seed(), count(abs(*));

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_sprng_make_seed___`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_sprng_make_seed___`=VALUES(`_sprng_make_seed___`),
`_count_abs_*___`=`_count_abs_*___` +  VALUES(`_count_abs_*___`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT sprng_make_seed() AS `_sprng_make_seed___`,COUNT(abs(*)) AS `_count_abs_*___` 
)


-- AGGREGATION SQL:
SELECT `_sprng_make_seed___`,SUM(`_count_abs_*___`) AS `_count_abs_*___`
FROM `aggregation_tmp_46845055`   
ON DUPLICATE KEY UPDATE
`_sprng_make_seed___`=VALUES(`_sprng_make_seed___`),
`_count_abs_*___`=`_count_abs_*___` +  VALUES(`_count_abs_*___`)
This is the query plan for the query:
SELECT sprng_make_seed(), count(abs(*));

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_46845055 ENGINE=MyISAM SELECT sprng_make_seed() AS `_sprng_make_seed___`,COUNT(abs(*)) AS `_count_abs_*___`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_46845055 SELECT sprng_make_seed() AS `_sprng_make_seed___`,COUNT(abs(*)) AS `_count_abs_*___` ;
CALL paquLinkTmp('aggregation_tmp_46845055');
USE spider_tmp_shard; CREATE TABLE test.test ENGINE=MyISAM SELECT `_sprng_make_seed___`,SUM(`_count_abs_*___`) AS `_count_abs_*___`
FROM `aggregation_tmp_46845055`   ;
CALL paquDropTmp('aggregation_tmp_46845055');
This is the query plan optimisation output for the query:
SELECT sprng_make_seed(), count(abs(*));

-- INPUT SQL:
SELECT sprng_make_seed(), count(abs(*));

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_sprng_make_seed___`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_sprng_make_seed___`=VALUES(`_sprng_make_seed___`),
`_count_abs_*___`=`_count_abs_*___` +  VALUES(`_count_abs_*___`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT sprng_make_seed() AS `_sprng_make_seed___`,COUNT(abs(*)) AS `_count_abs_*___` 
)


-- AGGREGATION SQL:
SELECT `_sprng_make_seed___`,SUM(`_count_abs_*___`) AS `_count_abs_*___`
FROM `aggregation_tmp_18170639`   
ON DUPLICATE KEY UPDATE
`_sprng_make_seed___`=VALUES(`_sprng_make_seed___`),
`_count_abs_*___`=`_count_abs_*___` +  VALUES(`_count_abs_*___`)
This is the query plan for the query:
SELECT sprng_make_seed(), count(abs(*));

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_18170639 ENGINE=MyISAM SELECT sprng_make_seed() AS `_sprng_make_seed___`,COUNT(abs(*)) AS `_count_abs_*___`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_18170639 SELECT sprng_make_seed() AS `_sprng_make_seed___`,COUNT(abs(*)) AS `_count_abs_*___` ;
CALL paquLinkTmp('aggregation_tmp_18170639');
USE spider_tmp_shard; CREATE TABLE test.test ENGINE=MyISAM SELECT `_sprng_make_seed___`,SUM(`_count_abs_*___`) AS `_count_abs_*___`
FROM `aggregation_tmp_18170639`   ;
CALL paquDropTmp('aggregation_tmp_18170639');
This is the query plan optimisation output for the query:
SELECT sprng_make_seed(), count(abs(*));

-- INPUT SQL:
SELECT sprng_make_seed(), count(abs(*));

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_sprng_make_seed___`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_sprng_make_seed___`=VALUES(`_sprng_make_seed___`),
`_count_abs_*___`=`_count_abs_*___` +  VALUES(`_count_abs_*___`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT sprng_make_seed() AS `_sprng_make_seed___`,COUNT(abs(*)) AS `_count_abs_*___` 
)


-- AGGREGATION SQL:
SELECT `_sprng_make_seed___`,SUM(`_count_abs_*___`) AS `_count_abs_*___`
FROM `aggregation_tmp_19872321`   
ON DUPLICATE KEY UPDATE
`_sprng_make_seed___`=VALUES(`_sprng_make_seed___`),
`_count_abs_*___`=`_count_abs_*___` +  VALUES(`_count_abs_*___`)
This is the query plan for the query:
SELECT sprng_make_seed(), count(abs(*));

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_19872321 ENGINE=MyISAM SELECT sprng_make_seed() AS `_sprng_make_seed___`,COUNT(abs(*)) AS `_count_abs_*___`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_19872321 SELECT sprng_make_seed() AS `_sprng_make_seed___`,COUNT(abs(*)) AS `_count_abs_*___` ;
CALL paquLinkTmp('aggregation_tmp_19872321');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_sprng_make_seed___`,SUM(`_count_abs_*___`) AS `_count_abs_*___`
FROM `aggregation_tmp_19872321`   ;
CALL paquDropTmp('aggregation_tmp_19872321');
This is the query plan optimisation output for the query:
SELECT sprng_make_seed(), count(abs(*));

-- INPUT SQL:
SELECT sprng_make_seed(), count(abs(*));

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_sprng_make_seed___`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_sprng_make_seed___`=VALUES(`_sprng_make_seed___`),
`_count_abs_*___`=`_count_abs_*___` +  VALUES(`_count_abs_*___`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT sprng_make_seed() AS `_sprng_make_seed___`,COUNT(abs(*)) AS `_count_abs_*___` 
)


-- AGGREGATION SQL:
SELECT `_sprng_make_seed___`,SUM(`_count_abs_*___`) AS `_count_abs_*___`
FROM `aggregation_tmp_43817547`   
ON DUPLICATE KEY UPDATE
`_sprng_make_seed___`=VALUES(`_sprng_make_seed___`),
`_count_abs_*___`=`_count_abs_*___` +  VALUES(`_count_abs_*___`)
This is the query plan for the query:
SELECT sprng_make_seed(), count(abs(*));

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_43817547 ENGINE=MyISAM SELECT sprng_make_seed() AS `_sprng_make_seed___`,COUNT(abs(*)) AS `_count_abs_*___`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_43817547 SELECT sprng_make_seed() AS `_sprng_make_seed___`,COUNT(abs(*)) AS `_count_abs_*___` ;
CALL paquLinkTmp('aggregation_tmp_43817547');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_sprng_make_seed___`,SUM(`_count_abs_*___`) AS `_count_abs_*___`
FROM `aggregation_tmp_43817547`   ;
CALL paquDropTmp('aggregation_tmp_43817547');
This is the query plan optimisation output for the query:
select (x+y) from MDR1.FOF limit 10

-- INPUT SQL:
select (x+y) from MDR1.FOF limit 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
Array

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
Array=VALUES(Array)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT (x+y) AS Array
FROM MDR1.FOF AS `Array`  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT Array
FROM `aggregation_tmp_27224227`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
Array=VALUES(Array)
This is the query plan for the query:
select (x+y) from MDR1.FOF limit 10

CALL paquExec('SELECT (x+y) AS Array FROM MDR1.FOF AS `Array`  LIMIT 0,10', 'aggregation_tmp_27224227');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT Array
FROM `aggregation_tmp_27224227`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_27224227');
This is the query plan optimisation output for the query:
select (x+y) from MDR1.FOF limit 10

-- INPUT SQL:
select (x+y) from MDR1.FOF limit 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
Array

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
Array=VALUES(Array)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT (x+y) AS Array
FROM MDR1.FOF AS `Array`  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT Array
FROM `aggregation_tmp_79075988`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
Array=VALUES(Array)
This is the query plan for the query:
select (x+y) from MDR1.FOF limit 10

CALL paquExec('SELECT (x+y) AS Array FROM MDR1.FOF AS `Array`  LIMIT 0,10', 'aggregation_tmp_79075988');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT Array
FROM `aggregation_tmp_79075988`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_79075988');
This is the query plan optimisation output for the query:
select (x+y) from MDR1.FOF limit 10

-- INPUT SQL:
select (x+y) from MDR1.FOF limit 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`(x+y)`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`(x+y)`=VALUES(`(x+y)`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT (x+y) AS `(x+y)`
FROM MDR1.FOF  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `(x+y)`
FROM `aggregation_tmp_35749599`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`(x+y)`=VALUES(`(x+y)`)
This is the query plan for the query:
select (x+y) from MDR1.FOF limit 10

CALL paquExec('SELECT (x+y) AS `(x+y)` FROM MDR1.FOF  LIMIT 0,10', 'aggregation_tmp_35749599');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `(x+y)`
FROM `aggregation_tmp_35749599`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_35749599');
This is the query plan optimisation output for the query:
select rand() from MDR1.Particles62 limit 100

-- INPUT SQL:
select rand() from MDR1.Particles62 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
_rand_

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
_rand_=VALUES(_rand_)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT rand() AS _rand_
FROM MDR1.Particles62  LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT _rand_
FROM `aggregation_tmp_1225963`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
_rand_=VALUES(_rand_)
This is the query plan for the query:
select rand() from MDR1.Particles62 limit 100

CALL paquExec('SELECT rand() AS _rand_ FROM MDR1.Particles62  LIMIT 0,100', 'aggregation_tmp_1225963');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT _rand_
FROM `aggregation_tmp_1225963`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_1225963');
This is the query plan optimisation output for the query:
select rand() from MDR1.Particles62 limit 100

-- INPUT SQL:
select rand() from MDR1.Particles62 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
_rand___

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
_rand___=VALUES(_rand___)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT rand() AS _rand___
FROM MDR1.Particles62  LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT _rand___
FROM `aggregation_tmp_60124274`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
_rand___=VALUES(_rand___)
This is the query plan for the query:
select rand() from MDR1.Particles62 limit 100

CALL paquExec('SELECT rand() AS _rand___ FROM MDR1.Particles62  LIMIT 0,100', 'aggregation_tmp_60124274');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT _rand___
FROM `aggregation_tmp_60124274`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_60124274');
This is the query plan optimisation output for the query:
select rand() from MDR1.Particles62 limit 100

-- INPUT SQL:
select rand() from MDR1.Particles62 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_rand___`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_rand___`=VALUES(`_rand___`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT rand() AS `_rand___`
FROM MDR1.Particles62  LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `_rand___`
FROM `aggregation_tmp_92273101`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`_rand___`=VALUES(`_rand___`)
This is the query plan for the query:
select rand() from MDR1.Particles62 limit 100

CALL paquExec('SELECT rand() AS `_rand___` FROM MDR1.Particles62  LIMIT 0,100', 'aggregation_tmp_92273101');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_rand___`
FROM `aggregation_tmp_92273101`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_92273101');
This is the query plan optimisation output for the query:
select rand(3) from MDR1.Particles62 limit 100

-- INPUT SQL:
select rand(3) from MDR1.Particles62 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_rand___`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_rand___`=VALUES(`_rand___`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT rand() AS `_rand___`
FROM MDR1.Particles62  LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `_rand___`
FROM `aggregation_tmp_90608501`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`_rand___`=VALUES(`_rand___`)
This is the query plan for the query:
select rand(3) from MDR1.Particles62 limit 100

CALL paquExec('SELECT rand() AS `_rand___` FROM MDR1.Particles62  LIMIT 0,100', 'aggregation_tmp_90608501');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_rand___`
FROM `aggregation_tmp_90608501`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_90608501');
This is the query plan optimisation output for the query:
select rand(3) as  from MDR1.Particles62 limit 100

-- INPUT SQL:
select rand(3) as  from MDR1.Particles62 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
as

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
as=VALUES(as)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT rand() AS as
FROM MDR1.Particles62  LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT as
FROM `aggregation_tmp_80711270`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
as=VALUES(as)
This is the query plan for the query:
select rand(3) as  from MDR1.Particles62 limit 100

CALL paquExec('SELECT rand() AS as FROM MDR1.Particles62  LIMIT 0,100', 'aggregation_tmp_80711270');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT as
FROM `aggregation_tmp_80711270`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_80711270');
This is the query plan optimisation output for the query:
select rand(3) as `random` from MDR1.Particles62 limit 100

-- INPUT SQL:
select rand(3) as `random` from MDR1.Particles62 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
as `random`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
as `random`=VALUES(as `random`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT rand() AS as `random`
FROM MDR1.Particles62  LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT as `random`
FROM `aggregation_tmp_94206553`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
as `random`=VALUES(as `random`)
This is the query plan for the query:
select rand(3) as `random` from MDR1.Particles62 limit 100

CALL paquExec('SELECT rand() AS as `random` FROM MDR1.Particles62  LIMIT 0,100', 'aggregation_tmp_94206553');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT as `random`
FROM `aggregation_tmp_94206553`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_94206553');
This is the query plan optimisation output for the query:
select rand(3) as `random` from MDR1.Particles62 limit 100

-- INPUT SQL:
select rand(3) as `random` from MDR1.Particles62 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
random

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
random=VALUES(random)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT rand() AS random
FROM MDR1.Particles62  LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT random
FROM `aggregation_tmp_65602729`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
random=VALUES(random)
This is the query plan for the query:
select rand(3) as `random` from MDR1.Particles62 limit 100

CALL paquExec('SELECT rand() AS random FROM MDR1.Particles62  LIMIT 0,100', 'aggregation_tmp_65602729');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT random
FROM `aggregation_tmp_65602729`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_65602729');
This is the query plan optimisation output for the query:
select rand(3) as `random` from MDR1.Particles62 limit 100

-- INPUT SQL:
select rand(3) as `random` from MDR1.Particles62 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`random`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`random`=VALUES(`random`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT rand() AS `random`
FROM MDR1.Particles62  LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `random`
FROM `aggregation_tmp_45560669`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`random`=VALUES(`random`)
This is the query plan for the query:
select rand(3) as `random` from MDR1.Particles62 limit 100

CALL paquExec('SELECT rand() AS `random` FROM MDR1.Particles62  LIMIT 0,100', 'aggregation_tmp_45560669');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `random`
FROM `aggregation_tmp_45560669`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_45560669');
This is the query plan optimisation output for the query:
select rand(3) as `random` from MDR1.Particles62 limit 100

-- INPUT SQL:
select rand(3) as `random` from MDR1.Particles62 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`random`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`random`=VALUES(`random`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT rand(3) AS `random`
FROM MDR1.Particles62  LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `random`
FROM `aggregation_tmp_58695515`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`random`=VALUES(`random`)
This is the query plan for the query:
select rand(3) as `random` from MDR1.Particles62 limit 100

CALL paquExec('SELECT rand(3) AS `random` FROM MDR1.Particles62  LIMIT 0,100', 'aggregation_tmp_58695515');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `random`
FROM `aggregation_tmp_58695515`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_58695515');
This is the query plan optimisation output for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand(3) <= 0.0006 limit 100

-- INPUT SQL:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand(3) <= 0.0006 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz`
FROM MDR1.Particles62 WHERE (  (  3 ) <= 0.0006 )    LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_44374714`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)
This is the query plan for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand(3) <= 0.0006 limit 100

CALL paquExec('SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz` FROM MDR1.Particles62 WHERE (  (  3 ) <= 0.0006 )    LIMIT 0,100', 'aggregation_tmp_44374714');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_44374714`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_44374714');
This is the query plan optimisation output for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand(3) <= 0.0006 limit 100

-- INPUT SQL:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand(3) <= 0.0006 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz`
FROM MDR1.Particles62 WHERE (  (  3 ) <= 0.0006 )    LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_51042550`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)
This is the query plan for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand(3) <= 0.0006 limit 100

CALL paquExec('SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz` FROM MDR1.Particles62 WHERE (  (  3 ) <= 0.0006 )    LIMIT 0,100', 'aggregation_tmp_51042550');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_51042550`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_51042550');
This is the query plan optimisation output for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand(3) <= 0.0006 limit 100

-- INPUT SQL:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand(3) <= 0.0006 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz`
FROM MDR1.Particles62 WHERE (  rand( 3 ) <= 0.0006 )    LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_56248091`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)
This is the query plan for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand(3) <= 0.0006 limit 100

CALL paquExec('SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz` FROM MDR1.Particles62 WHERE (  rand( 3 ) <= 0.0006 )    LIMIT 0,100', 'aggregation_tmp_56248091');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_56248091`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_56248091');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_28241131`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_28241131`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_12345630`  ORDER BY ``prog.fofTreeId`` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   ', 'aggregation_tmp_28241131');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_28241131`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_12345630');
CALL paquDropTmp('aggregation_tmp_28241131');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_12345630`  ORDER BY ``prog.fofTreeId`` ASC ;
CALL paquDropTmp('aggregation_tmp_12345630');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_27440358`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_27440358`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_73411946`  ORDER BY ``prog.fofTreeId`` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   ', 'aggregation_tmp_27440358');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_27440358`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_73411946');
CALL paquDropTmp('aggregation_tmp_27440358');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_73411946`  ORDER BY ``prog.fofTreeId`` ASC ;
CALL paquDropTmp('aggregation_tmp_73411946');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_99137166`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_99137166`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_63477221`  ORDER BY ``prog.fofTreeId`` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   ', 'aggregation_tmp_99137166');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_99137166`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_63477221');
CALL paquDropTmp('aggregation_tmp_99137166');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_63477221`  ORDER BY ``prog.fofTreeId`` ASC ;
CALL paquDropTmp('aggregation_tmp_63477221');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_58764845`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_58764845`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_33642618`  ORDER BY ``prog.fofTreeId`` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   ', 'aggregation_tmp_58764845');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_58764845`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_33642618');
CALL paquDropTmp('aggregation_tmp_58764845');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_33642618`  ORDER BY ``prog.fofTreeId`` ASC ;
CALL paquDropTmp('aggregation_tmp_33642618');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_89772333`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_89772333`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_52524997`  ORDER BY ``prog.fofTreeId`` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   ', 'aggregation_tmp_89772333');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_89772333`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_52524997');
CALL paquDropTmp('aggregation_tmp_89772333');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_52524997`  ORDER BY ``prog.fofTreeId`` ASC ;
CALL paquDropTmp('aggregation_tmp_52524997');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_50147610`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_50147610`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_39254847`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   ', 'aggregation_tmp_50147610');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_50147610`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_39254847');
CALL paquDropTmp('aggregation_tmp_50147610');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_39254847`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_39254847');
This is the query plan optimisation output for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

-- INPUT SQL:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,
FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `*`,
FROM `aggregation_tmp_86187523`  ORDER BY `` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)
This is the query plan for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

CALL paquExec('SELECT * AS `*`, FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `` DESC  LIMIT 0,10', 'aggregation_tmp_86187523');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`,
FROM `aggregation_tmp_86187523`  ORDER BY `` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_86187523');
This is the query plan optimisation output for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

-- INPUT SQL:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,
FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `*`,
FROM `aggregation_tmp_66255161`  ORDER BY `` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)
This is the query plan for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

CALL paquExec('SELECT * AS `*`, FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `` DESC  LIMIT 0,10', 'aggregation_tmp_66255161');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`,
FROM `aggregation_tmp_66255161`  ORDER BY `` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_66255161');
This is the query plan optimisation output for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

-- INPUT SQL:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,
FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `*`,
FROM `aggregation_tmp_23433548`  ORDER BY `` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)
This is the query plan for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

CALL paquExec('SELECT * AS `*`, FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `` DESC  LIMIT 0,10', 'aggregation_tmp_23433548');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`,
FROM `aggregation_tmp_23433548`  ORDER BY `` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_23433548');
This is the query plan optimisation output for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

-- INPUT SQL:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,
FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `*`,
FROM `aggregation_tmp_47095031`  ORDER BY `` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)
This is the query plan for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

CALL paquExec('SELECT * AS `*`, FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `` DESC  LIMIT 0,10', 'aggregation_tmp_47095031');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`,
FROM `aggregation_tmp_47095031`  ORDER BY `` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_47095031');
This is the query plan optimisation output for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

-- INPUT SQL:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,
FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `*`,
FROM `aggregation_tmp_13412860`  ORDER BY `mass` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)
This is the query plan for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

CALL paquExec('SELECT * AS `*`, FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10', 'aggregation_tmp_13412860');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`,
FROM `aggregation_tmp_13412860`  ORDER BY `mass` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_13412860');
This is the query plan optimisation output for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

-- INPUT SQL:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,
FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `*`,
FROM `aggregation_tmp_2744267`  ORDER BY `mass` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)
This is the query plan for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

CALL paquExec('SELECT * AS `*`, FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10', 'aggregation_tmp_2744267');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`,
FROM `aggregation_tmp_2744267`  ORDER BY `mass` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_2744267');
This is the query plan optimisation output for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

-- INPUT SQL:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,
FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `*`,
FROM `aggregation_tmp_85020373`  ORDER BY `mass` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)
This is the query plan for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

CALL paquExec('SELECT * AS `*`, FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10', 'aggregation_tmp_85020373');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`,
FROM `aggregation_tmp_85020373`  ORDER BY `mass` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_85020373');
This is the query plan optimisation output for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

-- INPUT SQL:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,
FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `*`,
FROM `aggregation_tmp_46820786`  ORDER BY `mass` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)
This is the query plan for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

CALL paquExec('SELECT * AS `*`, FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10', 'aggregation_tmp_46820786');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`,
FROM `aggregation_tmp_46820786`  ORDER BY `mass` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_46820786');
This is the query plan optimisation output for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

-- INPUT SQL:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,
FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `*`,
FROM `aggregation_tmp_13497509`  ORDER BY `mass` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)
This is the query plan for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

CALL paquExec('SELECT * AS `*`, FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10', 'aggregation_tmp_13497509');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`,
FROM `aggregation_tmp_13497509`  ORDER BY `mass` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_13497509');
This is the query plan optimisation output for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

-- INPUT SQL:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`,`mass`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`mass`=VALUES(`mass`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,mass AS `mass`
FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `*`,`mass`
FROM `aggregation_tmp_20480282`  ORDER BY `mass` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`mass`=VALUES(`mass`)
This is the query plan for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

CALL paquExec('SELECT * AS `*`,mass AS `mass` FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10', 'aggregation_tmp_20480282');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`,`mass`
FROM `aggregation_tmp_20480282`  ORDER BY `mass` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_20480282');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`num`,_FLOOR_LOG10_Mvir_/_0__25_

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=VALUES(`num`),
_FLOOR_LOG10_Mvir_/_0__25_=VALUES(_FLOOR_LOG10_Mvir_/_0__25_)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT() AS `num`,FLOOR(LOG10(Mvir)/0.25) AS _FLOOR_LOG10_Mvir_/_0__25_
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,`num`,_FLOOR_LOG10_Mvir_/_0__25_
FROM `aggregation_tmp_58284850`  GROUP BY ``  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=VALUES(`num`),
_FLOOR_LOG10_Mvir_/_0__25_=VALUES(_FLOOR_LOG10_Mvir_/_0__25_)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT() AS `num`,FLOOR(LOG10(Mvir)/0.25) AS _FLOOR_LOG10_Mvir_/_0__25_ FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_58284850');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,`num`,_FLOOR_LOG10_Mvir_/_0__25_
FROM `aggregation_tmp_58284850`  GROUP BY ``  ;
CALL paquDropTmp('aggregation_tmp_58284850');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`num`,_FLOOR_LOG10_Mvir_/_0__25_

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=VALUES(`num`),
_FLOOR_LOG10_Mvir_/_0__25_=VALUES(_FLOOR_LOG10_Mvir_/_0__25_)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT() AS `num`,FLOOR(LOG10(Mvir)/0.25) AS _FLOOR_LOG10_Mvir_/_0__25_
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,`num`,_FLOOR_LOG10_Mvir_/_0__25_
FROM `aggregation_tmp_87058444`  GROUP BY ``  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=VALUES(`num`),
_FLOOR_LOG10_Mvir_/_0__25_=VALUES(_FLOOR_LOG10_Mvir_/_0__25_)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT() AS `num`,FLOOR(LOG10(Mvir)/0.25) AS _FLOOR_LOG10_Mvir_/_0__25_ FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_87058444');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,`num`,_FLOOR_LOG10_Mvir_/_0__25_
FROM `aggregation_tmp_87058444`  GROUP BY ``  ;
CALL paquDropTmp('aggregation_tmp_87058444');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`num`,_FLOOR_LOG10_Mvir_/_0__25_

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=VALUES(`num`),
_FLOOR_LOG10_Mvir_/_0__25_=VALUES(_FLOOR_LOG10_Mvir_/_0__25_)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT() AS `num`,FLOOR(LOG10(Mvir)/0.25) AS _FLOOR_LOG10_Mvir_/_0__25_
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,`num`,_FLOOR_LOG10_Mvir_/_0__25_
FROM `aggregation_tmp_93602249`  GROUP BY ``  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=VALUES(`num`),
_FLOOR_LOG10_Mvir_/_0__25_=VALUES(_FLOOR_LOG10_Mvir_/_0__25_)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT() AS `num`,FLOOR(LOG10(Mvir)/0.25) AS _FLOOR_LOG10_Mvir_/_0__25_ FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_93602249');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,`num`,_FLOOR_LOG10_Mvir_/_0__25_
FROM `aggregation_tmp_93602249`  GROUP BY ``  ;
CALL paquDropTmp('aggregation_tmp_93602249');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`num`,_FLOOR_LOG10_Mvir_/_0__25_

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=VALUES(`num`),
_FLOOR_LOG10_Mvir_/_0__25_=VALUES(_FLOOR_LOG10_Mvir_/_0__25_)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT() AS `num`,FLOOR(LOG10(Mvir)/0.25) AS _FLOOR_LOG10_Mvir_/_0__25_
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,`num`,_FLOOR_LOG10_Mvir_/_0__25_
FROM `aggregation_tmp_93365306`  GROUP BY ``  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=VALUES(`num`),
_FLOOR_LOG10_Mvir_/_0__25_=VALUES(_FLOOR_LOG10_Mvir_/_0__25_)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT() AS `num`,FLOOR(LOG10(Mvir)/0.25) AS _FLOOR_LOG10_Mvir_/_0__25_ FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_93365306');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,`num`,_FLOOR_LOG10_Mvir_/_0__25_
FROM `aggregation_tmp_93365306`  GROUP BY ``  ;
CALL paquDropTmp('aggregation_tmp_93365306');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`num`,_FLOOR_LOG10_Mvir_/_0__25_

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=VALUES(`num`),
_FLOOR_LOG10_Mvir_/_0__25_=VALUES(_FLOOR_LOG10_Mvir_/_0__25_)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT() AS `num`,FLOOR(LOG10(Mvir)/0.25) AS _FLOOR_LOG10_Mvir_/_0__25_
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,`num`,_FLOOR_LOG10_Mvir_/_0__25_
FROM `aggregation_tmp_86148962`  GROUP BY ``  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=VALUES(`num`),
_FLOOR_LOG10_Mvir_/_0__25_=VALUES(_FLOOR_LOG10_Mvir_/_0__25_)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT() AS `num`,FLOOR(LOG10(Mvir)/0.25) AS _FLOOR_LOG10_Mvir_/_0__25_ FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_86148962');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,`num`,_FLOOR_LOG10_Mvir_/_0__25_
FROM `aggregation_tmp_86148962`  GROUP BY ``  ;
CALL paquDropTmp('aggregation_tmp_86148962');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`num`,_FLOOR_LOG10_Mvir_/_0__25_

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=VALUES(`num`),
_FLOOR_LOG10_Mvir_/_0__25_=VALUES(_FLOOR_LOG10_Mvir_/_0__25_)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT() AS `num`,FLOOR(LOG10(Mvir)/0.25) AS _FLOOR_LOG10_Mvir_/_0__25_
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,`num`,_FLOOR_LOG10_Mvir_/_0__25_
FROM `aggregation_tmp_7689831`  GROUP BY ``  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=VALUES(`num`),
_FLOOR_LOG10_Mvir_/_0__25_=VALUES(_FLOOR_LOG10_Mvir_/_0__25_)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT() AS `num`,FLOOR(LOG10(Mvir)/0.25) AS _FLOOR_LOG10_Mvir_/_0__25_ FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_7689831');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,`num`,_FLOOR_LOG10_Mvir_/_0__25_
FROM `aggregation_tmp_7689831`  GROUP BY ``  ;
CALL paquDropTmp('aggregation_tmp_7689831');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`num`,_FLOOR_LOG10_Mvir_/_0__25_

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=VALUES(`num`),
_FLOOR_LOG10_Mvir_/_0__25_=VALUES(_FLOOR_LOG10_Mvir_/_0__25_)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT() AS `num`,FLOOR(LOG10(Mvir)/0.25) AS _FLOOR_LOG10_Mvir_/_0__25_
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,`num`,_FLOOR_LOG10_Mvir_/_0__25_
FROM `aggregation_tmp_21335411`  GROUP BY ``  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=VALUES(`num`),
_FLOOR_LOG10_Mvir_/_0__25_=VALUES(_FLOOR_LOG10_Mvir_/_0__25_)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT() AS `num`,FLOOR(LOG10(Mvir)/0.25) AS _FLOOR_LOG10_Mvir_/_0__25_ FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_21335411');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,`num`,_FLOOR_LOG10_Mvir_/_0__25_
FROM `aggregation_tmp_21335411`  GROUP BY ``  ;
CALL paquDropTmp('aggregation_tmp_21335411');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,``num``,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
``num``=VALUES(``num``),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT() AS ``num``,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,``num``,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_27217538`  GROUP BY ``  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
``num``=VALUES(``num``),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT() AS ``num``,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_27217538');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,``num``,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_27217538`  GROUP BY ``  ;
CALL paquDropTmp('aggregation_tmp_27217538');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,``num``,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
``num``=VALUES(``num``),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT() AS ``num``,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,``num``,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_96886064`  GROUP BY ``  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
``num``=VALUES(``num``),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT() AS ``num``,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_96886064');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,``num``,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_96886064`  GROUP BY ``  ;
CALL paquDropTmp('aggregation_tmp_96886064');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`num`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT() AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,`num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_94161313`  GROUP BY ``  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT() AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_94161313');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,`num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_94161313`  GROUP BY ``  ;
CALL paquDropTmp('aggregation_tmp_94161313');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`num`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT() AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,`num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_40150157`  GROUP BY ``  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT() AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_40150157');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,`num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_40150157`  GROUP BY ``  ;
CALL paquDropTmp('aggregation_tmp_40150157');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`num`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT() AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,`num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_34195994`  GROUP BY ``  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT() AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_34195994');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,`num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_34195994`  GROUP BY ``  ;
CALL paquDropTmp('aggregation_tmp_34195994');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`num`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT() AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,`num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_5323835`  GROUP BY ``  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT() AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_5323835');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,`num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_5323835`  GROUP BY ``  ;
CALL paquDropTmp('aggregation_tmp_5323835');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(COUNT) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_30794521`  GROUP BY ``  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(COUNT) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_30794521');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_30794521`  GROUP BY ``  ;
CALL paquDropTmp('aggregation_tmp_30794521');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(COUNT(*)) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_68152251`  GROUP BY ``  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(COUNT(*)) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_68152251');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_68152251`  GROUP BY ``  ;
CALL paquDropTmp('aggregation_tmp_68152251');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT() AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_76473218`  GROUP BY ``  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT() AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_76473218');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_76473218`  GROUP BY ``  ;
CALL paquDropTmp('aggregation_tmp_76473218');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_71560934`  GROUP BY ``  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_71560934');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_71560934`  GROUP BY ``  ;
CALL paquDropTmp('aggregation_tmp_71560934');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_88153248`  GROUP BY ``  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_88153248');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_88153248`  GROUP BY ``  ;
CALL paquDropTmp('aggregation_tmp_88153248');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_49112067`  GROUP BY ``  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_49112067');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_49112067`  GROUP BY ``  ;
CALL paquDropTmp('aggregation_tmp_49112067');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_50872032`  GROUP BY ``  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_50872032');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_50872032`  GROUP BY ``  ;
CALL paquDropTmp('aggregation_tmp_50872032');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_52180242`  GROUP BY ``  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_52180242');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_52180242`  GROUP BY ``  ;
CALL paquDropTmp('aggregation_tmp_52180242');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_55062584`  GROUP BY ``  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_55062584');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_55062584`  GROUP BY ``  ;
CALL paquDropTmp('aggregation_tmp_55062584');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_22499134`  GROUP BY ``  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_22499134');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_22499134`  GROUP BY ``  ;
CALL paquDropTmp('aggregation_tmp_22499134');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass``log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_8178298`  GROUP BY ``  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_8178298');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass``log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_8178298`  GROUP BY ``  ;
CALL paquDropTmp('aggregation_tmp_8178298');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass``log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_30962179`  GROUP BY ``  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_30962179');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass``log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_30962179`  GROUP BY ``  ;
CALL paquDropTmp('aggregation_tmp_30962179');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_24605481`  GROUP BY ``  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_24605481');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_24605481`  GROUP BY ``  ;
CALL paquDropTmp('aggregation_tmp_24605481');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass``log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_53312259`  GROUP BY ``  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_53312259');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass``log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_53312259`  GROUP BY ``  ;
CALL paquDropTmp('aggregation_tmp_53312259');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass``log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_94549089`  GROUP BY ``  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_94549089');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass``log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_94549089`  GROUP BY ``  ;
CALL paquDropTmp('aggregation_tmp_94549089');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass``log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_52778166`  GROUP BY ``  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_52778166');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass``log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_52778166`  GROUP BY ``  ;
CALL paquDropTmp('aggregation_tmp_52778166');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass``log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_53672391`  GROUP BY ``  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_53672391');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass``log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_53672391`  GROUP BY ``  ;
CALL paquDropTmp('aggregation_tmp_53672391');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass``log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_24050743`  GROUP BY ``  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_24050743');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass``log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_24050743`  GROUP BY ``  ;
CALL paquDropTmp('aggregation_tmp_24050743');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass``log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_12243597`  GROUP BY ``  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_12243597');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass``log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_12243597`  GROUP BY ``  ;
CALL paquDropTmp('aggregation_tmp_12243597');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_6118575`  GROUP BY ``  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_6118575');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_6118575`  GROUP BY ``  ;
CALL paquDropTmp('aggregation_tmp_6118575');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_77152568`  GROUP BY ``  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`_FLOOR_LOG10_Mvir_/_0__25_`=VALUES(`_FLOOR_LOG10_Mvir_/_0__25_`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_77152568');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`,`_FLOOR_LOG10_Mvir_/_0__25_`
FROM `aggregation_tmp_77152568`  GROUP BY ``  ;
CALL paquDropTmp('aggregation_tmp_77152568');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_43641822`  GROUP BY ``  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_43641822');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_43641822`  GROUP BY ``  ;
CALL paquDropTmp('aggregation_tmp_43641822');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_68999333`  GROUP BY   
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_68999333');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_68999333`  GROUP BY   ;
CALL paquDropTmp('aggregation_tmp_68999333');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_14877813`  GROUP BY   
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_14877813');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_14877813`  GROUP BY   ;
CALL paquDropTmp('aggregation_tmp_14877813');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_50324034`  GROUP BY `_FLOOR_LOG10_Mvir_/_0__25_`  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_50324034');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_50324034`  GROUP BY `_FLOOR_LOG10_Mvir_/_0__25_`  ;
CALL paquDropTmp('aggregation_tmp_50324034');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_5441365`  GROUP BY `_FLOOR_LOG10_Mvir_/_0__25_`  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_5441365');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_5441365`  GROUP BY `_FLOOR_LOG10_Mvir_/_0__25_`  ;
CALL paquDropTmp('aggregation_tmp_5441365');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_49998920`  GROUP BY `_FLOOR_LOG10_Mvir_/_0__25_`  
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_49998920');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_49998920`  GROUP BY `_FLOOR_LOG10_Mvir_/_0__25_`  ;
CALL paquDropTmp('aggregation_tmp_49998920');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_11605524`  GROUP BY `_FLOOR_LOG10_Mvir_/_0__25_` ORDER BY `FLOOR(LOG10(Mvir)/0.25)` ASC 
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_11605524');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_11605524`  GROUP BY `_FLOOR_LOG10_Mvir_/_0__25_` ORDER BY `FLOOR(LOG10(Mvir)/0.25)` ASC ;
CALL paquDropTmp('aggregation_tmp_11605524');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_82656814`  GROUP BY `_FLOOR_LOG10_Mvir_/_0__25_` ORDER BY `_FLOOR_LOG10_Mvir_/_0__25_` ASC 
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_82656814');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_82656814`  GROUP BY `_FLOOR_LOG10_Mvir_/_0__25_` ORDER BY `_FLOOR_LOG10_Mvir_/_0__25_` ASC ;
CALL paquDropTmp('aggregation_tmp_82656814');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`
FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `.` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`
FROM `aggregation_tmp_6031244`  ORDER BY `.` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolf__bdmProfileId`=VALUES(`Bolf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId`
FROM `aggregation_tmp_6031244`  ORDER BY `.` DESC  LIMIT 0,1)    
)


-- AGGREGATION SQL:
SELECT `Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_84456740`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolf__bdmProfileId`=VALUES(`Bolf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId` FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `.` DESC  LIMIT 0,1', 'aggregation_tmp_6031244');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId` FROM `aggregation_tmp_6031244`  ORDER BY `.` DESC  LIMIT 0,1)    ', 'aggregation_tmp_84456740');
CALL paquDropTmp('aggregation_tmp_6031244');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_84456740`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_84456740');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`,
FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `BDMV.Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`,
FROM `aggregation_tmp_68219502`  ORDER BY `BDMV.Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolf__bdmProfileId`=VALUES(`Bolf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId`,
FROM `aggregation_tmp_68219502`  ORDER BY `BDMV.Mvir` DESC  LIMIT 0,1)    
)


-- AGGREGATION SQL:
SELECT `Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_47048286`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolf__bdmProfileId`=VALUES(`Bolf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId`, FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `BDMV.Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_68219502');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId`, FROM `aggregation_tmp_68219502`  ORDER BY `BDMV.Mvir` DESC  LIMIT 0,1)    ', 'aggregation_tmp_47048286');
CALL paquDropTmp('aggregation_tmp_68219502');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_47048286`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_47048286');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`,
FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY ``BDMV`.Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`,
FROM `aggregation_tmp_64481521`  ORDER BY ``BDMV`.Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolf__bdmProfileId`=VALUES(`Bolf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId`,
FROM `aggregation_tmp_64481521`  ORDER BY ``BDMV`.Mvir` DESC  LIMIT 0,1)    
)


-- AGGREGATION SQL:
SELECT `Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_17313611`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolf__bdmProfileId`=VALUES(`Bolf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId`, FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY ``BDMV`.Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_64481521');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId`, FROM `aggregation_tmp_64481521`  ORDER BY ``BDMV`.Mvir` DESC  LIMIT 0,1)    ', 'aggregation_tmp_17313611');
CALL paquDropTmp('aggregation_tmp_64481521');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_17313611`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_17313611');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`,
FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`,
FROM `aggregation_tmp_67079583`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolf__bdmProfileId`=VALUES(`Bolf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId`,
FROM `aggregation_tmp_67079583`  ORDER BY `Mvir` DESC  LIMIT 0,1)    
)


-- AGGREGATION SQL:
SELECT `Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_3978959`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolf__bdmProfileId`=VALUES(`Bolf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId`, FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_67079583');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId`, FROM `aggregation_tmp_67079583`  ORDER BY `Mvir` DESC  LIMIT 0,1)    ', 'aggregation_tmp_3978959');
CALL paquDropTmp('aggregation_tmp_67079583');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_3978959`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_3978959');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`),
`Mvir`=VALUES(`Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`,`Mvir`
FROM `aggregation_tmp_50130`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`),
`Mvir`=VALUES(`Mvir`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolf__bdmProfileId`=VALUES(`Bolf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId`,`Mvir`
FROM `aggregation_tmp_50130`  ORDER BY `Mvir` DESC  LIMIT 0,1)    
)


-- AGGREGATION SQL:
SELECT `Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_33260406`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolf__bdmProfileId`=VALUES(`Bolf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_50130');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId`,`Mvir` FROM `aggregation_tmp_50130`  ORDER BY `Mvir` DESC  LIMIT 0,1)    ', 'aggregation_tmp_33260406');
CALL paquDropTmp('aggregation_tmp_50130');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_33260406`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_33260406');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`),
`Mvir`=VALUES(`Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`,`Mvir`
FROM `aggregation_tmp_21136754`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`),
`Mvir`=VALUES(`Mvir`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolf__bdmProfileId`=VALUES(`Bolf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId`,`Mvir`
FROM `aggregation_tmp_21136754`  ORDER BY `Mvir` DESC  LIMIT 0,1)    
)


-- AGGREGATION SQL:
SELECT `Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_91103179`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolf__bdmProfileId`=VALUES(`Bolf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_21136754');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId`,`Mvir` FROM `aggregation_tmp_21136754`  ORDER BY `Mvir` DESC  LIMIT 0,1)    ', 'aggregation_tmp_91103179');
CALL paquDropTmp('aggregation_tmp_21136754');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_91103179`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_91103179');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`
FROM `aggregation_tmp_50360200`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolf__bdmProfileId`=VALUES(`Bolf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId`
FROM `aggregation_tmp_50360200`  ORDER BY `Mvir` DESC  LIMIT 0,1)    
)


-- AGGREGATION SQL:
SELECT `Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_28794285`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolf__bdmProfileId`=VALUES(`Bolf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_50360200');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId` FROM `aggregation_tmp_50360200`  ORDER BY `Mvir` DESC  LIMIT 0,1)    ', 'aggregation_tmp_28794285');
CALL paquDropTmp('aggregation_tmp_50360200');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_28794285`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_28794285');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`
FROM `aggregation_tmp_58738663`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolf__bdmProfileId`=VALUES(`Bolf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId`
FROM `aggregation_tmp_58738663`  ORDER BY `Mvir` DESC  LIMIT 0,1)    
)


-- AGGREGATION SQL:
SELECT `Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_57001481`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolf__bdmProfileId`=VALUES(`Bolf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_58738663');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId` FROM `aggregation_tmp_58738663`  ORDER BY `Mvir` DESC  LIMIT 0,1)    ', 'aggregation_tmp_57001481');
CALL paquDropTmp('aggregation_tmp_58738663');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_57001481`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_57001481');
This is the query plan optimisation output for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z`
FROM MDR1.FOF AS `f` 
)


-- AGGREGATION SQL:
SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_57719185`   
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
-- INPUT SQL:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,`f`.`f.x` AS `f.x`,`f`.`f.y` AS `f.y`,`f`.`f.z` AS `f.z`
FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_57719185`   ) AS `f`  WHERE (  POWER( b.x - `f`.`f.x` 2 ) < 1000 )    LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_63337778`    LIMIT 0,1
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
This is the query plan for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

CALL paquExec('SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z` FROM MDR1.FOF AS `f` ', 'aggregation_tmp_57719185');
CALL paquExec('SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,`f`.`f.x` AS `f.x`,`f`.`f.y` AS `f.y`,`f`.`f.z` AS `f.z` FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z` FROM `aggregation_tmp_57719185`   ) AS `f`  WHERE (  POWER( b.x - `f`.`f.x` 2 ) < 1000 )    LIMIT 0,1', 'aggregation_tmp_63337778');
CALL paquDropTmp('aggregation_tmp_57719185');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_63337778`    LIMIT 0,1;
CALL paquDropTmp('aggregation_tmp_63337778');
This is the query plan optimisation output for the query:
select (MDR1.FOF.x+`a.b`.y+z) from MDR1.FOF as `a.b` limit 10

-- INPUT SQL:
select (MDR1.FOF.x+`a.b`.y+z) from MDR1.FOF as `a.b` limit 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
``

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
``=VALUES(``)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT (MDR1.FOF.x+`a.b`.y+z) AS ``
FROM MDR1.FOF AS ``a.b``  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT ``
FROM `aggregation_tmp_33938042`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
``=VALUES(``)
This is the query plan for the query:
select (MDR1.FOF.x+`a.b`.y+z) from MDR1.FOF as `a.b` limit 10

CALL paquExec('SELECT (MDR1.FOF.x+`a.b`.y+z) AS `` FROM MDR1.FOF AS ``a.b``  LIMIT 0,10', 'aggregation_tmp_33938042');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT ``
FROM `aggregation_tmp_33938042`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_33938042');
This is the query plan optimisation output for the query:
select (MDR1.FOF.x+`a.b`.y+z) from MDR1.FOF as `a.b` limit 10

-- INPUT SQL:
select (MDR1.FOF.x+`a.b`.y+z) from MDR1.FOF as `a.b` limit 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_`a__b`__y_+_z_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_`a__b`__y_+_z_`=VALUES(`_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_`a__b`__y_+_z_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT (MDR1.FOF.x+`a.b`.y+z) AS `_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_`a__b`__y_+_z_`
FROM MDR1.FOF AS ``a.b``  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_`a__b`__y_+_z_`
FROM `aggregation_tmp_2747956`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_`a__b`__y_+_z_`=VALUES(`_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_`a__b`__y_+_z_`)
This is the query plan for the query:
select (MDR1.FOF.x+`a.b`.y+z) from MDR1.FOF as `a.b` limit 10

CALL paquExec('SELECT (MDR1.FOF.x+`a.b`.y+z) AS `_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_`a__b`__y_+_z_` FROM MDR1.FOF AS ``a.b``  LIMIT 0,10', 'aggregation_tmp_2747956');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_`a__b`__y_+_z_`
FROM `aggregation_tmp_2747956`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_2747956');
This is the query plan optimisation output for the query:
select (MDR1.FOF.x+`a.b`.y+z) from MDR1.FOF as `a.b` limit 10

-- INPUT SQL:
select (MDR1.FOF.x+`a.b`.y+z) from MDR1.FOF as `a.b` limit 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_-a__b-__y_+_z_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_-a__b-__y_+_z_`=VALUES(`_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_-a__b-__y_+_z_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT (MDR1.FOF.x+`a.b`.y+z) AS `_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_-a__b-__y_+_z_`
FROM MDR1.FOF AS ``a.b``  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_-a__b-__y_+_z_`
FROM `aggregation_tmp_9564953`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_-a__b-__y_+_z_`=VALUES(`_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_-a__b-__y_+_z_`)
This is the query plan for the query:
select (MDR1.FOF.x+`a.b`.y+z) from MDR1.FOF as `a.b` limit 10

CALL paquExec('SELECT (MDR1.FOF.x+`a.b`.y+z) AS `_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_-a__b-__y_+_z_` FROM MDR1.FOF AS ``a.b``  LIMIT 0,10', 'aggregation_tmp_9564953');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_-a__b-__y_+_z_`
FROM `aggregation_tmp_9564953`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_9564953');
This is the query plan optimisation output for the query:
select (MDR1.FOF.x+`a.b`.y+z) from MDR1.FOF as `a.b` limit 10

-- INPUT SQL:
select (MDR1.FOF.x+`a.b`.y+z) from MDR1.FOF as `a.b` limit 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_'a__b'__y_+_z_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_'a__b'__y_+_z_`=VALUES(`_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_'a__b'__y_+_z_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT (MDR1.FOF.x+`a.b`.y+z) AS `_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_'a__b'__y_+_z_`
FROM MDR1.FOF AS ``a.b``  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_'a__b'__y_+_z_`
FROM `aggregation_tmp_13367443`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_'a__b'__y_+_z_`=VALUES(`_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_'a__b'__y_+_z_`)
This is the query plan for the query:
select (MDR1.FOF.x+`a.b`.y+z) from MDR1.FOF as `a.b` limit 10

CALL paquExec('SELECT (MDR1.FOF.x+`a.b`.y+z) AS `_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_\'a__b\'__y_+_z_` FROM MDR1.FOF AS ``a.b``  LIMIT 0,10', 'aggregation_tmp_13367443');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_'a__b'__y_+_z_`
FROM `aggregation_tmp_13367443`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_13367443');
This is the query plan optimisation output for the query:
select (MDR1.FOF.x+`a.b`.y+z) from MDR1.FOF as `a.b` limit 10

-- INPUT SQL:
select (MDR1.FOF.x+`a.b`.y+z) from MDR1.FOF as `a.b` limit 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_a__b__y_+_z_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_a__b__y_+_z_`=VALUES(`_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_a__b__y_+_z_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT (MDR1.FOF.x+`a.b`.y+z) AS `_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_a__b__y_+_z_`
FROM MDR1.FOF AS ``a.b``  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_a__b__y_+_z_`
FROM `aggregation_tmp_68780518`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_a__b__y_+_z_`=VALUES(`_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_a__b__y_+_z_`)
This is the query plan for the query:
select (MDR1.FOF.x+`a.b`.y+z) from MDR1.FOF as `a.b` limit 10

CALL paquExec('SELECT (MDR1.FOF.x+`a.b`.y+z) AS `_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_a__b__y_+_z_` FROM MDR1.FOF AS ``a.b``  LIMIT 0,10', 'aggregation_tmp_68780518');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_a__b__y_+_z_`
FROM `aggregation_tmp_68780518`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_68780518');
This is the query plan optimisation output for the query:
select (MDR1.FOF.x+`a.b`.y+z) from MDR1.FOF as `a.b` limit 10

-- INPUT SQL:
select (MDR1.FOF.x+`a.b`.y+z) from MDR1.FOF as `a.b` limit 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_a__b__y_+_z_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_a__b__y_+_z_`=VALUES(`_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_a__b__y_+_z_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT (MDR1.FOF.x+`a.b`.y+z) AS `_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_a__b__y_+_z_`
FROM MDR1.FOF AS ``a.b``  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_a__b__y_+_z_`
FROM `aggregation_tmp_47486744`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_a__b__y_+_z_`=VALUES(`_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_a__b__y_+_z_`)
This is the query plan for the query:
select (MDR1.FOF.x+`a.b`.y+z) from MDR1.FOF as `a.b` limit 10

CALL paquExec('SELECT (MDR1.FOF.x+`a.b`.y+z) AS `_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_a__b__y_+_z_` FROM MDR1.FOF AS ``a.b``  LIMIT 0,10', 'aggregation_tmp_47486744');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_(MDR1.FOF.x+`a.b`.y+z)_MDR1__FOF__x_+_a__b__y_+_z_`
FROM `aggregation_tmp_47486744`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_47486744');
This is the query plan optimisation output for the query:
select (MDR1.FOF.x+`a.b`.y+z) from MDR1.FOF as `a.b` limit 10

-- INPUT SQL:
select (MDR1.FOF.x+`a.b`.y+z) from MDR1.FOF as `a.b` limit 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_MDR1__FOF__x_+_a__b__y_+_z_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_MDR1__FOF__x_+_a__b__y_+_z_`=VALUES(`_MDR1__FOF__x_+_a__b__y_+_z_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT (MDR1.FOF.x+`a.b`.y+z) AS `_MDR1__FOF__x_+_a__b__y_+_z_`
FROM MDR1.FOF AS ``a.b``  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_MDR1__FOF__x_+_a__b__y_+_z_`
FROM `aggregation_tmp_62837685`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_MDR1__FOF__x_+_a__b__y_+_z_`=VALUES(`_MDR1__FOF__x_+_a__b__y_+_z_`)
This is the query plan for the query:
select (MDR1.FOF.x+`a.b`.y+z) from MDR1.FOF as `a.b` limit 10

CALL paquExec('SELECT (MDR1.FOF.x+`a.b`.y+z) AS `_MDR1__FOF__x_+_a__b__y_+_z_` FROM MDR1.FOF AS ``a.b``  LIMIT 0,10', 'aggregation_tmp_62837685');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_MDR1__FOF__x_+_a__b__y_+_z_`
FROM `aggregation_tmp_62837685`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_62837685');
This is the query plan optimisation output for the query:
select (MDR1.FOF.x+`a.b`.y+z) from MDR1.FOF as `a.b` limit 10

-- INPUT SQL:
select (MDR1.FOF.x+`a.b`.y+z) from MDR1.FOF as `a.b` limit 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_MDR1__FOF__x_+_a__b__y_+_z_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_MDR1__FOF__x_+_a__b__y_+_z_`=VALUES(`_MDR1__FOF__x_+_a__b__y_+_z_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT (MDR1.FOF.x+`a.b`.y+z) AS `_MDR1__FOF__x_+_a__b__y_+_z_`
FROM MDR1.FOF AS ``a.b``  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_MDR1__FOF__x_+_a__b__y_+_z_`
FROM `aggregation_tmp_472624`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_MDR1__FOF__x_+_a__b__y_+_z_`=VALUES(`_MDR1__FOF__x_+_a__b__y_+_z_`)
This is the query plan for the query:
select (MDR1.FOF.x+`a.b`.y+z) from MDR1.FOF as `a.b` limit 10

CALL paquExec('SELECT (MDR1.FOF.x+`a.b`.y+z) AS `_MDR1__FOF__x_+_a__b__y_+_z_` FROM MDR1.FOF AS ``a.b``  LIMIT 0,10', 'aggregation_tmp_472624');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_MDR1__FOF__x_+_a__b__y_+_z_`
FROM `aggregation_tmp_472624`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_472624');
This is the query plan optimisation output for the query:
select (MDR1.FOF.x+`a.b`.y+z) from MDR1.FOF as `a.b` limit 10

-- INPUT SQL:
select (MDR1.FOF.x+`a.b`.y+z) from MDR1.FOF as `a.b` limit 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_MDR1__FOF__x_+_a__b__y_+_z_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_MDR1__FOF__x_+_a__b__y_+_z_`=VALUES(`_MDR1__FOF__x_+_a__b__y_+_z_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT (MDR1.FOF.x+`a.b`.y+z) AS `_MDR1__FOF__x_+_a__b__y_+_z_`
FROM MDR1.FOF AS ``  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_MDR1__FOF__x_+_a__b__y_+_z_`
FROM `aggregation_tmp_44985744`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_MDR1__FOF__x_+_a__b__y_+_z_`=VALUES(`_MDR1__FOF__x_+_a__b__y_+_z_`)
This is the query plan for the query:
select (MDR1.FOF.x+`a.b`.y+z) from MDR1.FOF as `a.b` limit 10

CALL paquExec('SELECT (MDR1.FOF.x+`a.b`.y+z) AS `_MDR1__FOF__x_+_a__b__y_+_z_` FROM MDR1.FOF AS ``  LIMIT 0,10', 'aggregation_tmp_44985744');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_MDR1__FOF__x_+_a__b__y_+_z_`
FROM `aggregation_tmp_44985744`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_44985744');
This is the query plan optimisation output for the query:
select (x+y) from MDR1.FOF limit 10

-- INPUT SQL:
select (x+y) from MDR1.FOF limit 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_x_+_y_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_x_+_y_`=VALUES(`_x_+_y_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT (x+y) AS `_x_+_y_`
FROM MDR1.FOF  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_x_+_y_`
FROM `aggregation_tmp_38817113`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_x_+_y_`=VALUES(`_x_+_y_`)
This is the query plan for the query:
select (x+y) from MDR1.FOF limit 10

CALL paquExec('SELECT (x+y) AS `_x_+_y_` FROM MDR1.FOF  LIMIT 0,10', 'aggregation_tmp_38817113');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_x_+_y_`
FROM `aggregation_tmp_38817113`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_38817113');
This is the query plan optimisation output for the query:
select (x+y) from MDR1.FOF limit 10

-- INPUT SQL:
select (x+y) from MDR1.FOF limit 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_x_+_y_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_x_+_y_`=VALUES(`_x_+_y_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT (x+y) AS `_x_+_y_`
FROM MDR1.FOF  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_x_+_y_`
FROM `aggregation_tmp_40589278`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_x_+_y_`=VALUES(`_x_+_y_`)
This is the query plan for the query:
select (x+y) from MDR1.FOF limit 10

CALL paquExec('SELECT (x+y) AS `_x_+_y_` FROM MDR1.FOF  LIMIT 0,10', 'aggregation_tmp_40589278');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_x_+_y_`
FROM `aggregation_tmp_40589278`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_40589278');
This is the query plan optimisation output for the query:
select rand(3) as  from MDR1.Particles62 limit 100

-- INPUT SQL:
select rand(3) as  from MDR1.Particles62 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_rand_3_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_rand_3_`=VALUES(`_rand_3_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT rand(3) AS `_rand_3_`
FROM MDR1.Particles62  LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `_rand_3_`
FROM `aggregation_tmp_88244126`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`_rand_3_`=VALUES(`_rand_3_`)
This is the query plan for the query:
select rand(3) as  from MDR1.Particles62 limit 100

CALL paquExec('SELECT rand(3) AS `_rand_3_` FROM MDR1.Particles62  LIMIT 0,100', 'aggregation_tmp_88244126');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_rand_3_`
FROM `aggregation_tmp_88244126`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_88244126');
This is the query plan optimisation output for the query:
select rand(3) as  from MDR1.Particles62 limit 100

-- INPUT SQL:
select rand(3) as  from MDR1.Particles62 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_rand_3_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_rand_3_`=VALUES(`_rand_3_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT rand(3) AS `_rand_3_`
FROM MDR1.Particles62  LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `_rand_3_`
FROM `aggregation_tmp_12117364`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`_rand_3_`=VALUES(`_rand_3_`)
This is the query plan for the query:
select rand(3) as  from MDR1.Particles62 limit 100

CALL paquExec('SELECT rand(3) AS `_rand_3_` FROM MDR1.Particles62  LIMIT 0,100', 'aggregation_tmp_12117364');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_rand_3_`
FROM `aggregation_tmp_12117364`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_12117364');
This is the query plan optimisation output for the query:
select rand(3) as `random` from MDR1.Particles62 limit 100

-- INPUT SQL:
select rand(3) as `random` from MDR1.Particles62 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
``random``

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
``random``=VALUES(``random``)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT rand(3) AS ``random``
FROM MDR1.Particles62  LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT ``random``
FROM `aggregation_tmp_98782080`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
``random``=VALUES(``random``)
This is the query plan for the query:
select rand(3) as `random` from MDR1.Particles62 limit 100

CALL paquExec('SELECT rand(3) AS ``random`` FROM MDR1.Particles62  LIMIT 0,100', 'aggregation_tmp_98782080');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT ``random``
FROM `aggregation_tmp_98782080`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_98782080');
This is the query plan optimisation output for the query:
select rand(3) as `random` from MDR1.Particles62 limit 100

-- INPUT SQL:
select rand(3) as `random` from MDR1.Particles62 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_rand_3_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_rand_3_`=VALUES(`_rand_3_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT rand(3) AS `_rand_3_`
FROM MDR1.Particles62  LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `_rand_3_`
FROM `aggregation_tmp_41539228`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`_rand_3_`=VALUES(`_rand_3_`)
This is the query plan for the query:
select rand(3) as `random` from MDR1.Particles62 limit 100

CALL paquExec('SELECT rand(3) AS `_rand_3_` FROM MDR1.Particles62  LIMIT 0,100', 'aggregation_tmp_41539228');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_rand_3_`
FROM `aggregation_tmp_41539228`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_41539228');
This is the query plan optimisation output for the query:
select rand(3) as `random` from MDR1.Particles62 limit 100

-- INPUT SQL:
select rand(3) as `random` from MDR1.Particles62 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_rand_3_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_rand_3_`=VALUES(`_rand_3_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT rand(3) AS `_rand_3_`
FROM MDR1.Particles62  LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `_rand_3_`
FROM `aggregation_tmp_67308207`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`_rand_3_`=VALUES(`_rand_3_`)
This is the query plan for the query:
select rand(3) as `random` from MDR1.Particles62 limit 100

CALL paquExec('SELECT rand(3) AS `_rand_3_` FROM MDR1.Particles62  LIMIT 0,100', 'aggregation_tmp_67308207');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_rand_3_`
FROM `aggregation_tmp_67308207`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_67308207');
This is the query plan optimisation output for the query:
select rand(3) as `random` from MDR1.Particles62 limit 100

-- INPUT SQL:
select rand(3) as `random` from MDR1.Particles62 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`random`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`random`=VALUES(`random`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT rand(3) AS `random`
FROM MDR1.Particles62  LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `random`
FROM `aggregation_tmp_5843633`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`random`=VALUES(`random`)
This is the query plan for the query:
select rand(3) as `random` from MDR1.Particles62 limit 100

CALL paquExec('SELECT rand(3) AS `random` FROM MDR1.Particles62  LIMIT 0,100', 'aggregation_tmp_5843633');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `random`
FROM `aggregation_tmp_5843633`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_5843633');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS ``` WHERE (  descend.fofTreeId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_19572448`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS ``` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_19572448`   ) AS ```  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_8605087`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS ``` WHERE (  descend.fofTreeId = 85000000000 )   ', 'aggregation_tmp_19572448');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS ``` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_19572448`   ) AS ```  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_8605087');
CALL paquDropTmp('aggregation_tmp_19572448');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_8605087`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_8605087');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS ``` WHERE (  descend.fofTreeId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_48113453`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS ``` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_48113453`   ) AS ```  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_3118736`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS ``` WHERE (  descend.fofTreeId = 85000000000 )   ', 'aggregation_tmp_48113453');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS ``` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_48113453`   ) AS ```  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_3118736');
CALL paquDropTmp('aggregation_tmp_48113453');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_3118736`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_3118736');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS ``` WHERE (  descend.fofTreeId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_76761767`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS ``` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_76761767`   ) AS ```  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_34867242`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS ``` WHERE (  descend.fofTreeId = 85000000000 )   ', 'aggregation_tmp_76761767');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS ``` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_76761767`   ) AS ```  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_34867242');
CALL paquDropTmp('aggregation_tmp_76761767');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_34867242`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_34867242');
This is the query plan optimisation output for the query:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_7465085`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog__fofTreeId`=VALUES(`prog__fofTreeId`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.fofTreeId AS `prog__fofTreeId`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_7465085`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_48086633`  ORDER BY ``prog__fofTreeId`` ASC 
ON DUPLICATE KEY UPDATE
`prog__fofTreeId`=VALUES(`prog__fofTreeId`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)
This is the query plan for the query:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   ', 'aggregation_tmp_7465085');
CALL paquExec('SELECT `prog`.fofTreeId AS `prog__fofTreeId`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_7465085`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_48086633');
CALL paquDropTmp('aggregation_tmp_7465085');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_48086633`  ORDER BY ``prog__fofTreeId`` ASC ;
CALL paquDropTmp('aggregation_tmp_48086633');
This is the query plan optimisation output for the query:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_94869925`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog__fofTreeId`=VALUES(`prog__fofTreeId`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.fofTreeId AS `prog__fofTreeId`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_94869925`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_82864236`  ORDER BY ``prog__fofTreeId`` ASC 
ON DUPLICATE KEY UPDATE
`prog__fofTreeId`=VALUES(`prog__fofTreeId`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)
This is the query plan for the query:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   ', 'aggregation_tmp_94869925');
CALL paquExec('SELECT `prog`.fofTreeId AS `prog__fofTreeId`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_94869925`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_82864236');
CALL paquDropTmp('aggregation_tmp_94869925');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_82864236`  ORDER BY ``prog__fofTreeId`` ASC ;
CALL paquDropTmp('aggregation_tmp_82864236');
This is the query plan optimisation output for the query:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_99127033`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog__fofTreeId`=VALUES(`prog__fofTreeId`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.fofTreeId AS `prog__fofTreeId`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_99127033`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_64206229`  ORDER BY `prog__fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog__fofTreeId`=VALUES(`prog__fofTreeId`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)
This is the query plan for the query:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   ', 'aggregation_tmp_99127033');
CALL paquExec('SELECT `prog`.fofTreeId AS `prog__fofTreeId`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_99127033`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_64206229');
CALL paquDropTmp('aggregation_tmp_99127033');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_64206229`  ORDER BY `prog__fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_64206229');
This is the query plan optimisation output for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

-- INPUT SQL:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`,`mass`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`mass`=VALUES(`mass`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,mass AS `mass`
FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `*`,`mass`
FROM `aggregation_tmp_95676970`  ORDER BY `mass` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`mass`=VALUES(`mass`)
This is the query plan for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

CALL paquExec('SELECT * AS `*`,mass AS `mass` FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10', 'aggregation_tmp_95676970');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`,`mass`
FROM `aggregation_tmp_95676970`  ORDER BY `mass` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_95676970');
This is the query plan optimisation output for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

-- INPUT SQL:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`,`mass`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`mass`=VALUES(`mass`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,mass AS `mass`
FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `*`,`mass`
FROM `aggregation_tmp_38024501`  ORDER BY `mass` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`mass`=VALUES(`mass`)
This is the query plan for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

CALL paquExec('SELECT * AS `*`,mass AS `mass` FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10', 'aggregation_tmp_38024501');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`,`mass`
FROM `aggregation_tmp_38024501`  ORDER BY `mass` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_38024501');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`FLOOR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR AS `FLOOR`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_30253347`  GROUP BY `FLOOR` ORDER BY `FLOOR` ASC 
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR AS `FLOOR` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR  ', 'aggregation_tmp_30253347');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_30253347`  GROUP BY `FLOOR` ORDER BY `FLOOR` ASC ;
CALL paquDropTmp('aggregation_tmp_30253347');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`FLOOR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR AS `FLOOR`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_23555162`  GROUP BY `FLOOR` ORDER BY `FLOOR` ASC 
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR AS `FLOOR` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR  ', 'aggregation_tmp_23555162');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_23555162`  GROUP BY `FLOOR` ORDER BY `FLOOR` ASC ;
CALL paquDropTmp('aggregation_tmp_23555162');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10(Mvir)/0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25LOG10(Mvir)/0.25) AS `_FLOOR_LOG10(Mvir)/0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_89057779`  GROUP BY `FLOOR` ORDER BY `FLOOR` ASC 
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25LOG10(Mvir)/0.25) AS `_FLOOR_LOG10(Mvir)/0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR  ', 'aggregation_tmp_89057779');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_89057779`  GROUP BY `FLOOR` ORDER BY `FLOOR` ASC ;
CALL paquDropTmp('aggregation_tmp_89057779');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10(Mvir)/0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25LOG10(Mvir)/0.25) AS `_FLOOR_LOG10(Mvir)/0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_36703962`  GROUP BY `FLOOR` ORDER BY `FLOOR` ASC 
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25LOG10(Mvir)/0.25) AS `_FLOOR_LOG10(Mvir)/0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR  ', 'aggregation_tmp_36703962');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_36703962`  GROUP BY `FLOOR` ORDER BY `FLOOR` ASC ;
CALL paquDropTmp('aggregation_tmp_36703962');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10(Mvir)/0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25LOG10(Mvir)/0.25) AS `_FLOOR_LOG10(Mvir)/0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_9389259`  GROUP BY `FLOOR` ORDER BY `FLOOR` ASC 
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25LOG10(Mvir)/0.25) AS `_FLOOR_LOG10(Mvir)/0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR  ', 'aggregation_tmp_9389259');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_9389259`  GROUP BY `FLOOR` ORDER BY `FLOOR` ASC ;
CALL paquDropTmp('aggregation_tmp_9389259');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10(Mvir)/0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10(Mvir)/0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_42923180`  GROUP BY `FLOOR` ORDER BY `FLOOR` ASC 
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10(Mvir)/0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR  ', 'aggregation_tmp_42923180');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_42923180`  GROUP BY `FLOOR` ORDER BY `FLOOR` ASC ;
CALL paquDropTmp('aggregation_tmp_42923180');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10(Mvir)/0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10(Mvir)/0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_19596886`  GROUP BY `FLOOR` ORDER BY `FLOOR` ASC 
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10(Mvir)/0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR  ', 'aggregation_tmp_19596886');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_19596886`  GROUP BY `FLOOR` ORDER BY `FLOOR` ASC ;
CALL paquDropTmp('aggregation_tmp_19596886');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10(Mvir)/0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10(Mvir)/0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_99374414`  GROUP BY `FLOOR` ORDER BY `FLOOR` ASC 
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10(Mvir)/0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR  ', 'aggregation_tmp_99374414');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_99374414`  GROUP BY `FLOOR` ORDER BY `FLOOR` ASC ;
CALL paquDropTmp('aggregation_tmp_99374414');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10(Mvir)/0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10(Mvir)/0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_1908417`  GROUP BY `FLOOR` ORDER BY `FLOOR` ASC 
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10(Mvir)/0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR  ', 'aggregation_tmp_1908417');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_1908417`  GROUP BY `FLOOR` ORDER BY `FLOOR` ASC ;
CALL paquDropTmp('aggregation_tmp_1908417');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10(Mvir)/0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10(Mvir)/0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_43837139`  GROUP BY `FLOOR` ORDER BY `FLOOR` ASC 
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10(Mvir)/0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR  ', 'aggregation_tmp_43837139');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_43837139`  GROUP BY `FLOOR` ORDER BY `FLOOR` ASC ;
CALL paquDropTmp('aggregation_tmp_43837139');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10(Mvir)/0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10(Mvir)/0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_58796980`  GROUP BY `FLOOR` ORDER BY `FLOOR` ASC 
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10(Mvir)/0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR  ', 'aggregation_tmp_58796980');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_58796980`  GROUP BY `FLOOR` ORDER BY `FLOOR` ASC ;
CALL paquDropTmp('aggregation_tmp_58796980');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_72140135`  GROUP BY `FLOOR` ORDER BY `FLOOR` ASC 
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR  ', 'aggregation_tmp_72140135');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_72140135`  GROUP BY `FLOOR` ORDER BY `FLOOR` ASC ;
CALL paquDropTmp('aggregation_tmp_72140135');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_68731083`  GROUP BY `_FLOOR_LOG10_Mvir_/_0__25_` ORDER BY `_FLOOR_LOG10_Mvir_/_0__25_` ASC 
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_68731083');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_68731083`  GROUP BY `_FLOOR_LOG10_Mvir_/_0__25_` ORDER BY `_FLOOR_LOG10_Mvir_/_0__25_` ASC ;
CALL paquDropTmp('aggregation_tmp_68731083');
This is the query plan optimisation output for the query:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_92323646`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog__fofTreeId`=VALUES(`prog__fofTreeId`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.fofTreeId AS `prog__fofTreeId`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_92323646`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_18592475`  ORDER BY `_`prog__fofTreeId`_` ASC 
ON DUPLICATE KEY UPDATE
`prog__fofTreeId`=VALUES(`prog__fofTreeId`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)
This is the query plan for the query:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   ', 'aggregation_tmp_92323646');
CALL paquExec('SELECT `prog`.fofTreeId AS `prog__fofTreeId`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_92323646`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_18592475');
CALL paquDropTmp('aggregation_tmp_92323646');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_18592475`  ORDER BY `_`prog__fofTreeId`_` ASC ;
CALL paquDropTmp('aggregation_tmp_18592475');
This is the query plan optimisation output for the query:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_93709478`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog__fofTreeId`=VALUES(`prog__fofTreeId`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.fofTreeId AS `prog__fofTreeId`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_93709478`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_19800731`  ORDER BY `_`prog__fofTreeId`_` ASC 
ON DUPLICATE KEY UPDATE
`prog__fofTreeId`=VALUES(`prog__fofTreeId`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)
This is the query plan for the query:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   ', 'aggregation_tmp_93709478');
CALL paquExec('SELECT `prog`.fofTreeId AS `prog__fofTreeId`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_93709478`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_19800731');
CALL paquDropTmp('aggregation_tmp_93709478');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_19800731`  ORDER BY `_`prog__fofTreeId`_` ASC ;
CALL paquDropTmp('aggregation_tmp_19800731');
This is the query plan optimisation output for the query:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_28164568`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog__fofTreeId`=VALUES(`prog__fofTreeId`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.fofTreeId AS `prog__fofTreeId`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_28164568`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_11606769`  ORDER BY `_`prog__fofTreeId`_` ASC 
ON DUPLICATE KEY UPDATE
`prog__fofTreeId`=VALUES(`prog__fofTreeId`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)
This is the query plan for the query:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   ', 'aggregation_tmp_28164568');
CALL paquExec('SELECT `prog`.fofTreeId AS `prog__fofTreeId`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_28164568`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_11606769');
CALL paquDropTmp('aggregation_tmp_28164568');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_11606769`  ORDER BY `_`prog__fofTreeId`_` ASC ;
CALL paquDropTmp('aggregation_tmp_11606769');
This is the query plan optimisation output for the query:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_67346078`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog__fofTreeId`=VALUES(`prog__fofTreeId`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.fofTreeId AS `prog__fofTreeId`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_67346078`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_67963698`  ORDER BY `_`prog__fofTreeId`_` ASC 
ON DUPLICATE KEY UPDATE
`prog__fofTreeId`=VALUES(`prog__fofTreeId`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)
This is the query plan for the query:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   ', 'aggregation_tmp_67346078');
CALL paquExec('SELECT `prog`.fofTreeId AS `prog__fofTreeId`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_67346078`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_67963698');
CALL paquDropTmp('aggregation_tmp_67346078');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_67963698`  ORDER BY `_`prog__fofTreeId`_` ASC ;
CALL paquDropTmp('aggregation_tmp_67963698');
This is the query plan optimisation output for the query:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_34562410`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog__fofTreeId`=VALUES(`prog__fofTreeId`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.fofTreeId AS `prog__fofTreeId`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_34562410`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_58191513`  ORDER BY `_`prog__fofTreeId`_` ASC 
ON DUPLICATE KEY UPDATE
`prog__fofTreeId`=VALUES(`prog__fofTreeId`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)
This is the query plan for the query:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   ', 'aggregation_tmp_34562410');
CALL paquExec('SELECT `prog`.fofTreeId AS `prog__fofTreeId`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_34562410`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_58191513');
CALL paquDropTmp('aggregation_tmp_34562410');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_58191513`  ORDER BY `_`prog__fofTreeId`_` ASC ;
CALL paquDropTmp('aggregation_tmp_58191513');
This is the query plan optimisation output for the query:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_5728879`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog__fofTreeId`=VALUES(`prog__fofTreeId`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.fofTreeId AS `prog__fofTreeId`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_5728879`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_95602030`  ORDER BY `_`prog__fofTreeId`_` ASC 
ON DUPLICATE KEY UPDATE
`prog__fofTreeId`=VALUES(`prog__fofTreeId`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)
This is the query plan for the query:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   ', 'aggregation_tmp_5728879');
CALL paquExec('SELECT `prog`.fofTreeId AS `prog__fofTreeId`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_5728879`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_95602030');
CALL paquDropTmp('aggregation_tmp_5728879');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_95602030`  ORDER BY `_`prog__fofTreeId`_` ASC ;
CALL paquDropTmp('aggregation_tmp_95602030');
This is the query plan optimisation output for the query:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_34768416`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog__fofTreeId`=VALUES(`prog__fofTreeId`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.fofTreeId AS `prog__fofTreeId`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_34768416`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_87734569`  ORDER BY `prog__fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog__fofTreeId`=VALUES(`prog__fofTreeId`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)
This is the query plan for the query:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   ', 'aggregation_tmp_34768416');
CALL paquExec('SELECT `prog`.fofTreeId AS `prog__fofTreeId`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_34768416`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_87734569');
CALL paquDropTmp('aggregation_tmp_34768416');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_87734569`  ORDER BY `prog__fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_87734569');
This is the query plan optimisation output for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z`
FROM MDR1.FOF AS `f` 
)


-- AGGREGATION SQL:
SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_63172181`   
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
-- INPUT SQL:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z`
FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_63172181`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_73604347`    LIMIT 0,1
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
This is the query plan for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

CALL paquExec('SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z` FROM MDR1.FOF AS `f` ', 'aggregation_tmp_63172181');
CALL paquExec('SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z` FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z` FROM `aggregation_tmp_63172181`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1', 'aggregation_tmp_73604347');
CALL paquDropTmp('aggregation_tmp_63172181');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_73604347`    LIMIT 0,1;
CALL paquDropTmp('aggregation_tmp_73604347');
This is the query plan optimisation output for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z`
FROM MDR1.FOF AS `f` 
)


-- AGGREGATION SQL:
SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_49098384`   
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
-- INPUT SQL:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z`
FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_49098384`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_67998670`    LIMIT 0,1
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
This is the query plan for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

CALL paquExec('SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z` FROM MDR1.FOF AS `f` ', 'aggregation_tmp_49098384');
CALL paquExec('SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z` FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z` FROM `aggregation_tmp_49098384`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1', 'aggregation_tmp_67998670');
CALL paquDropTmp('aggregation_tmp_49098384');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_67998670`    LIMIT 0,1;
CALL paquDropTmp('aggregation_tmp_67998670');
This is the query plan optimisation output for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z`
FROM MDR1.FOF AS `f` 
)


-- AGGREGATION SQL:
SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_81031024`   
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
-- INPUT SQL:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`f.y`,`f.z`,`b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,`f`.`f.y` AS `f.y`,`f`.`f.z` AS `f.z`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,`f`.`f.x` AS `f.x`,`f`.`f.y` AS `f.y`,`f`.`f.z` AS `f.z`
FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_81031024`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`f.y`,`f.z`,`b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_97890206`    LIMIT 0,1
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
This is the query plan for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

CALL paquExec('SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z` FROM MDR1.FOF AS `f` ', 'aggregation_tmp_81031024');
CALL paquExec('SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,`f`.`f.y` AS `f.y`,`f`.`f.z` AS `f.z`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,`f`.`f.x` AS `f.x`,`f`.`f.y` AS `f.y`,`f`.`f.z` AS `f.z` FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z` FROM `aggregation_tmp_81031024`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1', 'aggregation_tmp_97890206');
CALL paquDropTmp('aggregation_tmp_81031024');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `b.x`,`b.y`,`b.z`,`f.y`,`f.z`,`b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_97890206`    LIMIT 0,1;
CALL paquDropTmp('aggregation_tmp_97890206');
This is the query plan optimisation output for the query:
select (x+y) from MDR1.FOF limit 10

-- INPUT SQL:
select (x+y) from MDR1.FOF limit 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_x_+_y_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_x_+_y_`=VALUES(`_x_+_y_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT (x+y) AS `_x_+_y_`
FROM MDR1.FOF  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_x_+_y_`
FROM `aggregation_tmp_81506047`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_x_+_y_`=VALUES(`_x_+_y_`)
This is the query plan for the query:
select (x+y) from MDR1.FOF limit 10

CALL paquExec('SELECT (x+y) AS `_x_+_y_` FROM MDR1.FOF  LIMIT 0,10', 'aggregation_tmp_81506047');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_x_+_y_`
FROM `aggregation_tmp_81506047`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_81506047');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_84594273`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_84594273`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_65800135`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   ', 'aggregation_tmp_84594273');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_84594273`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_65800135');
CALL paquDropTmp('aggregation_tmp_84594273');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_65800135`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_65800135');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `fofTreeId` AS `fofTreeId`,`lastProgId` AS `lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_87393404`   
ON DUPLICATE KEY UPDATE
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`fofTreeId`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`fofTreeId`=VALUES(`fofTreeId`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,`fofTreeId` AS `fofTreeId`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`lastProgId`
FROM `aggregation_tmp_87393404`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`fofTreeId`,`prog.fofTreeId`
FROM `aggregation_tmp_29582611`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`fofTreeId`=VALUES(`fofTreeId`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT `fofTreeId` AS `fofTreeId`,`lastProgId` AS `lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   ', 'aggregation_tmp_87393404');
CALL paquExec('SELECT prog.* AS `prog.*`,`fofTreeId` AS `fofTreeId`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `fofTreeId`,`lastProgId` FROM `aggregation_tmp_87393404`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`lastProgId` )   ', 'aggregation_tmp_29582611');
CALL paquDropTmp('aggregation_tmp_87393404');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`fofTreeId`,`prog.fofTreeId`
FROM `aggregation_tmp_29582611`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_29582611');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend`.`fofTreeId`,`prog`.`fofTreeId`,`descend`.`lastProgId`,`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend`.`fofTreeId`=VALUES(`descend`.`fofTreeId`),
`prog`.`fofTreeId`=VALUES(`prog`.`fofTreeId`),
`descend`.`lastProgId`=VALUES(`descend`.`lastProgId`),
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend`.`fofTreeId`,prog.fofTreeId AS `prog`.`fofTreeId`,descend.lastProgId AS `descend`.`lastProgId`,`fofTreeId` AS `fofTreeId`,`lastProgId` AS `lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend`.`fofTreeId`,`prog`.`fofTreeId`,`descend`.`lastProgId`,`fofTreeId`,`lastProgId`
FROM `aggregation_tmp_17522301`   
ON DUPLICATE KEY UPDATE
`descend`.`fofTreeId`=VALUES(`descend`.`fofTreeId`),
`prog`.`fofTreeId`=VALUES(`prog`.`fofTreeId`),
`descend`.`lastProgId`=VALUES(`descend`.`lastProgId`),
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog`.`fofTreeId`,`fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog`.`fofTreeId`=VALUES(`prog`.`fofTreeId`),
`fofTreeId`=VALUES(`fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog`.`fofTreeId`,`fofTreeId` AS `fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend`.`fofTreeId`,`prog`.`fofTreeId`,`descend`.`lastProgId`,`fofTreeId`,`lastProgId`
FROM `aggregation_tmp_17522301`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog`.`fofTreeId`,`fofTreeId`
FROM `aggregation_tmp_20725076`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog`.`fofTreeId`=VALUES(`prog`.`fofTreeId`),
`fofTreeId`=VALUES(`fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend`.`fofTreeId`,prog.fofTreeId AS `prog`.`fofTreeId`,descend.lastProgId AS `descend`.`lastProgId`,`fofTreeId` AS `fofTreeId`,`lastProgId` AS `lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   ', 'aggregation_tmp_17522301');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog`.`fofTreeId`,`fofTreeId` AS `fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend`.`fofTreeId`,`prog`.`fofTreeId`,`descend`.`lastProgId`,`fofTreeId`,`lastProgId` FROM `aggregation_tmp_17522301`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`lastProgId` )   ', 'aggregation_tmp_20725076');
CALL paquDropTmp('aggregation_tmp_17522301');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog`.`fofTreeId`,`fofTreeId`
FROM `aggregation_tmp_20725076`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_20725076');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend`.`fofTreeId`,`prog`.`fofTreeId`,`descend`.`lastProgId`,`fofTreeId`,`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend`.`fofTreeId`=VALUES(`descend`.`fofTreeId`),
`prog`.`fofTreeId`=VALUES(`prog`.`fofTreeId`),
`descend`.`lastProgId`=VALUES(`descend`.`lastProgId`),
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend`.`fofTreeId`,prog.fofTreeId AS `prog`.`fofTreeId`,descend.lastProgId AS `descend`.`lastProgId`,`fofTreeId` AS `fofTreeId`,`lastProgId` AS `lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend`.`fofTreeId`,`prog`.`fofTreeId`,`descend`.`lastProgId`,`fofTreeId`,`lastProgId`
FROM `aggregation_tmp_24203411`   
ON DUPLICATE KEY UPDATE
`descend`.`fofTreeId`=VALUES(`descend`.`fofTreeId`),
`prog`.`fofTreeId`=VALUES(`prog`.`fofTreeId`),
`descend`.`lastProgId`=VALUES(`descend`.`lastProgId`),
`fofTreeId`=VALUES(`fofTreeId`),
`lastProgId`=VALUES(`lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog`.`fofTreeId`,`fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog`.`fofTreeId`=VALUES(`prog`.`fofTreeId`),
`fofTreeId`=VALUES(`fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog`.`fofTreeId`,`fofTreeId` AS `fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend`.`fofTreeId`,`prog`.`fofTreeId`,`descend`.`lastProgId`,`fofTreeId`,`lastProgId`
FROM `aggregation_tmp_24203411`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog`.`fofTreeId`,`fofTreeId`
FROM `aggregation_tmp_28529265`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog`.`fofTreeId`=VALUES(`prog`.`fofTreeId`),
`fofTreeId`=VALUES(`fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend`.`fofTreeId`,prog.fofTreeId AS `prog`.`fofTreeId`,descend.lastProgId AS `descend`.`lastProgId`,`fofTreeId` AS `fofTreeId`,`lastProgId` AS `lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   ', 'aggregation_tmp_24203411');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog`.`fofTreeId`,`fofTreeId` AS `fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend`.`fofTreeId`,`prog`.`fofTreeId`,`descend`.`lastProgId`,`fofTreeId`,`lastProgId` FROM `aggregation_tmp_24203411`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`lastProgId` )   ', 'aggregation_tmp_28529265');
CALL paquDropTmp('aggregation_tmp_24203411');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog`.`fofTreeId`,`fofTreeId`
FROM `aggregation_tmp_28529265`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_28529265');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend`.`fofTreeId`,`descend`.`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend`.`fofTreeId`=VALUES(`descend`.`fofTreeId`),
`descend`.`lastProgId`=VALUES(`descend`.`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend`.`fofTreeId`,descend.lastProgId AS `descend`.`lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend`.`fofTreeId`,`descend`.`lastProgId`
FROM `aggregation_tmp_41215268`   
ON DUPLICATE KEY UPDATE
`descend`.`fofTreeId`=VALUES(`descend`.`fofTreeId`),
`descend`.`lastProgId`=VALUES(`descend`.`lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog`.`fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog`.`fofTreeId`=VALUES(`prog`.`fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog`.`fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend`.`fofTreeId`,`descend`.`lastProgId`
FROM `aggregation_tmp_41215268`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog`.`fofTreeId`
FROM `aggregation_tmp_41209707`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog`.`fofTreeId`=VALUES(`prog`.`fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend`.`fofTreeId`,descend.lastProgId AS `descend`.`lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   ', 'aggregation_tmp_41215268');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog`.`fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend`.`fofTreeId`,`descend`.`lastProgId` FROM `aggregation_tmp_41215268`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_41209707');
CALL paquDropTmp('aggregation_tmp_41215268');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog`.`fofTreeId`
FROM `aggregation_tmp_41209707`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_41209707');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend`.`fofTreeId`,`descend`.`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend`.`fofTreeId`=VALUES(`descend`.`fofTreeId`),
`descend`.`lastProgId`=VALUES(`descend`.`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend`.`fofTreeId`,descend.lastProgId AS `descend`.`lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend`.`fofTreeId`,`descend`.`lastProgId`
FROM `aggregation_tmp_83338714`   
ON DUPLICATE KEY UPDATE
`descend`.`fofTreeId`=VALUES(`descend`.`fofTreeId`),
`descend`.`lastProgId`=VALUES(`descend`.`lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog`.`fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog`.`fofTreeId`=VALUES(`prog`.`fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog`.`fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend`.`fofTreeId`,`descend`.`lastProgId`
FROM `aggregation_tmp_83338714`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog`.`fofTreeId`
FROM `aggregation_tmp_94234227`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog`.`fofTreeId`=VALUES(`prog`.`fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend`.`fofTreeId`,descend.lastProgId AS `descend`.`lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   ', 'aggregation_tmp_83338714');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog`.`fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend`.`fofTreeId`,`descend`.`lastProgId` FROM `aggregation_tmp_83338714`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_94234227');
CALL paquDropTmp('aggregation_tmp_83338714');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog`.`fofTreeId`
FROM `aggregation_tmp_94234227`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_94234227');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend`.`fofTreeId`,`descend`.`lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend`.`fofTreeId`=VALUES(`descend`.`fofTreeId`),
`descend`.`lastProgId`=VALUES(`descend`.`lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend`.`fofTreeId`,descend.lastProgId AS `descend`.`lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend`.`fofTreeId`,`descend`.`lastProgId`
FROM `aggregation_tmp_87921290`   
ON DUPLICATE KEY UPDATE
`descend`.`fofTreeId`=VALUES(`descend`.`fofTreeId`),
`descend`.`lastProgId`=VALUES(`descend`.`lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog`.`fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog`.`fofTreeId`=VALUES(`prog`.`fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog`.`fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend`.`fofTreeId`,`descend`.`lastProgId`
FROM `aggregation_tmp_87921290`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog`.`fofTreeId`
FROM `aggregation_tmp_12951825`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog`.`fofTreeId`=VALUES(`prog`.`fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend`.`fofTreeId`,descend.lastProgId AS `descend`.`lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   ', 'aggregation_tmp_87921290');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog`.`fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend`.`fofTreeId`,`descend`.`lastProgId` FROM `aggregation_tmp_87921290`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_12951825');
CALL paquDropTmp('aggregation_tmp_87921290');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog`.`fofTreeId`
FROM `aggregation_tmp_12951825`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_12951825');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_63837216`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_63837216`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_27137397`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   ', 'aggregation_tmp_63837216');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_63837216`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_27137397');
CALL paquDropTmp('aggregation_tmp_63837216');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_27137397`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_27137397');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_6313688`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_6313688`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_71071269`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   ', 'aggregation_tmp_6313688');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_6313688`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_71071269');
CALL paquDropTmp('aggregation_tmp_6313688');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_71071269`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_71071269');
This is the query plan optimisation output for the query:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_86604730`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog__fofTreeId`=VALUES(`prog__fofTreeId`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.fofTreeId AS `prog__fofTreeId`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_86604730`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_60369630`  ORDER BY `prog__fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog__fofTreeId`=VALUES(`prog__fofTreeId`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)
This is the query plan for the query:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE (  descend.fofTreeId = 85000000000 )   ', 'aggregation_tmp_86604730');
CALL paquExec('SELECT `prog`.fofTreeId AS `prog__fofTreeId`,`prog`.fofId AS `prog__fofId`,`prog`.treeSnapnum AS `prog__treeSnapnum`,`prog`.descendantId AS `prog__descendantId`,`prog`.lastProgId AS `prog__lastProgId`,`prog`.mainLeafId AS `prog__mainLeafId`,`prog`.treeRootId AS `prog__treeRootId`,`prog`.x AS `prog__x`,`prog`.y AS `prog__y`,`prog`.z AS `prog__z`,`prog`.vx AS `prog__vx`,`prog`.vy AS `prog__vy`,`prog`.vz AS `prog__vz`,`prog`.np AS `prog__np`,`prog`.mass AS `prog__mass`,`prog`.size AS `prog__size`,`prog`.spin AS `prog__spin`,`prog`.ix AS `prog__ix`,`prog`.iy AS `prog__iy`,`prog`.iz AS `prog__iz`,`prog`.phkey AS `prog__phkey` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_86604730`   ) AS `descend`  WHERE (  prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_60369630');
CALL paquDropTmp('aggregation_tmp_86604730');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_60369630`  ORDER BY `prog__fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_60369630');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`
FROM `aggregation_tmp_83744197`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolf__bdmProfileId`=VALUES(`Bolf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId`
FROM `aggregation_tmp_83744197`  ORDER BY `Mvir` DESC  LIMIT 0,1)    
)


-- AGGREGATION SQL:
SELECT `Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_56374195`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolf__bdmProfileId`=VALUES(`Bolf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_83744197');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId` FROM `aggregation_tmp_83744197`  ORDER BY `Mvir` DESC  LIMIT 0,1)    ', 'aggregation_tmp_56374195');
CALL paquDropTmp('aggregation_tmp_83744197');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_56374195`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_56374195');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`
FROM `aggregation_tmp_81461287`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolf__bdmProfileId`=VALUES(`Bolf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId`
FROM `aggregation_tmp_81461287`  ORDER BY `Mvir` DESC  LIMIT 0,1)    
)


-- AGGREGATION SQL:
SELECT `Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_30495634`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolf__bdmProfileId`=VALUES(`Bolf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_81461287');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId` FROM `aggregation_tmp_81461287`  ORDER BY `Mvir` DESC  LIMIT 0,1)    ', 'aggregation_tmp_30495634');
CALL paquDropTmp('aggregation_tmp_81461287');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_30495634`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_30495634');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`
FROM `aggregation_tmp_66127095`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolf__bdmProfileId`=VALUES(`Bolf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId`
FROM `aggregation_tmp_66127095`  ORDER BY `Mvir` DESC  LIMIT 0,1)    
)


-- AGGREGATION SQL:
SELECT `Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_57972267`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolf__bdmProfileId`=VALUES(`Bolf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_66127095');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId` FROM `aggregation_tmp_66127095`  ORDER BY `Mvir` DESC  LIMIT 0,1)    ', 'aggregation_tmp_57972267');
CALL paquDropTmp('aggregation_tmp_66127095');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_57972267`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_57972267');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`
FROM `aggregation_tmp_67592126`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolf__bdmProfileId`=VALUES(`Bolf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId`
FROM `aggregation_tmp_67592126`  ORDER BY `Mvir` DESC  LIMIT 0,1)    
)


-- AGGREGATION SQL:
SELECT `Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_95986430`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolf__bdmProfileId`=VALUES(`Bolf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_67592126');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId` FROM `aggregation_tmp_67592126`  ORDER BY `Mvir` DESC  LIMIT 0,1)    ', 'aggregation_tmp_95986430');
CALL paquDropTmp('aggregation_tmp_67592126');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_95986430`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_95986430');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`
FROM `aggregation_tmp_11124966`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolf__bdmProfileId`=VALUES(`Bolf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId`
FROM `aggregation_tmp_11124966`  ORDER BY `Mvir` DESC  LIMIT 0,1)    
)


-- AGGREGATION SQL:
SELECT `Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_67025139`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolf__bdmProfileId`=VALUES(`Bolf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_11124966');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId` FROM `aggregation_tmp_11124966`  ORDER BY `Mvir` DESC  LIMIT 0,1)    ', 'aggregation_tmp_67025139');
CALL paquDropTmp('aggregation_tmp_11124966');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_67025139`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_67025139');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`
FROM `aggregation_tmp_25239934`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolf__bdmProfileId`=VALUES(`Bolf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId`
FROM `aggregation_tmp_25239934`  ORDER BY `Mvir` DESC  LIMIT 0,1)    
)


-- AGGREGATION SQL:
SELECT `Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_79443023`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolf__bdmProfileId`=VALUES(`Bolf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_25239934');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId` FROM `aggregation_tmp_25239934`  ORDER BY `Mvir` DESC  LIMIT 0,1)    ', 'aggregation_tmp_79443023');
CALL paquDropTmp('aggregation_tmp_25239934');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_79443023`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_79443023');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`
FROM `aggregation_tmp_81486976`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolf__bdmProfileId`=VALUES(`Bolf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId`
FROM `aggregation_tmp_81486976`  ORDER BY `Mvir` DESC  LIMIT 0,1)    
)


-- AGGREGATION SQL:
SELECT `Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_6796597`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolf__bdmProfileId`=VALUES(`Bolf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_81486976');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId` FROM `aggregation_tmp_81486976`  ORDER BY `Mvir` DESC  LIMIT 0,1)    ', 'aggregation_tmp_6796597');
CALL paquDropTmp('aggregation_tmp_81486976');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_6796597`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_6796597');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`
FROM `aggregation_tmp_31689391`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolf__bdmProfileId`=VALUES(`Bolf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId`
FROM `aggregation_tmp_31689391`  ORDER BY `Mvir` DESC  LIMIT 0,1)    
)


-- AGGREGATION SQL:
SELECT `Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_8804317`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolf__bdmProfileId`=VALUES(`Bolf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE (  snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_31689391');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId` FROM `aggregation_tmp_31689391`  ORDER BY `Mvir` DESC  LIMIT 0,1)    ', 'aggregation_tmp_8804317');
CALL paquDropTmp('aggregation_tmp_31689391');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_8804317`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_8804317');
This is the query plan optimisation output for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z`
FROM MDR1.FOF AS `f` 
)


-- AGGREGATION SQL:
SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_57259399`   
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
-- INPUT SQL:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z`
FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_57259399`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_1212834`    LIMIT 0,1
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
This is the query plan for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

CALL paquExec('SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z` FROM MDR1.FOF AS `f` ', 'aggregation_tmp_57259399');
CALL paquExec('SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z` FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z` FROM `aggregation_tmp_57259399`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1', 'aggregation_tmp_1212834');
CALL paquDropTmp('aggregation_tmp_57259399');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_1212834`    LIMIT 0,1;
CALL paquDropTmp('aggregation_tmp_1212834');
This is the query plan optimisation output for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z`
FROM MDR1.FOF AS `f` 
)


-- AGGREGATION SQL:
SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_95506660`   
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
-- INPUT SQL:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`
FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_95506660`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`
FROM `aggregation_tmp_14808828`    LIMIT 0,1
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`)
This is the query plan for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

CALL paquExec('SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z` FROM MDR1.FOF AS `f` ', 'aggregation_tmp_95506660');
CALL paquExec('SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z` FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z` FROM `aggregation_tmp_95506660`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1', 'aggregation_tmp_14808828');
CALL paquDropTmp('aggregation_tmp_95506660');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `b.x`,`b.y`,`b.z`
FROM `aggregation_tmp_14808828`    LIMIT 0,1;
CALL paquDropTmp('aggregation_tmp_14808828');
This is the query plan optimisation output for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z`
FROM MDR1.FOF AS `f` 
)


-- AGGREGATION SQL:
SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_86821268`   
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
-- INPUT SQL:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`
FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_86821268`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`
FROM `aggregation_tmp_69329064`    LIMIT 0,1
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`)
This is the query plan for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

CALL paquExec('SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z` FROM MDR1.FOF AS `f` ', 'aggregation_tmp_86821268');
CALL paquExec('SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z` FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z` FROM `aggregation_tmp_86821268`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1', 'aggregation_tmp_69329064');
CALL paquDropTmp('aggregation_tmp_86821268');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `b.x`,`b.y`,`b.z`
FROM `aggregation_tmp_69329064`    LIMIT 0,1;
CALL paquDropTmp('aggregation_tmp_69329064');
This is the query plan optimisation output for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z`
FROM MDR1.FOF AS `f` 
)


-- AGGREGATION SQL:
SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_48486118`   
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
-- INPUT SQL:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`
FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_48486118`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`
FROM `aggregation_tmp_32759771`    LIMIT 0,1
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`)
This is the query plan for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

CALL paquExec('SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z` FROM MDR1.FOF AS `f` ', 'aggregation_tmp_48486118');
CALL paquExec('SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z` FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z` FROM `aggregation_tmp_48486118`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1', 'aggregation_tmp_32759771');
CALL paquDropTmp('aggregation_tmp_48486118');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `b.x`,`b.y`,`b.z`
FROM `aggregation_tmp_32759771`    LIMIT 0,1;
CALL paquDropTmp('aggregation_tmp_32759771');
This is the query plan optimisation output for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z`
FROM MDR1.FOF AS `f` 
)


-- AGGREGATION SQL:
SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_94878671`   
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
-- INPUT SQL:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`
FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_94878671`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`
FROM `aggregation_tmp_32497294`    LIMIT 0,1
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`)
This is the query plan for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

CALL paquExec('SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z` FROM MDR1.FOF AS `f` ', 'aggregation_tmp_94878671');
CALL paquExec('SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z` FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z` FROM `aggregation_tmp_94878671`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1', 'aggregation_tmp_32497294');
CALL paquDropTmp('aggregation_tmp_94878671');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `b.x`,`b.y`,`b.z`
FROM `aggregation_tmp_32497294`    LIMIT 0,1;
CALL paquDropTmp('aggregation_tmp_32497294');
This is the query plan optimisation output for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z`
FROM MDR1.FOF AS `f` 
)


-- AGGREGATION SQL:
SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_17596083`   
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
-- INPUT SQL:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,``,``,``

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS ``,f.`f.y` AS ``,f.`f.z` AS ``
FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_17596083`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,``,``,``
FROM `aggregation_tmp_13100221`    LIMIT 0,1
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``)
This is the query plan for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

CALL paquExec('SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z` FROM MDR1.FOF AS `f` ', 'aggregation_tmp_17596083');
CALL paquExec('SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS ``,f.`f.y` AS ``,f.`f.z` AS `` FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z` FROM `aggregation_tmp_17596083`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1', 'aggregation_tmp_13100221');
CALL paquDropTmp('aggregation_tmp_17596083');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `b.x`,`b.y`,`b.z`,``,``,``
FROM `aggregation_tmp_13100221`    LIMIT 0,1;
CALL paquDropTmp('aggregation_tmp_13100221');
This is the query plan optimisation output for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z`
FROM MDR1.FOF AS `f` 
)


-- AGGREGATION SQL:
SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_69973417`   
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
-- INPUT SQL:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,``,``,``

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS ``,f.`f.y` AS ``,f.`f.z` AS ``
FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_69973417`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,``,``,``
FROM `aggregation_tmp_49315304`    LIMIT 0,1
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``)
This is the query plan for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

CALL paquExec('SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z` FROM MDR1.FOF AS `f` ', 'aggregation_tmp_69973417');
CALL paquExec('SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS ``,f.`f.y` AS ``,f.`f.z` AS `` FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z` FROM `aggregation_tmp_69973417`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1', 'aggregation_tmp_49315304');
CALL paquDropTmp('aggregation_tmp_69973417');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `b.x`,`b.y`,`b.z`,``,``,``
FROM `aggregation_tmp_49315304`    LIMIT 0,1;
CALL paquDropTmp('aggregation_tmp_49315304');
This is the query plan optimisation output for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z`
FROM MDR1.FOF AS `f` 
)


-- AGGREGATION SQL:
SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_30687639`   
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
-- INPUT SQL:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,``,``,``

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS ``,f.`f.y` AS ``,f.`f.z` AS ``
FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_30687639`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,``,``,``
FROM `aggregation_tmp_11003678`    LIMIT 0,1
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``)
This is the query plan for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

CALL paquExec('SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z` FROM MDR1.FOF AS `f` ', 'aggregation_tmp_30687639');
CALL paquExec('SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS ``,f.`f.y` AS ``,f.`f.z` AS `` FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z` FROM `aggregation_tmp_30687639`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1', 'aggregation_tmp_11003678');
CALL paquDropTmp('aggregation_tmp_30687639');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `b.x`,`b.y`,`b.z`,``,``,``
FROM `aggregation_tmp_11003678`    LIMIT 0,1;
CALL paquDropTmp('aggregation_tmp_11003678');
This is the query plan optimisation output for the query:
select (x+y) from MDR1.FOF limit 10

-- INPUT SQL:
select (x+y) from MDR1.FOF limit 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_x_+_y_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_x_+_y_`=VALUES(`_x_+_y_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT (x+y) AS `_x_+_y_`
FROM MDR1.FOF  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_x_+_y_`
FROM `aggregation_tmp_60037885`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_x_+_y_`=VALUES(`_x_+_y_`)
This is the query plan for the query:
select (x+y) from MDR1.FOF limit 10

CALL paquExec('SELECT (x+y) AS `_x_+_y_` FROM MDR1.FOF  LIMIT 0,10', 'aggregation_tmp_60037885');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_x_+_y_`
FROM `aggregation_tmp_60037885`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_60037885');
This is the query plan optimisation output for the query:
select (x+y) from MDR1.FOF limit 10

-- INPUT SQL:
select (x+y) from MDR1.FOF limit 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_x_+_y_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_x_+_y_`=VALUES(`_x_+_y_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT (x+y) AS `_x_+_y_`
FROM MDR1.FOF  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_x_+_y_`
FROM `aggregation_tmp_16703930`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_x_+_y_`=VALUES(`_x_+_y_`)
This is the query plan for the query:
select (x+y) from MDR1.FOF limit 10

CALL paquExec('SELECT (x+y) AS `_x_+_y_` FROM MDR1.FOF  LIMIT 0,10', 'aggregation_tmp_16703930');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_x_+_y_`
FROM `aggregation_tmp_16703930`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_16703930');
This is the query plan optimisation output for the query:
select (x+y) from MDR1.FOF limit 10

-- INPUT SQL:
select (x+y) from MDR1.FOF limit 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_x_+_y_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_x_+_y_`=VALUES(`_x_+_y_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT (x+y) AS `_x_+_y_`
FROM MDR1.FOF  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_x_+_y_`
FROM `aggregation_tmp_97861521`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_x_+_y_`=VALUES(`_x_+_y_`)
This is the query plan for the query:
select (x+y) from MDR1.FOF limit 10

CALL paquExec('SELECT (x+y) AS `_x_+_y_` FROM MDR1.FOF  LIMIT 0,10', 'aggregation_tmp_97861521');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_x_+_y_`
FROM `aggregation_tmp_97861521`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_97861521');
This is the query plan optimisation output for the query:
select (x+y) from MDR1.FOF limit 10

-- INPUT SQL:
select (x+y) from MDR1.FOF limit 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_x_+_y_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_x_+_y_`=VALUES(`_x_+_y_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT (x+y) AS `_x_+_y_`
FROM MDR1.FOF  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_x_+_y_`
FROM `aggregation_tmp_39310204`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_x_+_y_`=VALUES(`_x_+_y_`)
This is the query plan for the query:
select (x+y) from MDR1.FOF limit 10

CALL paquExec('SELECT (x+y) AS `_x_+_y_` FROM MDR1.FOF  LIMIT 0,10', 'aggregation_tmp_39310204');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_x_+_y_`
FROM `aggregation_tmp_39310204`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_39310204');
This is the query plan optimisation output for the query:
select (x+y) from MDR1.FOF limit 10

-- INPUT SQL:
select (x+y) from MDR1.FOF limit 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_x_+_y_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_x_+_y_`=VALUES(`_x_+_y_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT (x+y) AS `_x_+_y_`
FROM MDR1.FOF  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_x_+_y_`
FROM `aggregation_tmp_59563348`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_x_+_y_`=VALUES(`_x_+_y_`)
This is the query plan for the query:
select (x+y) from MDR1.FOF limit 10

CALL paquExec('SELECT (x+y) AS `_x_+_y_` FROM MDR1.FOF  LIMIT 0,10', 'aggregation_tmp_59563348');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_x_+_y_`
FROM `aggregation_tmp_59563348`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_59563348');
This is the query plan optimisation output for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

-- INPUT SQL:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`,`mass`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`mass`=VALUES(`mass`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,mass AS `mass`
FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `*`,`mass`
FROM `aggregation_tmp_30766467`  ORDER BY `mass` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`mass`=VALUES(`mass`)
This is the query plan for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

CALL paquExec('SELECT * AS `*`,mass AS `mass` FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10', 'aggregation_tmp_30766467');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`,`mass`
FROM `aggregation_tmp_30766467`  ORDER BY `mass` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_30766467');
This is the query plan optimisation output for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

-- INPUT SQL:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`,`mass`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`mass`=VALUES(`mass`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,mass AS `mass`
FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `*`,`mass`
FROM `aggregation_tmp_5471393`  ORDER BY `mass` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`mass`=VALUES(`mass`)
This is the query plan for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

CALL paquExec('SELECT * AS `*`,mass AS `mass` FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10', 'aggregation_tmp_5471393');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`,`mass`
FROM `aggregation_tmp_5471393`  ORDER BY `mass` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_5471393');
This is the query plan optimisation output for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

-- INPUT SQL:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`,`mass`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`mass`=VALUES(`mass`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,mass AS `mass`
FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `*`,`mass`
FROM `aggregation_tmp_8050162`  ORDER BY `mass` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`mass`=VALUES(`mass`)
This is the query plan for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

CALL paquExec('SELECT * AS `*`,mass AS `mass` FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10', 'aggregation_tmp_8050162');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`,`mass`
FROM `aggregation_tmp_8050162`  ORDER BY `mass` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_8050162');
This is the query plan optimisation output for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

-- INPUT SQL:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`,`mass`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`mass`=VALUES(`mass`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,mass AS `mass`
FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `*`,`mass`
FROM `aggregation_tmp_37611952`  ORDER BY `mass` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`mass`=VALUES(`mass`)
This is the query plan for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

CALL paquExec('SELECT * AS `*`,mass AS `mass` FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10', 'aggregation_tmp_37611952');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`,`mass`
FROM `aggregation_tmp_37611952`  ORDER BY `mass` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_37611952');
This is the query plan optimisation output for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

-- INPUT SQL:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`,`mass`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`mass`=VALUES(`mass`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,mass AS `mass`
FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `*`,`mass`
FROM `aggregation_tmp_21590433`  ORDER BY `mass` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`mass`=VALUES(`mass`)
This is the query plan for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

CALL paquExec('SELECT * AS `*`,mass AS `mass` FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10', 'aggregation_tmp_21590433');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`,`mass`
FROM `aggregation_tmp_21590433`  ORDER BY `mass` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_21590433');
This is the query plan optimisation output for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

-- INPUT SQL:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`,`mass`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`mass`=VALUES(`mass`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,mass AS `mass`
FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `*`,`mass`
FROM `aggregation_tmp_9048117`  ORDER BY `mass` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`mass`=VALUES(`mass`)
This is the query plan for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

CALL paquExec('SELECT * AS `*`,mass AS `mass` FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10', 'aggregation_tmp_9048117');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`,`mass`
FROM `aggregation_tmp_9048117`  ORDER BY `mass` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_9048117');
This is the query plan optimisation output for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

-- INPUT SQL:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`,`mass`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`mass`=VALUES(`mass`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,mass AS `mass`
FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `*`,`mass`
FROM `aggregation_tmp_33735967`  ORDER BY `mass` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`mass`=VALUES(`mass`)
This is the query plan for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

CALL paquExec('SELECT * AS `*`,mass AS `mass` FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10', 'aggregation_tmp_33735967');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`,`mass`
FROM `aggregation_tmp_33735967`  ORDER BY `mass` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_33735967');
This is the query plan optimisation output for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

-- INPUT SQL:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`,`mass`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`mass`=VALUES(`mass`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,mass AS `mass`
FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `*`,`mass`
FROM `aggregation_tmp_77575151`  ORDER BY `mass` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`mass`=VALUES(`mass`)
This is the query plan for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

CALL paquExec('SELECT * AS `*`,mass AS `mass` FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10', 'aggregation_tmp_77575151');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`,`mass`
FROM `aggregation_tmp_77575151`  ORDER BY `mass` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_77575151');
This is the query plan optimisation output for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

-- INPUT SQL:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`,`mass`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`mass`=VALUES(`mass`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,mass AS `mass`
FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `*`,`mass`
FROM `aggregation_tmp_79362023`  ORDER BY `mass` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`mass`=VALUES(`mass`)
This is the query plan for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

CALL paquExec('SELECT * AS `*`,mass AS `mass` FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10', 'aggregation_tmp_79362023');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`,`mass`
FROM `aggregation_tmp_79362023`  ORDER BY `mass` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_79362023');
This is the query plan optimisation output for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

-- INPUT SQL:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`,`mass`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`mass`=VALUES(`mass`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,mass AS `mass`
FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `*`,`mass`
FROM `aggregation_tmp_41721401`  ORDER BY `mass` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`mass`=VALUES(`mass`)
This is the query plan for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

CALL paquExec('SELECT * AS `*`,mass AS `mass` FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10', 'aggregation_tmp_41721401');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`,`mass`
FROM `aggregation_tmp_41721401`  ORDER BY `mass` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_41721401');
This is the query plan optimisation output for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

-- INPUT SQL:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`,`mass`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`mass`=VALUES(`mass`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,mass AS `mass`
FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `*`,`mass`
FROM `aggregation_tmp_11194649`  ORDER BY `mass` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`mass`=VALUES(`mass`)
This is the query plan for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

CALL paquExec('SELECT * AS `*`,mass AS `mass` FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10', 'aggregation_tmp_11194649');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`,`mass`
FROM `aggregation_tmp_11194649`  ORDER BY `mass` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_11194649');
This is the query plan optimisation output for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

-- INPUT SQL:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`,`mass`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`mass`=VALUES(`mass`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,mass AS `mass`
FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `*`,`mass`
FROM `aggregation_tmp_28783079`  ORDER BY `mass` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`mass`=VALUES(`mass`)
This is the query plan for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

CALL paquExec('SELECT * AS `*`,mass AS `mass` FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10', 'aggregation_tmp_28783079');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`,`mass`
FROM `aggregation_tmp_28783079`  ORDER BY `mass` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_28783079');
This is the query plan optimisation output for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

-- INPUT SQL:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`,`mass`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`mass`=VALUES(`mass`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,mass AS `mass`
FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `*`,`mass`
FROM `aggregation_tmp_21899994`  ORDER BY `mass` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`mass`=VALUES(`mass`)
This is the query plan for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY mass desc LIMIT 10

CALL paquExec('SELECT * AS `*`,mass AS `mass` FROM MDR1.FOF WHERE (  snapnum = 85 )  ORDER BY `mass` DESC  LIMIT 0,10', 'aggregation_tmp_21899994');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`,`mass`
FROM `aggregation_tmp_21899994`  ORDER BY `mass` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_21899994');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_97579507`  GROUP BY `_FLOOR_LOG10_Mvir_/_0__25_` ORDER BY `_FLOOR_LOG10_Mvir_/_0__25_` ASC 
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_97579507');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_97579507`  GROUP BY `_FLOOR_LOG10_Mvir_/_0__25_` ORDER BY `_FLOOR_LOG10_Mvir_/_0__25_` ASC ;
CALL paquDropTmp('aggregation_tmp_97579507');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_77463355`  GROUP BY `_FLOOR_LOG10_Mvir_/_0__25_` ORDER BY `_FLOOR_LOG10_Mvir_/_0__25_` ASC 
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_77463355');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_77463355`  GROUP BY `_FLOOR_LOG10_Mvir_/_0__25_` ORDER BY `_FLOOR_LOG10_Mvir_/_0__25_` ASC ;
CALL paquDropTmp('aggregation_tmp_77463355');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_69908246`  GROUP BY `_FLOOR_LOG10_Mvir_/_0__25_` ORDER BY `_FLOOR_LOG10_Mvir_/_0__25_` ASC 
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_69908246');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_69908246`  GROUP BY `_FLOOR_LOG10_Mvir_/_0__25_` ORDER BY `_FLOOR_LOG10_Mvir_/_0__25_` ASC ;
CALL paquDropTmp('aggregation_tmp_69908246');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_76678349`  GROUP BY `_FLOOR_LOG10_Mvir_/_0__25_` ORDER BY `_FLOOR_LOG10_Mvir_/_0__25_` ASC 
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_76678349');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_76678349`  GROUP BY `_FLOOR_LOG10_Mvir_/_0__25_` ORDER BY `_FLOOR_LOG10_Mvir_/_0__25_` ASC ;
CALL paquDropTmp('aggregation_tmp_76678349');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_34479156`  GROUP BY `_FLOOR_LOG10_Mvir_/_0__25_` ORDER BY `_FLOOR_LOG10_Mvir_/_0__25_` ASC 
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_34479156');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_34479156`  GROUP BY `_FLOOR_LOG10_Mvir_/_0__25_` ORDER BY `_FLOOR_LOG10_Mvir_/_0__25_` ASC ;
CALL paquDropTmp('aggregation_tmp_34479156');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_17990599`  GROUP BY `_FLOOR_LOG10_Mvir_/_0__25_` ORDER BY `_FLOOR_LOG10_Mvir_/_0__25_` ASC 
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir)/0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE (  snapnum = 85 )  GROUP BY FLOOR(LOG10(Mvir)/0.25)  ', 'aggregation_tmp_17990599');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_17990599`  GROUP BY `_FLOOR_LOG10_Mvir_/_0__25_` ORDER BY `_FLOOR_LOG10_Mvir_/_0__25_` ASC ;
CALL paquDropTmp('aggregation_tmp_17990599');
This is the query plan optimisation output for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z`
FROM MDR1.FOF AS `f` 
)


-- AGGREGATION SQL:
SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_52960297`   
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
-- INPUT SQL:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,``,``,``

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS ``,f.`f.y` AS ``,f.`f.z` AS ``
FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_52960297`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,``,``,``
FROM `aggregation_tmp_43520640`    LIMIT 0,1
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``)
This is the query plan for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

CALL paquExec('SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z` FROM MDR1.FOF AS `f` ', 'aggregation_tmp_52960297');
CALL paquExec('SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS ``,f.`f.y` AS ``,f.`f.z` AS `` FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z` FROM `aggregation_tmp_52960297`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1', 'aggregation_tmp_43520640');
CALL paquDropTmp('aggregation_tmp_52960297');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `b.x`,`b.y`,`b.z`,``,``,``
FROM `aggregation_tmp_43520640`    LIMIT 0,1;
CALL paquDropTmp('aggregation_tmp_43520640');
This is the query plan optimisation output for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z`
FROM MDR1.FOF AS `f` 
)


-- AGGREGATION SQL:
SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_9565316`   
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
-- INPUT SQL:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,``,``,``

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS ``,f.`f.y` AS ``,f.`f.z` AS ``
FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_9565316`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,``,``,``
FROM `aggregation_tmp_70391339`    LIMIT 0,1
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``)
This is the query plan for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

CALL paquExec('SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z` FROM MDR1.FOF AS `f` ', 'aggregation_tmp_9565316');
CALL paquExec('SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS ``,f.`f.y` AS ``,f.`f.z` AS `` FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z` FROM `aggregation_tmp_9565316`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1', 'aggregation_tmp_70391339');
CALL paquDropTmp('aggregation_tmp_9565316');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `b.x`,`b.y`,`b.z`,``,``,``
FROM `aggregation_tmp_70391339`    LIMIT 0,1;
CALL paquDropTmp('aggregation_tmp_70391339');
This is the query plan optimisation output for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z`
FROM MDR1.FOF AS `f` 
)


-- AGGREGATION SQL:
SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_66945319`   
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
-- INPUT SQL:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS `f.x`,f.`f.y` AS `f.y`,f.`f.z` AS `f.z`
FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_66945319`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_23707175`    LIMIT 0,1
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
This is the query plan for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

CALL paquExec('SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z` FROM MDR1.FOF AS `f` ', 'aggregation_tmp_66945319');
CALL paquExec('SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS `f.x`,f.`f.y` AS `f.y`,f.`f.z` AS `f.z` FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z` FROM `aggregation_tmp_66945319`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1', 'aggregation_tmp_23707175');
CALL paquDropTmp('aggregation_tmp_66945319');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_23707175`    LIMIT 0,1;
CALL paquDropTmp('aggregation_tmp_23707175');
This is the query plan optimisation output for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z`
FROM MDR1.FOF AS `f` 
)


-- AGGREGATION SQL:
SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_65006010`   
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
-- INPUT SQL:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS `f.x`,f.`f.y` AS `f.y`,f.`f.z` AS `f.z`
FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_65006010`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_3774770`    LIMIT 0,1
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
This is the query plan for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

CALL paquExec('SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z` FROM MDR1.FOF AS `f` ', 'aggregation_tmp_65006010');
CALL paquExec('SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS `f.x`,f.`f.y` AS `f.y`,f.`f.z` AS `f.z` FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z` FROM `aggregation_tmp_65006010`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1', 'aggregation_tmp_3774770');
CALL paquDropTmp('aggregation_tmp_65006010');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_3774770`    LIMIT 0,1;
CALL paquDropTmp('aggregation_tmp_3774770');
This is the query plan optimisation output for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z`
FROM MDR1.FOF AS `f` 
)


-- AGGREGATION SQL:
SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_62729536`   
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
-- INPUT SQL:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS `f.x`,f.`f.y` AS `f.y`,f.`f.z` AS `f.z`
FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_62729536`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_12919205`    LIMIT 0,1
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
This is the query plan for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

CALL paquExec('SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z` FROM MDR1.FOF AS `f` ', 'aggregation_tmp_62729536');
CALL paquExec('SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS `f.x`,f.`f.y` AS `f.y`,f.`f.z` AS `f.z` FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z` FROM `aggregation_tmp_62729536`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1', 'aggregation_tmp_12919205');
CALL paquDropTmp('aggregation_tmp_62729536');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_12919205`    LIMIT 0,1;
CALL paquDropTmp('aggregation_tmp_12919205');
This is the query plan optimisation output for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z`
FROM MDR1.FOF AS `f` 
)


-- AGGREGATION SQL:
SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_29167211`   
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
-- INPUT SQL:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS `f.x`,f.`f.y` AS `f.y`,f.`f.z` AS `f.z`
FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_29167211`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_35709682`    LIMIT 0,1
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
This is the query plan for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

CALL paquExec('SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z` FROM MDR1.FOF AS `f` ', 'aggregation_tmp_29167211');
CALL paquExec('SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS `f.x`,f.`f.y` AS `f.y`,f.`f.z` AS `f.z` FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z` FROM `aggregation_tmp_29167211`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1', 'aggregation_tmp_35709682');
CALL paquDropTmp('aggregation_tmp_29167211');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_35709682`    LIMIT 0,1;
CALL paquDropTmp('aggregation_tmp_35709682');
This is the query plan optimisation output for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z`
FROM MDR1.FOF AS `f` 
)


-- AGGREGATION SQL:
SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_96413187`   
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
-- INPUT SQL:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS `f.x`,f.`f.y` AS `f.y`,f.`f.z` AS `f.z`
FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_96413187`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_40161129`    LIMIT 0,1
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
This is the query plan for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

CALL paquExec('SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z` FROM MDR1.FOF AS `f` ', 'aggregation_tmp_96413187');
CALL paquExec('SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS `f.x`,f.`f.y` AS `f.y`,f.`f.z` AS `f.z` FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z` FROM `aggregation_tmp_96413187`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1', 'aggregation_tmp_40161129');
CALL paquDropTmp('aggregation_tmp_96413187');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_40161129`    LIMIT 0,1;
CALL paquDropTmp('aggregation_tmp_40161129');
This is the query plan optimisation output for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z`
FROM MDR1.FOF AS `f` 
)


-- AGGREGATION SQL:
SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_2757783`   
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
-- INPUT SQL:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS `f.x`,f.`f.y` AS `f.y`,f.`f.z` AS `f.z`
FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_2757783`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_1675262`    LIMIT 0,1
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
This is the query plan for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

CALL paquExec('SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z` FROM MDR1.FOF AS `f` ', 'aggregation_tmp_2757783');
CALL paquExec('SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS `f.x`,f.`f.y` AS `f.y`,f.`f.z` AS `f.z` FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z` FROM `aggregation_tmp_2757783`   ) AS `f`  WHERE (  POWER( (  b.x - `f`.`f.x` ) 2 ) < 1000 )    LIMIT 0,1', 'aggregation_tmp_1675262');
CALL paquDropTmp('aggregation_tmp_2757783');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_1675262`    LIMIT 0,1;
CALL paquDropTmp('aggregation_tmp_1675262');
This is the query plan optimisation output for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z`
FROM MDR1.FOF AS `f` 
)


-- AGGREGATION SQL:
SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_24337017`   
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
-- INPUT SQL:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS `f.x`,f.`f.y` AS `f.y`,f.`f.z` AS `f.z`
FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_24337017`   ) AS `f`  WHERE POWER(b.x-`f`.`f.x`, 2)<1000    LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_71187682`    LIMIT 0,1
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
This is the query plan for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

CALL paquExec('SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z` FROM MDR1.FOF AS `f` ', 'aggregation_tmp_24337017');
CALL paquExec('SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS `f.x`,f.`f.y` AS `f.y`,f.`f.z` AS `f.z` FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z` FROM `aggregation_tmp_24337017`   ) AS `f`  WHERE POWER(b.x-`f`.`f.x`, 2)<1000    LIMIT 0,1', 'aggregation_tmp_71187682');
CALL paquDropTmp('aggregation_tmp_24337017');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_71187682`    LIMIT 0,1;
CALL paquDropTmp('aggregation_tmp_71187682');
This is the query plan optimisation output for the query:
select rand() from MDR1.Particles62 limit 100

-- INPUT SQL:
select rand() from MDR1.Particles62 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_rand_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_rand_`=VALUES(`_rand_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT rand) AS `_rand_`
FROM MDR1.Particles62  LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `_rand_`
FROM `aggregation_tmp_86051140`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`_rand_`=VALUES(`_rand_`)
This is the query plan for the query:
select rand() from MDR1.Particles62 limit 100

CALL paquExec('SELECT rand) AS `_rand_` FROM MDR1.Particles62  LIMIT 0,100', 'aggregation_tmp_86051140');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_rand_`
FROM `aggregation_tmp_86051140`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_86051140');
This is the query plan optimisation output for the query:
select rand() from MDR1.Particles62 limit 100

-- INPUT SQL:
select rand() from MDR1.Particles62 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_rand_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_rand_`=VALUES(`_rand_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT rand) AS `_rand_`
FROM MDR1.Particles62  LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `_rand_`
FROM `aggregation_tmp_47491492`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`_rand_`=VALUES(`_rand_`)
This is the query plan for the query:
select rand() from MDR1.Particles62 limit 100

CALL paquExec('SELECT rand) AS `_rand_` FROM MDR1.Particles62  LIMIT 0,100', 'aggregation_tmp_47491492');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_rand_`
FROM `aggregation_tmp_47491492`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_47491492');
This is the query plan optimisation output for the query:
select rand() from MDR1.Particles62 limit 100

-- INPUT SQL:
select rand() from MDR1.Particles62 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_rand_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_rand_`=VALUES(`_rand_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT rand) AS `_rand_`
FROM MDR1.Particles62  LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `_rand_`
FROM `aggregation_tmp_86833192`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`_rand_`=VALUES(`_rand_`)
This is the query plan for the query:
select rand() from MDR1.Particles62 limit 100

CALL paquExec('SELECT rand) AS `_rand_` FROM MDR1.Particles62  LIMIT 0,100', 'aggregation_tmp_86833192');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_rand_`
FROM `aggregation_tmp_86833192`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_86833192');
This is the query plan optimisation output for the query:
select rand() from MDR1.Particles62 limit 100

-- INPUT SQL:
select rand() from MDR1.Particles62 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_rand_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_rand_`=VALUES(`_rand_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT rand) AS `_rand_`
FROM MDR1.Particles62  LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `_rand_`
FROM `aggregation_tmp_62179652`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`_rand_`=VALUES(`_rand_`)
This is the query plan for the query:
select rand() from MDR1.Particles62 limit 100

CALL paquExec('SELECT rand) AS `_rand_` FROM MDR1.Particles62  LIMIT 0,100', 'aggregation_tmp_62179652');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_rand_`
FROM `aggregation_tmp_62179652`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_62179652');
This is the query plan optimisation output for the query:
select rand() from MDR1.Particles62 limit 100

-- INPUT SQL:
select rand() from MDR1.Particles62 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_rand_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_rand_`=VALUES(`_rand_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT rand(rand) AS `_rand_`
FROM MDR1.Particles62  LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `_rand_`
FROM `aggregation_tmp_45728327`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`_rand_`=VALUES(`_rand_`)
This is the query plan for the query:
select rand() from MDR1.Particles62 limit 100

CALL paquExec('SELECT rand(rand) AS `_rand_` FROM MDR1.Particles62  LIMIT 0,100', 'aggregation_tmp_45728327');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_rand_`
FROM `aggregation_tmp_45728327`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_45728327');
This is the query plan optimisation output for the query:
select rand() from MDR1.Particles62 limit 100

-- INPUT SQL:
select rand() from MDR1.Particles62 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_rand_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_rand_`=VALUES(`_rand_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT rand() AS `_rand_`
FROM MDR1.Particles62  LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `_rand_`
FROM `aggregation_tmp_36997494`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`_rand_`=VALUES(`_rand_`)
This is the query plan for the query:
select rand() from MDR1.Particles62 limit 100

CALL paquExec('SELECT rand() AS `_rand_` FROM MDR1.Particles62  LIMIT 0,100', 'aggregation_tmp_36997494');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_rand_`
FROM `aggregation_tmp_36997494`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_36997494');
This is the query plan optimisation output for the query:
select rand() from MDR1.Particles62 limit 100

-- INPUT SQL:
select rand() from MDR1.Particles62 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_rand_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_rand_`=VALUES(`_rand_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT rand() AS `_rand_`
FROM MDR1.Particles62  LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `_rand_`
FROM `aggregation_tmp_99154757`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`_rand_`=VALUES(`_rand_`)
This is the query plan for the query:
select rand() from MDR1.Particles62 limit 100

CALL paquExec('SELECT rand() AS `_rand_` FROM MDR1.Particles62  LIMIT 0,100', 'aggregation_tmp_99154757');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_rand_`
FROM `aggregation_tmp_99154757`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_99154757');
This is the query plan optimisation output for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

-- INPUT SQL:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz`
FROM MDR1.Particles62 WHERE ( randrand<= 0.0006 )    LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_42184320`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)
This is the query plan for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

CALL paquExec('SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz` FROM MDR1.Particles62 WHERE ( randrand<= 0.0006 )    LIMIT 0,100', 'aggregation_tmp_42184320');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_42184320`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_42184320');
This is the query plan optimisation output for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

-- INPUT SQL:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz`
FROM MDR1.Particles62 WHERE ( randrand<= 0.0006 )    LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_23717540`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)
This is the query plan for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

CALL paquExec('SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz` FROM MDR1.Particles62 WHERE ( randrand<= 0.0006 )    LIMIT 0,100', 'aggregation_tmp_23717540');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_23717540`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_23717540');
This is the query plan optimisation output for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

-- INPUT SQL:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz`
FROM MDR1.Particles62 WHERE ( randrand<= 0.0006 )    LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_94371870`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)
This is the query plan for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

CALL paquExec('SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz` FROM MDR1.Particles62 WHERE ( randrand<= 0.0006 )    LIMIT 0,100', 'aggregation_tmp_94371870');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_94371870`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_94371870');
This is the query plan optimisation output for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

-- INPUT SQL:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz`
FROM MDR1.Particles62 WHERE ( randrand<= 0.0006 )    LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_82705495`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)
This is the query plan for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

CALL paquExec('SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz` FROM MDR1.Particles62 WHERE ( randrand<= 0.0006 )    LIMIT 0,100', 'aggregation_tmp_82705495');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_82705495`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_82705495');
This is the query plan optimisation output for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

-- INPUT SQL:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz`
FROM MDR1.Particles62 WHERE ( randrand<= 0.0006 )    LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_9614685`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)
This is the query plan for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

CALL paquExec('SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz` FROM MDR1.Particles62 WHERE ( randrand<= 0.0006 )    LIMIT 0,100', 'aggregation_tmp_9614685');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_9614685`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_9614685');
This is the query plan optimisation output for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

-- INPUT SQL:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz`
FROM MDR1.Particles62 WHERE ( randrand<= 0.0006 )    LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_75842958`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)
This is the query plan for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

CALL paquExec('SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz` FROM MDR1.Particles62 WHERE ( randrand<= 0.0006 )    LIMIT 0,100', 'aggregation_tmp_75842958');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_75842958`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_75842958');
This is the query plan optimisation output for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

-- INPUT SQL:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz`
FROM MDR1.Particles62 WHERE ( rand()<=0.0006 )    LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_1087840`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)
This is the query plan for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

CALL paquExec('SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz` FROM MDR1.Particles62 WHERE ( rand()<=0.0006 )    LIMIT 0,100', 'aggregation_tmp_1087840');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_1087840`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_1087840');
This is the query plan optimisation output for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

-- INPUT SQL:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz`
FROM MDR1.Particles62 WHERE ( rand() <= 0.0006 )    LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_62423202`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)
This is the query plan for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

CALL paquExec('SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz` FROM MDR1.Particles62 WHERE ( rand() <= 0.0006 )    LIMIT 0,100', 'aggregation_tmp_62423202');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_62423202`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_62423202');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as ,Bolshoi.BDMVProf.bdmId as ,Bolshoi.BDMVProf.snapnum as ,Bolshoi.BDMVProf.NinCat as ,Bolshoi.BDMVProf.R_Rvir as ,Bolshoi.BDMVProf.Rbin as ,Bolshoi.BDMVProf.np as ,Bolshoi.BDMVProf.mass as ,Bolshoi.BDMVProf.dens as ,Bolshoi.BDMVProf.Vcirc as ,Bolshoi.BDMVProf.VpropRms as ,Bolshoi.BDMVProf.Vrad as ,Bolshoi.BDMVProf.VradRms as ,Bolshoi.BDMVProf.boundR_Rvir as ,Bolshoi.BDMVProf.boundNp as ,Bolshoi.BDMVProf.boundMass as ,Bolshoi.BDMVProf.boundDens as ,Bolshoi.BDMVProf.boundVcirc as ,Bolshoi.BDMVProf.boundVcircRms as ,Bolshoi.BDMVProf.boundVrad as ,Bolshoi.BDMVProf.boundVradRms as  FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY  ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`
FROM `aggregation_tmp_72232374`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as ,Bolshoi.BDMVProf.bdmId as ,Bolshoi.BDMVProf.snapnum as ,Bolshoi.BDMVProf.NinCat as ,Bolshoi.BDMVProf.R_Rvir as ,Bolshoi.BDMVProf.Rbin as ,Bolshoi.BDMVProf.np as ,Bolshoi.BDMVProf.mass as ,Bolshoi.BDMVProf.dens as ,Bolshoi.BDMVProf.Vcirc as ,Bolshoi.BDMVProf.VpropRms as ,Bolshoi.BDMVProf.Vrad as ,Bolshoi.BDMVProf.VradRms as ,Bolshoi.BDMVProf.boundR_Rvir as ,Bolshoi.BDMVProf.boundNp as ,Bolshoi.BDMVProf.boundMass as ,Bolshoi.BDMVProf.boundDens as ,Bolshoi.BDMVProf.boundVcirc as ,Bolshoi.BDMVProf.boundVcircRms as ,Bolshoi.BDMVProf.boundVrad as ,Bolshoi.BDMVProf.boundVradRms as  FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY  ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
``,``,``,``,``,``,``,``,``,``,``,``,``,``,``,``,``,``,``,``,``

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
``=VALUES(``),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS ``,Bolshoi.BDMVProf.bdmId AS ``,Bolshoi.BDMVProf.snapnum AS ``,Bolshoi.BDMVProf.NinCat AS ``,Bolshoi.BDMVProf.R_Rvir AS ``,Bolshoi.BDMVProf.Rbin AS ``,Bolshoi.BDMVProf.np AS ``,Bolshoi.BDMVProf.mass AS ``,Bolshoi.BDMVProf.dens AS ``,Bolshoi.BDMVProf.Vcirc AS ``,Bolshoi.BDMVProf.VpropRms AS ``,Bolshoi.BDMVProf.Vrad AS ``,Bolshoi.BDMVProf.VradRms AS ``,Bolshoi.BDMVProf.boundR_Rvir AS ``,Bolshoi.BDMVProf.boundNp AS ``,Bolshoi.BDMVProf.boundMass AS ``,Bolshoi.BDMVProf.boundDens AS ``,Bolshoi.BDMVProf.boundVcirc AS ``,Bolshoi.BDMVProf.boundVcircRms AS ``,Bolshoi.BDMVProf.boundVrad AS ``,Bolshoi.BDMVProf.boundVradRms AS ``
FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId`
FROM `aggregation_tmp_72232374`  ORDER BY `Mvir` DESC  LIMIT 0,1)    
)


-- AGGREGATION SQL:
SELECT ``,``,``,``,``,``,``,``,``,``,``,``,``,``,``,``,``,``,``,``,``
FROM `aggregation_tmp_15605291`  ORDER BY ``  
ON DUPLICATE KEY UPDATE
``=VALUES(``),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``),
``=VALUES(``)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as ,Bolshoi.BDMVProf.bdmId as ,Bolshoi.BDMVProf.snapnum as ,Bolshoi.BDMVProf.NinCat as ,Bolshoi.BDMVProf.R_Rvir as ,Bolshoi.BDMVProf.Rbin as ,Bolshoi.BDMVProf.np as ,Bolshoi.BDMVProf.mass as ,Bolshoi.BDMVProf.dens as ,Bolshoi.BDMVProf.Vcirc as ,Bolshoi.BDMVProf.VpropRms as ,Bolshoi.BDMVProf.Vrad as ,Bolshoi.BDMVProf.VradRms as ,Bolshoi.BDMVProf.boundR_Rvir as ,Bolshoi.BDMVProf.boundNp as ,Bolshoi.BDMVProf.boundMass as ,Bolshoi.BDMVProf.boundDens as ,Bolshoi.BDMVProf.boundVcirc as ,Bolshoi.BDMVProf.boundVcircRms as ,Bolshoi.BDMVProf.boundVrad as ,Bolshoi.BDMVProf.boundVradRms as  FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY  ASC

CALL paquExec('SELECT bdmId AS `bdmId`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_72232374');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS ``,Bolshoi.BDMVProf.bdmId AS ``,Bolshoi.BDMVProf.snapnum AS ``,Bolshoi.BDMVProf.NinCat AS ``,Bolshoi.BDMVProf.R_Rvir AS ``,Bolshoi.BDMVProf.Rbin AS ``,Bolshoi.BDMVProf.np AS ``,Bolshoi.BDMVProf.mass AS ``,Bolshoi.BDMVProf.dens AS ``,Bolshoi.BDMVProf.Vcirc AS ``,Bolshoi.BDMVProf.VpropRms AS ``,Bolshoi.BDMVProf.Vrad AS ``,Bolshoi.BDMVProf.VradRms AS ``,Bolshoi.BDMVProf.boundR_Rvir AS ``,Bolshoi.BDMVProf.boundNp AS ``,Bolshoi.BDMVProf.boundMass AS ``,Bolshoi.BDMVProf.boundDens AS ``,Bolshoi.BDMVProf.boundVcirc AS ``,Bolshoi.BDMVProf.boundVcircRms AS ``,Bolshoi.BDMVProf.boundVrad AS ``,Bolshoi.BDMVProf.boundVradRms AS `` FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId` FROM `aggregation_tmp_72232374`  ORDER BY `Mvir` DESC  LIMIT 0,1)    ', 'aggregation_tmp_15605291');
CALL paquDropTmp('aggregation_tmp_72232374');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT ``,``,``,``,``,``,``,``,``,``,``,``,``,``,``,``,``,``,``,``,``
FROM `aggregation_tmp_15605291`  ORDER BY ``  ;
CALL paquDropTmp('aggregation_tmp_15605291');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`
FROM `aggregation_tmp_63645205`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId`
FROM `aggregation_tmp_63645205`  ORDER BY `Mvir` DESC  LIMIT 0,1)    
)


-- AGGREGATION SQL:
SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_33618594`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_63645205');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId` FROM `aggregation_tmp_63645205`  ORDER BY `Mvir` DESC  LIMIT 0,1)    ', 'aggregation_tmp_33618594');
CALL paquDropTmp('aggregation_tmp_63645205');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_33618594`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_33618594');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`
FROM `aggregation_tmp_67238972`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId`
FROM `aggregation_tmp_67238972`  ORDER BY `Mvir` DESC  LIMIT 0,1)    
)


-- AGGREGATION SQL:
SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_92144962`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_67238972');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId` FROM `aggregation_tmp_67238972`  ORDER BY `Mvir` DESC  LIMIT 0,1)    ', 'aggregation_tmp_92144962');
CALL paquDropTmp('aggregation_tmp_67238972');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_92144962`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_92144962');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`
FROM `aggregation_tmp_59513953`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId`
FROM `aggregation_tmp_59513953`  ORDER BY `Mvir` DESC  LIMIT 0,1)    
)


-- AGGREGATION SQL:
SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_88618116`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_59513953');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId` FROM `aggregation_tmp_59513953`  ORDER BY `Mvir` DESC  LIMIT 0,1)    ', 'aggregation_tmp_88618116');
CALL paquDropTmp('aggregation_tmp_59513953');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_88618116`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_88618116');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`
FROM `aggregation_tmp_14401339`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId`
FROM `aggregation_tmp_14401339`  ORDER BY `Mvir` DESC  LIMIT 0,1)    
)


-- AGGREGATION SQL:
SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_53069052`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_14401339');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId` FROM `aggregation_tmp_14401339`  ORDER BY `Mvir` DESC  LIMIT 0,1)    ', 'aggregation_tmp_53069052');
CALL paquDropTmp('aggregation_tmp_14401339');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_53069052`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_53069052');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`
FROM `aggregation_tmp_62358841`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId`
FROM `aggregation_tmp_62358841`  ORDER BY `Mvir` DESC  LIMIT 0,1)    
)


-- AGGREGATION SQL:
SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_51964942`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_62358841');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId` FROM `aggregation_tmp_62358841`  ORDER BY `Mvir` DESC  LIMIT 0,1)    ', 'aggregation_tmp_51964942');
CALL paquDropTmp('aggregation_tmp_62358841');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_51964942`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_51964942');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`
FROM `aggregation_tmp_73646661`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId`
FROM `aggregation_tmp_73646661`  ORDER BY `Mvir` DESC  LIMIT 0,1)    
)


-- AGGREGATION SQL:
SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_4423629`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_73646661');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId` FROM `aggregation_tmp_73646661`  ORDER BY `Mvir` DESC  LIMIT 0,1)    ', 'aggregation_tmp_4423629');
CALL paquDropTmp('aggregation_tmp_73646661');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_4423629`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_4423629');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`
FROM `aggregation_tmp_37554657`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId`
FROM `aggregation_tmp_37554657`  ORDER BY `Mvir` DESC  LIMIT 0,1)    
)


-- AGGREGATION SQL:
SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_58797371`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_37554657');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId` FROM `aggregation_tmp_37554657`  ORDER BY `Mvir` DESC  LIMIT 0,1)    ', 'aggregation_tmp_58797371');
CALL paquDropTmp('aggregation_tmp_37554657');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_58797371`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_58797371');
This is the query plan optimisation output for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z`
FROM MDR1.FOF AS `f` 
)


-- AGGREGATION SQL:
SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_22460889`   
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
-- INPUT SQL:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS `f.x`,f.`f.y` AS `f.y`,f.`f.z` AS `f.z`
FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_22460889`   ) AS `f`  WHERE POWER(b.x - `f`.`f.x`, 2) < 1000    LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_63841606`    LIMIT 0,1
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
This is the query plan for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

CALL paquExec('SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z` FROM MDR1.FOF AS `f` ', 'aggregation_tmp_22460889');
CALL paquExec('SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS `f.x`,f.`f.y` AS `f.y`,f.`f.z` AS `f.z` FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z` FROM `aggregation_tmp_22460889`   ) AS `f`  WHERE POWER(b.x - `f`.`f.x`, 2) < 1000    LIMIT 0,1', 'aggregation_tmp_63841606');
CALL paquDropTmp('aggregation_tmp_22460889');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_63841606`    LIMIT 0,1;
CALL paquDropTmp('aggregation_tmp_63841606');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`h.haloX`,`h.haloY`,`h.haloZ`,`h.hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`h.haloX`=VALUES(`h.haloX`),
`h.haloY`=VALUES(`h.haloY`),
`h.haloZ`=VALUES(`h.haloZ`),
`h.hR`=VALUES(`h.hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT h.haloX AS `h.haloX`,h.haloY AS `h.haloY`,h.haloZ AS `h.haloZ`,h.hR AS `h.hR`
FROM  AS `h` 
)


-- AGGREGATION SQL:
SELECT `h.haloX`,`h.haloY`,`h.haloZ`,`h.hR`
FROM `aggregation_tmp_1345181`   
ON DUPLICATE KEY UPDATE
`h.haloX`=VALUES(`h.haloX`),
`h.haloY`=VALUES(`h.haloY`),
`h.haloZ`=VALUES(`h.haloZ`),
`h.hR`=VALUES(`h.hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `h.haloX`,`h.haloY`,`h.haloZ`,`h.hR`
FROM `aggregation_tmp_1345181`   ) AS `h`  WHERE POWER(`h`.`haloX` - p.x, 2) + POWER(`h`.`haloY` - p.y, 2) + POWER(`h`.`haloZ` - p.z, 2) <= `h`.`hR` * `h`.`hR`   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_9286000`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT h.haloX AS `h.haloX`,h.haloY AS `h.haloY`,h.haloZ AS `h.haloZ`,h.hR AS `h.hR` FROM  AS `h` ', 'aggregation_tmp_1345181');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `h.haloX`,`h.haloY`,`h.haloZ`,`h.hR` FROM `aggregation_tmp_1345181`   ) AS `h`  WHERE POWER(`h`.`haloX` - p.x, 2) + POWER(`h`.`haloY` - p.y, 2) + POWER(`h`.`haloZ` - p.z, 2) <= `h`.`hR` * `h`.`hR`   ', 'aggregation_tmp_9286000');
CALL paquDropTmp('aggregation_tmp_1345181');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_9286000`   ;
CALL paquDropTmp('aggregation_tmp_9286000');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE descend.fofTreeId = 85000000000   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_30819987`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_30819987`   ) AS `descend`  WHERE prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId`   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_15439315`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE descend.fofTreeId = 85000000000   ', 'aggregation_tmp_30819987');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_30819987`   ) AS `descend`  WHERE prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId`   ', 'aggregation_tmp_15439315');
CALL paquDropTmp('aggregation_tmp_30819987');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_15439315`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_15439315');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE descend.fofTreeId = 85000000000   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_5535236`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_5535236`   ) AS `descend`  WHERE prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId`   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_42982109`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE descend.fofTreeId = 85000000000   ', 'aggregation_tmp_5535236');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_5535236`   ) AS `descend`  WHERE prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId`   ', 'aggregation_tmp_42982109');
CALL paquDropTmp('aggregation_tmp_5535236');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_42982109`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_42982109');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE descend.fofTreeId = 85000000000   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_66927114`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_66927114`   ) AS `descend`  WHERE prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId`   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_72063896`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE descend.fofTreeId = 85000000000   ', 'aggregation_tmp_66927114');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_66927114`   ) AS `descend`  WHERE prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId`   ', 'aggregation_tmp_72063896');
CALL paquDropTmp('aggregation_tmp_66927114');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_72063896`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_72063896');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE descend.fofTreeId = 85000000000   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_36228262`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_36228262`   ) AS `descend`  WHERE prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId`   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_31727422`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE descend.fofTreeId = 85000000000   ', 'aggregation_tmp_36228262');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_36228262`   ) AS `descend`  WHERE prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId`   ', 'aggregation_tmp_31727422');
CALL paquDropTmp('aggregation_tmp_36228262');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_31727422`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_31727422');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE descend.fofTreeId = 85000000000   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_20375789`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_20375789`   ) AS `descend`  WHERE prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId`   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_35556271`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE descend.fofTreeId = 85000000000   ', 'aggregation_tmp_20375789');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_20375789`   ) AS `descend`  WHERE prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId`   ', 'aggregation_tmp_35556271');
CALL paquDropTmp('aggregation_tmp_20375789');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_35556271`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_35556271');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `haloX`,y AS `haloY`,z AS `haloZ`,Rvir AS `hR`
FROM MDR1.BDMV WHERE bdmId = 6200000001   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_47451227`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_47451227`   ) AS `h`  WHERE POWER(`h`.`haloX` - p.x, 2) + POWER(`h`.`haloY` - p.y, 2) + POWER(`h`.`haloZ` - p.z, 2) <= `h`.`hR` * `h`.`hR`   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_70252430`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x AS `haloX`,y AS `haloY`,z AS `haloZ`,Rvir AS `hR` FROM MDR1.BDMV WHERE bdmId = 6200000001   ', 'aggregation_tmp_47451227');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_47451227`   ) AS `h`  WHERE POWER(`h`.`haloX` - p.x, 2) + POWER(`h`.`haloY` - p.y, 2) + POWER(`h`.`haloZ` - p.z, 2) <= `h`.`hR` * `h`.`hR`   ', 'aggregation_tmp_70252430');
CALL paquDropTmp('aggregation_tmp_47451227');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_70252430`   ;
CALL paquDropTmp('aggregation_tmp_70252430');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `haloX`,y AS `haloY`,z AS `haloZ`,Rvir AS `hR`
FROM MDR1.BDMV WHERE bdmId = 6200000001   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_24659407`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_24659407`   ) AS `h`  WHERE POWER(`h`.`haloX` - p.x, 2) + POWER(`h`.`haloY` - p.y, 2) + POWER(`h`.`haloZ` - p.z, 2) <= `h`.`hR` * `h`.`hR`   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_52723389`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x AS `haloX`,y AS `haloY`,z AS `haloZ`,Rvir AS `hR` FROM MDR1.BDMV WHERE bdmId = 6200000001   ', 'aggregation_tmp_24659407');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_24659407`   ) AS `h`  WHERE POWER(`h`.`haloX` - p.x, 2) + POWER(`h`.`haloY` - p.y, 2) + POWER(`h`.`haloZ` - p.z, 2) <= `h`.`hR` * `h`.`hR`   ', 'aggregation_tmp_52723389');
CALL paquDropTmp('aggregation_tmp_24659407');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_52723389`   ;
CALL paquDropTmp('aggregation_tmp_52723389');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `haloX`,y AS `haloY`,z AS `haloZ`,Rvir AS `hR`
FROM MDR1.BDMV WHERE bdmId = 6200000001   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_69054154`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_69054154`   ) AS `h`  WHERE POWER(`h`.`haloX` - p.x, 2) + POWER(`h`.`haloY` - p.y, 2) + POWER(`h`.`haloZ` - p.z, 2) <= `h`.`hR` * `h`.`hR`   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_58382828`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x AS `haloX`,y AS `haloY`,z AS `haloZ`,Rvir AS `hR` FROM MDR1.BDMV WHERE bdmId = 6200000001   ', 'aggregation_tmp_69054154');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_69054154`   ) AS `h`  WHERE POWER(`h`.`haloX` - p.x, 2) + POWER(`h`.`haloY` - p.y, 2) + POWER(`h`.`haloZ` - p.z, 2) <= `h`.`hR` * `h`.`hR`   ', 'aggregation_tmp_58382828');
CALL paquDropTmp('aggregation_tmp_69054154');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_58382828`   ;
CALL paquDropTmp('aggregation_tmp_58382828');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `haloX`,y AS `haloY`,z AS `haloZ`,Rvir AS `hR`
FROM MDR1.BDMV WHERE bdmId = 6200000001   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_87104914`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_87104914`   ) AS `h`  WHERE POWER(`h`.`haloX` - p.x, 2) + POWER(`h`.`haloY` - p.y, 2) + POWER(`h`.`haloZ` - p.z, 2) <= `h`.`hR` * `h`.`hR`   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_7815419`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x AS `haloX`,y AS `haloY`,z AS `haloZ`,Rvir AS `hR` FROM MDR1.BDMV WHERE bdmId = 6200000001   ', 'aggregation_tmp_87104914');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_87104914`   ) AS `h`  WHERE POWER(`h`.`haloX` - p.x, 2) + POWER(`h`.`haloY` - p.y, 2) + POWER(`h`.`haloZ` - p.z, 2) <= `h`.`hR` * `h`.`hR`   ', 'aggregation_tmp_7815419');
CALL paquDropTmp('aggregation_tmp_87104914');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_7815419`   ;
CALL paquDropTmp('aggregation_tmp_7815419');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `haloX`,y AS `haloY`,z AS `haloZ`,Rvir AS `hR`
FROM MDR1.BDMV WHERE bdmId = 6200000001   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_60345760`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_60345760`   ) AS `h`  WHERE POWER(`h`.`haloX` - p.x, 2) + POWER(`h`.`haloY` - p.y, 2) + POWER(`h`.`haloZ` - p.z, 2) <= `h`.`hR` * `h`.`hR`   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_26796451`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x AS `haloX`,y AS `haloY`,z AS `haloZ`,Rvir AS `hR` FROM MDR1.BDMV WHERE bdmId = 6200000001   ', 'aggregation_tmp_60345760');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_60345760`   ) AS `h`  WHERE POWER(`h`.`haloX` - p.x, 2) + POWER(`h`.`haloY` - p.y, 2) + POWER(`h`.`haloZ` - p.z, 2) <= `h`.`hR` * `h`.`hR`   ', 'aggregation_tmp_26796451');
CALL paquDropTmp('aggregation_tmp_60345760');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_26796451`   ;
CALL paquDropTmp('aggregation_tmp_26796451');
This is the query plan optimisation output for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`DES.fofTreeId`=VALUES(`DES.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,DES.fofTreeId AS `DES.fofTreeId`
FROM MDR1.FOFMtree AS `DES` WHERE DES.treeSnapnum = 39   
)


-- AGGREGATION SQL:
SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId`
FROM `aggregation_tmp_82567424`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`DES.fofTreeId`=VALUES(`DES.fofTreeId`)
-- INPUT SQL:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`PROG.fofTreeId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`PROG.fofTreeId`=VALUES(`PROG.fofTreeId`),
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,PROG.fofTreeId AS `PROG.fofTreeId`,DES.`DES.mass` AS `DES.mass`,DES.`DES.treeSnapnum` AS `DES.treeSnapnum`,DES.`DES.fofId` AS `DES.fofId`,DES.`DES.lastProgId` AS `DES.lastProgId`
FROM MDR1.FOFMtree AS `PROG` JOIN ( SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId`
FROM `aggregation_tmp_82567424`  ORDER BY `DES.fofId` ASC ) AS `DES`  WHERE PROG.mass > 1.e13 AND PROG.fofTreeId BETWEEN `DES`.`DES.fofTreeId` AND `DES`.`DES.lastProgId`   
)


-- AGGREGATION SQL:
SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`PROG.fofTreeId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`
FROM `aggregation_tmp_75093228`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`PROG.fofTreeId`=VALUES(`PROG.fofTreeId`),
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`)
This is the query plan for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

CALL paquExec('SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,DES.fofTreeId AS `DES.fofTreeId` FROM MDR1.FOFMtree AS `DES` WHERE DES.treeSnapnum = 39   ', 'aggregation_tmp_82567424');
CALL paquExec('SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,PROG.fofTreeId AS `PROG.fofTreeId`,DES.`DES.mass` AS `DES.mass`,DES.`DES.treeSnapnum` AS `DES.treeSnapnum`,DES.`DES.fofId` AS `DES.fofId`,DES.`DES.lastProgId` AS `DES.lastProgId` FROM MDR1.FOFMtree AS `PROG` JOIN ( SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId` FROM `aggregation_tmp_82567424`  ORDER BY `DES.fofId` ASC ) AS `DES`  WHERE PROG.mass > 1.e13 AND PROG.fofTreeId BETWEEN `DES`.`DES.fofTreeId` AND `DES`.`DES.lastProgId`   ', 'aggregation_tmp_75093228');
CALL paquDropTmp('aggregation_tmp_82567424');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`PROG.fofTreeId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`
FROM `aggregation_tmp_75093228`  ORDER BY `DES.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_75093228');
This is the query plan optimisation output for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`DES.fofTreeId`=VALUES(`DES.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,DES.fofTreeId AS `DES.fofTreeId`
FROM MDR1.FOFMtree AS `DES` WHERE DES.treeSnapnum = 39   
)


-- AGGREGATION SQL:
SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId`
FROM `aggregation_tmp_75033927`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`DES.fofTreeId`=VALUES(`DES.fofTreeId`)
-- INPUT SQL:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`PROG.fofTreeId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`PROG.fofTreeId`=VALUES(`PROG.fofTreeId`),
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,PROG.fofTreeId AS `PROG.fofTreeId`,DES.`DES.mass` AS `DES.mass`,DES.`DES.treeSnapnum` AS `DES.treeSnapnum`,DES.`DES.fofId` AS `DES.fofId`,DES.`DES.lastProgId` AS `DES.lastProgId`
FROM MDR1.FOFMtree AS `PROG` JOIN ( SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId`
FROM `aggregation_tmp_75033927`  ORDER BY `DES.fofId` ASC ) AS `DES`  WHERE PROG.mass > 1.e13 AND PROG.fofTreeId BETWEEN `DES`.`DES.fofTreeId` AND `DES`.`DES.lastProgId`   
)


-- AGGREGATION SQL:
SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`PROG.fofTreeId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`
FROM `aggregation_tmp_24157638`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`PROG.fofTreeId`=VALUES(`PROG.fofTreeId`),
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`)
This is the query plan for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

CALL paquExec('SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,DES.fofTreeId AS `DES.fofTreeId` FROM MDR1.FOFMtree AS `DES` WHERE DES.treeSnapnum = 39   ', 'aggregation_tmp_75033927');
CALL paquExec('SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,PROG.fofTreeId AS `PROG.fofTreeId`,DES.`DES.mass` AS `DES.mass`,DES.`DES.treeSnapnum` AS `DES.treeSnapnum`,DES.`DES.fofId` AS `DES.fofId`,DES.`DES.lastProgId` AS `DES.lastProgId` FROM MDR1.FOFMtree AS `PROG` JOIN ( SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId` FROM `aggregation_tmp_75033927`  ORDER BY `DES.fofId` ASC ) AS `DES`  WHERE PROG.mass > 1.e13 AND PROG.fofTreeId BETWEEN `DES`.`DES.fofTreeId` AND `DES`.`DES.lastProgId`   ', 'aggregation_tmp_24157638');
CALL paquDropTmp('aggregation_tmp_75033927');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`PROG.fofTreeId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`
FROM `aggregation_tmp_24157638`  ORDER BY `DES.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_24157638');
This is the query plan optimisation output for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`DES.fofTreeId`=VALUES(`DES.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,DES.fofTreeId AS `DES.fofTreeId`
FROM MDR1.FOFMtree AS `DES` WHERE DES.treeSnapnum = 39   
)


-- AGGREGATION SQL:
SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId`
FROM `aggregation_tmp_29267210`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`DES.fofTreeId`=VALUES(`DES.fofTreeId`)
-- INPUT SQL:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`PROG.fofTreeId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`PROG.fofTreeId`=VALUES(`PROG.fofTreeId`),
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,PROG.fofTreeId AS `PROG.fofTreeId`,DES.`DES.mass` AS `DES.mass`,DES.`DES.treeSnapnum` AS `DES.treeSnapnum`,DES.`DES.fofId` AS `DES.fofId`,DES.`DES.lastProgId` AS `DES.lastProgId`
FROM MDR1.FOFMtree AS `PROG` JOIN ( SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId`
FROM `aggregation_tmp_29267210`  ORDER BY `DES.fofId` ASC ) AS `DES`  WHERE PROG.mass > 1.e13 AND PROG.fofTreeId BETWEEN `DES`.`DES.fofTreeId` AND `DES`.`DES.lastProgId`   
)


-- AGGREGATION SQL:
SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`PROG.fofTreeId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`
FROM `aggregation_tmp_73177396`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`PROG.fofTreeId`=VALUES(`PROG.fofTreeId`),
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`)
This is the query plan for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

CALL paquExec('SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,DES.fofTreeId AS `DES.fofTreeId` FROM MDR1.FOFMtree AS `DES` WHERE DES.treeSnapnum = 39   ', 'aggregation_tmp_29267210');
CALL paquExec('SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,PROG.fofTreeId AS `PROG.fofTreeId`,DES.`DES.mass` AS `DES.mass`,DES.`DES.treeSnapnum` AS `DES.treeSnapnum`,DES.`DES.fofId` AS `DES.fofId`,DES.`DES.lastProgId` AS `DES.lastProgId` FROM MDR1.FOFMtree AS `PROG` JOIN ( SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId` FROM `aggregation_tmp_29267210`  ORDER BY `DES.fofId` ASC ) AS `DES`  WHERE PROG.mass > 1.e13 AND PROG.fofTreeId BETWEEN `DES`.`DES.fofTreeId` AND `DES`.`DES.lastProgId`   ', 'aggregation_tmp_73177396');
CALL paquDropTmp('aggregation_tmp_29267210');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`PROG.fofTreeId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`
FROM `aggregation_tmp_73177396`  ORDER BY `DES.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_73177396');
This is the query plan optimisation output for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`DES.fofTreeId`=VALUES(`DES.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,DES.fofTreeId AS `DES.fofTreeId`
FROM MDR1.FOFMtree AS `DES` WHERE DES.treeSnapnum = 39   
)


-- AGGREGATION SQL:
SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId`
FROM `aggregation_tmp_83762522`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`DES.fofTreeId`=VALUES(`DES.fofTreeId`)
-- INPUT SQL:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`PROG.fofTreeId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`PROG.fofTreeId`=VALUES(`PROG.fofTreeId`),
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,PROG.fofTreeId AS `PROG.fofTreeId`,DES.`DES.mass` AS `DES.mass`,DES.`DES.treeSnapnum` AS `DES.treeSnapnum`,DES.`DES.fofId` AS `DES.fofId`,DES.`DES.lastProgId` AS `DES.lastProgId`
FROM MDR1.FOFMtree AS `PROG` JOIN ( SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId`
FROM `aggregation_tmp_83762522`  ORDER BY `DES.fofId` ASC ) AS `DES`  WHERE PROG.mass > 1.e13 AND PROG.fofTreeId BETWEEN `DES`.`DES.fofTreeId` AND `DES`.`DES.lastProgId`   
)


-- AGGREGATION SQL:
SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`PROG.fofTreeId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`
FROM `aggregation_tmp_77023692`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`PROG.fofTreeId`=VALUES(`PROG.fofTreeId`),
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`)
This is the query plan for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

CALL paquExec('SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,DES.fofTreeId AS `DES.fofTreeId` FROM MDR1.FOFMtree AS `DES` WHERE DES.treeSnapnum = 39   ', 'aggregation_tmp_83762522');
CALL paquExec('SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,PROG.fofTreeId AS `PROG.fofTreeId`,DES.`DES.mass` AS `DES.mass`,DES.`DES.treeSnapnum` AS `DES.treeSnapnum`,DES.`DES.fofId` AS `DES.fofId`,DES.`DES.lastProgId` AS `DES.lastProgId` FROM MDR1.FOFMtree AS `PROG` JOIN ( SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId` FROM `aggregation_tmp_83762522`  ORDER BY `DES.fofId` ASC ) AS `DES`  WHERE PROG.mass > 1.e13 AND PROG.fofTreeId BETWEEN `DES`.`DES.fofTreeId` AND `DES`.`DES.lastProgId`   ', 'aggregation_tmp_77023692');
CALL paquDropTmp('aggregation_tmp_83762522');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`PROG.fofTreeId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`
FROM `aggregation_tmp_77023692`  ORDER BY `DES.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_77023692');
This is the query plan optimisation output for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`DES.fofTreeId`=VALUES(`DES.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,DES.fofTreeId AS `DES.fofTreeId`
FROM MDR1.FOFMtree AS `DES` WHERE DES.treeSnapnum = 39   
)


-- AGGREGATION SQL:
SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId`
FROM `aggregation_tmp_69745548`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`DES.fofTreeId`=VALUES(`DES.fofTreeId`)
-- INPUT SQL:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`PROG.fofTreeId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`PROG.fofTreeId`=VALUES(`PROG.fofTreeId`),
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,PROG.fofTreeId AS `PROG.fofTreeId`,DES.`DES.mass` AS `DES.mass`,DES.`DES.treeSnapnum` AS `DES.treeSnapnum`,DES.`DES.fofId` AS `DES.fofId`,DES.`DES.lastProgId` AS `DES.lastProgId`
FROM MDR1.FOFMtree AS `PROG` JOIN ( SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId`
FROM `aggregation_tmp_69745548`  ORDER BY `DES.fofId` ASC ) AS `DES`  WHERE PROG.mass > 1.e13 AND PROG.fofTreeId BETWEEN `DES`.`DES.fofTreeId` AND `DES`.`DES.lastProgId`   
)


-- AGGREGATION SQL:
SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`PROG.fofTreeId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`
FROM `aggregation_tmp_42537772`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`PROG.fofTreeId`=VALUES(`PROG.fofTreeId`),
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`)
This is the query plan for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

CALL paquExec('SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,DES.fofTreeId AS `DES.fofTreeId` FROM MDR1.FOFMtree AS `DES` WHERE DES.treeSnapnum = 39   ', 'aggregation_tmp_69745548');
CALL paquExec('SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,PROG.fofTreeId AS `PROG.fofTreeId`,DES.`DES.mass` AS `DES.mass`,DES.`DES.treeSnapnum` AS `DES.treeSnapnum`,DES.`DES.fofId` AS `DES.fofId`,DES.`DES.lastProgId` AS `DES.lastProgId` FROM MDR1.FOFMtree AS `PROG` JOIN ( SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId` FROM `aggregation_tmp_69745548`  ORDER BY `DES.fofId` ASC ) AS `DES`  WHERE PROG.mass > 1.e13 AND PROG.fofTreeId BETWEEN `DES`.`DES.fofTreeId` AND `DES`.`DES.lastProgId`   ', 'aggregation_tmp_42537772');
CALL paquDropTmp('aggregation_tmp_69745548');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`PROG.fofTreeId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`
FROM `aggregation_tmp_42537772`  ORDER BY `DES.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_42537772');
This is the query plan optimisation output for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`DES.fofTreeId`=VALUES(`DES.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,DES.fofTreeId AS `DES.fofTreeId`
FROM MDR1.FOFMtree AS `DES` WHERE DES.treeSnapnum = 39   
)


-- AGGREGATION SQL:
SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId`
FROM `aggregation_tmp_77888968`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`DES.fofTreeId`=VALUES(`DES.fofTreeId`)
-- INPUT SQL:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`PROG.fofTreeId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`PROG.fofTreeId`=VALUES(`PROG.fofTreeId`),
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,PROG.fofTreeId AS `PROG.fofTreeId`,DES.`DES.mass` AS `DES.mass`,DES.`DES.treeSnapnum` AS `DES.treeSnapnum`,DES.`DES.fofId` AS `DES.fofId`,DES.`DES.lastProgId` AS `DES.lastProgId`
FROM MDR1.FOFMtree AS `PROG` JOIN ( SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId`
FROM `aggregation_tmp_77888968`  ORDER BY `DES.fofId` ASC ) AS `DES`  WHERE PROG.mass > 1.e13 AND PROG.fofTreeId BETWEEN `DES`.`DES.fofTreeId` AND `DES`.`DES.lastProgId`   
)


-- AGGREGATION SQL:
SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`PROG.fofTreeId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`
FROM `aggregation_tmp_13979234`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`PROG.fofTreeId`=VALUES(`PROG.fofTreeId`),
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`)
This is the query plan for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

CALL paquExec('SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,DES.fofTreeId AS `DES.fofTreeId` FROM MDR1.FOFMtree AS `DES` WHERE DES.treeSnapnum = 39   ', 'aggregation_tmp_77888968');
CALL paquExec('SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,PROG.fofTreeId AS `PROG.fofTreeId`,DES.`DES.mass` AS `DES.mass`,DES.`DES.treeSnapnum` AS `DES.treeSnapnum`,DES.`DES.fofId` AS `DES.fofId`,DES.`DES.lastProgId` AS `DES.lastProgId` FROM MDR1.FOFMtree AS `PROG` JOIN ( SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId` FROM `aggregation_tmp_77888968`  ORDER BY `DES.fofId` ASC ) AS `DES`  WHERE PROG.mass > 1.e13 AND PROG.fofTreeId BETWEEN `DES`.`DES.fofTreeId` AND `DES`.`DES.lastProgId`   ', 'aggregation_tmp_13979234');
CALL paquDropTmp('aggregation_tmp_77888968');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`PROG.fofTreeId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`
FROM `aggregation_tmp_13979234`  ORDER BY `DES.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_13979234');
This is the query plan optimisation output for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`DES.fofTreeId`=VALUES(`DES.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,DES.fofTreeId AS `DES.fofTreeId`
FROM MDR1.FOFMtree AS `DES` WHERE DES.treeSnapnum = 39   
)


-- AGGREGATION SQL:
SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId`
FROM `aggregation_tmp_94985272`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`),
`DES.fofTreeId`=VALUES(`DES.fofTreeId`)
-- INPUT SQL:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,DES.`DES.mass` AS `DES.mass`,DES.`DES.treeSnapnum` AS `DES.treeSnapnum`,DES.`DES.fofId` AS `DES.fofId`,DES.`DES.lastProgId` AS `DES.lastProgId`
FROM MDR1.FOFMtree AS `PROG` JOIN ( SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId`
FROM `aggregation_tmp_94985272`  ORDER BY `DES.fofId` ASC ) AS `DES`  WHERE PROG.mass > 1.e13 AND PROG.fofTreeId BETWEEN `DES`.`DES.fofTreeId` AND `DES`.`DES.lastProgId`   
)


-- AGGREGATION SQL:
SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`
FROM `aggregation_tmp_27497840`  ORDER BY `DES.fofId` ASC 
ON DUPLICATE KEY UPDATE
`PROG.mass`=VALUES(`PROG.mass`),
`PROG.treeSnapnum`=VALUES(`PROG.treeSnapnum`),
`PROG.fofId`=VALUES(`PROG.fofId`),
`DES.mass`=VALUES(`DES.mass`),
`DES.treeSnapnum`=VALUES(`DES.treeSnapnum`),
`DES.fofId`=VALUES(`DES.fofId`),
`DES.lastProgId`=VALUES(`DES.lastProgId`)
This is the query plan for the query:
SELECT PROG.mass, PROG.treeSnapnum, DES.mass, DES.treeSnapnum, DES.fofId, PROG.fofId, DES.lastProgId FROM MDR1.FOFMtree AS PROG, MDR1.FOFMtree AS DES WHERE DES.treeSnapnum=39 AND PROG.fofTreeId BETWEEN DES.fofTreeId AND DES.lastProgId AND PROG.mass > 1.e13 ORDER BY DES.fofId

CALL paquExec('SELECT DES.mass AS `DES.mass`,DES.treeSnapnum AS `DES.treeSnapnum`,DES.fofId AS `DES.fofId`,DES.lastProgId AS `DES.lastProgId`,DES.fofTreeId AS `DES.fofTreeId` FROM MDR1.FOFMtree AS `DES` WHERE DES.treeSnapnum = 39   ', 'aggregation_tmp_94985272');
CALL paquExec('SELECT PROG.mass AS `PROG.mass`,PROG.treeSnapnum AS `PROG.treeSnapnum`,PROG.fofId AS `PROG.fofId`,DES.`DES.mass` AS `DES.mass`,DES.`DES.treeSnapnum` AS `DES.treeSnapnum`,DES.`DES.fofId` AS `DES.fofId`,DES.`DES.lastProgId` AS `DES.lastProgId` FROM MDR1.FOFMtree AS `PROG` JOIN ( SELECT `DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`,`DES.fofTreeId` FROM `aggregation_tmp_94985272`  ORDER BY `DES.fofId` ASC ) AS `DES`  WHERE PROG.mass > 1.e13 AND PROG.fofTreeId BETWEEN `DES`.`DES.fofTreeId` AND `DES`.`DES.lastProgId`   ', 'aggregation_tmp_27497840');
CALL paquDropTmp('aggregation_tmp_94985272');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `PROG.mass`,`PROG.treeSnapnum`,`PROG.fofId`,`DES.mass`,`DES.treeSnapnum`,`DES.fofId`,`DES.lastProgId`
FROM `aggregation_tmp_27497840`  ORDER BY `DES.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_27497840');
This is the query plan optimisation output for the query:
SELECT x,y,z FROM MDR1.Particles85 WHERE RAND(154321) <= 2.91E-5

-- INPUT SQL:
SELECT x,y,z FROM MDR1.Particles85 WHERE RAND(154321) <= 2.91E-5

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`,`y`,`z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`,y AS `y`,z AS `z`
FROM MDR1.Particles85 
)


-- AGGREGATION SQL:
SELECT `x`,`y`,`z`
FROM `aggregation_tmp_5172802`   
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`)
This is the query plan for the query:
SELECT x,y,z FROM MDR1.Particles85 WHERE RAND(154321) <= 2.91E-5

CALL paquExec('SELECT x AS `x`,y AS `y`,z AS `z` FROM MDR1.Particles85 ', 'aggregation_tmp_5172802');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `x`,`y`,`z`
FROM `aggregation_tmp_5172802`   ;
CALL paquDropTmp('aggregation_tmp_5172802');
This is the query plan optimisation output for the query:
SELECT x,y,z FROM MDR1.Particles85 WHERE RAND(154321) <= 2.91E-5

-- INPUT SQL:
SELECT x,y,z FROM MDR1.Particles85 WHERE RAND(154321) <= 2.91E-5

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`,`y`,`z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`,y AS `y`,z AS `z`
FROM MDR1.Particles85 
)


-- AGGREGATION SQL:
SELECT `x`,`y`,`z`
FROM `aggregation_tmp_9090950`   
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`)
This is the query plan for the query:
SELECT x,y,z FROM MDR1.Particles85 WHERE RAND(154321) <= 2.91E-5

CALL paquExec('SELECT x AS `x`,y AS `y`,z AS `z` FROM MDR1.Particles85 ', 'aggregation_tmp_9090950');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `x`,`y`,`z`
FROM `aggregation_tmp_9090950`   ;
CALL paquDropTmp('aggregation_tmp_9090950');
This is the query plan optimisation output for the query:
SELECT x,y,z FROM MDR1.Particles85 WHERE RAND(154321) <= 2.91E-5

-- INPUT SQL:
SELECT x,y,z FROM MDR1.Particles85 WHERE RAND(154321) <= 2.91E-5

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`,`y`,`z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`,y AS `y`,z AS `z`
FROM MDR1.Particles85 WHERE RAND(154321) <= 2.91E-5   
)


-- AGGREGATION SQL:
SELECT `x`,`y`,`z`
FROM `aggregation_tmp_66979974`   
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`)
This is the query plan for the query:
SELECT x,y,z FROM MDR1.Particles85 WHERE RAND(154321) <= 2.91E-5

CALL paquExec('SELECT x AS `x`,y AS `y`,z AS `z` FROM MDR1.Particles85 WHERE RAND(154321) <= 2.91E-5   ', 'aggregation_tmp_66979974');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `x`,`y`,`z`
FROM `aggregation_tmp_66979974`   ;
CALL paquDropTmp('aggregation_tmp_66979974');
This is the query plan optimisation output for the query:
SELECT sprng_make_seed(), count(abs(*));

-- INPUT SQL:
SELECT sprng_make_seed(), count(abs(*));

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_sprng_make_seed_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_count_abs_*_`=`_count_abs_*_` +  VALUES(`_count_abs_*_`),
`_sprng_make_seed_`=VALUES(`_sprng_make_seed_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT COUNT(abs(*)) AS `_count_abs_*_`,sprng_make_seed() AS `_sprng_make_seed_` 
)


-- AGGREGATION SQL:
SELECT SUM(`_count_abs_*_`) AS `_count_abs_*_`,`_sprng_make_seed_`
FROM `aggregation_tmp_39660404`   
ON DUPLICATE KEY UPDATE
`_count_abs_*_`=`_count_abs_*_` +  VALUES(`_count_abs_*_`),
`_sprng_make_seed_`=VALUES(`_sprng_make_seed_`)
This is the query plan for the query:
SELECT sprng_make_seed(), count(abs(*));

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_39660404 ENGINE=MyISAM SELECT COUNT(abs(*)) AS `_count_abs_*_`,sprng_make_seed() AS `_sprng_make_seed_`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_39660404 SELECT COUNT(abs(*)) AS `_count_abs_*_`,sprng_make_seed() AS `_sprng_make_seed_` ;
CALL paquLinkTmp('aggregation_tmp_39660404');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT SUM(`_count_abs_*_`) AS `_count_abs_*_`,`_sprng_make_seed_`
FROM `aggregation_tmp_39660404`   ;
CALL paquDropTmp('aggregation_tmp_39660404');
This is the query plan optimisation output for the query:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a;

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`id`=VALUES(`id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT id AS `id`
FROM t1 JOIN t2  JOIN t3  
)


-- AGGREGATION SQL:
SELECT `id`
FROM `aggregation_tmp_17469036`   
ON DUPLICATE KEY UPDATE
`id`=VALUES(`id`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1_id`,`date_id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1_id AS `t1_id`,date_id AS `date_id`
FROM t1 JOIN t2  JOIN t3  JOIN ( SELECT `id`
FROM `aggregation_tmp_17469036`   )  
)


-- AGGREGATION SQL:
SELECT `t1_id`,`date_id`
FROM `aggregation_tmp_51824786`   
ON DUPLICATE KEY UPDATE
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)
-- INPUT SQL:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a;

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1.a`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*_`=`_count_*_` +  VALUES(`_count_*_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*_`
FROM t1 JOIN t2  JOIN t3  JOIN ( SELECT `t1_id`,`date_id`
FROM `aggregation_tmp_51824786`   )  GROUP BY t1.a 
)


-- AGGREGATION SQL:
SELECT `t1.a`,SUM(`_count_*_`) AS `_count_*_`
FROM `aggregation_tmp_75974073`  GROUP BY `t1.a`  
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*_`=`_count_*_` +  VALUES(`_count_*_`)
This is the query plan for the query:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a;

CALL paquExec('SELECT id AS `id` FROM t1 JOIN t2  JOIN t3  ', 'aggregation_tmp_17469036');
CALL paquExec('SELECT t1_id AS `t1_id`,date_id AS `date_id` FROM t1 JOIN t2  JOIN t3  JOIN ( SELECT `id` FROM `aggregation_tmp_17469036`   )  ', 'aggregation_tmp_51824786');
CALL paquExec('SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*_` FROM t1 JOIN t2  JOIN t3  JOIN ( SELECT `t1_id`,`date_id` FROM `aggregation_tmp_51824786`   )  GROUP BY t1.a ', 'aggregation_tmp_75974073');
CALL paquDropTmp('aggregation_tmp_17469036');
CALL paquDropTmp('aggregation_tmp_51824786');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `t1.a`,SUM(`_count_*_`) AS `_count_*_`
FROM `aggregation_tmp_75974073`  GROUP BY `t1.a`  ;
CALL paquDropTmp('aggregation_tmp_75974073');
This is the query plan optimisation output for the query:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a;

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`id`=VALUES(`id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT id AS `id`
FROM t1 JOIN t2  JOIN t3  
)


-- AGGREGATION SQL:
SELECT `id`
FROM `aggregation_tmp_81382682`   
ON DUPLICATE KEY UPDATE
`id`=VALUES(`id`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1_id`,`date_id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1_id AS `t1_id`,date_id AS `date_id`
FROM t1 JOIN t2  JOIN t3  JOIN ( SELECT `id`
FROM `aggregation_tmp_81382682`   )  
)


-- AGGREGATION SQL:
SELECT `t1_id`,`date_id`
FROM `aggregation_tmp_70543003`   
ON DUPLICATE KEY UPDATE
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)
-- INPUT SQL:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a;

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1.a`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*_`=`_count_*_` +  VALUES(`_count_*_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*_`
FROM t1 JOIN t2  JOIN t3  JOIN ( SELECT `t1_id`,`date_id`
FROM `aggregation_tmp_70543003`   )  GROUP BY t1.a 
)


-- AGGREGATION SQL:
SELECT `t1.a`,SUM(`_count_*_`) AS `_count_*_`
FROM `aggregation_tmp_40932126`  GROUP BY `t1.a`  
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*_`=`_count_*_` +  VALUES(`_count_*_`)
This is the query plan for the query:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a;

CALL paquExec('SELECT id AS `id` FROM t1 JOIN t2  JOIN t3  ', 'aggregation_tmp_81382682');
CALL paquExec('SELECT t1_id AS `t1_id`,date_id AS `date_id` FROM t1 JOIN t2  JOIN t3  JOIN ( SELECT `id` FROM `aggregation_tmp_81382682`   )  ', 'aggregation_tmp_70543003');
CALL paquExec('SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*_` FROM t1 JOIN t2  JOIN t3  JOIN ( SELECT `t1_id`,`date_id` FROM `aggregation_tmp_70543003`   )  GROUP BY t1.a ', 'aggregation_tmp_40932126');
CALL paquDropTmp('aggregation_tmp_81382682');
CALL paquDropTmp('aggregation_tmp_70543003');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `t1.a`,SUM(`_count_*_`) AS `_count_*_`
FROM `aggregation_tmp_40932126`  GROUP BY `t1.a`  ;
CALL paquDropTmp('aggregation_tmp_40932126');
This is the query plan optimisation output for the query:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a;

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`id`=VALUES(`id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT id AS `id`
FROM t1 JOIN t2  JOIN t3  
)


-- AGGREGATION SQL:
SELECT `id`
FROM `aggregation_tmp_23457338`   
ON DUPLICATE KEY UPDATE
`id`=VALUES(`id`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1_id`,`date_id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1_id AS `t1_id`,date_id AS `date_id`
FROM t1 JOIN t2  JOIN t3  JOIN ( SELECT `id`
FROM `aggregation_tmp_23457338`   )  
)


-- AGGREGATION SQL:
SELECT `t1_id`,`date_id`
FROM `aggregation_tmp_69006902`   
ON DUPLICATE KEY UPDATE
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)
-- INPUT SQL:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a;

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1.a`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*_`=`_count_*_` +  VALUES(`_count_*_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*_`
FROM t1 JOIN t2  JOIN t3  JOIN ( SELECT `t1_id`,`date_id`
FROM `aggregation_tmp_69006902`   )  GROUP BY t1.a 
)


-- AGGREGATION SQL:
SELECT `t1.a`,SUM(`_count_*_`) AS `_count_*_`
FROM `aggregation_tmp_56719427`  GROUP BY `t1.a`  
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*_`=`_count_*_` +  VALUES(`_count_*_`)
This is the query plan for the query:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a;

CALL paquExec('SELECT id AS `id` FROM t1 JOIN t2  JOIN t3  ', 'aggregation_tmp_23457338');
CALL paquExec('SELECT t1_id AS `t1_id`,date_id AS `date_id` FROM t1 JOIN t2  JOIN t3  JOIN ( SELECT `id` FROM `aggregation_tmp_23457338`   )  ', 'aggregation_tmp_69006902');
CALL paquExec('SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*_` FROM t1 JOIN t2  JOIN t3  JOIN ( SELECT `t1_id`,`date_id` FROM `aggregation_tmp_69006902`   )  GROUP BY t1.a ', 'aggregation_tmp_56719427');
CALL paquDropTmp('aggregation_tmp_23457338');
CALL paquDropTmp('aggregation_tmp_69006902');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `t1.a`,SUM(`_count_*_`) AS `_count_*_`
FROM `aggregation_tmp_56719427`  GROUP BY `t1.a`  ;
CALL paquDropTmp('aggregation_tmp_56719427');
This is the query plan optimisation output for the query:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a;

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`id`=VALUES(`id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT id AS `id`
FROM t1 JOIN t2  JOIN t3  
)


-- AGGREGATION SQL:
SELECT `id`
FROM `aggregation_tmp_14036`   
ON DUPLICATE KEY UPDATE
`id`=VALUES(`id`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1_id`,`date_id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1_id AS `t1_id`,date_id AS `date_id`
FROM t1 JOIN t2  JOIN t3  JOIN ( SELECT `id`
FROM `aggregation_tmp_14036`   )  
)


-- AGGREGATION SQL:
SELECT `t1_id`,`date_id`
FROM `aggregation_tmp_64369711`   
ON DUPLICATE KEY UPDATE
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)
-- INPUT SQL:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a;

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1.a`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*_`=`_count_*_` +  VALUES(`_count_*_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*_`
FROM t1 JOIN t2  JOIN t3  JOIN ( SELECT `t1_id`,`date_id`
FROM `aggregation_tmp_64369711`   )  GROUP BY t1.a 
)


-- AGGREGATION SQL:
SELECT `t1.a`,SUM(`_count_*_`) AS `_count_*_`
FROM `aggregation_tmp_20273078`  GROUP BY `t1.a`  
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*_`=`_count_*_` +  VALUES(`_count_*_`)
This is the query plan for the query:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a;

CALL paquExec('SELECT id AS `id` FROM t1 JOIN t2  JOIN t3  ', 'aggregation_tmp_14036');
CALL paquExec('SELECT t1_id AS `t1_id`,date_id AS `date_id` FROM t1 JOIN t2  JOIN t3  JOIN ( SELECT `id` FROM `aggregation_tmp_14036`   )  ', 'aggregation_tmp_64369711');
CALL paquExec('SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*_` FROM t1 JOIN t2  JOIN t3  JOIN ( SELECT `t1_id`,`date_id` FROM `aggregation_tmp_64369711`   )  GROUP BY t1.a ', 'aggregation_tmp_20273078');
CALL paquDropTmp('aggregation_tmp_14036');
CALL paquDropTmp('aggregation_tmp_64369711');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `t1.a`,SUM(`_count_*_`) AS `_count_*_`
FROM `aggregation_tmp_20273078`  GROUP BY `t1.a`  ;
CALL paquDropTmp('aggregation_tmp_20273078');
This is the query plan optimisation output for the query:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a;

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`id`=VALUES(`id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT id AS `id`
FROM t3 
)


-- AGGREGATION SQL:
SELECT `id`
FROM `aggregation_tmp_35368203`   
ON DUPLICATE KEY UPDATE
`id`=VALUES(`id`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1_id`,`date_id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1_id AS `t1_id`,date_id AS `date_id`
FROM t2 JOIN ( SELECT `id`
FROM `aggregation_tmp_35368203`   )  
)


-- AGGREGATION SQL:
SELECT `t1_id`,`date_id`
FROM `aggregation_tmp_54431121`   
ON DUPLICATE KEY UPDATE
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)
-- INPUT SQL:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a;

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1.a`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*_`=`_count_*_` +  VALUES(`_count_*_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*_`
FROM t1 JOIN ( SELECT `t1_id`,`date_id`
FROM `aggregation_tmp_54431121`   )  GROUP BY t1.a 
)


-- AGGREGATION SQL:
SELECT `t1.a`,SUM(`_count_*_`) AS `_count_*_`
FROM `aggregation_tmp_53584264`  GROUP BY `t1.a`  
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*_`=`_count_*_` +  VALUES(`_count_*_`)
This is the query plan for the query:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a;

CALL paquExec('SELECT id AS `id` FROM t3 ', 'aggregation_tmp_35368203');
CALL paquExec('SELECT t1_id AS `t1_id`,date_id AS `date_id` FROM t2 JOIN ( SELECT `id` FROM `aggregation_tmp_35368203`   )  ', 'aggregation_tmp_54431121');
CALL paquExec('SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*_` FROM t1 JOIN ( SELECT `t1_id`,`date_id` FROM `aggregation_tmp_54431121`   )  GROUP BY t1.a ', 'aggregation_tmp_53584264');
CALL paquDropTmp('aggregation_tmp_35368203');
CALL paquDropTmp('aggregation_tmp_54431121');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `t1.a`,SUM(`_count_*_`) AS `_count_*_`
FROM `aggregation_tmp_53584264`  GROUP BY `t1.a`  ;
CALL paquDropTmp('aggregation_tmp_53584264');
This is the query plan optimisation output for the query:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a;

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`id`=VALUES(`id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT id AS `id`
FROM t3 
)


-- AGGREGATION SQL:
SELECT `id`
FROM `aggregation_tmp_98060197`   
ON DUPLICATE KEY UPDATE
`id`=VALUES(`id`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1_id`,`date_id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1_id AS `t1_id`,date_id AS `date_id`
FROM t2 JOIN ( SELECT `id`
FROM `aggregation_tmp_98060197`   )  
)


-- AGGREGATION SQL:
SELECT `t1_id`,`date_id`
FROM `aggregation_tmp_57312281`   
ON DUPLICATE KEY UPDATE
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)
-- INPUT SQL:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a;

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1.a`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*_`=`_count_*_` +  VALUES(`_count_*_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*_`
FROM t1 JOIN ( SELECT `t1_id`,`date_id`
FROM `aggregation_tmp_57312281`   )  GROUP BY t1.a 
)


-- AGGREGATION SQL:
SELECT `t1.a`,SUM(`_count_*_`) AS `_count_*_`
FROM `aggregation_tmp_65014392`  GROUP BY `t1.a`  
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*_`=`_count_*_` +  VALUES(`_count_*_`)
This is the query plan for the query:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a;

CALL paquExec('SELECT id AS `id` FROM t3 ', 'aggregation_tmp_98060197');
CALL paquExec('SELECT t1_id AS `t1_id`,date_id AS `date_id` FROM t2 JOIN ( SELECT `id` FROM `aggregation_tmp_98060197`   )  ', 'aggregation_tmp_57312281');
CALL paquExec('SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*_` FROM t1 JOIN ( SELECT `t1_id`,`date_id` FROM `aggregation_tmp_57312281`   )  GROUP BY t1.a ', 'aggregation_tmp_65014392');
CALL paquDropTmp('aggregation_tmp_98060197');
CALL paquDropTmp('aggregation_tmp_57312281');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `t1.a`,SUM(`_count_*_`) AS `_count_*_`
FROM `aggregation_tmp_65014392`  GROUP BY `t1.a`  ;
CALL paquDropTmp('aggregation_tmp_65014392');
This is the query plan optimisation output for the query:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a;

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`id`=VALUES(`id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT id AS `id`
FROM t3 
)


-- AGGREGATION SQL:
SELECT `id`
FROM `aggregation_tmp_71133705`   
ON DUPLICATE KEY UPDATE
`id`=VALUES(`id`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1_id`,`date_id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1_id AS `t1_id`,date_id AS `date_id`
FROM t2 JOIN ( SELECT `id`
FROM `aggregation_tmp_71133705`   )  
)


-- AGGREGATION SQL:
SELECT `t1_id`,`date_id`
FROM `aggregation_tmp_20047570`   
ON DUPLICATE KEY UPDATE
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)
-- INPUT SQL:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a;

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1.a`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*_`=`_count_*_` +  VALUES(`_count_*_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*_`
FROM t1 JOIN ( SELECT `t1_id`,`date_id`
FROM `aggregation_tmp_20047570`   )  GROUP BY t1.a 
)


-- AGGREGATION SQL:
SELECT `t1.a`,SUM(`_count_*_`) AS `_count_*_`
FROM `aggregation_tmp_92501731`  GROUP BY `t1.a`  
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*_`=`_count_*_` +  VALUES(`_count_*_`)
This is the query plan for the query:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a;

CALL paquExec('SELECT id AS `id` FROM t3 ', 'aggregation_tmp_71133705');
CALL paquExec('SELECT t1_id AS `t1_id`,date_id AS `date_id` FROM t2 JOIN ( SELECT `id` FROM `aggregation_tmp_71133705`   )  ', 'aggregation_tmp_20047570');
CALL paquExec('SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*_` FROM t1 JOIN ( SELECT `t1_id`,`date_id` FROM `aggregation_tmp_20047570`   )  GROUP BY t1.a ', 'aggregation_tmp_92501731');
CALL paquDropTmp('aggregation_tmp_71133705');
CALL paquDropTmp('aggregation_tmp_20047570');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `t1.a`,SUM(`_count_*_`) AS `_count_*_`
FROM `aggregation_tmp_92501731`  GROUP BY `t1.a`  ;
CALL paquDropTmp('aggregation_tmp_92501731');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`snapnum`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`snapnum`=VALUES(`snapnum`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,snapnum AS `snapnum`,FLOOR(LOG10(Mvir) / 0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE snapnum = 85  GROUP BY FLOOR(LOG10(Mvir) / 0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`,`snapnum`
FROM `aggregation_tmp_96195658`  GROUP BY `_FLOOR_LOG10_Mvir_/_0__25_` ORDER BY `_FLOOR_LOG10_Mvir_/_0__25_` ASC 
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`),
`snapnum`=VALUES(`snapnum`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,snapnum AS `snapnum`,FLOOR(LOG10(Mvir) / 0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE snapnum = 85  GROUP BY FLOOR(LOG10(Mvir) / 0.25)  ', 'aggregation_tmp_96195658');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`,`snapnum`
FROM `aggregation_tmp_96195658`  GROUP BY `_FLOOR_LOG10_Mvir_/_0__25_` ORDER BY `_FLOOR_LOG10_Mvir_/_0__25_` ASC ;
CALL paquDropTmp('aggregation_tmp_96195658');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir) / 0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE snapnum = 85  GROUP BY FLOOR(LOG10(Mvir) / 0.25)  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_54692684`  GROUP BY `_FLOOR_LOG10_Mvir_/_0__25_` ORDER BY `_FLOOR_LOG10_Mvir_/_0__25_` ASC 
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT(*) AS `num`,FLOOR(LOG10(Mvir) / 0.25) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE snapnum = 85  GROUP BY FLOOR(LOG10(Mvir) / 0.25)  ', 'aggregation_tmp_54692684');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_54692684`  GROUP BY `_FLOOR_LOG10_Mvir_/_0__25_` ORDER BY `_FLOOR_LOG10_Mvir_/_0__25_` ASC ;
CALL paquDropTmp('aggregation_tmp_54692684');
This is the query plan optimisation output for the query:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a;

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`id`=VALUES(`id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT id AS `id`
FROM t3 
)


-- AGGREGATION SQL:
SELECT `id`
FROM `aggregation_tmp_68769924`   
ON DUPLICATE KEY UPDATE
`id`=VALUES(`id`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1_id`,`date_id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1_id AS `t1_id`,date_id AS `date_id`
FROM t2 JOIN ( SELECT `id`
FROM `aggregation_tmp_68769924`   )  
)


-- AGGREGATION SQL:
SELECT `t1_id`,`date_id`
FROM `aggregation_tmp_62978794`   
ON DUPLICATE KEY UPDATE
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)
-- INPUT SQL:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a;

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1.a`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*_`=`_count_*_` +  VALUES(`_count_*_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*_`
FROM t1 JOIN ( SELECT `t1_id`,`date_id`
FROM `aggregation_tmp_62978794`   )  GROUP BY t1.a 
)


-- AGGREGATION SQL:
SELECT `t1.a`,SUM(`_count_*_`) AS `_count_*_`
FROM `aggregation_tmp_59233043`  GROUP BY `t1.a`  
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*_`=`_count_*_` +  VALUES(`_count_*_`)
This is the query plan for the query:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a;

CALL paquExec('SELECT id AS `id` FROM t3 ', 'aggregation_tmp_68769924');
CALL paquExec('SELECT t1_id AS `t1_id`,date_id AS `date_id` FROM t2 JOIN ( SELECT `id` FROM `aggregation_tmp_68769924`   )  ', 'aggregation_tmp_62978794');
CALL paquExec('SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*_` FROM t1 JOIN ( SELECT `t1_id`,`date_id` FROM `aggregation_tmp_62978794`   )  GROUP BY t1.a ', 'aggregation_tmp_59233043');
CALL paquDropTmp('aggregation_tmp_68769924');
CALL paquDropTmp('aggregation_tmp_62978794');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `t1.a`,SUM(`_count_*_`) AS `_count_*_`
FROM `aggregation_tmp_59233043`  GROUP BY `t1.a`  ;
CALL paquDropTmp('aggregation_tmp_59233043');
This is the query plan optimisation output for the query:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a;

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`id`=VALUES(`id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT id AS `id`
FROM t3 
)


-- AGGREGATION SQL:
SELECT `id`
FROM `aggregation_tmp_35373661`   
ON DUPLICATE KEY UPDATE
`id`=VALUES(`id`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1_id`,`date_id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1_id AS `t1_id`,date_id AS `date_id`
FROM t2 JOIN ( SELECT `id`
FROM `aggregation_tmp_35373661`   )  WHERE `t3`.`id` = t2.date_id   
)


-- AGGREGATION SQL:
SELECT `t1_id`,`date_id`
FROM `aggregation_tmp_31346178`   
ON DUPLICATE KEY UPDATE
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)
-- INPUT SQL:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a;

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1.a`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*_`=`_count_*_` +  VALUES(`_count_*_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*_`
FROM t1 JOIN ( SELECT `t1_id`,`date_id`
FROM `aggregation_tmp_31346178`   )  WHERE t1.id = `t2`.`t1_id`  GROUP BY t1.a  
)


-- AGGREGATION SQL:
SELECT `t1.a`,SUM(`_count_*_`) AS `_count_*_`
FROM `aggregation_tmp_17633270`  GROUP BY `t1.a`  
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*_`=`_count_*_` +  VALUES(`_count_*_`)
This is the query plan for the query:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a;

CALL paquExec('SELECT id AS `id` FROM t3 ', 'aggregation_tmp_35373661');
CALL paquExec('SELECT t1_id AS `t1_id`,date_id AS `date_id` FROM t2 JOIN ( SELECT `id` FROM `aggregation_tmp_35373661`   )  WHERE `t3`.`id` = t2.date_id   ', 'aggregation_tmp_31346178');
CALL paquExec('SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*_` FROM t1 JOIN ( SELECT `t1_id`,`date_id` FROM `aggregation_tmp_31346178`   )  WHERE t1.id = `t2`.`t1_id`  GROUP BY t1.a  ', 'aggregation_tmp_17633270');
CALL paquDropTmp('aggregation_tmp_35373661');
CALL paquDropTmp('aggregation_tmp_31346178');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `t1.a`,SUM(`_count_*_`) AS `_count_*_`
FROM `aggregation_tmp_17633270`  GROUP BY `t1.a`  ;
CALL paquDropTmp('aggregation_tmp_17633270');
This is the query plan optimisation output for the query:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a;

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`id`=VALUES(`id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT id AS `id`
FROM t3 
)


-- AGGREGATION SQL:
SELECT `id`
FROM `aggregation_tmp_76498181`   
ON DUPLICATE KEY UPDATE
`id`=VALUES(`id`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1_id`,`date_id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1_id AS `t1_id`,date_id AS `date_id`
FROM t2 JOIN ( SELECT `id`
FROM `aggregation_tmp_76498181`   ) AS `t3`  WHERE `t3`.`id` = t2.date_id   
)


-- AGGREGATION SQL:
SELECT `t1_id`,`date_id`
FROM `aggregation_tmp_45014868`   
ON DUPLICATE KEY UPDATE
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)
-- INPUT SQL:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a;

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1.a`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*_`=`_count_*_` +  VALUES(`_count_*_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*_`
FROM t1 JOIN ( SELECT `t1_id`,`date_id`
FROM `aggregation_tmp_45014868`   ) AS `t2`  WHERE t1.id = `t2`.`t1_id`  GROUP BY t1.a  
)


-- AGGREGATION SQL:
SELECT `t1.a`,SUM(`_count_*_`) AS `_count_*_`
FROM `aggregation_tmp_28512794`  GROUP BY `t1.a`  
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*_`=`_count_*_` +  VALUES(`_count_*_`)
This is the query plan for the query:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a;

CALL paquExec('SELECT id AS `id` FROM t3 ', 'aggregation_tmp_76498181');
CALL paquExec('SELECT t1_id AS `t1_id`,date_id AS `date_id` FROM t2 JOIN ( SELECT `id` FROM `aggregation_tmp_76498181`   ) AS `t3`  WHERE `t3`.`id` = t2.date_id   ', 'aggregation_tmp_45014868');
CALL paquExec('SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*_` FROM t1 JOIN ( SELECT `t1_id`,`date_id` FROM `aggregation_tmp_45014868`   ) AS `t2`  WHERE t1.id = `t2`.`t1_id`  GROUP BY t1.a  ', 'aggregation_tmp_28512794');
CALL paquDropTmp('aggregation_tmp_76498181');
CALL paquDropTmp('aggregation_tmp_45014868');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `t1.a`,SUM(`_count_*_`) AS `_count_*_`
FROM `aggregation_tmp_28512794`  GROUP BY `t1.a`  ;
CALL paquDropTmp('aggregation_tmp_28512794');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE descend.fofTreeId = 85000000000   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_32232248`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_32232248`   ) AS `descend`  
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_57375738`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE descend.fofTreeId = 85000000000   ', 'aggregation_tmp_32232248');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_32232248`   ) AS `descend`  ', 'aggregation_tmp_57375738');
CALL paquDropTmp('aggregation_tmp_32232248');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_57375738`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_57375738');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE descend.fofTreeId = 85000000000   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_1246834`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_1246834`   ) AS `descend`  
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_48245648`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE descend.fofTreeId = 85000000000   ', 'aggregation_tmp_1246834');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_1246834`   ) AS `descend`  ', 'aggregation_tmp_48245648');
CALL paquDropTmp('aggregation_tmp_1246834');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_48245648`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_48245648');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE descend.fofTreeId = 85000000000   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_30221117`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_30221117`   ) AS `descend`  
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_24534910`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE descend.fofTreeId = 85000000000   ', 'aggregation_tmp_30221117');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_30221117`   ) AS `descend`  ', 'aggregation_tmp_24534910');
CALL paquDropTmp('aggregation_tmp_30221117');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_24534910`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_24534910');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE descend.fofTreeId = 85000000000   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_52214429`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_52214429`   ) AS `descend`  
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_37857843`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE descend.fofTreeId = 85000000000   ', 'aggregation_tmp_52214429');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_52214429`   ) AS `descend`  ', 'aggregation_tmp_37857843');
CALL paquDropTmp('aggregation_tmp_52214429');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_37857843`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_37857843');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE descend.fofTreeId = 85000000000   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_85687545`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_85687545`   ) AS `descend`  
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_33012540`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE descend.fofTreeId = 85000000000   ', 'aggregation_tmp_85687545');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_85687545`   ) AS `descend`  ', 'aggregation_tmp_33012540');
CALL paquDropTmp('aggregation_tmp_85687545');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_33012540`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_33012540');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE descend.fofTreeId = 85000000000   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_79468898`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_79468898`   ) AS `descend`  
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_98573542`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE descend.fofTreeId = 85000000000   ', 'aggregation_tmp_79468898');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_79468898`   ) AS `descend`  ', 'aggregation_tmp_98573542');
CALL paquDropTmp('aggregation_tmp_79468898');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_98573542`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_98573542');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE descend.fofTreeId = 85000000000   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_18411226`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_18411226`   ) AS `descend`  
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_47916410`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE descend.fofTreeId = 85000000000   ', 'aggregation_tmp_18411226');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_18411226`   ) AS `descend`  ', 'aggregation_tmp_47916410');
CALL paquDropTmp('aggregation_tmp_18411226');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_47916410`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_47916410');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE descend.fofTreeId = 85000000000   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_59163106`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_59163106`   ) AS `descend`  WHERE ``.`fofTreeId` BETWEEN ``.`fofTreeId` AND ``.`lastProgId`   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_65363511`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE descend.fofTreeId = 85000000000   ', 'aggregation_tmp_59163106');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_59163106`   ) AS `descend`  WHERE ``.`fofTreeId` BETWEEN ``.`fofTreeId` AND ``.`lastProgId`   ', 'aggregation_tmp_65363511');
CALL paquDropTmp('aggregation_tmp_59163106');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_65363511`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_65363511');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE descend.fofTreeId = 85000000000   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_54669098`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_54669098`   ) AS `descend`  WHERE prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`lastProgId`   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_51656910`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE descend.fofTreeId = 85000000000   ', 'aggregation_tmp_54669098');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_54669098`   ) AS `descend`  WHERE prog.fofTreeId BETWEEN `descend`.`fofTreeId` AND `descend`.`lastProgId`   ', 'aggregation_tmp_51656910');
CALL paquDropTmp('aggregation_tmp_54669098');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_51656910`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_51656910');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE descend.fofTreeId = 85000000000   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_18578954`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_18578954`   ) AS `descend`  WHERE prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId`   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_98607779`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE descend.fofTreeId = 85000000000   ', 'aggregation_tmp_18578954');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_18578954`   ) AS `descend`  WHERE prog.fofTreeId BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId`   ', 'aggregation_tmp_98607779');
CALL paquDropTmp('aggregation_tmp_18578954');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_98607779`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_98607779');
This is the query plan optimisation output for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z`
FROM MDR1.FOF AS `f` 
)


-- AGGREGATION SQL:
SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_39940030`   
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
-- INPUT SQL:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS `f.x`,f.`f.y` AS `f.y`,f.`f.z` AS `f.z`
FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_39940030`   ) AS `f`  WHERE POWER(b.x - `f`.`x`, 2) < 1000    LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_34594929`    LIMIT 0,1
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
This is the query plan for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

CALL paquExec('SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z` FROM MDR1.FOF AS `f` ', 'aggregation_tmp_39940030');
CALL paquExec('SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS `f.x`,f.`f.y` AS `f.y`,f.`f.z` AS `f.z` FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z` FROM `aggregation_tmp_39940030`   ) AS `f`  WHERE POWER(b.x - `f`.`x`, 2) < 1000    LIMIT 0,1', 'aggregation_tmp_34594929');
CALL paquDropTmp('aggregation_tmp_39940030');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_34594929`    LIMIT 0,1;
CALL paquDropTmp('aggregation_tmp_34594929');
This is the query plan optimisation output for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z`
FROM MDR1.FOF AS `f` 
)


-- AGGREGATION SQL:
SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_71562817`   
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
-- INPUT SQL:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS `f.x`,f.`f.y` AS `f.y`,f.`f.z` AS `f.z`
FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_71562817`   ) AS `f`  WHERE POWER(b.x - `f`.`x`, 2) < 1000    LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_13459543`    LIMIT 0,1
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
This is the query plan for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

CALL paquExec('SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z` FROM MDR1.FOF AS `f` ', 'aggregation_tmp_71562817');
CALL paquExec('SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS `f.x`,f.`f.y` AS `f.y`,f.`f.z` AS `f.z` FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z` FROM `aggregation_tmp_71562817`   ) AS `f`  WHERE POWER(b.x - `f`.`x`, 2) < 1000    LIMIT 0,1', 'aggregation_tmp_13459543');
CALL paquDropTmp('aggregation_tmp_71562817');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_13459543`    LIMIT 0,1;
CALL paquDropTmp('aggregation_tmp_13459543');
This is the query plan optimisation output for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z`
FROM MDR1.FOF AS `f` 
)


-- AGGREGATION SQL:
SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_189759`   
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
-- INPUT SQL:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS `f.x`,f.`f.y` AS `f.y`,f.`f.z` AS `f.z`
FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_189759`   ) AS `f`  WHERE POWER(b.x - `f`.`x`, 2) < 1000    LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_49074711`    LIMIT 0,1
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
This is the query plan for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

CALL paquExec('SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z` FROM MDR1.FOF AS `f` ', 'aggregation_tmp_189759');
CALL paquExec('SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS `f.x`,f.`f.y` AS `f.y`,f.`f.z` AS `f.z` FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z` FROM `aggregation_tmp_189759`   ) AS `f`  WHERE POWER(b.x - `f`.`x`, 2) < 1000    LIMIT 0,1', 'aggregation_tmp_49074711');
CALL paquDropTmp('aggregation_tmp_189759');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_49074711`    LIMIT 0,1;
CALL paquDropTmp('aggregation_tmp_49074711');
This is the query plan optimisation output for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z`
FROM MDR1.FOF AS `f` 
)


-- AGGREGATION SQL:
SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_79413606`   
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
-- INPUT SQL:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS `f.x`,f.`f.y` AS `f.y`,f.`f.z` AS `f.z`
FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_79413606`   ) AS `f`  WHERE POWER(b.x - `f`.`f.x`, 2) < 1000    LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_2171693`    LIMIT 0,1
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
This is the query plan for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

CALL paquExec('SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z` FROM MDR1.FOF AS `f` ', 'aggregation_tmp_79413606');
CALL paquExec('SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS `f.x`,f.`f.y` AS `f.y`,f.`f.z` AS `f.z` FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z` FROM `aggregation_tmp_79413606`   ) AS `f`  WHERE POWER(b.x - `f`.`f.x`, 2) < 1000    LIMIT 0,1', 'aggregation_tmp_2171693');
CALL paquDropTmp('aggregation_tmp_79413606');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_2171693`    LIMIT 0,1;
CALL paquDropTmp('aggregation_tmp_2171693');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `haloX`,y AS `haloY`,z AS `haloZ`,Rvir AS `hR`
FROM MDR1.BDMV WHERE bdmId = 6200000001   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_8951403`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_8951403`   ) AS `h`  
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_29835879`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x AS `haloX`,y AS `haloY`,z AS `haloZ`,Rvir AS `hR` FROM MDR1.BDMV WHERE bdmId = 6200000001   ', 'aggregation_tmp_8951403');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_8951403`   ) AS `h`  ', 'aggregation_tmp_29835879');
CALL paquDropTmp('aggregation_tmp_8951403');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_29835879`   ;
CALL paquDropTmp('aggregation_tmp_29835879');
This is the query plan optimisation output for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`haloX`,`haloY`,`haloZ`,`hR`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `haloX`,y AS `haloY`,z AS `haloZ`,Rvir AS `hR`
FROM MDR1.BDMV WHERE bdmId = 6200000001   
)


-- AGGREGATION SQL:
SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_53387043`   
ON DUPLICATE KEY UPDATE
`haloX`=VALUES(`haloX`),
`haloY`=VALUES(`haloY`),
`haloZ`=VALUES(`haloZ`),
`hR`=VALUES(`hR`)
-- INPUT SQL:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.particleId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`
FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR`
FROM `aggregation_tmp_53387043`   ) AS `h`  WHERE POWER(`h`.`haloX` - p.x, 2) + POWER(`h`.`haloY` - p.y, 2) + POWER(`h`.`haloZ` - p.z, 2) <= `h`.`hR` * `h`.`hR`   
)


-- AGGREGATION SQL:
SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_96315143`   
ON DUPLICATE KEY UPDATE
`p.particleId`=VALUES(`p.particleId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT p.particleId,p.x,p.y,p.z FROM (SELECT x AS haloX, y AS haloY, z AS haloZ, Rvir AS hR FROM MDR1.BDMV WHERE bdmId = 6200000001) AS h, MDR1.Particles62 AS p WHERE POWER(h.haloX-p.x,2) + POWER(h.haloY-p.y,2) + POWER(h.haloZ-p.z,2) <= h.hR*h.hR

CALL paquExec('SELECT x AS `haloX`,y AS `haloY`,z AS `haloZ`,Rvir AS `hR` FROM MDR1.BDMV WHERE bdmId = 6200000001   ', 'aggregation_tmp_53387043');
CALL paquExec('SELECT p.particleId AS `p.particleId`,p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z` FROM MDR1.Particles62 AS `p` JOIN ( SELECT `haloX`,`haloY`,`haloZ`,`hR` FROM `aggregation_tmp_53387043`   ) AS `h`  WHERE POWER(`h`.`haloX` - p.x, 2) + POWER(`h`.`haloY` - p.y, 2) + POWER(`h`.`haloZ` - p.z, 2) <= `h`.`hR` * `h`.`hR`   ', 'aggregation_tmp_96315143');
CALL paquDropTmp('aggregation_tmp_53387043');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `p.particleId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_96315143`   ;
CALL paquDropTmp('aggregation_tmp_96315143');
This is the query plan optimisation output for the query:
SELECT h.foo FROM (SELECT b.foo FROM bar as b) as h

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.foo`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.foo`=VALUES(`b.foo`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.foo AS `b.foo`
FROM bar AS `b` 
)


-- AGGREGATION SQL:
SELECT `b.foo`
FROM `aggregation_tmp_90755113`   
ON DUPLICATE KEY UPDATE
`b.foo`=VALUES(`b.foo`)
-- INPUT SQL:
SELECT h.foo FROM (SELECT b.foo FROM bar as b) as h

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`h.foo`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`h.foo`=VALUES(`h.foo`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT h.foo AS `h.foo`
FROM ( SELECT `b.foo`
FROM `aggregation_tmp_90755113`   ) AS `h` 
)


-- AGGREGATION SQL:
SELECT `h.foo`
FROM `aggregation_tmp_45174312`   
ON DUPLICATE KEY UPDATE
`h.foo`=VALUES(`h.foo`)
This is the query plan for the query:
SELECT h.foo FROM (SELECT b.foo FROM bar as b) as h

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_90755113 ENGINE=MyISAM SELECT b.foo AS `b.foo`
FROM bar AS `b`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_90755113 SELECT b.foo AS `b.foo`
FROM bar AS `b` ;
CALL paquLinkTmp('aggregation_tmp_90755113');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_45174312 ENGINE=MyISAM SELECT h.foo AS `h.foo`
FROM ( SELECT `b.foo`
FROM `aggregation_tmp_90755113`   ) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_45174312 SELECT h.foo AS `h.foo`
FROM ( SELECT `b.foo`
FROM `aggregation_tmp_90755113`   ) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_45174312');
CALL paquDropTmp('aggregation_tmp_90755113');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `h.foo`
FROM `aggregation_tmp_45174312`   ;
CALL paquDropTmp('aggregation_tmp_45174312');
This is the query plan optimisation output for the query:
SELECT h.barfoo FROM (SELECT b.barfoo FROM bar as b) as h

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.barfoo`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.barfoo`=VALUES(`b.barfoo`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.barfoo AS `b.barfoo`
FROM bar AS `b` 
)


-- AGGREGATION SQL:
SELECT `b.barfoo`
FROM `aggregation_tmp_12961514`   
ON DUPLICATE KEY UPDATE
`b.barfoo`=VALUES(`b.barfoo`)
-- INPUT SQL:
SELECT h.barfoo FROM (SELECT b.barfoo FROM bar as b) as h

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`h.barfoo`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`h.barfoo`=VALUES(`h.barfoo`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT h.barfoo AS `h.barfoo`
FROM ( SELECT `b.barfoo`
FROM `aggregation_tmp_12961514`   ) AS `h` 
)


-- AGGREGATION SQL:
SELECT `h.barfoo`
FROM `aggregation_tmp_12713477`   
ON DUPLICATE KEY UPDATE
`h.barfoo`=VALUES(`h.barfoo`)
This is the query plan for the query:
SELECT h.barfoo FROM (SELECT b.barfoo FROM bar as b) as h

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_12961514 ENGINE=MyISAM SELECT b.barfoo AS `b.barfoo`
FROM bar AS `b`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_12961514 SELECT b.barfoo AS `b.barfoo`
FROM bar AS `b` ;
CALL paquLinkTmp('aggregation_tmp_12961514');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_12713477 ENGINE=MyISAM SELECT h.barfoo AS `h.barfoo`
FROM ( SELECT `b.barfoo`
FROM `aggregation_tmp_12961514`   ) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_12713477 SELECT h.barfoo AS `h.barfoo`
FROM ( SELECT `b.barfoo`
FROM `aggregation_tmp_12961514`   ) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_12713477');
CALL paquDropTmp('aggregation_tmp_12961514');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `h.barfoo`
FROM `aggregation_tmp_12713477`   ;
CALL paquDropTmp('aggregation_tmp_12713477');
This is the query plan optimisation output for the query:
SELECT h.barfoo FROM (SELECT b.barfoo FROM bar as b) as h

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.barfoo`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.barfoo`=VALUES(`b.barfoo`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.barfoo AS `b.barfoo`
FROM bar AS `b` 
)


-- AGGREGATION SQL:
SELECT `b.barfoo`
FROM `aggregation_tmp_53838745`   
ON DUPLICATE KEY UPDATE
`b.barfoo`=VALUES(`b.barfoo`)
-- INPUT SQL:
SELECT h.barfoo FROM (SELECT b.barfoo FROM bar as b) as h

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`h.barfoo`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`h.barfoo`=VALUES(`h.barfoo`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT h.barfoo AS `h.barfoo`
FROM ( SELECT `b.barfoo`
FROM `aggregation_tmp_53838745`   ) AS `h` 
)


-- AGGREGATION SQL:
SELECT `h.barfoo`
FROM `aggregation_tmp_64287973`   
ON DUPLICATE KEY UPDATE
`h.barfoo`=VALUES(`h.barfoo`)
This is the query plan for the query:
SELECT h.barfoo FROM (SELECT b.barfoo FROM bar as b) as h

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_53838745 ENGINE=MyISAM SELECT b.barfoo AS `b.barfoo`
FROM bar AS `b`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_53838745 SELECT b.barfoo AS `b.barfoo`
FROM bar AS `b` ;
CALL paquLinkTmp('aggregation_tmp_53838745');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_64287973 ENGINE=MyISAM SELECT h.barfoo AS `h.barfoo`
FROM ( SELECT `b.barfoo`
FROM `aggregation_tmp_53838745`   ) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_64287973 SELECT h.barfoo AS `h.barfoo`
FROM ( SELECT `b.barfoo`
FROM `aggregation_tmp_53838745`   ) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_64287973');
CALL paquDropTmp('aggregation_tmp_53838745');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `h.barfoo`
FROM `aggregation_tmp_64287973`   ;
CALL paquDropTmp('aggregation_tmp_64287973');
This is the query plan optimisation output for the query:
SELECT h.niceCol FROM (SELECT b.niceCol FROM bar as b) as h

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.niceCol`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.niceCol`=VALUES(`b.niceCol`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.niceCol AS `b.niceCol`
FROM bar AS `b` 
)


-- AGGREGATION SQL:
SELECT `b.niceCol`
FROM `aggregation_tmp_44239038`   
ON DUPLICATE KEY UPDATE
`b.niceCol`=VALUES(`b.niceCol`)
-- INPUT SQL:
SELECT h.niceCol FROM (SELECT b.niceCol FROM bar as b) as h

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`h.niceCol`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`h.niceCol`=VALUES(`h.niceCol`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT h.niceCol AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_44239038`   ) AS `h` 
)


-- AGGREGATION SQL:
SELECT `h.niceCol`
FROM `aggregation_tmp_24781950`   
ON DUPLICATE KEY UPDATE
`h.niceCol`=VALUES(`h.niceCol`)
This is the query plan for the query:
SELECT h.niceCol FROM (SELECT b.niceCol FROM bar as b) as h

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_44239038 ENGINE=MyISAM SELECT b.niceCol AS `b.niceCol`
FROM bar AS `b`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_44239038 SELECT b.niceCol AS `b.niceCol`
FROM bar AS `b` ;
CALL paquLinkTmp('aggregation_tmp_44239038');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_24781950 ENGINE=MyISAM SELECT h.niceCol AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_44239038`   ) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_24781950 SELECT h.niceCol AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_44239038`   ) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_24781950');
CALL paquDropTmp('aggregation_tmp_44239038');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `h.niceCol`
FROM `aggregation_tmp_24781950`   ;
CALL paquDropTmp('aggregation_tmp_24781950');
This is the query plan optimisation output for the query:
SELECT h.niceCol FROM (SELECT b.niceCol FROM bar as b) as h

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.niceCol`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.niceCol`=VALUES(`b.niceCol`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.niceCol AS `b.niceCol`
FROM bar AS `b` 
)


-- AGGREGATION SQL:
SELECT `b.niceCol`
FROM `aggregation_tmp_9560791`   
ON DUPLICATE KEY UPDATE
`b.niceCol`=VALUES(`b.niceCol`)
-- INPUT SQL:
SELECT h.niceCol FROM (SELECT b.niceCol FROM bar as b) as h

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`h.niceCol`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`h.niceCol`=VALUES(`h.niceCol`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT h.niceCol AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_9560791`   ) AS `h` 
)


-- AGGREGATION SQL:
SELECT `h.niceCol`
FROM `aggregation_tmp_91005016`   
ON DUPLICATE KEY UPDATE
`h.niceCol`=VALUES(`h.niceCol`)
This is the query plan for the query:
SELECT h.niceCol FROM (SELECT b.niceCol FROM bar as b) as h

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_9560791 ENGINE=MyISAM SELECT b.niceCol AS `b.niceCol`
FROM bar AS `b`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_9560791 SELECT b.niceCol AS `b.niceCol`
FROM bar AS `b` ;
CALL paquLinkTmp('aggregation_tmp_9560791');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_91005016 ENGINE=MyISAM SELECT h.niceCol AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_9560791`   ) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_91005016 SELECT h.niceCol AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_9560791`   ) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_91005016');
CALL paquDropTmp('aggregation_tmp_9560791');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `h.niceCol`
FROM `aggregation_tmp_91005016`   ;
CALL paquDropTmp('aggregation_tmp_91005016');
This is the query plan optimisation output for the query:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.niceCol`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.niceCol`=VALUES(`b.niceCol`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.niceCol AS `b.niceCol`
FROM niceTbl AS `b` 
)


-- AGGREGATION SQL:
SELECT `b.niceCol`
FROM `aggregation_tmp_11630094`   
ON DUPLICATE KEY UPDATE
`b.niceCol`=VALUES(`b.niceCol`)
-- INPUT SQL:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`h.niceCol`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`h.niceCol`=VALUES(`h.niceCol`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT h.niceCol AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_11630094`   ) AS `h` 
)


-- AGGREGATION SQL:
SELECT `h.niceCol`
FROM `aggregation_tmp_35625106`   
ON DUPLICATE KEY UPDATE
`h.niceCol`=VALUES(`h.niceCol`)
This is the query plan for the query:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

CALL paquExec('SELECT b.niceCol AS `b.niceCol` FROM niceTbl AS `b` ', 'aggregation_tmp_11630094');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_35625106 ENGINE=MyISAM SELECT h.niceCol AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_11630094`   ) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_35625106 SELECT h.niceCol AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_11630094`   ) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_35625106');
CALL paquDropTmp('aggregation_tmp_11630094');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `h.niceCol`
FROM `aggregation_tmp_35625106`   ;
CALL paquDropTmp('aggregation_tmp_35625106');
This is the query plan optimisation output for the query:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.niceCol`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.niceCol`=VALUES(`b.niceCol`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.niceCol AS `b.niceCol`
FROM niceTbl AS `b` 
)


-- AGGREGATION SQL:
SELECT `b.niceCol`
FROM `aggregation_tmp_49583196`   
ON DUPLICATE KEY UPDATE
`b.niceCol`=VALUES(`b.niceCol`)
-- INPUT SQL:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`h.niceCol`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`h.niceCol`=VALUES(`h.niceCol`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT h.niceCol AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_49583196`   ) AS `h` 
)


-- AGGREGATION SQL:
SELECT `h.niceCol`
FROM `aggregation_tmp_20888221`   
ON DUPLICATE KEY UPDATE
`h.niceCol`=VALUES(`h.niceCol`)
This is the query plan for the query:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

CALL paquExec('SELECT b.niceCol AS `b.niceCol` FROM niceTbl AS `b` ', 'aggregation_tmp_49583196');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_20888221 ENGINE=MyISAM SELECT h.niceCol AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_49583196`   ) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_20888221 SELECT h.niceCol AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_49583196`   ) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_20888221');
CALL paquDropTmp('aggregation_tmp_49583196');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `h.niceCol`
FROM `aggregation_tmp_20888221`   ;
CALL paquDropTmp('aggregation_tmp_20888221');
This is the query plan optimisation output for the query:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.niceCol`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.niceCol`=VALUES(`b.niceCol`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.niceCol AS `b.niceCol`
FROM niceTbl AS `b` 
)


-- AGGREGATION SQL:
SELECT `b.niceCol`
FROM `aggregation_tmp_94970660`   
ON DUPLICATE KEY UPDATE
`b.niceCol`=VALUES(`b.niceCol`)
-- INPUT SQL:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`h.niceCol`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`h.niceCol`=VALUES(`h.niceCol`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT h.niceCol AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_94970660`   ) AS `h` 
)


-- AGGREGATION SQL:
SELECT `h.niceCol`
FROM `aggregation_tmp_15665999`   
ON DUPLICATE KEY UPDATE
`h.niceCol`=VALUES(`h.niceCol`)
This is the query plan for the query:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

CALL paquExec('SELECT b.niceCol AS `b.niceCol` FROM niceTbl AS `b` ', 'aggregation_tmp_94970660');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_15665999 ENGINE=MyISAM SELECT h.niceCol AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_94970660`   ) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_15665999 SELECT h.niceCol AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_94970660`   ) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_15665999');
CALL paquDropTmp('aggregation_tmp_94970660');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `h.niceCol`
FROM `aggregation_tmp_15665999`   ;
CALL paquDropTmp('aggregation_tmp_15665999');
This is the query plan optimisation output for the query:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.niceCol`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.niceCol`=VALUES(`b.niceCol`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.niceCol AS `b.niceCol`
FROM niceTbl AS `b` 
)


-- AGGREGATION SQL:
SELECT `b.niceCol`
FROM `aggregation_tmp_75789792`   
ON DUPLICATE KEY UPDATE
`b.niceCol`=VALUES(`b.niceCol`)
-- INPUT SQL:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`h.niceCol`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`h.niceCol`=VALUES(`h.niceCol`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `h`.`b.niceCol` AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_75789792`   ) AS `h` 
)


-- AGGREGATION SQL:
SELECT `h.niceCol`
FROM `aggregation_tmp_44010199`   
ON DUPLICATE KEY UPDATE
`h.niceCol`=VALUES(`h.niceCol`)
This is the query plan for the query:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

CALL paquExec('SELECT b.niceCol AS `b.niceCol` FROM niceTbl AS `b` ', 'aggregation_tmp_75789792');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_44010199 ENGINE=MyISAM SELECT `h`.`b.niceCol` AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_75789792`   ) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_44010199 SELECT `h`.`b.niceCol` AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_75789792`   ) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_44010199');
CALL paquDropTmp('aggregation_tmp_75789792');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `h.niceCol`
FROM `aggregation_tmp_44010199`   ;
CALL paquDropTmp('aggregation_tmp_44010199');
This is the query plan optimisation output for the query:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.niceCol`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.niceCol`=VALUES(`b.niceCol`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.niceCol AS `b.niceCol`
FROM niceTbl AS `b` 
)


-- AGGREGATION SQL:
SELECT `b.niceCol`
FROM `aggregation_tmp_14292927`   
ON DUPLICATE KEY UPDATE
`b.niceCol`=VALUES(`b.niceCol`)
-- INPUT SQL:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`h.niceCol`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`h.niceCol`=VALUES(`h.niceCol`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT h.niceCol AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_14292927`   ) AS `h` 
)


-- AGGREGATION SQL:
SELECT `h.niceCol`
FROM `aggregation_tmp_52776172`   
ON DUPLICATE KEY UPDATE
`h.niceCol`=VALUES(`h.niceCol`)
This is the query plan for the query:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

CALL paquExec('SELECT b.niceCol AS `b.niceCol` FROM niceTbl AS `b` ', 'aggregation_tmp_14292927');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_52776172 ENGINE=MyISAM SELECT h.niceCol AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_14292927`   ) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_52776172 SELECT h.niceCol AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_14292927`   ) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_52776172');
CALL paquDropTmp('aggregation_tmp_14292927');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `h.niceCol`
FROM `aggregation_tmp_52776172`   ;
CALL paquDropTmp('aggregation_tmp_52776172');
This is the query plan optimisation output for the query:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.niceCol`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.niceCol`=VALUES(`b.niceCol`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.niceCol AS `b.niceCol`
FROM niceTbl AS `b` 
)


-- AGGREGATION SQL:
SELECT `b.niceCol`
FROM `aggregation_tmp_63046109`   
ON DUPLICATE KEY UPDATE
`b.niceCol`=VALUES(`b.niceCol`)
-- INPUT SQL:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`h.niceCol`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`h.niceCol`=VALUES(`h.niceCol`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `h`.`b.niceCol` AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_63046109`   ) AS `h` 
)


-- AGGREGATION SQL:
SELECT `h.niceCol`
FROM `aggregation_tmp_92089137`   
ON DUPLICATE KEY UPDATE
`h.niceCol`=VALUES(`h.niceCol`)
This is the query plan for the query:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

CALL paquExec('SELECT b.niceCol AS `b.niceCol` FROM niceTbl AS `b` ', 'aggregation_tmp_63046109');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_92089137 ENGINE=MyISAM SELECT `h`.`b.niceCol` AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_63046109`   ) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_92089137 SELECT `h`.`b.niceCol` AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_63046109`   ) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_92089137');
CALL paquDropTmp('aggregation_tmp_63046109');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `h.niceCol`
FROM `aggregation_tmp_92089137`   ;
CALL paquDropTmp('aggregation_tmp_92089137');
This is the query plan optimisation output for the query:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.niceCol`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.niceCol`=VALUES(`b.niceCol`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.niceCol AS `b.niceCol`
FROM niceTbl AS `b` 
)


-- AGGREGATION SQL:
SELECT `b.niceCol`
FROM `aggregation_tmp_80702280`   
ON DUPLICATE KEY UPDATE
`b.niceCol`=VALUES(`b.niceCol`)
-- INPUT SQL:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`h.niceCol`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`h.niceCol`=VALUES(`h.niceCol`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `h`.`b.niceCol` AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_80702280`   ) AS `h` 
)


-- AGGREGATION SQL:
SELECT `h.niceCol`
FROM `aggregation_tmp_19347752`   
ON DUPLICATE KEY UPDATE
`h.niceCol`=VALUES(`h.niceCol`)
This is the query plan for the query:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

CALL paquExec('SELECT b.niceCol AS `b.niceCol` FROM niceTbl AS `b` ', 'aggregation_tmp_80702280');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_19347752 ENGINE=MyISAM SELECT `h`.`b.niceCol` AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_80702280`   ) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_19347752 SELECT `h`.`b.niceCol` AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_80702280`   ) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_19347752');
CALL paquDropTmp('aggregation_tmp_80702280');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `h.niceCol`
FROM `aggregation_tmp_19347752`   ;
CALL paquDropTmp('aggregation_tmp_19347752');
This is the query plan optimisation output for the query:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.niceCol`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.niceCol`=VALUES(`b.niceCol`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.niceCol AS `b.niceCol`
FROM niceTbl AS `b` 
)


-- AGGREGATION SQL:
SELECT `b.niceCol`
FROM `aggregation_tmp_1852605`   
ON DUPLICATE KEY UPDATE
`b.niceCol`=VALUES(`b.niceCol`)
-- INPUT SQL:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`h.niceCol`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`h.niceCol`=VALUES(`h.niceCol`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT h.niceCol AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_1852605`   ) AS `h` 
)


-- AGGREGATION SQL:
SELECT `h.niceCol`
FROM `aggregation_tmp_9758177`   
ON DUPLICATE KEY UPDATE
`h.niceCol`=VALUES(`h.niceCol`)
This is the query plan for the query:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

CALL paquExec('SELECT b.niceCol AS `b.niceCol` FROM niceTbl AS `b` ', 'aggregation_tmp_1852605');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_9758177 ENGINE=MyISAM SELECT h.niceCol AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_1852605`   ) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_9758177 SELECT h.niceCol AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_1852605`   ) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_9758177');
CALL paquDropTmp('aggregation_tmp_1852605');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `h.niceCol`
FROM `aggregation_tmp_9758177`   ;
CALL paquDropTmp('aggregation_tmp_9758177');
This is the query plan optimisation output for the query:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.niceCol`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.niceCol`=VALUES(`b.niceCol`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.niceCol AS `b.niceCol`
FROM niceTbl AS `b` 
)


-- AGGREGATION SQL:
SELECT `b.niceCol`
FROM `aggregation_tmp_84506250`   
ON DUPLICATE KEY UPDATE
`b.niceCol`=VALUES(`b.niceCol`)
-- INPUT SQL:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`h.niceCol`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`h.niceCol`=VALUES(`h.niceCol`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `h`.`b.niceCol` AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_84506250`   ) AS `h` 
)


-- AGGREGATION SQL:
SELECT `h.niceCol`
FROM `aggregation_tmp_10678127`   
ON DUPLICATE KEY UPDATE
`h.niceCol`=VALUES(`h.niceCol`)
This is the query plan for the query:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

CALL paquExec('SELECT b.niceCol AS `b.niceCol` FROM niceTbl AS `b` ', 'aggregation_tmp_84506250');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_10678127 ENGINE=MyISAM SELECT `h`.`b.niceCol` AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_84506250`   ) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_10678127 SELECT `h`.`b.niceCol` AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_84506250`   ) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_10678127');
CALL paquDropTmp('aggregation_tmp_84506250');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `h.niceCol`
FROM `aggregation_tmp_10678127`   ;
CALL paquDropTmp('aggregation_tmp_10678127');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.fofId`,`f.particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.fofId`=VALUES(`f.fofId`),
`f.particleId`=VALUES(`f.particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.fofId AS `f.fofId`,f.particleId AS `f.particleId`
FROM MDR1.FOFParticles AS `f` WHERE f.fofId = 85000000479   
)


-- AGGREGATION SQL:
SELECT `f.fofId`,`f.particleId`
FROM `aggregation_tmp_75722052`   
ON DUPLICATE KEY UPDATE
`f.fofId`=VALUES(`f.fofId`),
`f.particleId`=VALUES(`f.particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`p.particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`p.particleId`=VALUES(`p.particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,p.particleId AS `p.particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `f.fofId`,`f.particleId`
FROM `aggregation_tmp_75722052`   ) AS `f`  WHERE p.particleId = `f`.`f.particleId`   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`p.particleId`
FROM `aggregation_tmp_5893970`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`p.particleId`=VALUES(`p.particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,p.`p.x` AS `p.x`,p.`p.y` AS `p.y`,p.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`p.particleId`
FROM `aggregation_tmp_5893970`   ) AS `p`  WHERE `f`.`p.particleId` = f3.particleId   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_93837184`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT f.fofId AS `f.fofId`,f.particleId AS `f.particleId` FROM MDR1.FOFParticles AS `f` WHERE f.fofId = 85000000479   ', 'aggregation_tmp_75722052');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,p.particleId AS `p.particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `f.fofId`,`f.particleId` FROM `aggregation_tmp_75722052`   ) AS `f`  WHERE p.particleId = `f`.`f.particleId`   ', 'aggregation_tmp_5893970');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,p.`p.x` AS `p.x`,p.`p.y` AS `p.y`,p.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`p.particleId` FROM `aggregation_tmp_5893970`   ) AS `p`  WHERE `f`.`p.particleId` = f3.particleId   ', 'aggregation_tmp_93837184');
CALL paquDropTmp('aggregation_tmp_75722052');
CALL paquDropTmp('aggregation_tmp_5893970');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_93837184`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_93837184');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.fofId`,`f.particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.fofId`=VALUES(`f.fofId`),
`f.particleId`=VALUES(`f.particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.fofId AS `f.fofId`,f.particleId AS `f.particleId`
FROM MDR1.FOFParticles AS `f` WHERE f.fofId = 85000000479   
)


-- AGGREGATION SQL:
SELECT `f.fofId`,`f.particleId`
FROM `aggregation_tmp_1969334`   
ON DUPLICATE KEY UPDATE
`f.fofId`=VALUES(`f.fofId`),
`f.particleId`=VALUES(`f.particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`p.particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`p.particleId`=VALUES(`p.particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,p.particleId AS `p.particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `f.fofId`,`f.particleId`
FROM `aggregation_tmp_1969334`   ) AS `f`  WHERE p.particleId = `f`.`f.particleId`   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`p.particleId`
FROM `aggregation_tmp_20305440`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`p.particleId`=VALUES(`p.particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,p.`p.x` AS `p.x`,p.`p.y` AS `p.y`,p.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`p.particleId`
FROM `aggregation_tmp_20305440`   ) AS `p`  WHERE `f`.`p.particleId` = f3.particleId   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_10309017`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT f.fofId AS `f.fofId`,f.particleId AS `f.particleId` FROM MDR1.FOFParticles AS `f` WHERE f.fofId = 85000000479   ', 'aggregation_tmp_1969334');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,p.particleId AS `p.particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `f.fofId`,`f.particleId` FROM `aggregation_tmp_1969334`   ) AS `f`  WHERE p.particleId = `f`.`f.particleId`   ', 'aggregation_tmp_20305440');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,p.`p.x` AS `p.x`,p.`p.y` AS `p.y`,p.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`p.particleId` FROM `aggregation_tmp_20305440`   ) AS `p`  WHERE `f`.`p.particleId` = f3.particleId   ', 'aggregation_tmp_10309017');
CALL paquDropTmp('aggregation_tmp_1969334');
CALL paquDropTmp('aggregation_tmp_20305440');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_10309017`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_10309017');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.fofId`,`f.particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.fofId`=VALUES(`f.fofId`),
`f.particleId`=VALUES(`f.particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.fofId AS `f.fofId`,f.particleId AS `f.particleId`
FROM MDR1.FOFParticles AS `f` WHERE f.fofId = 85000000479   
)


-- AGGREGATION SQL:
SELECT `f.fofId`,`f.particleId`
FROM `aggregation_tmp_45887734`   
ON DUPLICATE KEY UPDATE
`f.fofId`=VALUES(`f.fofId`),
`f.particleId`=VALUES(`f.particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`p.particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`p.particleId`=VALUES(`p.particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,p.particleId AS `p.particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `f.fofId`,`f.particleId`
FROM `aggregation_tmp_45887734`   ) AS `f`  WHERE p.particleId = `f`.`f.particleId`   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`p.particleId`
FROM `aggregation_tmp_36052640`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`p.particleId`=VALUES(`p.particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,p.`p.x` AS `p.x`,p.`p.y` AS `p.y`,p.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`p.particleId`
FROM `aggregation_tmp_36052640`   ) AS `p`  WHERE `f`.`p.particleId` = f3.particleId   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_77351887`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT f.fofId AS `f.fofId`,f.particleId AS `f.particleId` FROM MDR1.FOFParticles AS `f` WHERE f.fofId = 85000000479   ', 'aggregation_tmp_45887734');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,p.particleId AS `p.particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `f.fofId`,`f.particleId` FROM `aggregation_tmp_45887734`   ) AS `f`  WHERE p.particleId = `f`.`f.particleId`   ', 'aggregation_tmp_36052640');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,p.`p.x` AS `p.x`,p.`p.y` AS `p.y`,p.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`p.particleId` FROM `aggregation_tmp_36052640`   ) AS `p`  WHERE `f`.`p.particleId` = f3.particleId   ', 'aggregation_tmp_77351887');
CALL paquDropTmp('aggregation_tmp_45887734');
CALL paquDropTmp('aggregation_tmp_36052640');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_77351887`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_77351887');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.fofId`,`f.particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.fofId`=VALUES(`f.fofId`),
`f.particleId`=VALUES(`f.particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.fofId AS `f.fofId`,f.particleId AS `f.particleId`
FROM MDR1.FOFParticles AS `f` WHERE f.fofId = 85000000479   
)


-- AGGREGATION SQL:
SELECT `f.fofId`,`f.particleId`
FROM `aggregation_tmp_68473273`   
ON DUPLICATE KEY UPDATE
`f.fofId`=VALUES(`f.fofId`),
`f.particleId`=VALUES(`f.particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`p.particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`p.particleId`=VALUES(`p.particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,p.particleId AS `p.particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `f.fofId`,`f.particleId`
FROM `aggregation_tmp_68473273`   ) AS `f`  WHERE p.particleId = `f`.`f.particleId`   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`p.particleId`
FROM `aggregation_tmp_13960488`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`p.particleId`=VALUES(`p.particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,p.`p.x` AS `p.x`,p.`p.y` AS `p.y`,p.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`p.particleId`
FROM `aggregation_tmp_13960488`   ) AS `p`  WHERE `f`.`p.particleId` = f3.particleId   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_44164090`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT f.fofId AS `f.fofId`,f.particleId AS `f.particleId` FROM MDR1.FOFParticles AS `f` WHERE f.fofId = 85000000479   ', 'aggregation_tmp_68473273');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,p.particleId AS `p.particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `f.fofId`,`f.particleId` FROM `aggregation_tmp_68473273`   ) AS `f`  WHERE p.particleId = `f`.`f.particleId`   ', 'aggregation_tmp_13960488');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,p.`p.x` AS `p.x`,p.`p.y` AS `p.y`,p.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`p.particleId` FROM `aggregation_tmp_13960488`   ) AS `p`  WHERE `f`.`p.particleId` = f3.particleId   ', 'aggregation_tmp_44164090');
CALL paquDropTmp('aggregation_tmp_68473273');
CALL paquDropTmp('aggregation_tmp_13960488');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_44164090`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_44164090');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.fofId`,`f.particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.fofId`=VALUES(`f.fofId`),
`f.particleId`=VALUES(`f.particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.fofId AS `f.fofId`,f.particleId AS `f.particleId`
FROM MDR1.FOFParticles AS `f` WHERE f.fofId = 85000000479   
)


-- AGGREGATION SQL:
SELECT `f.fofId`,`f.particleId`
FROM `aggregation_tmp_19952586`   
ON DUPLICATE KEY UPDATE
`f.fofId`=VALUES(`f.fofId`),
`f.particleId`=VALUES(`f.particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`p.particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`p.particleId`=VALUES(`p.particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,p.particleId AS `p.particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `f.fofId`,`f.particleId`
FROM `aggregation_tmp_19952586`   ) AS `f`  WHERE ( `f`.`particleId` = `f`.`f.particleId` )   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`p.particleId`
FROM `aggregation_tmp_91890297`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`p.particleId`=VALUES(`p.particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,p.`p.x` AS `p.x`,p.`p.y` AS `p.y`,p.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`p.particleId`
FROM `aggregation_tmp_91890297`   ) AS `p`  WHERE ( `p`.`p.particleId` = f3.particleId )   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_29323908`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT f.fofId AS `f.fofId`,f.particleId AS `f.particleId` FROM MDR1.FOFParticles AS `f` WHERE f.fofId = 85000000479   ', 'aggregation_tmp_19952586');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,p.particleId AS `p.particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `f.fofId`,`f.particleId` FROM `aggregation_tmp_19952586`   ) AS `f`  WHERE ( `f`.`particleId` = `f`.`f.particleId` )   ', 'aggregation_tmp_91890297');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,p.`p.x` AS `p.x`,p.`p.y` AS `p.y`,p.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`p.particleId` FROM `aggregation_tmp_91890297`   ) AS `p`  WHERE ( `p`.`p.particleId` = f3.particleId )   ', 'aggregation_tmp_29323908');
CALL paquDropTmp('aggregation_tmp_19952586');
CALL paquDropTmp('aggregation_tmp_91890297');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_29323908`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_29323908');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.fofId`,`f.particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.fofId`=VALUES(`f.fofId`),
`f.particleId`=VALUES(`f.particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.fofId AS `f.fofId`,f.particleId AS `f.particleId`
FROM MDR1.FOFParticles AS `f` WHERE f.fofId = 85000000479   
)


-- AGGREGATION SQL:
SELECT `f.fofId`,`f.particleId`
FROM `aggregation_tmp_18247707`   
ON DUPLICATE KEY UPDATE
`f.fofId`=VALUES(`f.fofId`),
`f.particleId`=VALUES(`f.particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`p.particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`p.particleId`=VALUES(`p.particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,p.particleId AS `p.particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `f.fofId`,`f.particleId`
FROM `aggregation_tmp_18247707`   ) AS `f`  WHERE p.particleId = `f`.`f.particleId`   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`p.particleId`
FROM `aggregation_tmp_34025185`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`p.particleId`=VALUES(`p.particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,p.`p.x` AS `p.x`,p.`p.y` AS `p.y`,p.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`p.particleId`
FROM `aggregation_tmp_34025185`   ) AS `p`  WHERE `f`.`p.particleId` = f3.particleId   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_22085684`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT f.fofId AS `f.fofId`,f.particleId AS `f.particleId` FROM MDR1.FOFParticles AS `f` WHERE f.fofId = 85000000479   ', 'aggregation_tmp_18247707');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,p.particleId AS `p.particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `f.fofId`,`f.particleId` FROM `aggregation_tmp_18247707`   ) AS `f`  WHERE p.particleId = `f`.`f.particleId`   ', 'aggregation_tmp_34025185');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,p.`p.x` AS `p.x`,p.`p.y` AS `p.y`,p.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`p.particleId` FROM `aggregation_tmp_34025185`   ) AS `p`  WHERE `f`.`p.particleId` = f3.particleId   ', 'aggregation_tmp_22085684');
CALL paquDropTmp('aggregation_tmp_18247707');
CALL paquDropTmp('aggregation_tmp_34025185');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_22085684`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_22085684');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.fofId`,`f.particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.fofId`=VALUES(`f.fofId`),
`f.particleId`=VALUES(`f.particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.fofId AS `f.fofId`,f.particleId AS `f.particleId`
FROM MDR1.FOFParticles AS `f` WHERE f.fofId = 85000000479   
)


-- AGGREGATION SQL:
SELECT `f.fofId`,`f.particleId`
FROM `aggregation_tmp_33941186`   
ON DUPLICATE KEY UPDATE
`f.fofId`=VALUES(`f.fofId`),
`f.particleId`=VALUES(`f.particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`p.particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`p.particleId`=VALUES(`p.particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,p.particleId AS `p.particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `f.fofId`,`f.particleId`
FROM `aggregation_tmp_33941186`   ) AS `f`  WHERE p.particleId = `f`.`f.particleId`   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`p.particleId`
FROM `aggregation_tmp_95562740`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`p.particleId`=VALUES(`p.particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,p.`p.x` AS `p.x`,p.`p.y` AS `p.y`,p.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`p.particleId`
FROM `aggregation_tmp_95562740`   ) AS `p`  WHERE `f`.`p.particleId` = f3.particleId   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_53451973`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT f.fofId AS `f.fofId`,f.particleId AS `f.particleId` FROM MDR1.FOFParticles AS `f` WHERE f.fofId = 85000000479   ', 'aggregation_tmp_33941186');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,p.particleId AS `p.particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `f.fofId`,`f.particleId` FROM `aggregation_tmp_33941186`   ) AS `f`  WHERE p.particleId = `f`.`f.particleId`   ', 'aggregation_tmp_95562740');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,p.`p.x` AS `p.x`,p.`p.y` AS `p.y`,p.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`p.particleId` FROM `aggregation_tmp_95562740`   ) AS `p`  WHERE `f`.`p.particleId` = f3.particleId   ', 'aggregation_tmp_53451973');
CALL paquDropTmp('aggregation_tmp_33941186');
CALL paquDropTmp('aggregation_tmp_95562740');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_53451973`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_53451973');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.fofId`,`f.particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.fofId`=VALUES(`f.fofId`),
`f.particleId`=VALUES(`f.particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.fofId AS `f.fofId`,f.particleId AS `f.particleId`
FROM MDR1.FOFParticles AS `f` WHERE f.fofId = 85000000479   
)


-- AGGREGATION SQL:
SELECT `f.fofId`,`f.particleId`
FROM `aggregation_tmp_87765587`   
ON DUPLICATE KEY UPDATE
`f.fofId`=VALUES(`f.fofId`),
`f.particleId`=VALUES(`f.particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`p.particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`p.particleId`=VALUES(`p.particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,p.particleId AS `p.particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `f.fofId`,`f.particleId`
FROM `aggregation_tmp_87765587`   ) AS `f`  WHERE p.particleId = `f`.`f.particleId`   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`p.particleId`
FROM `aggregation_tmp_37289000`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`p.particleId`=VALUES(`p.particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,p.`p.x` AS `p.x`,p.`p.y` AS `p.y`,p.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`p.particleId`
FROM `aggregation_tmp_37289000`   ) AS `p`  WHERE `f`.`p.particleId` = f3.particleId   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_79224377`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT f.fofId AS `f.fofId`,f.particleId AS `f.particleId` FROM MDR1.FOFParticles AS `f` WHERE f.fofId = 85000000479   ', 'aggregation_tmp_87765587');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,p.particleId AS `p.particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `f.fofId`,`f.particleId` FROM `aggregation_tmp_87765587`   ) AS `f`  WHERE p.particleId = `f`.`f.particleId`   ', 'aggregation_tmp_37289000');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,p.`p.x` AS `p.x`,p.`p.y` AS `p.y`,p.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`p.particleId` FROM `aggregation_tmp_37289000`   ) AS `p`  WHERE `f`.`p.particleId` = f3.particleId   ', 'aggregation_tmp_79224377');
CALL paquDropTmp('aggregation_tmp_87765587');
CALL paquDropTmp('aggregation_tmp_37289000');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_79224377`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_79224377');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.fofId`,`f.particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.fofId`=VALUES(`f.fofId`),
`f.particleId`=VALUES(`f.particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.fofId AS `f.fofId`,f.particleId AS `f.particleId`
FROM MDR1.FOFParticles AS `f` WHERE f.fofId = 85000000479   
)


-- AGGREGATION SQL:
SELECT `f.fofId`,`f.particleId`
FROM `aggregation_tmp_21862885`   
ON DUPLICATE KEY UPDATE
`f.fofId`=VALUES(`f.fofId`),
`f.particleId`=VALUES(`f.particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`p.particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`p.particleId`=VALUES(`p.particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,p.particleId AS `p.particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `f.fofId`,`f.particleId`
FROM `aggregation_tmp_21862885`   ) AS `f`  WHERE p.particleId = `f`.`f.particleId`   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`p.particleId`
FROM `aggregation_tmp_44589526`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`p.particleId`=VALUES(`p.particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,p.`p.x` AS `p.x`,p.`p.y` AS `p.y`,p.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`p.particleId`
FROM `aggregation_tmp_44589526`   ) AS `p`  WHERE `f`.`p.particleId` = f3.particleId   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_57543705`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT f.fofId AS `f.fofId`,f.particleId AS `f.particleId` FROM MDR1.FOFParticles AS `f` WHERE f.fofId = 85000000479   ', 'aggregation_tmp_21862885');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,p.particleId AS `p.particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `f.fofId`,`f.particleId` FROM `aggregation_tmp_21862885`   ) AS `f`  WHERE p.particleId = `f`.`f.particleId`   ', 'aggregation_tmp_44589526');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,p.`p.x` AS `p.x`,p.`p.y` AS `p.y`,p.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`p.particleId` FROM `aggregation_tmp_44589526`   ) AS `p`  WHERE `f`.`p.particleId` = f3.particleId   ', 'aggregation_tmp_57543705');
CALL paquDropTmp('aggregation_tmp_21862885');
CALL paquDropTmp('aggregation_tmp_44589526');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_57543705`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_57543705');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.fofId`,`f.particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.fofId`=VALUES(`f.fofId`),
`f.particleId`=VALUES(`f.particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.fofId AS `f.fofId`,f.particleId AS `f.particleId`
FROM MDR1.FOFParticles AS `f` WHERE f.fofId = 85000000479   
)


-- AGGREGATION SQL:
SELECT `f.fofId`,`f.particleId`
FROM `aggregation_tmp_82060700`   
ON DUPLICATE KEY UPDATE
`f.fofId`=VALUES(`f.fofId`),
`f.particleId`=VALUES(`f.particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`p.particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`p.particleId`=VALUES(`p.particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,p.particleId AS `p.particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `f.fofId`,`f.particleId`
FROM `aggregation_tmp_82060700`   ) AS `f`  WHERE p.particleId = `f`.`f.particleId`   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`p.particleId`
FROM `aggregation_tmp_32690750`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`p.particleId`=VALUES(`p.particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,p.`p.x` AS `p.x`,p.`p.y` AS `p.y`,p.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`p.particleId`
FROM `aggregation_tmp_32690750`   ) AS `p`  WHERE `f`.`p.particleId` = f3.particleId   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_87841276`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT f.fofId AS `f.fofId`,f.particleId AS `f.particleId` FROM MDR1.FOFParticles AS `f` WHERE f.fofId = 85000000479   ', 'aggregation_tmp_82060700');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,p.particleId AS `p.particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `f.fofId`,`f.particleId` FROM `aggregation_tmp_82060700`   ) AS `f`  WHERE p.particleId = `f`.`f.particleId`   ', 'aggregation_tmp_32690750');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,p.`p.x` AS `p.x`,p.`p.y` AS `p.y`,p.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`p.particleId` FROM `aggregation_tmp_32690750`   ) AS `p`  WHERE `f`.`p.particleId` = f3.particleId   ', 'aggregation_tmp_87841276');
CALL paquDropTmp('aggregation_tmp_82060700');
CALL paquDropTmp('aggregation_tmp_32690750');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_87841276`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_87841276');
This is the query plan optimisation output for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.fofId`,`f.particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.fofId`=VALUES(`f.fofId`),
`f.particleId`=VALUES(`f.particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.fofId AS `f.fofId`,f.particleId AS `f.particleId`
FROM MDR1.FOFParticles AS `f` WHERE f.fofId = 85000000479   
)


-- AGGREGATION SQL:
SELECT `f.fofId`,`f.particleId`
FROM `aggregation_tmp_91672642`   
ON DUPLICATE KEY UPDATE
`f.fofId`=VALUES(`f.fofId`),
`f.particleId`=VALUES(`f.particleId`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`p.x`,`p.y`,`p.z`,`p.particleId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`p.particleId`=VALUES(`p.particleId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,p.particleId AS `p.particleId`
FROM MDR1.particles85 AS `p` JOIN ( SELECT `f.fofId`,`f.particleId`
FROM `aggregation_tmp_91672642`   ) AS `f`  WHERE p.particleId = `f`.`f.particleId`   
)


-- AGGREGATION SQL:
SELECT `p.x`,`p.y`,`p.z`,`p.particleId`
FROM `aggregation_tmp_59841824`   
ON DUPLICATE KEY UPDATE
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`),
`p.particleId`=VALUES(`p.particleId`)
-- INPUT SQL:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f3.fofId`,`p.x`,`p.y`,`p.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f3.fofId AS `f3.fofId`,p.`p.x` AS `p.x`,p.`p.y` AS `p.y`,p.`p.z` AS `p.z`
FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`p.particleId`
FROM `aggregation_tmp_59841824`   ) AS `p`  WHERE p.`p.particleId` = f3.particleId   
)


-- AGGREGATION SQL:
SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_4853632`  ORDER BY `f3.fofId` ASC 
ON DUPLICATE KEY UPDATE
`f3.fofId`=VALUES(`f3.fofId`),
`p.x`=VALUES(`p.x`),
`p.y`=VALUES(`p.y`),
`p.z`=VALUES(`p.z`)
This is the query plan for the query:
SELECT f3.fofId, p.x,p.y,p.z FROM MDR1.FOFParticles f, MDR1.FOFParticles3 f3, MDR1.particles85 p WHERE f.fofId = 85000000479 AND f.particleId = f3.particleId AND p.particleId = f.particleId ORDER BY f3.fofId ASC

CALL paquExec('SELECT f.fofId AS `f.fofId`,f.particleId AS `f.particleId` FROM MDR1.FOFParticles AS `f` WHERE f.fofId = 85000000479   ', 'aggregation_tmp_91672642');
CALL paquExec('SELECT p.x AS `p.x`,p.y AS `p.y`,p.z AS `p.z`,p.particleId AS `p.particleId` FROM MDR1.particles85 AS `p` JOIN ( SELECT `f.fofId`,`f.particleId` FROM `aggregation_tmp_91672642`   ) AS `f`  WHERE p.particleId = `f`.`f.particleId`   ', 'aggregation_tmp_59841824');
CALL paquExec('SELECT f3.fofId AS `f3.fofId`,p.`p.x` AS `p.x`,p.`p.y` AS `p.y`,p.`p.z` AS `p.z` FROM MDR1.FOFParticles3 AS `f3` JOIN ( SELECT `p.x`,`p.y`,`p.z`,`p.particleId` FROM `aggregation_tmp_59841824`   ) AS `p`  WHERE p.`p.particleId` = f3.particleId   ', 'aggregation_tmp_4853632');
CALL paquDropTmp('aggregation_tmp_91672642');
CALL paquDropTmp('aggregation_tmp_59841824');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `f3.fofId`,`p.x`,`p.y`,`p.z`
FROM `aggregation_tmp_4853632`  ORDER BY `f3.fofId` ASC ;
CALL paquDropTmp('aggregation_tmp_4853632');
This is the query plan optimisation output for the query:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`id`=VALUES(`id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT id AS `id`
FROM t3 
)


-- AGGREGATION SQL:
SELECT `id`
FROM `aggregation_tmp_63054419`   
ON DUPLICATE KEY UPDATE
`id`=VALUES(`id`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1_id`,`date_id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1_id AS `t1_id`,date_id AS `date_id`
FROM t2 JOIN ( SELECT `id`
FROM `aggregation_tmp_63054419`   ) AS `t3`  WHERE `t3`.`id` = `t3`.`date_id`   
)


-- AGGREGATION SQL:
SELECT `t1_id`,`date_id`
FROM `aggregation_tmp_75803402`   
ON DUPLICATE KEY UPDATE
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)
-- INPUT SQL:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1.a`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*_`=`_count_*_` +  VALUES(`_count_*_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*_`
FROM t1 JOIN ( SELECT `t1_id`,`date_id`
FROM `aggregation_tmp_75803402`   ) AS `t2`  WHERE `t2`.`id` = `t2`.`t1_id`  GROUP BY t1.a  
)


-- AGGREGATION SQL:
SELECT `t1.a`,SUM(`_count_*_`) AS `_count_*_`
FROM `aggregation_tmp_83760394`  GROUP BY `t1.a`  
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*_`=`_count_*_` +  VALUES(`_count_*_`)
This is the query plan for the query:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

CALL paquExec('SELECT id AS `id` FROM t3 ', 'aggregation_tmp_63054419');
CALL paquExec('SELECT t1_id AS `t1_id`,date_id AS `date_id` FROM t2 JOIN ( SELECT `id` FROM `aggregation_tmp_63054419`   ) AS `t3`  WHERE `t3`.`id` = `t3`.`date_id`   ', 'aggregation_tmp_75803402');
CALL paquExec('SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*_` FROM t1 JOIN ( SELECT `t1_id`,`date_id` FROM `aggregation_tmp_75803402`   ) AS `t2`  WHERE `t2`.`id` = `t2`.`t1_id`  GROUP BY t1.a  ', 'aggregation_tmp_83760394');
CALL paquDropTmp('aggregation_tmp_63054419');
CALL paquDropTmp('aggregation_tmp_75803402');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `t1.a`,SUM(`_count_*_`) AS `_count_*_`
FROM `aggregation_tmp_83760394`  GROUP BY `t1.a`  ;
CALL paquDropTmp('aggregation_tmp_83760394');
This is the query plan optimisation output for the query:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`id`=VALUES(`id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT id AS `id`
FROM t3 
)


-- AGGREGATION SQL:
SELECT `id`
FROM `aggregation_tmp_33922138`   
ON DUPLICATE KEY UPDATE
`id`=VALUES(`id`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1_id`,`date_id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1_id AS `t1_id`,date_id AS `date_id`
FROM t2 JOIN ( SELECT `id`
FROM `aggregation_tmp_33922138`   ) AS `t3`  WHERE `t3`.`id` = `t3`.`date_id`   
)


-- AGGREGATION SQL:
SELECT `t1_id`,`date_id`
FROM `aggregation_tmp_66341051`   
ON DUPLICATE KEY UPDATE
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)
-- INPUT SQL:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1.a`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*_`=`_count_*_` +  VALUES(`_count_*_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*_`
FROM t1 JOIN ( SELECT `t1_id`,`date_id`
FROM `aggregation_tmp_66341051`   ) AS `t2`  WHERE `t2`.`id` = `t2`.`t1_id`  GROUP BY t1.a  
)


-- AGGREGATION SQL:
SELECT `t1.a`,SUM(`_count_*_`) AS `_count_*_`
FROM `aggregation_tmp_10758066`  GROUP BY `t1.a`  
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*_`=`_count_*_` +  VALUES(`_count_*_`)
This is the query plan for the query:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

CALL paquExec('SELECT id AS `id` FROM t3 ', 'aggregation_tmp_33922138');
CALL paquExec('SELECT t1_id AS `t1_id`,date_id AS `date_id` FROM t2 JOIN ( SELECT `id` FROM `aggregation_tmp_33922138`   ) AS `t3`  WHERE `t3`.`id` = `t3`.`date_id`   ', 'aggregation_tmp_66341051');
CALL paquExec('SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*_` FROM t1 JOIN ( SELECT `t1_id`,`date_id` FROM `aggregation_tmp_66341051`   ) AS `t2`  WHERE `t2`.`id` = `t2`.`t1_id`  GROUP BY t1.a  ', 'aggregation_tmp_10758066');
CALL paquDropTmp('aggregation_tmp_33922138');
CALL paquDropTmp('aggregation_tmp_66341051');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `t1.a`,SUM(`_count_*_`) AS `_count_*_`
FROM `aggregation_tmp_10758066`  GROUP BY `t1.a`  ;
CALL paquDropTmp('aggregation_tmp_10758066');
This is the query plan optimisation output for the query:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`id`=VALUES(`id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT id AS `id`
FROM t3 
)


-- AGGREGATION SQL:
SELECT `id`
FROM `aggregation_tmp_80934148`   
ON DUPLICATE KEY UPDATE
`id`=VALUES(`id`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1_id`,`date_id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1_id AS `t1_id`,date_id AS `date_id`
FROM t2 JOIN ( SELECT `id`
FROM `aggregation_tmp_80934148`   ) AS `t3`  WHERE `t3`.`id` = t2.date_id   
)


-- AGGREGATION SQL:
SELECT `t1_id`,`date_id`
FROM `aggregation_tmp_9718685`   
ON DUPLICATE KEY UPDATE
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)
-- INPUT SQL:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1.a`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*_`=`_count_*_` +  VALUES(`_count_*_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*_`
FROM t1 JOIN ( SELECT `t1_id`,`date_id`
FROM `aggregation_tmp_9718685`   ) AS `t2`  WHERE t1.id = `t2`.`t1_id`  GROUP BY t1.a  
)


-- AGGREGATION SQL:
SELECT `t1.a`,SUM(`_count_*_`) AS `_count_*_`
FROM `aggregation_tmp_48719286`  GROUP BY `t1.a`  
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_*_`=`_count_*_` +  VALUES(`_count_*_`)
This is the query plan for the query:
SELECT t1.a, count(*) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

CALL paquExec('SELECT id AS `id` FROM t3 ', 'aggregation_tmp_80934148');
CALL paquExec('SELECT t1_id AS `t1_id`,date_id AS `date_id` FROM t2 JOIN ( SELECT `id` FROM `aggregation_tmp_80934148`   ) AS `t3`  WHERE `t3`.`id` = t2.date_id   ', 'aggregation_tmp_9718685');
CALL paquExec('SELECT t1.a AS `t1.a`,COUNT(*) AS `_count_*_` FROM t1 JOIN ( SELECT `t1_id`,`date_id` FROM `aggregation_tmp_9718685`   ) AS `t2`  WHERE t1.id = `t2`.`t1_id`  GROUP BY t1.a  ', 'aggregation_tmp_48719286');
CALL paquDropTmp('aggregation_tmp_80934148');
CALL paquDropTmp('aggregation_tmp_9718685');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `t1.a`,SUM(`_count_*_`) AS `_count_*_`
FROM `aggregation_tmp_48719286`  GROUP BY `t1.a`  ;
CALL paquDropTmp('aggregation_tmp_48719286');
This is the query plan optimisation output for the query:
SELECT x from table where ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 ) 

-- INPUT SQL:
SELECT x from table where ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 ) 

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`
FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )   
)


-- AGGREGATION SQL:
SELECT `x`
FROM `aggregation_tmp_51697496`   
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)
This is the query plan for the query:
SELECT x from table where ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 ) 

CALL paquExec('SELECT x AS `x` FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )   ', 'aggregation_tmp_51697496');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `x`
FROM `aggregation_tmp_51697496`   ;
CALL paquDropTmp('aggregation_tmp_51697496');
This is the query plan optimisation output for the query:
SELECT x from table where x=0.998373 or (y=sin(0.998373) and z=0.998373) and z=43 or ((z=23 and z=4) or x=1) or y=34 and x between 1 and 2

-- INPUT SQL:
SELECT x from table where x=0.998373 or (y=sin(0.998373) and z=0.998373) and z=43 or ((z=23 and z=4) or x=1) or y=34 and x between 1 and 2

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`
FROM table WHERE ( x = 0.998373 ) or ( ( ( y = sin( 0.998373 ) ) and ( z = 0.998373 ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) )   
)


-- AGGREGATION SQL:
SELECT `x`
FROM `aggregation_tmp_65438843`   
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)
This is the query plan for the query:
SELECT x from table where x=0.998373 or (y=sin(0.998373) and z=0.998373) and z=43 or ((z=23 and z=4) or x=1) or y=34 and x between 1 and 2

CALL paquExec('SELECT x AS `x` FROM table WHERE ( x = 0.998373 ) or ( ( ( y = sin( 0.998373 ) ) and ( z = 0.998373 ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) )   ', 'aggregation_tmp_65438843');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `x`
FROM `aggregation_tmp_65438843`   ;
CALL paquDropTmp('aggregation_tmp_65438843');
This is the query plan optimisation output for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

-- INPUT SQL:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz`
FROM MDR1.Particles62 WHERE rand <= 0.0006    LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_77370950`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)
This is the query plan for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

CALL paquExec('SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz` FROM MDR1.Particles62 WHERE rand <= 0.0006    LIMIT 0,100', 'aggregation_tmp_77370950');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_77370950`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_77370950');
This is the query plan optimisation output for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

-- INPUT SQL:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz`
FROM MDR1.Particles62 WHERE rand <= 0.0006    LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_57571470`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)
This is the query plan for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

CALL paquExec('SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz` FROM MDR1.Particles62 WHERE rand <= 0.0006    LIMIT 0,100', 'aggregation_tmp_57571470');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_57571470`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_57571470');
This is the query plan optimisation output for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

-- INPUT SQL:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz`
FROM MDR1.Particles62 WHERE rand <= 0.0006    LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_45384170`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)
This is the query plan for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

CALL paquExec('SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz` FROM MDR1.Particles62 WHERE rand <= 0.0006    LIMIT 0,100', 'aggregation_tmp_45384170');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_45384170`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_45384170');
This is the query plan optimisation output for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

-- INPUT SQL:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz`
FROM MDR1.Particles62 WHERE rand <= 0.0006    LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_4340374`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)
This is the query plan for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

CALL paquExec('SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz` FROM MDR1.Particles62 WHERE rand <= 0.0006    LIMIT 0,100', 'aggregation_tmp_4340374');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_4340374`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_4340374');
This is the query plan optimisation output for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

-- INPUT SQL:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz`
FROM MDR1.Particles62 WHERE rand <= 0.0006    LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_63952300`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)
This is the query plan for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

CALL paquExec('SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz` FROM MDR1.Particles62 WHERE rand <= 0.0006    LIMIT 0,100', 'aggregation_tmp_63952300');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_63952300`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_63952300');
This is the query plan optimisation output for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

-- INPUT SQL:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz`
FROM MDR1.Particles62 WHERE rand <= 0.0006    LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_75366803`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)
This is the query plan for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

CALL paquExec('SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz` FROM MDR1.Particles62 WHERE rand <= 0.0006    LIMIT 0,100', 'aggregation_tmp_75366803');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_75366803`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_75366803');
This is the query plan optimisation output for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

-- INPUT SQL:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz`
FROM MDR1.Particles62 WHERE rand <= 0.0006    LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_87682064`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)
This is the query plan for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

CALL paquExec('SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz` FROM MDR1.Particles62 WHERE rand <= 0.0006    LIMIT 0,100', 'aggregation_tmp_87682064');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_87682064`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_87682064');
This is the query plan optimisation output for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

-- INPUT SQL:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz`
FROM MDR1.Particles62 WHERE rand <= 0.0006    LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_40657349`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)
This is the query plan for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

CALL paquExec('SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz` FROM MDR1.Particles62 WHERE rand <= 0.0006    LIMIT 0,100', 'aggregation_tmp_40657349');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_40657349`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_40657349');
This is the query plan optimisation output for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

-- INPUT SQL:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz`
FROM MDR1.Particles62 WHERE rand <= 0.0006    LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_58286138`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)
This is the query plan for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

CALL paquExec('SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz` FROM MDR1.Particles62 WHERE rand <= 0.0006    LIMIT 0,100', 'aggregation_tmp_58286138');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_58286138`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_58286138');
This is the query plan optimisation output for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

-- INPUT SQL:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz`
FROM MDR1.Particles62 WHERE     LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_11722600`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)
This is the query plan for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

CALL paquExec('SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz` FROM MDR1.Particles62 WHERE     LIMIT 0,100', 'aggregation_tmp_11722600');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_11722600`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_11722600');
This is the query plan optimisation output for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

-- INPUT SQL:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz`
FROM MDR1.Particles62 WHERE rand <= 0.0006    LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_59453794`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)
This is the query plan for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

CALL paquExec('SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz` FROM MDR1.Particles62 WHERE rand <= 0.0006    LIMIT 0,100', 'aggregation_tmp_59453794');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_59453794`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_59453794');
This is the query plan optimisation output for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

-- INPUT SQL:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz`
FROM MDR1.Particles62 WHERE rand  0.0006    LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_70075239`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)
This is the query plan for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

CALL paquExec('SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz` FROM MDR1.Particles62 WHERE rand  0.0006    LIMIT 0,100', 'aggregation_tmp_70075239');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_70075239`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_70075239');
This is the query plan optimisation output for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

-- INPUT SQL:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz`
FROM MDR1.Particles62 WHERE rand  0.0006    LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_47657873`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)
This is the query plan for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

CALL paquExec('SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz` FROM MDR1.Particles62 WHERE rand  0.0006    LIMIT 0,100', 'aggregation_tmp_47657873');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_47657873`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_47657873');
This is the query plan optimisation output for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

-- INPUT SQL:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz`
FROM MDR1.Particles62 WHERE rand  0.0006    LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_20431285`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)
This is the query plan for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

CALL paquExec('SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz` FROM MDR1.Particles62 WHERE rand  0.0006    LIMIT 0,100', 'aggregation_tmp_20431285');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_20431285`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_20431285');
This is the query plan optimisation output for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

-- INPUT SQL:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz`
FROM MDR1.Particles62 WHERE   0.0006    LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_14826619`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)
This is the query plan for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

CALL paquExec('SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz` FROM MDR1.Particles62 WHERE   0.0006    LIMIT 0,100', 'aggregation_tmp_14826619');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_14826619`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_14826619');
This is the query plan optimisation output for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

-- INPUT SQL:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz`
FROM MDR1.Particles62 WHERE rand()  0.0006    LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_12781425`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)
This is the query plan for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

CALL paquExec('SELECT particleId AS `particleId`,x AS `x`,y AS `y`,z AS `z`,vx AS `vx`,vy AS `vy`,vz AS `vz` FROM MDR1.Particles62 WHERE rand()  0.0006    LIMIT 0,100', 'aggregation_tmp_12781425');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_12781425`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_12781425');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   
)


-- AGGREGATION SQL:
SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_31700349`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   ', 'aggregation_tmp_31700349');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_31700349`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_31700349');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   
)


-- AGGREGATION SQL:
SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_16073027`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   ', 'aggregation_tmp_16073027');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_16073027`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_16073027');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   
)


-- AGGREGATION SQL:
SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_89333623`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   ', 'aggregation_tmp_89333623');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_89333623`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_89333623');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   
)


-- AGGREGATION SQL:
SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_52152624`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   ', 'aggregation_tmp_52152624');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_52152624`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_52152624');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   
)


-- AGGREGATION SQL:
SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_6507910`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   ', 'aggregation_tmp_6507910');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_6507910`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_6507910');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   
)


-- AGGREGATION SQL:
SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_41657539`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   ', 'aggregation_tmp_41657539');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_41657539`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_41657539');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   
)


-- AGGREGATION SQL:
SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_67799469`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   ', 'aggregation_tmp_67799469');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_67799469`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_67799469');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   
)


-- AGGREGATION SQL:
SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_90682407`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   ', 'aggregation_tmp_90682407');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_90682407`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_90682407');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   
)


-- AGGREGATION SQL:
SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_6488614`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   ', 'aggregation_tmp_6488614');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_6488614`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_6488614');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   
)


-- AGGREGATION SQL:
SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_61273625`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   ', 'aggregation_tmp_61273625');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_61273625`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_61273625');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`
FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`
FROM `aggregation_tmp_34839797`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId`
FROM `aggregation_tmp_34839797`  ORDER BY `Mvir` DESC  LIMIT 0,1)    
)


-- AGGREGATION SQL:
SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_21709529`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId` FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_34839797');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId` FROM `aggregation_tmp_34839797`  ORDER BY `Mvir` DESC  LIMIT 0,1)    ', 'aggregation_tmp_21709529');
CALL paquDropTmp('aggregation_tmp_34839797');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_21709529`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_21709529');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`
FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`
FROM `aggregation_tmp_23930733`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId`
FROM `aggregation_tmp_23930733`  ORDER BY `Mvir` DESC  LIMIT 0,1)    
)


-- AGGREGATION SQL:
SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_28166505`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId` FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_23930733');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId` FROM `aggregation_tmp_23930733`  ORDER BY `Mvir` DESC  LIMIT 0,1)    ', 'aggregation_tmp_28166505');
CALL paquDropTmp('aggregation_tmp_23930733');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_28166505`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_28166505');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`
FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`
FROM `aggregation_tmp_79435645`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId`
FROM `aggregation_tmp_79435645`  ORDER BY `Mvir` DESC  LIMIT 0,1)    
)


-- AGGREGATION SQL:
SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_13022838`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId` FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_79435645');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId` FROM `aggregation_tmp_79435645`  ORDER BY `Mvir` DESC  LIMIT 0,1)    ', 'aggregation_tmp_13022838');
CALL paquDropTmp('aggregation_tmp_79435645');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_13022838`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_13022838');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`
FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`
FROM `aggregation_tmp_10912150`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   
)


-- AGGREGATION SQL:
SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_53380109`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId` FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_10912150');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   ', 'aggregation_tmp_53380109');
CALL paquDropTmp('aggregation_tmp_10912150');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_53380109`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_53380109');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`
FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`
FROM `aggregation_tmp_13048139`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   
)


-- AGGREGATION SQL:
SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_47773170`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId` FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_13048139');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   ', 'aggregation_tmp_47773170');
CALL paquDropTmp('aggregation_tmp_13048139');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_47773170`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_47773170');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`
FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`
FROM `aggregation_tmp_4828976`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   
)


-- AGGREGATION SQL:
SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_45065450`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId` FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_4828976');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   ', 'aggregation_tmp_45065450');
CALL paquDropTmp('aggregation_tmp_4828976');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_45065450`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_45065450');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`
FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`
FROM `aggregation_tmp_92127348`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   
)


-- AGGREGATION SQL:
SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_59517583`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId` FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_92127348');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   ', 'aggregation_tmp_59517583');
CALL paquDropTmp('aggregation_tmp_92127348');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_59517583`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_59517583');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`
FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`
FROM `aggregation_tmp_63981362`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   
)


-- AGGREGATION SQL:
SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_35632384`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId` FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_63981362');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   ', 'aggregation_tmp_35632384');
CALL paquDropTmp('aggregation_tmp_63981362');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_35632384`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_35632384');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`
FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`
FROM `aggregation_tmp_89608725`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   
)


-- AGGREGATION SQL:
SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_37453412`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId` FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_89608725');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   ', 'aggregation_tmp_37453412');
CALL paquDropTmp('aggregation_tmp_89608725');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_37453412`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_37453412');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`
FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`
FROM `aggregation_tmp_27679245`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   
)


-- AGGREGATION SQL:
SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_68708758`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId` FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_27679245');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   ', 'aggregation_tmp_68708758');
CALL paquDropTmp('aggregation_tmp_27679245');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_68708758`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_68708758');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`
FROM `aggregation_tmp_32866099`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   
)


-- AGGREGATION SQL:
SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_95732971`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_32866099');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   ', 'aggregation_tmp_95732971');
CALL paquDropTmp('aggregation_tmp_32866099');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_95732971`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_95732971');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`
FROM `aggregation_tmp_15994442`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   
)


-- AGGREGATION SQL:
SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_57795529`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_15994442');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1)   ', 'aggregation_tmp_57795529');
CALL paquDropTmp('aggregation_tmp_15994442');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_57795529`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_57795529');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`
FROM `aggregation_tmp_98644687`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId`
FROM `aggregation_tmp_98644687`  ORDER BY `Mvir` DESC  LIMIT 0,1)    
)


-- AGGREGATION SQL:
SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_67944608`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_98644687');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId` FROM `aggregation_tmp_98644687`  ORDER BY `Mvir` DESC  LIMIT 0,1)    ', 'aggregation_tmp_67944608');
CALL paquDropTmp('aggregation_tmp_98644687');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_67944608`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_67944608');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`
FROM `aggregation_tmp_27161827`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId`
FROM `aggregation_tmp_27161827`  ORDER BY `Mvir` DESC  LIMIT 0,1)    
)


-- AGGREGATION SQL:
SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_21270075`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE snapnum = 416  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_27161827');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId` FROM `aggregation_tmp_27161827`  ORDER BY `Mvir` DESC  LIMIT 0,1)    ', 'aggregation_tmp_21270075');
CALL paquDropTmp('aggregation_tmp_27161827');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_21270075`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_21270075');
This is the query plan optimisation output for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z`
FROM MDR1.FOF AS `f` WHERE 1000   
)


-- AGGREGATION SQL:
SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_43387493`   
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
-- INPUT SQL:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS `f.x`,f.`f.y` AS `f.y`,f.`f.z` AS `f.z`
FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_43387493`   ) AS `f`  WHERE POWER( b.x - `f`.`f.x`, 2 )    LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_79312105`    LIMIT 0,1
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
This is the query plan for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

CALL paquExec('SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z` FROM MDR1.FOF AS `f` WHERE 1000   ', 'aggregation_tmp_43387493');
CALL paquExec('SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS `f.x`,f.`f.y` AS `f.y`,f.`f.z` AS `f.z` FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z` FROM `aggregation_tmp_43387493`   ) AS `f`  WHERE POWER( b.x - `f`.`f.x`, 2 )    LIMIT 0,1', 'aggregation_tmp_79312105');
CALL paquDropTmp('aggregation_tmp_43387493');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_79312105`    LIMIT 0,1;
CALL paquDropTmp('aggregation_tmp_79312105');
This is the query plan optimisation output for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z`
FROM MDR1.FOF AS `f` WHERE 1000   
)


-- AGGREGATION SQL:
SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_95980801`   
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
-- INPUT SQL:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS `f.x`,f.`f.y` AS `f.y`,f.`f.z` AS `f.z`
FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_95980801`   ) AS `f`  WHERE POWER( b.x - `f`.`f.x`, 2 )    LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_95450069`    LIMIT 0,1
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
This is the query plan for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

CALL paquExec('SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z` FROM MDR1.FOF AS `f` WHERE 1000   ', 'aggregation_tmp_95980801');
CALL paquExec('SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS `f.x`,f.`f.y` AS `f.y`,f.`f.z` AS `f.z` FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z` FROM `aggregation_tmp_95980801`   ) AS `f`  WHERE POWER( b.x - `f`.`f.x`, 2 )    LIMIT 0,1', 'aggregation_tmp_95450069');
CALL paquDropTmp('aggregation_tmp_95980801');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_95450069`    LIMIT 0,1;
CALL paquDropTmp('aggregation_tmp_95450069');
This is the query plan optimisation output for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z`
FROM MDR1.FOF AS `f` 
)


-- AGGREGATION SQL:
SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_48600124`   
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
-- INPUT SQL:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS `f.x`,f.`f.y` AS `f.y`,f.`f.z` AS `f.z`
FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_48600124`   ) AS `f`  WHERE ( POWER( b.x - `f`.`f.x`, 2 ) < 1000 )    LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_41662462`    LIMIT 0,1
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
This is the query plan for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

CALL paquExec('SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z` FROM MDR1.FOF AS `f` ', 'aggregation_tmp_48600124');
CALL paquExec('SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,f.`f.x` AS `f.x`,f.`f.y` AS `f.y`,f.`f.z` AS `f.z` FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z` FROM `aggregation_tmp_48600124`   ) AS `f`  WHERE ( POWER( b.x - `f`.`f.x`, 2 ) < 1000 )    LIMIT 0,1', 'aggregation_tmp_41662462');
CALL paquDropTmp('aggregation_tmp_48600124');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_41662462`    LIMIT 0,1;
CALL paquDropTmp('aggregation_tmp_41662462');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE ( bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) )   
)


-- AGGREGATION SQL:
SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_51771385`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE ( bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) )   ', 'aggregation_tmp_51771385');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_51771385`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_51771385');
This is the query plan optimisation output for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`bdmId`,`Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT bdmId AS `bdmId`,Mvir AS `Mvir`
FROM Bolshoi.BDMV WHERE ( snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `bdmId`
FROM `aggregation_tmp_24307582`  ORDER BY `Mvir` DESC  LIMIT 0,1
ON DUPLICATE KEY UPDATE
`bdmId`=VALUES(`bdmId`)
-- INPUT SQL:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms`
FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId`
FROM `aggregation_tmp_24307582`  ORDER BY `Mvir` DESC  LIMIT 0,1)    
)


-- AGGREGATION SQL:
SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_13247520`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC 
ON DUPLICATE KEY UPDATE
`Bolshoi__BDMVProf__bdmProfileId`=VALUES(`Bolshoi__BDMVProf__bdmProfileId`),
`Bolshoi__BDMVProf__bdmId`=VALUES(`Bolshoi__BDMVProf__bdmId`),
`Bolshoi__BDMVProf__snapnum`=VALUES(`Bolshoi__BDMVProf__snapnum`),
`Bolshoi__BDMVProf__NinCat`=VALUES(`Bolshoi__BDMVProf__NinCat`),
`Bolshoi__BDMVProf__R_Rvir`=VALUES(`Bolshoi__BDMVProf__R_Rvir`),
`Bolshoi__BDMVProf__Rbin`=VALUES(`Bolshoi__BDMVProf__Rbin`),
`Bolshoi__BDMVProf__np`=VALUES(`Bolshoi__BDMVProf__np`),
`Bolshoi__BDMVProf__mass`=VALUES(`Bolshoi__BDMVProf__mass`),
`Bolshoi__BDMVProf__dens`=VALUES(`Bolshoi__BDMVProf__dens`),
`Bolshoi__BDMVProf__Vcirc`=VALUES(`Bolshoi__BDMVProf__Vcirc`),
`Bolshoi__BDMVProf__VpropRms`=VALUES(`Bolshoi__BDMVProf__VpropRms`),
`Bolshoi__BDMVProf__Vrad`=VALUES(`Bolshoi__BDMVProf__Vrad`),
`Bolshoi__BDMVProf__VradRms`=VALUES(`Bolshoi__BDMVProf__VradRms`),
`Bolshoi__BDMVProf__boundR_Rvir`=VALUES(`Bolshoi__BDMVProf__boundR_Rvir`),
`Bolshoi__BDMVProf__boundNp`=VALUES(`Bolshoi__BDMVProf__boundNp`),
`Bolshoi__BDMVProf__boundMass`=VALUES(`Bolshoi__BDMVProf__boundMass`),
`Bolshoi__BDMVProf__boundDens`=VALUES(`Bolshoi__BDMVProf__boundDens`),
`Bolshoi__BDMVProf__boundVcirc`=VALUES(`Bolshoi__BDMVProf__boundVcirc`),
`Bolshoi__BDMVProf__boundVcircRms`=VALUES(`Bolshoi__BDMVProf__boundVcircRms`),
`Bolshoi__BDMVProf__boundVrad`=VALUES(`Bolshoi__BDMVProf__boundVrad`),
`Bolshoi__BDMVProf__boundVradRms`=VALUES(`Bolshoi__BDMVProf__boundVradRms`)
This is the query plan for the query:
SELECT Bolshoi.BDMVProf.bdmProfileId as `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId as `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum as `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat as `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir as `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin as `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np as `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass as `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens as `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc as `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms as `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad as `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms as `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir as `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp as `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass as `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens as `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc as `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms as `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad as `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms as `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = (SELECT bdmId FROM Bolshoi.BDMV WHERE snapnum=416 ORDER BY Mvir DESC LIMIT 1) ORDER BY `Bolshoi__BDMVProf__Rbin` ASC

CALL paquExec('SELECT bdmId AS `bdmId`,Mvir AS `Mvir` FROM Bolshoi.BDMV WHERE ( snapnum = 416 )  ORDER BY `Mvir` DESC  LIMIT 0,1', 'aggregation_tmp_24307582');
CALL paquExec('SELECT Bolshoi.BDMVProf.bdmProfileId AS `Bolshoi__BDMVProf__bdmProfileId`,Bolshoi.BDMVProf.bdmId AS `Bolshoi__BDMVProf__bdmId`,Bolshoi.BDMVProf.snapnum AS `Bolshoi__BDMVProf__snapnum`,Bolshoi.BDMVProf.NinCat AS `Bolshoi__BDMVProf__NinCat`,Bolshoi.BDMVProf.R_Rvir AS `Bolshoi__BDMVProf__R_Rvir`,Bolshoi.BDMVProf.Rbin AS `Bolshoi__BDMVProf__Rbin`,Bolshoi.BDMVProf.np AS `Bolshoi__BDMVProf__np`,Bolshoi.BDMVProf.mass AS `Bolshoi__BDMVProf__mass`,Bolshoi.BDMVProf.dens AS `Bolshoi__BDMVProf__dens`,Bolshoi.BDMVProf.Vcirc AS `Bolshoi__BDMVProf__Vcirc`,Bolshoi.BDMVProf.VpropRms AS `Bolshoi__BDMVProf__VpropRms`,Bolshoi.BDMVProf.Vrad AS `Bolshoi__BDMVProf__Vrad`,Bolshoi.BDMVProf.VradRms AS `Bolshoi__BDMVProf__VradRms`,Bolshoi.BDMVProf.boundR_Rvir AS `Bolshoi__BDMVProf__boundR_Rvir`,Bolshoi.BDMVProf.boundNp AS `Bolshoi__BDMVProf__boundNp`,Bolshoi.BDMVProf.boundMass AS `Bolshoi__BDMVProf__boundMass`,Bolshoi.BDMVProf.boundDens AS `Bolshoi__BDMVProf__boundDens`,Bolshoi.BDMVProf.boundVcirc AS `Bolshoi__BDMVProf__boundVcirc`,Bolshoi.BDMVProf.boundVcircRms AS `Bolshoi__BDMVProf__boundVcircRms`,Bolshoi.BDMVProf.boundVrad AS `Bolshoi__BDMVProf__boundVrad`,Bolshoi.BDMVProf.boundVradRms AS `Bolshoi__BDMVProf__boundVradRms` FROM Bolshoi.BDMVProf WHERE bdmId = ( SELECT `bdmId` FROM `aggregation_tmp_24307582`  ORDER BY `Mvir` DESC  LIMIT 0,1)    ', 'aggregation_tmp_13247520');
CALL paquDropTmp('aggregation_tmp_24307582');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `Bolshoi__BDMVProf__bdmProfileId`,`Bolshoi__BDMVProf__bdmId`,`Bolshoi__BDMVProf__snapnum`,`Bolshoi__BDMVProf__NinCat`,`Bolshoi__BDMVProf__R_Rvir`,`Bolshoi__BDMVProf__Rbin`,`Bolshoi__BDMVProf__np`,`Bolshoi__BDMVProf__mass`,`Bolshoi__BDMVProf__dens`,`Bolshoi__BDMVProf__Vcirc`,`Bolshoi__BDMVProf__VpropRms`,`Bolshoi__BDMVProf__Vrad`,`Bolshoi__BDMVProf__VradRms`,`Bolshoi__BDMVProf__boundR_Rvir`,`Bolshoi__BDMVProf__boundNp`,`Bolshoi__BDMVProf__boundMass`,`Bolshoi__BDMVProf__boundDens`,`Bolshoi__BDMVProf__boundVcirc`,`Bolshoi__BDMVProf__boundVcircRms`,`Bolshoi__BDMVProf__boundVrad`,`Bolshoi__BDMVProf__boundVradRms`
FROM `aggregation_tmp_13247520`  ORDER BY `Bolshoi__BDMVProf__Rbin` ASC ;
CALL paquDropTmp('aggregation_tmp_13247520');
This is the query plan optimisation output for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

-- INPUT SQL:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`
FROM table WHERE ( ( x = 0.998373 ) ) or ( ( ( ( y = SIN( 0.998373 ) ) ) and ( ( ( z = 0.998373 ) ) ) ) and ( ( z = 43 ) ) ) or ( ( ( ( z = 23 ) ) and ( ( ( z = 4 ) ) ) ) or ( ( ( x = 1 ) ) ) ) or ( ( ( y = 34 ) ) and ( ( x between 1 and 2 ) ) ) or ( ( ( z = 1 + 5 * 87.2134 ) ) )   
)


-- AGGREGATION SQL:
SELECT `x`
FROM `aggregation_tmp_96314375`   
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)
This is the query plan for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

CALL paquExec('SELECT x AS `x` FROM table WHERE ( ( x = 0.998373 ) ) or ( ( ( ( y = SIN( 0.998373 ) ) ) and ( ( ( z = 0.998373 ) ) ) ) and ( ( z = 43 ) ) ) or ( ( ( ( z = 23 ) ) and ( ( ( z = 4 ) ) ) ) or ( ( ( x = 1 ) ) ) ) or ( ( ( y = 34 ) ) and ( ( x between 1 and 2 ) ) ) or ( ( ( z = 1 + 5 * 87.2134 ) ) )   ', 'aggregation_tmp_96314375');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `x`
FROM `aggregation_tmp_96314375`   ;
CALL paquDropTmp('aggregation_tmp_96314375');
This is the query plan optimisation output for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

-- INPUT SQL:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`
FROM table WHERE ( x = 0.998373 ) or ( ( ( y = SIN( 0.998373 ) ) and ( z = 0.998373 ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) ) or ( ( z = 1 + 5 * 87.2134 ) )   
)


-- AGGREGATION SQL:
SELECT `x`
FROM `aggregation_tmp_4068469`   
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)
This is the query plan for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

CALL paquExec('SELECT x AS `x` FROM table WHERE ( x = 0.998373 ) or ( ( ( y = SIN( 0.998373 ) ) and ( z = 0.998373 ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) ) or ( ( z = 1 + 5 * 87.2134 ) )   ', 'aggregation_tmp_4068469');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `x`
FROM `aggregation_tmp_4068469`   ;
CALL paquDropTmp('aggregation_tmp_4068469');
This is the query plan optimisation output for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

-- INPUT SQL:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`
FROM table WHERE ( x = 0.998373 ) or ( ( ( y = SIN( 0.998373 ) ) and ( z = 0.998373 ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) ) or ( ( z = 1 + 5 * 87.2134 ) )   
)


-- AGGREGATION SQL:
SELECT `x`
FROM `aggregation_tmp_92745872`   
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)
This is the query plan for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

CALL paquExec('SELECT x AS `x` FROM table WHERE ( x = 0.998373 ) or ( ( ( y = SIN( 0.998373 ) ) and ( z = 0.998373 ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) ) or ( ( z = 1 + 5 * 87.2134 ) )   ', 'aggregation_tmp_92745872');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `x`
FROM `aggregation_tmp_92745872`   ;
CALL paquDropTmp('aggregation_tmp_92745872');
This is the query plan optimisation output for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

-- INPUT SQL:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`
FROM table WHERE ( x = 0.998373 ) or ( ( ( y = SIN( 0.998373 ) ) and ( z = 0.998373 ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) ) or ( ( z = 1 + 5 * 87.2134 ) )   
)


-- AGGREGATION SQL:
SELECT `x`
FROM `aggregation_tmp_39578726`   
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)
This is the query plan for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

CALL paquExec('SELECT x AS `x` FROM table WHERE ( x = 0.998373 ) or ( ( ( y = SIN( 0.998373 ) ) and ( z = 0.998373 ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) ) or ( ( z = 1 + 5 * 87.2134 ) )   ', 'aggregation_tmp_39578726');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `x`
FROM `aggregation_tmp_39578726`   ;
CALL paquDropTmp('aggregation_tmp_39578726');
This is the query plan optimisation output for the query:
SELECT x FROM table WHERE x=0.998373 or (y=sin(0.998373) and z=0.998373) and z=43 or ((z=23 and z=4) or x=1) or y=34 and x between 1 and 2

-- INPUT SQL:
SELECT x FROM table WHERE x=0.998373 or (y=sin(0.998373) and z=0.998373) and z=43 or ((z=23 and z=4) or x=1) or y=34 and x between 1 and 2

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`
FROM table WHERE ( x = 0.998373 ) or ( ( y = sin( 0.998373 ) and z = 0.998373 ) and ( z = 43 ) ) or ( ( z = 23 and z = 4 ) or x = 1 ) or ( ( y = 34 ) and ( x between 1 and 2 ) )   
)


-- AGGREGATION SQL:
SELECT `x`
FROM `aggregation_tmp_53288668`   
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)
This is the query plan for the query:
SELECT x FROM table WHERE x=0.998373 or (y=sin(0.998373) and z=0.998373) and z=43 or ((z=23 and z=4) or x=1) or y=34 and x between 1 and 2

CALL paquExec('SELECT x AS `x` FROM table WHERE ( x = 0.998373 ) or ( ( y = sin( 0.998373 ) and z = 0.998373 ) and ( z = 43 ) ) or ( ( z = 23 and z = 4 ) or x = 1 ) or ( ( y = 34 ) and ( x between 1 and 2 ) )   ', 'aggregation_tmp_53288668');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `x`
FROM `aggregation_tmp_53288668`   ;
CALL paquDropTmp('aggregation_tmp_53288668');
This is the query plan optimisation output for the query:
SELECT x FROM table WHERE x=0.998373 or (y=sin(0.998373) and z=0.998373) and z=43 or ((z=23 and z=4) or x=1) or y=34 and x between 1 and 2

-- INPUT SQL:
SELECT x FROM table WHERE x=0.998373 or (y=sin(0.998373) and z=0.998373) and z=43 or ((z=23 and z=4) or x=1) or y=34 and x between 1 and 2

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`
FROM table WHERE ( x = 0.998373 ) or ( ( ( y = sin( 0.998373 ) ) and ( z = 0.998373 ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) )   
)


-- AGGREGATION SQL:
SELECT `x`
FROM `aggregation_tmp_79483523`   
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)
This is the query plan for the query:
SELECT x FROM table WHERE x=0.998373 or (y=sin(0.998373) and z=0.998373) and z=43 or ((z=23 and z=4) or x=1) or y=34 and x between 1 and 2

CALL paquExec('SELECT x AS `x` FROM table WHERE ( x = 0.998373 ) or ( ( ( y = sin( 0.998373 ) ) and ( z = 0.998373 ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) )   ', 'aggregation_tmp_79483523');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `x`
FROM `aggregation_tmp_79483523`   ;
CALL paquDropTmp('aggregation_tmp_79483523');
This is the query plan optimisation output for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

-- INPUT SQL:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`
FROM table WHERE ( ( x = 0.998373 ) ) or ( ( ( ( y = SIN( 0.998373 ) ) ) and ( ( ( z = 0.998373 ) ) ) ) and ( ( z = 43 ) ) ) or ( ( ( ( z = 23 ) ) and ( ( ( z = 4 ) ) ) ) or ( ( ( x = 1 ) ) ) ) or ( ( ( y = 34 ) ) and ( ( x between 1 and 2 ) ) ) or ( ( ( z = 1 + 5 * 87.2134 ) ) )   
)


-- AGGREGATION SQL:
SELECT `x`
FROM `aggregation_tmp_47323565`   
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)
This is the query plan for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

CALL paquExec('SELECT x AS `x` FROM table WHERE ( ( x = 0.998373 ) ) or ( ( ( ( y = SIN( 0.998373 ) ) ) and ( ( ( z = 0.998373 ) ) ) ) and ( ( z = 43 ) ) ) or ( ( ( ( z = 23 ) ) and ( ( ( z = 4 ) ) ) ) or ( ( ( x = 1 ) ) ) ) or ( ( ( y = 34 ) ) and ( ( x between 1 and 2 ) ) ) or ( ( ( z = 1 + 5 * 87.2134 ) ) )   ', 'aggregation_tmp_47323565');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `x`
FROM `aggregation_tmp_47323565`   ;
CALL paquDropTmp('aggregation_tmp_47323565');
This is the query plan optimisation output for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

-- INPUT SQL:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`
FROM table WHERE ( ( x = 0.998373 ) ) or ( ( ( ( y = SIN( 0.998373 ) ) ) and ( ( ( z = 0.998373 ) ) ) ) and ( ( z = 43 ) ) ) or ( ( ( ( z = 23 ) ) and ( ( ( z = 4 ) ) ) ) or ( ( ( x = 1 ) ) ) ) or ( ( ( y = 34 ) ) and ( ( x between 1 and 2 ) ) ) or ( ( ( z = 1 + 5 * 87.2134 ) ) )   
)


-- AGGREGATION SQL:
SELECT `x`
FROM `aggregation_tmp_35298241`   
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)
This is the query plan for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

CALL paquExec('SELECT x AS `x` FROM table WHERE ( ( x = 0.998373 ) ) or ( ( ( ( y = SIN( 0.998373 ) ) ) and ( ( ( z = 0.998373 ) ) ) ) and ( ( z = 43 ) ) ) or ( ( ( ( z = 23 ) ) and ( ( ( z = 4 ) ) ) ) or ( ( ( x = 1 ) ) ) ) or ( ( ( y = 34 ) ) and ( ( x between 1 and 2 ) ) ) or ( ( ( z = 1 + 5 * 87.2134 ) ) )   ', 'aggregation_tmp_35298241');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `x`
FROM `aggregation_tmp_35298241`   ;
CALL paquDropTmp('aggregation_tmp_35298241');
This is the query plan optimisation output for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

-- INPUT SQL:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`
FROM table WHERE ( ( x = 0.998373 ) ) or ( ( ( ( y = SIN( 0.998373 ) ) ) and ( ( ( z = 0.998373 ) ) ) ) and ( ( z = 43 ) ) ) or ( ( ( ( z = 23 ) ) and ( ( ( z = 4 ) ) ) ) or ( ( ( x = 1 ) ) ) ) or ( ( ( y = 34 ) ) and ( ( x between 1 and 2 ) ) ) or ( ( ( z = 1 + 5 * 87.2134 ) ) )   
)


-- AGGREGATION SQL:
SELECT `x`
FROM `aggregation_tmp_4926182`   
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)
This is the query plan for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

CALL paquExec('SELECT x AS `x` FROM table WHERE ( ( x = 0.998373 ) ) or ( ( ( ( y = SIN( 0.998373 ) ) ) and ( ( ( z = 0.998373 ) ) ) ) and ( ( z = 43 ) ) ) or ( ( ( ( z = 23 ) ) and ( ( ( z = 4 ) ) ) ) or ( ( ( x = 1 ) ) ) ) or ( ( ( y = 34 ) ) and ( ( x between 1 and 2 ) ) ) or ( ( ( z = 1 + 5 * 87.2134 ) ) )   ', 'aggregation_tmp_4926182');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `x`
FROM `aggregation_tmp_4926182`   ;
CALL paquDropTmp('aggregation_tmp_4926182');
This is the query plan optimisation output for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

-- INPUT SQL:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`
FROM table WHERE ( x = 0.998373 ) or ( ( ( y = SIN( 0.998373 ) ) and ( ( z = 0.998373 ) ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( ( z = 4 ) ) ) or ( ( x = 1 ) ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) ) or ( ( z = 1 + 5 * 87.2134 ) )   
)


-- AGGREGATION SQL:
SELECT `x`
FROM `aggregation_tmp_93684208`   
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)
This is the query plan for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

CALL paquExec('SELECT x AS `x` FROM table WHERE ( x = 0.998373 ) or ( ( ( y = SIN( 0.998373 ) ) and ( ( z = 0.998373 ) ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( ( z = 4 ) ) ) or ( ( x = 1 ) ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) ) or ( ( z = 1 + 5 * 87.2134 ) )   ', 'aggregation_tmp_93684208');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `x`
FROM `aggregation_tmp_93684208`   ;
CALL paquDropTmp('aggregation_tmp_93684208');
This is the query plan optimisation output for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

-- INPUT SQL:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`
FROM table WHERE ( x = 0.998373 ) or ( ( ( y = SIN( 0.998373 ) ) and ( ( z = 0.998373 ) ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( ( z = 4 ) ) ) or ( ( x = 1 ) ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) ) or ( ( z = 1 + 5 * 87.2134 ) )   
)


-- AGGREGATION SQL:
SELECT `x`
FROM `aggregation_tmp_68993596`   
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)
This is the query plan for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

CALL paquExec('SELECT x AS `x` FROM table WHERE ( x = 0.998373 ) or ( ( ( y = SIN( 0.998373 ) ) and ( ( z = 0.998373 ) ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( ( z = 4 ) ) ) or ( ( x = 1 ) ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) ) or ( ( z = 1 + 5 * 87.2134 ) )   ', 'aggregation_tmp_68993596');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `x`
FROM `aggregation_tmp_68993596`   ;
CALL paquDropTmp('aggregation_tmp_68993596');
This is the query plan optimisation output for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

-- INPUT SQL:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`
FROM table WHERE ( x = 0.998373 ) or ( ( ( y = SIN( 0.998373 ) ) and ( ( z = 0.998373 ) ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( ( z = 4 ) ) ) or ( ( x = 1 ) ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) ) or ( ( z = 1 + 5 * 87.2134 ) )   
)


-- AGGREGATION SQL:
SELECT `x`
FROM `aggregation_tmp_91867346`   
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)
This is the query plan for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

CALL paquExec('SELECT x AS `x` FROM table WHERE ( x = 0.998373 ) or ( ( ( y = SIN( 0.998373 ) ) and ( ( z = 0.998373 ) ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( ( z = 4 ) ) ) or ( ( x = 1 ) ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) ) or ( ( z = 1 + 5 * 87.2134 ) )   ', 'aggregation_tmp_91867346');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `x`
FROM `aggregation_tmp_91867346`   ;
CALL paquDropTmp('aggregation_tmp_91867346');
This is the query plan optimisation output for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

-- INPUT SQL:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`
FROM table WHERE ( x = 0.998373 ) or ( ( ( y = SIN( 0.998373 ) ) and ( ( z = 0.998373 ) ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( ( z = 4 ) ) ) or ( ( x = 1 ) ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) ) or ( ( z = 1 + 5 * 87.2134 ) )   
)


-- AGGREGATION SQL:
SELECT `x`
FROM `aggregation_tmp_80765877`   
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)
This is the query plan for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

CALL paquExec('SELECT x AS `x` FROM table WHERE ( x = 0.998373 ) or ( ( ( y = SIN( 0.998373 ) ) and ( ( z = 0.998373 ) ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( ( z = 4 ) ) ) or ( ( x = 1 ) ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) ) or ( ( z = 1 + 5 * 87.2134 ) )   ', 'aggregation_tmp_80765877');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `x`
FROM `aggregation_tmp_80765877`   ;
CALL paquDropTmp('aggregation_tmp_80765877');
This is the query plan optimisation output for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

-- INPUT SQL:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`
FROM table WHERE ( x = 0.998373 ) or ( ( ( y = SIN( 0.998373 ) ) and ( ( z = 0.998373 ) ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( ( z = 4 ) ) ) or ( ( x = 1 ) ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) ) or ( ( z = 1 + 5 * 87.2134 ) )   
)


-- AGGREGATION SQL:
SELECT `x`
FROM `aggregation_tmp_73214877`   
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)
This is the query plan for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

CALL paquExec('SELECT x AS `x` FROM table WHERE ( x = 0.998373 ) or ( ( ( y = SIN( 0.998373 ) ) and ( ( z = 0.998373 ) ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( ( z = 4 ) ) ) or ( ( x = 1 ) ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) ) or ( ( z = 1 + 5 * 87.2134 ) )   ', 'aggregation_tmp_73214877');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `x`
FROM `aggregation_tmp_73214877`   ;
CALL paquDropTmp('aggregation_tmp_73214877');
This is the query plan optimisation output for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

-- INPUT SQL:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`
FROM table WHERE ( x = 0.998373 ) or ( ( ( y = SIN( 0.998373 ) ) and ( ( z = 0.998373 ) ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( ( z = 4 ) ) ) or ( ( x = 1 ) ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) ) or ( ( z = 1 + 5 * 87.2134 ) )   
)


-- AGGREGATION SQL:
SELECT `x`
FROM `aggregation_tmp_69240099`   
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)
This is the query plan for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

CALL paquExec('SELECT x AS `x` FROM table WHERE ( x = 0.998373 ) or ( ( ( y = SIN( 0.998373 ) ) and ( ( z = 0.998373 ) ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( ( z = 4 ) ) ) or ( ( x = 1 ) ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) ) or ( ( z = 1 + 5 * 87.2134 ) )   ', 'aggregation_tmp_69240099');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `x`
FROM `aggregation_tmp_69240099`   ;
CALL paquDropTmp('aggregation_tmp_69240099');
This is the query plan optimisation output for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

-- INPUT SQL:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`
FROM table WHERE ( x = 0.998373 ) or ( ( ( y = SIN( 0.998373 ) ) and ( ( z = 0.998373 ) ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( ( z = 4 ) ) ) or ( ( x = 1 ) ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) ) or ( ( z = 1 + 5 * 87.2134 ) )   
)


-- AGGREGATION SQL:
SELECT `x`
FROM `aggregation_tmp_84512595`   
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)
This is the query plan for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

CALL paquExec('SELECT x AS `x` FROM table WHERE ( x = 0.998373 ) or ( ( ( y = SIN( 0.998373 ) ) and ( ( z = 0.998373 ) ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( ( z = 4 ) ) ) or ( ( x = 1 ) ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) ) or ( ( z = 1 + 5 * 87.2134 ) )   ', 'aggregation_tmp_84512595');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `x`
FROM `aggregation_tmp_84512595`   ;
CALL paquDropTmp('aggregation_tmp_84512595');
This is the query plan optimisation output for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

-- INPUT SQL:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`
FROM table WHERE ( x = 0.998373 ) or ( ( ( y = SIN( 0.998373 ) ) and ( ( z = 0.998373 ) ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( ( z = 4 ) ) ) or ( ( x = 1 ) ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) ) or ( ( z = 1 + 5 * 87.2134 ) )   
)


-- AGGREGATION SQL:
SELECT `x`
FROM `aggregation_tmp_8352823`   
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)
This is the query plan for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

CALL paquExec('SELECT x AS `x` FROM table WHERE ( x = 0.998373 ) or ( ( ( y = SIN( 0.998373 ) ) and ( ( z = 0.998373 ) ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( ( z = 4 ) ) ) or ( ( x = 1 ) ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) ) or ( ( z = 1 + 5 * 87.2134 ) )   ', 'aggregation_tmp_8352823');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `x`
FROM `aggregation_tmp_8352823`   ;
CALL paquDropTmp('aggregation_tmp_8352823');
This is the query plan optimisation output for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

-- INPUT SQL:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`
FROM table WHERE ( x = 0.998373 ) or ( ( ( y = SIN( 0.998373 ) ) and ( ( z = 0.998373 ) ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( ( z = 4 ) ) ) or ( ( x = 1 ) ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) ) or ( ( z = 1 + 5 * 87.2134 ) )   
)


-- AGGREGATION SQL:
SELECT `x`
FROM `aggregation_tmp_78981955`   
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)
This is the query plan for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

CALL paquExec('SELECT x AS `x` FROM table WHERE ( x = 0.998373 ) or ( ( ( y = SIN( 0.998373 ) ) and ( ( z = 0.998373 ) ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( ( z = 4 ) ) ) or ( ( x = 1 ) ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) ) or ( ( z = 1 + 5 * 87.2134 ) )   ', 'aggregation_tmp_78981955');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `x`
FROM `aggregation_tmp_78981955`   ;
CALL paquDropTmp('aggregation_tmp_78981955');
This is the query plan optimisation output for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

-- INPUT SQL:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`
FROM table WHERE ( x = 0.998373 ) or ( ( ( y = SIN( 0.998373 ) ) and ( ( z = 0.998373 ) ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( ( z = 4 ) ) ) or ( ( x = 1 ) ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) ) or ( ( z = 1 + 5 * 87.2134 ) )   
)


-- AGGREGATION SQL:
SELECT `x`
FROM `aggregation_tmp_55442802`   
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)
This is the query plan for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

CALL paquExec('SELECT x AS `x` FROM table WHERE ( x = 0.998373 ) or ( ( ( y = SIN( 0.998373 ) ) and ( ( z = 0.998373 ) ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( ( z = 4 ) ) ) or ( ( x = 1 ) ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) ) or ( ( z = 1 + 5 * 87.2134 ) )   ', 'aggregation_tmp_55442802');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `x`
FROM `aggregation_tmp_55442802`   ;
CALL paquDropTmp('aggregation_tmp_55442802');
This is the query plan optimisation output for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

-- INPUT SQL:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`
FROM table WHERE ( x = 0.998373 ) or ( ( ( y = SIN( 0.998373 ) ) and ( ( z = 0.998373 ) ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( ( z = 4 ) ) ) or ( ( x = 1 ) ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) ) or ( ( z = 1 + 5 * 87.2134 ) )   
)


-- AGGREGATION SQL:
SELECT `x`
FROM `aggregation_tmp_62539580`   
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)
This is the query plan for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

CALL paquExec('SELECT x AS `x` FROM table WHERE ( x = 0.998373 ) or ( ( ( y = SIN( 0.998373 ) ) and ( ( z = 0.998373 ) ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( ( z = 4 ) ) ) or ( ( x = 1 ) ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) ) or ( ( z = 1 + 5 * 87.2134 ) )   ', 'aggregation_tmp_62539580');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `x`
FROM `aggregation_tmp_62539580`   ;
CALL paquDropTmp('aggregation_tmp_62539580');
This is the query plan optimisation output for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

-- INPUT SQL:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`
FROM table WHERE ( x = 0.998373 ) or ( ( ( y = SIN( 0.998373 ) ) and ( z = 0.998373 ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) ) or ( z = 1 + 5 * 87.2134 )   
)


-- AGGREGATION SQL:
SELECT `x`
FROM `aggregation_tmp_43610364`   
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)
This is the query plan for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

CALL paquExec('SELECT x AS `x` FROM table WHERE ( x = 0.998373 ) or ( ( ( y = SIN( 0.998373 ) ) and ( z = 0.998373 ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) ) or ( z = 1 + 5 * 87.2134 )   ', 'aggregation_tmp_43610364');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `x`
FROM `aggregation_tmp_43610364`   ;
CALL paquDropTmp('aggregation_tmp_43610364');
This is the query plan optimisation output for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

-- INPUT SQL:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`
FROM table WHERE ( x = 0.998373 ) or ( ( ( y = SIN( 0.998373 ) ) and ( z = 0.998373 ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) ) or ( z = 1 + 5 * 87.2134 )   
)


-- AGGREGATION SQL:
SELECT `x`
FROM `aggregation_tmp_356087`   
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)
This is the query plan for the query:
SELECT x FROM table WHERE ( x = 0.998373 ) or ( ( y = SIN (0.998373) ) and ( z = 0.998373 ) ) and ( z = 43 ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( y = 34 ) and ( x between 1 and 2 ) or ( z = 1 + 5 * 87.2134 )

CALL paquExec('SELECT x AS `x` FROM table WHERE ( x = 0.998373 ) or ( ( ( y = SIN( 0.998373 ) ) and ( z = 0.998373 ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) ) or ( z = 1 + 5 * 87.2134 )   ', 'aggregation_tmp_356087');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `x`
FROM `aggregation_tmp_356087`   ;
CALL paquDropTmp('aggregation_tmp_356087');
This is the query plan optimisation output for the query:
SELECT x FROM table WHERE x=0.998373 or (y=sin(0.998373) and z=0.998373) and z=43 or ((z=23 and z=4) or x=1) or y=34 and x between 1 and 2

-- INPUT SQL:
SELECT x FROM table WHERE x=0.998373 or (y=sin(0.998373) and z=0.998373) and z=43 or ((z=23 and z=4) or x=1) or y=34 and x between 1 and 2

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`x`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT x AS `x`
FROM table WHERE ( x = 0.998373 ) or ( ( ( y = sin( 0.998373 ) ) and ( z = 0.998373 ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) )   
)


-- AGGREGATION SQL:
SELECT `x`
FROM `aggregation_tmp_65962477`   
ON DUPLICATE KEY UPDATE
`x`=VALUES(`x`)
This is the query plan for the query:
SELECT x FROM table WHERE x=0.998373 or (y=sin(0.998373) and z=0.998373) and z=43 or ((z=23 and z=4) or x=1) or y=34 and x between 1 and 2

CALL paquExec('SELECT x AS `x` FROM table WHERE ( x = 0.998373 ) or ( ( ( y = sin( 0.998373 ) ) and ( z = 0.998373 ) ) and ( z = 43 ) ) or ( ( ( z = 23 ) and ( z = 4 ) ) or ( x = 1 ) ) or ( ( y = 34 ) and ( x between 1 and 2 ) )   ', 'aggregation_tmp_65962477');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `x`
FROM `aggregation_tmp_65962477`   ;
CALL paquDropTmp('aggregation_tmp_65962477');
This is the query plan optimisation output for the query:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.niceCol`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.niceCol`=VALUES(`b.niceCol`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.niceCol AS `b.niceCol`
FROM niceTbl AS `b` 
)


-- AGGREGATION SQL:
SELECT `b.niceCol`
FROM `aggregation_tmp_24469905`   
ON DUPLICATE KEY UPDATE
`b.niceCol`=VALUES(`b.niceCol`)
-- INPUT SQL:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`h.niceCol`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`h.niceCol`=VALUES(`h.niceCol`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `h`.`b.niceCol` AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_24469905`   ) AS `h` 
)


-- AGGREGATION SQL:
SELECT `h.niceCol`
FROM `aggregation_tmp_47509398`   
ON DUPLICATE KEY UPDATE
`h.niceCol`=VALUES(`h.niceCol`)
This is the query plan for the query:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

CALL paquExec('SELECT b.niceCol AS `b.niceCol` FROM niceTbl AS `b` ', 'aggregation_tmp_24469905');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_47509398 ENGINE=MyISAM SELECT `h`.`b.niceCol` AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_24469905`   ) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_47509398 SELECT `h`.`b.niceCol` AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_24469905`   ) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_47509398');
CALL paquDropTmp('aggregation_tmp_24469905');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `h.niceCol`
FROM `aggregation_tmp_47509398`   ;
CALL paquDropTmp('aggregation_tmp_47509398');
This is the query plan optimisation output for the query:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.niceCol`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.niceCol`=VALUES(`b.niceCol`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.niceCol AS `b.niceCol`
FROM niceTbl AS `b` 
)


-- AGGREGATION SQL:
SELECT `b.niceCol`
FROM `aggregation_tmp_15032812`   
ON DUPLICATE KEY UPDATE
`b.niceCol`=VALUES(`b.niceCol`)
-- INPUT SQL:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`h.niceCol`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`h.niceCol`=VALUES(`h.niceCol`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `h`.`b.niceCol` AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_15032812`   ) AS `h` 
)


-- AGGREGATION SQL:
SELECT `h.niceCol`
FROM `aggregation_tmp_23823376`   
ON DUPLICATE KEY UPDATE
`h.niceCol`=VALUES(`h.niceCol`)
This is the query plan for the query:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

CALL paquExec('SELECT b.niceCol AS `b.niceCol` FROM niceTbl AS `b` ', 'aggregation_tmp_15032812');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_23823376 ENGINE=MyISAM SELECT `h`.`b.niceCol` AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_15032812`   ) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_23823376 SELECT `h`.`b.niceCol` AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_15032812`   ) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_23823376');
CALL paquDropTmp('aggregation_tmp_15032812');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `h.niceCol`
FROM `aggregation_tmp_23823376`   ;
CALL paquDropTmp('aggregation_tmp_23823376');
This is the query plan optimisation output for the query:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.niceCol`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.niceCol`=VALUES(`b.niceCol`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.niceCol AS `b.niceCol`
FROM niceTbl AS `b` 
)


-- AGGREGATION SQL:
SELECT `b.niceCol`
FROM `aggregation_tmp_92960267`   
ON DUPLICATE KEY UPDATE
`b.niceCol`=VALUES(`b.niceCol`)
-- INPUT SQL:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`h.niceCol`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`h.niceCol`=VALUES(`h.niceCol`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `h`.`b.niceCol` AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_92960267`   ) AS `h` 
)


-- AGGREGATION SQL:
SELECT `h.niceCol`
FROM `aggregation_tmp_73258626`   
ON DUPLICATE KEY UPDATE
`h.niceCol`=VALUES(`h.niceCol`)
This is the query plan for the query:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

CALL paquExec('SELECT b.niceCol AS `b.niceCol` FROM niceTbl AS `b` ', 'aggregation_tmp_92960267');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_73258626 ENGINE=MyISAM SELECT `h`.`b.niceCol` AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_92960267`   ) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_73258626 SELECT `h`.`b.niceCol` AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_92960267`   ) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_73258626');
CALL paquDropTmp('aggregation_tmp_92960267');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `h.niceCol`
FROM `aggregation_tmp_73258626`   ;
CALL paquDropTmp('aggregation_tmp_73258626');
This is the query plan optimisation output for the query:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.niceCol`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.niceCol`=VALUES(`b.niceCol`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.niceCol AS `b.niceCol`
FROM niceTbl AS `b` 
)


-- AGGREGATION SQL:
SELECT `b.niceCol`
FROM `aggregation_tmp_73385990`   
ON DUPLICATE KEY UPDATE
`b.niceCol`=VALUES(`b.niceCol`)
-- INPUT SQL:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`h.niceCol`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`h.niceCol`=VALUES(`h.niceCol`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `h`.`b.niceCol` AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_73385990`   ) AS `h` 
)


-- AGGREGATION SQL:
SELECT `h.niceCol`
FROM `aggregation_tmp_16382891`   
ON DUPLICATE KEY UPDATE
`h.niceCol`=VALUES(`h.niceCol`)
This is the query plan for the query:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

CALL paquExec('SELECT b.niceCol AS `b.niceCol` FROM niceTbl AS `b` ', 'aggregation_tmp_73385990');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_16382891 ENGINE=MyISAM SELECT `h`.`b.niceCol` AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_73385990`   ) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_16382891 SELECT `h`.`b.niceCol` AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_73385990`   ) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_16382891');
CALL paquDropTmp('aggregation_tmp_73385990');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `h.niceCol`
FROM `aggregation_tmp_16382891`   ;
CALL paquDropTmp('aggregation_tmp_16382891');
This is the query plan optimisation output for the query:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.niceCol`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.niceCol`=VALUES(`b.niceCol`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.niceCol AS `b.niceCol`
FROM niceTbl AS `b` 
)


-- AGGREGATION SQL:
SELECT `b.niceCol`
FROM `aggregation_tmp_41484558`   
ON DUPLICATE KEY UPDATE
`b.niceCol`=VALUES(`b.niceCol`)
-- INPUT SQL:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`h.niceCol`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`h.niceCol`=VALUES(`h.niceCol`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `h`.`b.niceCol` AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_41484558`   ) AS `h` 
)


-- AGGREGATION SQL:
SELECT `h.niceCol`
FROM `aggregation_tmp_32849036`   
ON DUPLICATE KEY UPDATE
`h.niceCol`=VALUES(`h.niceCol`)
This is the query plan for the query:
SELECT h.niceCol FROM (SELECT b.niceCol FROM niceTbl as b) as h

CALL paquExec('SELECT b.niceCol AS `b.niceCol` FROM niceTbl AS `b` ', 'aggregation_tmp_41484558');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_32849036 ENGINE=MyISAM SELECT `h`.`b.niceCol` AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_41484558`   ) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_32849036 SELECT `h`.`b.niceCol` AS `h.niceCol`
FROM ( SELECT `b.niceCol`
FROM `aggregation_tmp_41484558`   ) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_32849036');
CALL paquDropTmp('aggregation_tmp_41484558');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `h.niceCol`
FROM `aggregation_tmp_32849036`   ;
CALL paquDropTmp('aggregation_tmp_32849036');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_80701103`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_80701103`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_6704966`  ORDER BY `prog`.`fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   ', 'aggregation_tmp_80701103');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_80701103`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_6704966');
CALL paquDropTmp('aggregation_tmp_80701103');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_6704966`  ORDER BY `prog`.`fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_6704966');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_82905798`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_82905798`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_30131324`  ORDER BY `prog`.`fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   ', 'aggregation_tmp_82905798');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_82905798`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_30131324');
CALL paquDropTmp('aggregation_tmp_82905798');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_30131324`  ORDER BY `prog`.`fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_30131324');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT() AS `num`,FLOOR( LOG10( `Mvir` ) / 0.25 ) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE ( `snapnum` = 85 )  GROUP BY FLOOR( LOG10( `Mvir` ) / 0.25 )  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_29219369`  GROUP BY `_FLOOR_LOG10_Mvir_/_0__25_` ORDER BY `_FLOOR_LOG10_Mvir_/_0__25_` ASC 
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS `log_mass`,COUNT() AS `num`,FLOOR( LOG10( `Mvir` ) / 0.25 ) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE ( `snapnum` = 85 )  GROUP BY FLOOR( LOG10( `Mvir` ) / 0.25 )  ', 'aggregation_tmp_29219369');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_29219369`  GROUP BY `_FLOOR_LOG10_Mvir_/_0__25_` ORDER BY `_FLOOR_LOG10_Mvir_/_0__25_` ASC ;
CALL paquDropTmp('aggregation_tmp_29219369');
This is the query plan optimisation output for the query:
SELECT `h`.`ca`+`h`.`ab` as `total` FROM (SELECT count( as `ca`, avg(b) as `ab` FROM tblA) as `h`

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT COUNT(as `ca`avg( `b` ) as `ab` FROM `tblA`) AS `h` 
)


-- AGGREGATION SQL:
SELECT SUM(`h`) AS `h`
FROM `aggregation_tmp_44465050`   
-- INPUT SQL:
SELECT `h`.`ca`+`h`.`ab` as `total` FROM (SELECT count( as `ca`, avg(b) as `ab` FROM tblA) as `h`

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`total`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`total`=VALUES(`total`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `h`.`ca`+`h`.`ab`() AS `total`
FROM ( SELECT SUM(`h`) AS `h`
FROM `aggregation_tmp_44465050`   ) 
)


-- AGGREGATION SQL:
SELECT `total`
FROM `aggregation_tmp_76512421`   
ON DUPLICATE KEY UPDATE
`total`=VALUES(`total`)
This is the query plan for the query:
SELECT `h`.`ca`+`h`.`ab` as `total` FROM (SELECT count( as `ca`, avg(b) as `ab` FROM tblA) as `h`

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_44465050 ENGINE=MyISAM SELECT COUNT(as `ca`avg( `b` ) as `ab` FROM `tblA`) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_44465050 SELECT COUNT(as `ca`avg( `b` ) as `ab` FROM `tblA`) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_44465050');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_76512421 ENGINE=MyISAM SELECT `h`.`ca`+`h`.`ab`() AS `total`
FROM ( SELECT SUM(`h`) AS `h`
FROM `aggregation_tmp_44465050`   )  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_76512421 SELECT `h`.`ca`+`h`.`ab`() AS `total`
FROM ( SELECT SUM(`h`) AS `h`
FROM `aggregation_tmp_44465050`   ) ;
CALL paquLinkTmp('aggregation_tmp_76512421');
CALL paquDropTmp('aggregation_tmp_44465050');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `total`
FROM `aggregation_tmp_76512421`   ;
CALL paquDropTmp('aggregation_tmp_76512421');
This is the query plan optimisation output for the query:
SELECT `h`.`ca`+`h`.`ab` as `total` FROM (SELECT count( as `ca`, avg(b) as `ab` FROM tblA) as `h`

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT COUNT(as `ca`avg( `b` ) as `ab` FROM `tblA`) AS `h` 
)


-- AGGREGATION SQL:
SELECT SUM(`h`) AS `h`
FROM `aggregation_tmp_74090941`   
-- INPUT SQL:
SELECT `h`.`ca`+`h`.`ab` as `total` FROM (SELECT count( as `ca`, avg(b) as `ab` FROM tblA) as `h`

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`total`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`total`=VALUES(`total`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `h`.`ca`+`h`.`ab`() AS `total`
FROM ( SELECT SUM(`h`) AS `h`
FROM `aggregation_tmp_74090941`   ) 
)


-- AGGREGATION SQL:
SELECT `total`
FROM `aggregation_tmp_72096466`   
ON DUPLICATE KEY UPDATE
`total`=VALUES(`total`)
This is the query plan for the query:
SELECT `h`.`ca`+`h`.`ab` as `total` FROM (SELECT count( as `ca`, avg(b) as `ab` FROM tblA) as `h`

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_74090941 ENGINE=MyISAM SELECT COUNT(as `ca`avg( `b` ) as `ab` FROM `tblA`) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_74090941 SELECT COUNT(as `ca`avg( `b` ) as `ab` FROM `tblA`) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_74090941');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_72096466 ENGINE=MyISAM SELECT `h`.`ca`+`h`.`ab`() AS `total`
FROM ( SELECT SUM(`h`) AS `h`
FROM `aggregation_tmp_74090941`   )  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_72096466 SELECT `h`.`ca`+`h`.`ab`() AS `total`
FROM ( SELECT SUM(`h`) AS `h`
FROM `aggregation_tmp_74090941`   ) ;
CALL paquLinkTmp('aggregation_tmp_72096466');
CALL paquDropTmp('aggregation_tmp_74090941');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `total`
FROM `aggregation_tmp_72096466`   ;
CALL paquDropTmp('aggregation_tmp_72096466');
This is the query plan optimisation output for the query:
SELECT `h`.`ca`+`h`.`ab` as `total` FROM (SELECT count( as `ca`, avg(b) as `ab` FROM tblA) as `h`

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT COUNT(as `ca`avg( `b` ) as `ab` FROM `tblA`) AS `h` 
)


-- AGGREGATION SQL:
SELECT SUM(`h`) AS `h`
FROM `aggregation_tmp_70531049`   
-- INPUT SQL:
SELECT `h`.`ca`+`h`.`ab` as `total` FROM (SELECT count( as `ca`, avg(b) as `ab` FROM tblA) as `h`

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`total`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`total`=VALUES(`total`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `h`.`ca`+`h`.`ab`() AS `total`
FROM ( SELECT SUM(`h`) AS `h`
FROM `aggregation_tmp_70531049`   ) 
)


-- AGGREGATION SQL:
SELECT `total`
FROM `aggregation_tmp_81256654`   
ON DUPLICATE KEY UPDATE
`total`=VALUES(`total`)
This is the query plan for the query:
SELECT `h`.`ca`+`h`.`ab` as `total` FROM (SELECT count( as `ca`, avg(b) as `ab` FROM tblA) as `h`

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_70531049 ENGINE=MyISAM SELECT COUNT(as `ca`avg( `b` ) as `ab` FROM `tblA`) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_70531049 SELECT COUNT(as `ca`avg( `b` ) as `ab` FROM `tblA`) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_70531049');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_81256654 ENGINE=MyISAM SELECT `h`.`ca`+`h`.`ab`() AS `total`
FROM ( SELECT SUM(`h`) AS `h`
FROM `aggregation_tmp_70531049`   )  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_81256654 SELECT `h`.`ca`+`h`.`ab`() AS `total`
FROM ( SELECT SUM(`h`) AS `h`
FROM `aggregation_tmp_70531049`   ) ;
CALL paquLinkTmp('aggregation_tmp_81256654');
CALL paquDropTmp('aggregation_tmp_70531049');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `total`
FROM `aggregation_tmp_81256654`   ;
CALL paquDropTmp('aggregation_tmp_81256654');
This is the query plan optimisation output for the query:
SELECT `h`.`ca`+`h`.`ab` as `total` FROM (SELECT count( as `ca`, avg(b) as `ab` FROM tblA) as `h`

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT COUNT(as `ca`avg( `b` ) as `ab` FROM `tblA`) AS `h` 
)


-- AGGREGATION SQL:
SELECT SUM(`h`) AS `h`
FROM `aggregation_tmp_12450444`   
-- INPUT SQL:
SELECT `h`.`ca`+`h`.`ab` as `total` FROM (SELECT count( as `ca`, avg(b) as `ab` FROM tblA) as `h`

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`total`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`total`=VALUES(`total`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `h`.`ca`+`h`.`ab`() AS `total`
FROM ( SELECT SUM(`h`) AS `h`
FROM `aggregation_tmp_12450444`   ) 
)


-- AGGREGATION SQL:
SELECT `total`
FROM `aggregation_tmp_16642667`   
ON DUPLICATE KEY UPDATE
`total`=VALUES(`total`)
This is the query plan for the query:
SELECT `h`.`ca`+`h`.`ab` as `total` FROM (SELECT count( as `ca`, avg(b) as `ab` FROM tblA) as `h`

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_12450444 ENGINE=MyISAM SELECT COUNT(as `ca`avg( `b` ) as `ab` FROM `tblA`) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_12450444 SELECT COUNT(as `ca`avg( `b` ) as `ab` FROM `tblA`) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_12450444');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_16642667 ENGINE=MyISAM SELECT `h`.`ca`+`h`.`ab`() AS `total`
FROM ( SELECT SUM(`h`) AS `h`
FROM `aggregation_tmp_12450444`   )  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_16642667 SELECT `h`.`ca`+`h`.`ab`() AS `total`
FROM ( SELECT SUM(`h`) AS `h`
FROM `aggregation_tmp_12450444`   ) ;
CALL paquLinkTmp('aggregation_tmp_16642667');
CALL paquDropTmp('aggregation_tmp_12450444');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `total`
FROM `aggregation_tmp_16642667`   ;
CALL paquDropTmp('aggregation_tmp_16642667');
This is the query plan optimisation output for the query:
SELECT `h`.`ca`+`h`.`ab` as `total` FROM (SELECT count( as `ca`, avg(b) as `ab` FROM tblA) as `h`

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT COUNT(as `ca`avg( `b` ) as `ab` FROM `tblA`) AS `h` 
)


-- AGGREGATION SQL:
SELECT SUM(`h`) AS `h`
FROM `aggregation_tmp_35844524`   
-- INPUT SQL:
SELECT `h`.`ca`+`h`.`ab` as `total` FROM (SELECT count( as `ca`, avg(b) as `ab` FROM tblA) as `h`

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`total`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`total`=VALUES(`total`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `h`.`ca`+`h`.`ab`() AS `total`
FROM ( SELECT SUM(`h`) AS `h`
FROM `aggregation_tmp_35844524`   ) 
)


-- AGGREGATION SQL:
SELECT `total`
FROM `aggregation_tmp_66465966`   
ON DUPLICATE KEY UPDATE
`total`=VALUES(`total`)
This is the query plan for the query:
SELECT `h`.`ca`+`h`.`ab` as `total` FROM (SELECT count( as `ca`, avg(b) as `ab` FROM tblA) as `h`

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_35844524 ENGINE=MyISAM SELECT COUNT(as `ca`avg( `b` ) as `ab` FROM `tblA`) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_35844524 SELECT COUNT(as `ca`avg( `b` ) as `ab` FROM `tblA`) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_35844524');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_66465966 ENGINE=MyISAM SELECT `h`.`ca`+`h`.`ab`() AS `total`
FROM ( SELECT SUM(`h`) AS `h`
FROM `aggregation_tmp_35844524`   )  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_66465966 SELECT `h`.`ca`+`h`.`ab`() AS `total`
FROM ( SELECT SUM(`h`) AS `h`
FROM `aggregation_tmp_35844524`   ) ;
CALL paquLinkTmp('aggregation_tmp_66465966');
CALL paquDropTmp('aggregation_tmp_35844524');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `total`
FROM `aggregation_tmp_66465966`   ;
CALL paquDropTmp('aggregation_tmp_66465966');
This is the query plan optimisation output for the query:
SELECT `h`.`ca`+`h`.`ab` as `total` FROM (SELECT count(a) as `ca`, avg(b) as `ab` FROM tblA) as `h`

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
ab

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`ca`=`ca` +  VALUES(`ca`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT COUNT(`a`) AS `ca`, COUNT(`b`) AS `cnt_ab`, SUM(`b`) AS `sum_ab`
FROM tblA 
)


-- AGGREGATION SQL:
SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_86256273`   
ON DUPLICATE KEY UPDATE
`ca`=`ca` +  VALUES(`ca`)
-- INPUT SQL:
SELECT `h`.`ca`+`h`.`ab` as `total` FROM (SELECT count(a) as `ca`, avg(b) as `ab` FROM tblA) as `h`

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`total`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`total`=VALUES(`total`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `h`.`ca`+`h`.`ab`() AS `total`
FROM ( SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_86256273`   ) AS `h` 
)


-- AGGREGATION SQL:
SELECT `total`
FROM `aggregation_tmp_6730070`   
ON DUPLICATE KEY UPDATE
`total`=VALUES(`total`)
This is the query plan for the query:
SELECT `h`.`ca`+`h`.`ab` as `total` FROM (SELECT count(a) as `ca`, avg(b) as `ab` FROM tblA) as `h`

CALL paquExec('SELECT COUNT(`a`) AS `ca`, COUNT(`b`) AS `cnt_ab`, SUM(`b`) AS `sum_ab` FROM tblA ', 'aggregation_tmp_86256273');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_6730070 ENGINE=MyISAM SELECT `h`.`ca`+`h`.`ab`() AS `total`
FROM ( SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_86256273`   ) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_6730070 SELECT `h`.`ca`+`h`.`ab`() AS `total`
FROM ( SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_86256273`   ) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_6730070');
CALL paquDropTmp('aggregation_tmp_86256273');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `total`
FROM `aggregation_tmp_6730070`   ;
CALL paquDropTmp('aggregation_tmp_6730070');
This is the query plan optimisation output for the query:
SELECT `h`.`ca`+`h`.`ab` as `total` FROM (SELECT count(a) as `ca`, avg(b) as `ab` FROM tblA) as `h`

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
ab

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`ca`=`ca` +  VALUES(`ca`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT COUNT(`a`) AS `ca`, COUNT(`b`) AS `cnt_ab`, SUM(`b`) AS `sum_ab`
FROM tblA 
)


-- AGGREGATION SQL:
SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_43065207`   
ON DUPLICATE KEY UPDATE
`ca`=`ca` +  VALUES(`ca`)
-- INPUT SQL:
SELECT `h`.`ca`+`h`.`ab` as `total` FROM (SELECT count(a) as `ca`, avg(b) as `ab` FROM tblA) as `h`

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`total`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`total`=VALUES(`total`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `h`.`ca`+`h`.`ab`() AS `total`
FROM ( SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_43065207`   ) AS `h` 
)


-- AGGREGATION SQL:
SELECT `total`
FROM `aggregation_tmp_29361836`   
ON DUPLICATE KEY UPDATE
`total`=VALUES(`total`)
This is the query plan for the query:
SELECT `h`.`ca`+`h`.`ab` as `total` FROM (SELECT count(a) as `ca`, avg(b) as `ab` FROM tblA) as `h`

CALL paquExec('SELECT COUNT(`a`) AS `ca`, COUNT(`b`) AS `cnt_ab`, SUM(`b`) AS `sum_ab` FROM tblA ', 'aggregation_tmp_43065207');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_29361836 ENGINE=MyISAM SELECT `h`.`ca`+`h`.`ab`() AS `total`
FROM ( SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_43065207`   ) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_29361836 SELECT `h`.`ca`+`h`.`ab`() AS `total`
FROM ( SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_43065207`   ) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_29361836');
CALL paquDropTmp('aggregation_tmp_43065207');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `total`
FROM `aggregation_tmp_29361836`   ;
CALL paquDropTmp('aggregation_tmp_29361836');
This is the query plan optimisation output for the query:
SELECT `h`.`ca`+`h`.`ab` as `total` FROM (SELECT count(a) as `ca`, avg(b) as `ab` FROM tblA) as `h`

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
ab

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`ca`=`ca` +  VALUES(`ca`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT COUNT(`a`) AS `ca`, COUNT(`b`) AS `cnt_ab`, SUM(`b`) AS `sum_ab`
FROM tblA 
)


-- AGGREGATION SQL:
SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_74286820`   
ON DUPLICATE KEY UPDATE
`ca`=`ca` +  VALUES(`ca`)
-- INPUT SQL:
SELECT `h`.`ca`+`h`.`ab` as `total` FROM (SELECT count(a) as `ca`, avg(b) as `ab` FROM tblA) as `h`

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`total`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`total`=VALUES(`total`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `h`.`ca`+`h`.`ab`() AS `total`
FROM ( SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_74286820`   ) AS `h` 
)


-- AGGREGATION SQL:
SELECT `total`
FROM `aggregation_tmp_42347390`   
ON DUPLICATE KEY UPDATE
`total`=VALUES(`total`)
This is the query plan for the query:
SELECT `h`.`ca`+`h`.`ab` as `total` FROM (SELECT count(a) as `ca`, avg(b) as `ab` FROM tblA) as `h`

CALL paquExec('SELECT COUNT(`a`) AS `ca`, COUNT(`b`) AS `cnt_ab`, SUM(`b`) AS `sum_ab` FROM tblA ', 'aggregation_tmp_74286820');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_42347390 ENGINE=MyISAM SELECT `h`.`ca`+`h`.`ab`() AS `total`
FROM ( SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_74286820`   ) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_42347390 SELECT `h`.`ca`+`h`.`ab`() AS `total`
FROM ( SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_74286820`   ) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_42347390');
CALL paquDropTmp('aggregation_tmp_74286820');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `total`
FROM `aggregation_tmp_42347390`   ;
CALL paquDropTmp('aggregation_tmp_42347390');
This is the query plan optimisation output for the query:
SELECT `h`.`ca`+`h`.`ab` as `total` FROM (SELECT count(a) as `ca`, avg(b) as `ab` FROM tblA) as `h`

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
ab

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`ca`=`ca` +  VALUES(`ca`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT COUNT(`a`) AS `ca`, COUNT(`b`) AS `cnt_ab`, SUM(`b`) AS `sum_ab`
FROM tblA 
)


-- AGGREGATION SQL:
SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_17708704`   
ON DUPLICATE KEY UPDATE
`ca`=`ca` +  VALUES(`ca`)
-- INPUT SQL:
SELECT `h`.`ca`+`h`.`ab` as `total` FROM (SELECT count(a) as `ca`, avg(b) as `ab` FROM tblA) as `h`

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`total`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`total`=VALUES(`total`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `h`.`ca`+`h`.`ab`() AS `total`
FROM ( SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_17708704`   ) AS `h` 
)


-- AGGREGATION SQL:
SELECT `total`
FROM `aggregation_tmp_84197111`   
ON DUPLICATE KEY UPDATE
`total`=VALUES(`total`)
This is the query plan for the query:
SELECT `h`.`ca`+`h`.`ab` as `total` FROM (SELECT count(a) as `ca`, avg(b) as `ab` FROM tblA) as `h`

CALL paquExec('SELECT COUNT(`a`) AS `ca`, COUNT(`b`) AS `cnt_ab`, SUM(`b`) AS `sum_ab` FROM tblA ', 'aggregation_tmp_17708704');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_84197111 ENGINE=MyISAM SELECT `h`.`ca`+`h`.`ab`() AS `total`
FROM ( SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_17708704`   ) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_84197111 SELECT `h`.`ca`+`h`.`ab`() AS `total`
FROM ( SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_17708704`   ) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_84197111');
CALL paquDropTmp('aggregation_tmp_17708704');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `total`
FROM `aggregation_tmp_84197111`   ;
CALL paquDropTmp('aggregation_tmp_84197111');
This is the query plan optimisation output for the query:
SELECT `h`.`ca`+`h`.`ab` as `total` FROM (SELECT count(a) as `ca`, avg(b) as `ab` FROM tblA) as `h`

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
ab

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`ca`=`ca` +  VALUES(`ca`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT COUNT(`a`) AS `ca`, COUNT(`b`) AS `cnt_ab`, SUM(`b`) AS `sum_ab`
FROM tblA 
)


-- AGGREGATION SQL:
SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_89622308`   
ON DUPLICATE KEY UPDATE
`ca`=`ca` +  VALUES(`ca`)
-- INPUT SQL:
SELECT `h`.`ca`+`h`.`ab` as `total` FROM (SELECT count(a) as `ca`, avg(b) as `ab` FROM tblA) as `h`

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`total`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`total`=VALUES(`total`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `h`.`ca`+`h`.`ab`() AS `total`
FROM ( SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_89622308`   ) AS `h` 
)


-- AGGREGATION SQL:
SELECT `total`
FROM `aggregation_tmp_82249144`   
ON DUPLICATE KEY UPDATE
`total`=VALUES(`total`)
This is the query plan for the query:
SELECT `h`.`ca`+`h`.`ab` as `total` FROM (SELECT count(a) as `ca`, avg(b) as `ab` FROM tblA) as `h`

CALL paquExec('SELECT COUNT(`a`) AS `ca`, COUNT(`b`) AS `cnt_ab`, SUM(`b`) AS `sum_ab` FROM tblA ', 'aggregation_tmp_89622308');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_82249144 ENGINE=MyISAM SELECT `h`.`ca`+`h`.`ab`() AS `total`
FROM ( SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_89622308`   ) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_82249144 SELECT `h`.`ca`+`h`.`ab`() AS `total`
FROM ( SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_89622308`   ) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_82249144');
CALL paquDropTmp('aggregation_tmp_89622308');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `total`
FROM `aggregation_tmp_82249144`   ;
CALL paquDropTmp('aggregation_tmp_82249144');
This is the query plan optimisation output for the query:
SELECT `h`.`ca`+`h`.`ab` as `total` FROM (SELECT count(a) as `ca`, avg(b) as `ab` FROM tblA) as `h`

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
ab

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`ca`=`ca` +  VALUES(`ca`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT COUNT(`a`) AS `ca`, COUNT(`b`) AS `cnt_ab`, SUM(`b`) AS `sum_ab`
FROM tblA 
)


-- AGGREGATION SQL:
SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_64863447`   
ON DUPLICATE KEY UPDATE
`ca`=`ca` +  VALUES(`ca`)
-- INPUT SQL:
SELECT `h`.`ca`+`h`.`ab` as `total` FROM (SELECT count(a) as `ca`, avg(b) as `ab` FROM tblA) as `h`

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`total`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`total`=VALUES(`total`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `h`.`ca`+`h`.`ab` AS `total`
FROM ( SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_64863447`   ) AS `h` 
)


-- AGGREGATION SQL:
SELECT `total`
FROM `aggregation_tmp_39535408`   
ON DUPLICATE KEY UPDATE
`total`=VALUES(`total`)
This is the query plan for the query:
SELECT `h`.`ca`+`h`.`ab` as `total` FROM (SELECT count(a) as `ca`, avg(b) as `ab` FROM tblA) as `h`

CALL paquExec('SELECT COUNT(`a`) AS `ca`, COUNT(`b`) AS `cnt_ab`, SUM(`b`) AS `sum_ab` FROM tblA ', 'aggregation_tmp_64863447');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_39535408 ENGINE=MyISAM SELECT `h`.`ca`+`h`.`ab` AS `total`
FROM ( SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_64863447`   ) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_39535408 SELECT `h`.`ca`+`h`.`ab` AS `total`
FROM ( SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_64863447`   ) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_39535408');
CALL paquDropTmp('aggregation_tmp_64863447');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `total`
FROM `aggregation_tmp_39535408`   ;
CALL paquDropTmp('aggregation_tmp_39535408');
This is the query plan optimisation output for the query:
SELECT 2.0*`p`.`total` as `totalTwo` FROM (SELECT SUM(`h`.`ca`+`h`.`ab`) as `total` FROM (SELECT count(a) as `ca`, avg(b) as `ab` FROM tblA) as `h`) as `p`

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
ab

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`ca`=`ca` +  VALUES(`ca`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT COUNT(`a`) AS `ca`, COUNT(`b`) AS `cnt_ab`, SUM(`b`) AS `sum_ab`
FROM tblA 
)


-- AGGREGATION SQL:
SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_17731116`   
ON DUPLICATE KEY UPDATE
`ca`=`ca` +  VALUES(`ca`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT SUM(`h`.`ca` + `h`.`ab`) AS `total`
FROM ( SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_17731116`   ) AS `h` 
)


-- AGGREGATION SQL:
SELECT SUM(`total`) AS `total`
FROM `aggregation_tmp_29954969`   
-- INPUT SQL:
SELECT 2.0*`p`.`total` as `totalTwo` FROM (SELECT SUM(`h`.`ca`+`h`.`ab`) as `total` FROM (SELECT count(a) as `ca`, avg(b) as `ab` FROM tblA) as `h`) as `p`

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`totalTwo`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`totalTwo`=VALUES(`totalTwo`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0*`p`.`total` AS `totalTwo`
FROM ( SELECT SUM(`total`) AS `total`
FROM `aggregation_tmp_29954969`   ) AS `p` 
)


-- AGGREGATION SQL:
SELECT `totalTwo`
FROM `aggregation_tmp_54945787`   
ON DUPLICATE KEY UPDATE
`totalTwo`=VALUES(`totalTwo`)
This is the query plan for the query:
SELECT 2.0*`p`.`total` as `totalTwo` FROM (SELECT SUM(`h`.`ca`+`h`.`ab`) as `total` FROM (SELECT count(a) as `ca`, avg(b) as `ab` FROM tblA) as `h`) as `p`

CALL paquExec('SELECT COUNT(`a`) AS `ca`, COUNT(`b`) AS `cnt_ab`, SUM(`b`) AS `sum_ab` FROM tblA ', 'aggregation_tmp_17731116');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_29954969 ENGINE=MyISAM SELECT SUM(`h`.`ca` + `h`.`ab`) AS `total`
FROM ( SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_17731116`   ) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_29954969 SELECT SUM(`h`.`ca` + `h`.`ab`) AS `total`
FROM ( SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_17731116`   ) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_29954969');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_54945787 ENGINE=MyISAM SELECT 2.0*`p`.`total` AS `totalTwo`
FROM ( SELECT SUM(`total`) AS `total`
FROM `aggregation_tmp_29954969`   ) AS `p`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_54945787 SELECT 2.0*`p`.`total` AS `totalTwo`
FROM ( SELECT SUM(`total`) AS `total`
FROM `aggregation_tmp_29954969`   ) AS `p` ;
CALL paquLinkTmp('aggregation_tmp_54945787');
CALL paquDropTmp('aggregation_tmp_17731116');
CALL paquDropTmp('aggregation_tmp_29954969');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `totalTwo`
FROM `aggregation_tmp_54945787`   ;
CALL paquDropTmp('aggregation_tmp_54945787');
This is the query plan optimisation output for the query:
SELECT 2.0*`p`.`total` as `totalTwo` FROM (SELECT SUM(`h`.`ca`+`h`.`ab`) as `total` FROM (SELECT count(a) as `ca`, avg(2.0 * (b / (5.0 + c))) as `ab` FROM tblA) as `h`) as `p`

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
ab

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`ca`=`ca` +  VALUES(`ca`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT COUNT(`a`) AS `ca`, COUNT(2.0 * ( `b` / ( 5.0 + `c`))) AS `cnt_ab`, SUM(2.0 * ( `b` / ( 5.0 + `c`))) AS `sum_ab`
FROM tblA 
)


-- AGGREGATION SQL:
SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_25702829`   
ON DUPLICATE KEY UPDATE
`ca`=`ca` +  VALUES(`ca`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT SUM(`h`.`ca` + `h`.`ab`) AS `total`
FROM ( SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_25702829`   ) AS `h` 
)


-- AGGREGATION SQL:
SELECT SUM(`total`) AS `total`
FROM `aggregation_tmp_95885938`   
-- INPUT SQL:
SELECT 2.0*`p`.`total` as `totalTwo` FROM (SELECT SUM(`h`.`ca`+`h`.`ab`) as `total` FROM (SELECT count(a) as `ca`, avg(2.0 * (b / (5.0 + c))) as `ab` FROM tblA) as `h`) as `p`

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`totalTwo`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`totalTwo`=VALUES(`totalTwo`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0*`p`.`total` AS `totalTwo`
FROM ( SELECT SUM(`total`) AS `total`
FROM `aggregation_tmp_95885938`   ) AS `p` 
)


-- AGGREGATION SQL:
SELECT `totalTwo`
FROM `aggregation_tmp_30520977`   
ON DUPLICATE KEY UPDATE
`totalTwo`=VALUES(`totalTwo`)
This is the query plan for the query:
SELECT 2.0*`p`.`total` as `totalTwo` FROM (SELECT SUM(`h`.`ca`+`h`.`ab`) as `total` FROM (SELECT count(a) as `ca`, avg(2.0 * (b / (5.0 + c))) as `ab` FROM tblA) as `h`) as `p`

CALL paquExec('SELECT COUNT(`a`) AS `ca`, COUNT(2.0 * ( `b` / ( 5.0 + `c`))) AS `cnt_ab`, SUM(2.0 * ( `b` / ( 5.0 + `c`))) AS `sum_ab` FROM tblA ', 'aggregation_tmp_25702829');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_95885938 ENGINE=MyISAM SELECT SUM(`h`.`ca` + `h`.`ab`) AS `total`
FROM ( SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_25702829`   ) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_95885938 SELECT SUM(`h`.`ca` + `h`.`ab`) AS `total`
FROM ( SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_25702829`   ) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_95885938');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_30520977 ENGINE=MyISAM SELECT 2.0*`p`.`total` AS `totalTwo`
FROM ( SELECT SUM(`total`) AS `total`
FROM `aggregation_tmp_95885938`   ) AS `p`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_30520977 SELECT 2.0*`p`.`total` AS `totalTwo`
FROM ( SELECT SUM(`total`) AS `total`
FROM `aggregation_tmp_95885938`   ) AS `p` ;
CALL paquLinkTmp('aggregation_tmp_30520977');
CALL paquDropTmp('aggregation_tmp_25702829');
CALL paquDropTmp('aggregation_tmp_95885938');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `totalTwo`
FROM `aggregation_tmp_30520977`   ;
CALL paquDropTmp('aggregation_tmp_30520977');
This is the query plan optimisation output for the query:
SELECT 2.0*`p`.`total` as `totalTwo` FROM (SELECT SUM(`h`.`ca`+`h`.`ab`) as `total` FROM (SELECT count(a) as `ca`, avg(2.0 * (b / (5.0 + c))) as `ab` FROM tblA) as `h`) as `p`

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
ab

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`ca`=`ca` +  VALUES(`ca`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT COUNT(`a`) AS `ca`, COUNT(2.0 * ( `b` / ( 5.0 + `c`))) AS `cnt_ab`, SUM(2.0 * ( `b` / ( 5.0 + `c`))) AS `sum_ab`
FROM tblA 
)


-- AGGREGATION SQL:
SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_64654228`   
ON DUPLICATE KEY UPDATE
`ca`=`ca` +  VALUES(`ca`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT SUM(`h`.`ca` + `h`.`ab`) AS `total`
FROM ( SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_64654228`   ) AS `h` 
)


-- AGGREGATION SQL:
SELECT SUM(`total`) AS `total`
FROM `aggregation_tmp_52138375`   
-- INPUT SQL:
SELECT 2.0*`p`.`total` as `totalTwo` FROM (SELECT SUM(`h`.`ca`+`h`.`ab`) as `total` FROM (SELECT count(a) as `ca`, avg(2.0 * (b / (5.0 + c))) as `ab` FROM tblA) as `h`) as `p`

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`totalTwo`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`totalTwo`=VALUES(`totalTwo`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0*`p`.`total` AS `totalTwo`
FROM ( SELECT SUM(`total`) AS `total`
FROM `aggregation_tmp_52138375`   ) AS `p` 
)


-- AGGREGATION SQL:
SELECT `totalTwo`
FROM `aggregation_tmp_66256477`   
ON DUPLICATE KEY UPDATE
`totalTwo`=VALUES(`totalTwo`)
This is the query plan for the query:
SELECT 2.0*`p`.`total` as `totalTwo` FROM (SELECT SUM(`h`.`ca`+`h`.`ab`) as `total` FROM (SELECT count(a) as `ca`, avg(2.0 * (b / (5.0 + c))) as `ab` FROM tblA) as `h`) as `p`

CALL paquExec('SELECT COUNT(`a`) AS `ca`, COUNT(2.0 * ( `b` / ( 5.0 + `c`))) AS `cnt_ab`, SUM(2.0 * ( `b` / ( 5.0 + `c`))) AS `sum_ab` FROM tblA ', 'aggregation_tmp_64654228');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_52138375 ENGINE=MyISAM SELECT SUM(`h`.`ca` + `h`.`ab`) AS `total`
FROM ( SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_64654228`   ) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_52138375 SELECT SUM(`h`.`ca` + `h`.`ab`) AS `total`
FROM ( SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_64654228`   ) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_52138375');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_66256477 ENGINE=MyISAM SELECT 2.0*`p`.`total` AS `totalTwo`
FROM ( SELECT SUM(`total`) AS `total`
FROM `aggregation_tmp_52138375`   ) AS `p`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_66256477 SELECT 2.0*`p`.`total` AS `totalTwo`
FROM ( SELECT SUM(`total`) AS `total`
FROM `aggregation_tmp_52138375`   ) AS `p` ;
CALL paquLinkTmp('aggregation_tmp_66256477');
CALL paquDropTmp('aggregation_tmp_64654228');
CALL paquDropTmp('aggregation_tmp_52138375');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `totalTwo`
FROM `aggregation_tmp_66256477`   ;
CALL paquDropTmp('aggregation_tmp_66256477');
This is the query plan optimisation output for the query:
SELECT 2.0*`p`.`total` as `totalTwo` FROM (SELECT SUM(`h`.`ca`+`h`.`ab`) as `total` FROM (SELECT count(a) as `ca`, avg(2.0 * (b / (5.0 + c))) as `ab` FROM tblA) as `h`) as `p`

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
ab

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`ca`=`ca` +  VALUES(`ca`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT COUNT(`a`) AS `ca`, COUNT(2.0 * ( `b` / ( 5.0 + `c`))) AS `cnt_ab`, SUM(2.0 * ( `b` / ( 5.0 + `c`))) AS `sum_ab`
FROM tblA 
)


-- AGGREGATION SQL:
SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_28604970`   
ON DUPLICATE KEY UPDATE
`ca`=`ca` +  VALUES(`ca`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT SUM(`h`.`ca` + `h`.`ab`) AS `total`
FROM ( SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_28604970`   ) AS `h` 
)


-- AGGREGATION SQL:
SELECT SUM(`total`) AS `total`
FROM `aggregation_tmp_63871661`   
-- INPUT SQL:
SELECT 2.0*`p`.`total` as `totalTwo` FROM (SELECT SUM(`h`.`ca`+`h`.`ab`) as `total` FROM (SELECT count(a) as `ca`, avg(2.0 * (b / (5.0 + c))) as `ab` FROM tblA) as `h`) as `p`

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`totalTwo`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`totalTwo`=VALUES(`totalTwo`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0*`p`.`total` AS `totalTwo`
FROM ( SELECT SUM(`total`) AS `total`
FROM `aggregation_tmp_63871661`   ) AS `p` 
)


-- AGGREGATION SQL:
SELECT `totalTwo`
FROM `aggregation_tmp_77772283`   
ON DUPLICATE KEY UPDATE
`totalTwo`=VALUES(`totalTwo`)
This is the query plan for the query:
SELECT 2.0*`p`.`total` as `totalTwo` FROM (SELECT SUM(`h`.`ca`+`h`.`ab`) as `total` FROM (SELECT count(a) as `ca`, avg(2.0 * (b / (5.0 + c))) as `ab` FROM tblA) as `h`) as `p`

CALL paquExec('SELECT COUNT(`a`) AS `ca`, COUNT(2.0 * ( `b` / ( 5.0 + `c`))) AS `cnt_ab`, SUM(2.0 * ( `b` / ( 5.0 + `c`))) AS `sum_ab` FROM tblA ', 'aggregation_tmp_28604970');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_63871661 ENGINE=MyISAM SELECT SUM(`h`.`ca` + `h`.`ab`) AS `total`
FROM ( SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_28604970`   ) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_63871661 SELECT SUM(`h`.`ca` + `h`.`ab`) AS `total`
FROM ( SELECT SUM(`ca`) AS `ca`, (SUM(`sum_ab`) / SUM(`cnt_ab`)) AS `ab`
FROM `aggregation_tmp_28604970`   ) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_63871661');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_77772283 ENGINE=MyISAM SELECT 2.0*`p`.`total` AS `totalTwo`
FROM ( SELECT SUM(`total`) AS `total`
FROM `aggregation_tmp_63871661`   ) AS `p`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_77772283 SELECT 2.0*`p`.`total` AS `totalTwo`
FROM ( SELECT SUM(`total`) AS `total`
FROM `aggregation_tmp_63871661`   ) AS `p` ;
CALL paquLinkTmp('aggregation_tmp_77772283');
CALL paquDropTmp('aggregation_tmp_28604970');
CALL paquDropTmp('aggregation_tmp_63871661');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `totalTwo`
FROM `aggregation_tmp_77772283`   ;
CALL paquDropTmp('aggregation_tmp_77772283');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_19869690`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_19869690`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_88320348`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   ', 'aggregation_tmp_19869690');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_19869690`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_88320348');
CALL paquDropTmp('aggregation_tmp_19869690');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_88320348`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_88320348');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN (descend.fofTreeId + 2.0) AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_42183874`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN (descend.fofTreeId + 2.0) AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_42183874`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN ( `descend`.`descend.fofTreeId` + 2.0 ) AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_92792330`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN (descend.fofTreeId + 2.0) AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   ', 'aggregation_tmp_42183874');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_42183874`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN ( `descend`.`descend.fofTreeId` + 2.0 ) AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_92792330');
CALL paquDropTmp('aggregation_tmp_42183874');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_92792330`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_92792330');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE (descend.fofTreeId / (2.0 * descent.fofTreeId)) = 85000000000 AND prog.fofTreeId BETWEEN (descend.fofTreeId + 2.0) AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` 
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_22061063`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE (descend.fofTreeId / (2.0 * descent.fofTreeId)) = 85000000000 AND prog.fofTreeId BETWEEN (descend.fofTreeId + 2.0) AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_22061063`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN ( `descend`.`descend.fofTreeId` + 2.0 ) AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_74018830`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE (descend.fofTreeId / (2.0 * descent.fofTreeId)) = 85000000000 AND prog.fofTreeId BETWEEN (descend.fofTreeId + 2.0) AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` ', 'aggregation_tmp_22061063');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_22061063`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN ( `descend`.`descend.fofTreeId` + 2.0 ) AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_74018830');
CALL paquDropTmp('aggregation_tmp_22061063');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_74018830`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_74018830');
This is the query plan optimisation output for the query:
SELECT prog.*, avg(descent.fofTreeId / 2.0) FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE (descend.fofTreeId / (2.0 * descent.fofTreeId)) = 85000000000 AND prog.fofTreeId BETWEEN (descend.fofTreeId + 2.0) AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` 
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_23217`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.*, avg(descent.fofTreeId / 2.0) FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE (descend.fofTreeId / (2.0 * descent.fofTreeId)) = 85000000000 AND prog.fofTreeId BETWEEN (descend.fofTreeId + 2.0) AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,_avg_descent__fofTreeId_/_2__0_,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`, COUNT(`descent`.`fofTreeId` / 2.0) AS `cnt__avg_descent__fofTreeId_/_2__0_`, SUM(`descent`.`fofTreeId` / 2.0) AS `sum__avg_descent__fofTreeId_/_2__0_`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_23217`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN ( `descend`.`descend.fofTreeId` + 2.0 ) AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`, (SUM(`sum__avg_descent__fofTreeId_/_2__0_`) / SUM(`cnt__avg_descent__fofTreeId_/_2__0_`)) AS `_avg_descent__fofTreeId_/_2__0_`,`prog.fofTreeId`
FROM `aggregation_tmp_54711924`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.*, avg(descent.fofTreeId / 2.0) FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE (descend.fofTreeId / (2.0 * descent.fofTreeId)) = 85000000000 AND prog.fofTreeId BETWEEN (descend.fofTreeId + 2.0) AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` ', 'aggregation_tmp_23217');
CALL paquExec('SELECT prog.* AS `prog.*`, COUNT(`descent`.`fofTreeId` / 2.0) AS `cnt__avg_descent__fofTreeId_/_2__0_`, SUM(`descent`.`fofTreeId` / 2.0) AS `sum__avg_descent__fofTreeId_/_2__0_`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_23217`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN ( `descend`.`descend.fofTreeId` + 2.0 ) AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_54711924');
CALL paquDropTmp('aggregation_tmp_23217');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`, (SUM(`sum__avg_descent__fofTreeId_/_2__0_`) / SUM(`cnt__avg_descent__fofTreeId_/_2__0_`)) AS `_avg_descent__fofTreeId_/_2__0_`,`prog.fofTreeId`
FROM `aggregation_tmp_54711924`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_54711924');
This is the query plan optimisation output for the query:
SELECT prog.*, avg(descent.fofTreeId / 2.0) FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE (descend.fofTreeId / (2.0 * descent.fofTreeId)) = 85000000000 AND prog.fofTreeId BETWEEN (descend.fofTreeId + 2.0) AND descend.lastProgId ORDER BY 1 ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`,`1`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`),
`1`=VALUES(`1`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`,1 AS `1`
FROM MDR1.FOFMtree AS `descend` 
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`,`1`
FROM `aggregation_tmp_11471535`  ORDER BY `1` ASC 
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`),
`1`=VALUES(`1`)
-- INPUT SQL:
SELECT prog.*, avg(descent.fofTreeId / 2.0) FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE (descend.fofTreeId / (2.0 * descent.fofTreeId)) = 85000000000 AND prog.fofTreeId BETWEEN (descend.fofTreeId + 2.0) AND descend.lastProgId ORDER BY 1 ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,_avg_descent__fofTreeId_/_2__0_

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`, COUNT(`descent`.`fofTreeId` / 2.0) AS `cnt__avg_descent__fofTreeId_/_2__0_`, SUM(`descent`.`fofTreeId` / 2.0) AS `sum__avg_descent__fofTreeId_/_2__0_`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`,`1`
FROM `aggregation_tmp_11471535`  ORDER BY `1` ASC ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN ( `descend`.`descend.fofTreeId` + 2.0 ) AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`, (SUM(`sum__avg_descent__fofTreeId_/_2__0_`) / SUM(`cnt__avg_descent__fofTreeId_/_2__0_`)) AS `_avg_descent__fofTreeId_/_2__0_`
FROM `aggregation_tmp_87459818`  ORDER BY `1` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`)
This is the query plan for the query:
SELECT prog.*, avg(descent.fofTreeId / 2.0) FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE (descend.fofTreeId / (2.0 * descent.fofTreeId)) = 85000000000 AND prog.fofTreeId BETWEEN (descend.fofTreeId + 2.0) AND descend.lastProgId ORDER BY 1 ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`,1 AS `1` FROM MDR1.FOFMtree AS `descend` ', 'aggregation_tmp_11471535');
CALL paquExec('SELECT prog.* AS `prog.*`, COUNT(`descent`.`fofTreeId` / 2.0) AS `cnt__avg_descent__fofTreeId_/_2__0_`, SUM(`descent`.`fofTreeId` / 2.0) AS `sum__avg_descent__fofTreeId_/_2__0_` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`,`1` FROM `aggregation_tmp_11471535`  ORDER BY `1` ASC ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN ( `descend`.`descend.fofTreeId` + 2.0 ) AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_87459818');
CALL paquDropTmp('aggregation_tmp_11471535');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`, (SUM(`sum__avg_descent__fofTreeId_/_2__0_`) / SUM(`cnt__avg_descent__fofTreeId_/_2__0_`)) AS `_avg_descent__fofTreeId_/_2__0_`
FROM `aggregation_tmp_87459818`  ORDER BY `1` ASC ;
CALL paquDropTmp('aggregation_tmp_87459818');
This is the query plan optimisation output for the query:
SELECT prog.*, avg(descent.fofTreeId / 2.0) FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE (descend.fofTreeId / (2.0 * descent.fofTreeId)) = 85000000000 AND prog.fofTreeId BETWEEN (descend.fofTreeId + 2.0) AND descend.lastProgId ORDER BY 1 ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`,`1`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`),
`1`=VALUES(`1`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`,1 AS `1`
FROM MDR1.FOFMtree AS `descend` 
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`,`1`
FROM `aggregation_tmp_61419806`  ORDER BY `1` ASC 
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`),
`1`=VALUES(`1`)
-- INPUT SQL:
SELECT prog.*, avg(descent.fofTreeId / 2.0) FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE (descend.fofTreeId / (2.0 * descent.fofTreeId)) = 85000000000 AND prog.fofTreeId BETWEEN (descend.fofTreeId + 2.0) AND descend.lastProgId ORDER BY 1 ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,_avg_descent__fofTreeId_/_2__0_

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`, COUNT(`descent`.`fofTreeId` / 2.0) AS `cnt__avg_descent__fofTreeId_/_2__0_`, SUM(`descent`.`fofTreeId` / 2.0) AS `sum__avg_descent__fofTreeId_/_2__0_`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`,`1`
FROM `aggregation_tmp_61419806`  ORDER BY `1` ASC ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN ( `descend`.`descend.fofTreeId` + 2.0 ) AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`, (SUM(`sum__avg_descent__fofTreeId_/_2__0_`) / SUM(`cnt__avg_descent__fofTreeId_/_2__0_`)) AS `_avg_descent__fofTreeId_/_2__0_`
FROM `aggregation_tmp_86585226`  ORDER BY `1` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`)
This is the query plan for the query:
SELECT prog.*, avg(descent.fofTreeId / 2.0) FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE (descend.fofTreeId / (2.0 * descent.fofTreeId)) = 85000000000 AND prog.fofTreeId BETWEEN (descend.fofTreeId + 2.0) AND descend.lastProgId ORDER BY 1 ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`,1 AS `1` FROM MDR1.FOFMtree AS `descend` ', 'aggregation_tmp_61419806');
CALL paquExec('SELECT prog.* AS `prog.*`, COUNT(`descent`.`fofTreeId` / 2.0) AS `cnt__avg_descent__fofTreeId_/_2__0_`, SUM(`descent`.`fofTreeId` / 2.0) AS `sum__avg_descent__fofTreeId_/_2__0_` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`,`1` FROM `aggregation_tmp_61419806`  ORDER BY `1` ASC ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN ( `descend`.`descend.fofTreeId` + 2.0 ) AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_86585226');
CALL paquDropTmp('aggregation_tmp_61419806');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`, (SUM(`sum__avg_descent__fofTreeId_/_2__0_`) / SUM(`cnt__avg_descent__fofTreeId_/_2__0_`)) AS `_avg_descent__fofTreeId_/_2__0_`
FROM `aggregation_tmp_86585226`  ORDER BY `1` ASC ;
CALL paquDropTmp('aggregation_tmp_86585226');
This is the query plan optimisation output for the query:
SELECT prog.*, avg(descent.fofTreeId / 2.0) FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE (descend.fofTreeId / (2.0 * descent.fofTreeId)) = 85000000000 AND prog.fofTreeId BETWEEN (descend.fofTreeId + 2.0) AND descend.lastProgId ORDER BY 2 ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`,`2`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`),
`2`=VALUES(`2`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`,2 AS `2`
FROM MDR1.FOFMtree AS `descend` 
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`,`2`
FROM `aggregation_tmp_56996040`  ORDER BY `2` ASC 
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`),
`2`=VALUES(`2`)
-- INPUT SQL:
SELECT prog.*, avg(descent.fofTreeId / 2.0) FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE (descend.fofTreeId / (2.0 * descent.fofTreeId)) = 85000000000 AND prog.fofTreeId BETWEEN (descend.fofTreeId + 2.0) AND descend.lastProgId ORDER BY 2 ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,_avg_descent__fofTreeId_/_2__0_

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`, COUNT(`descent`.`fofTreeId` / 2.0) AS `cnt__avg_descent__fofTreeId_/_2__0_`, SUM(`descent`.`fofTreeId` / 2.0) AS `sum__avg_descent__fofTreeId_/_2__0_`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`,`2`
FROM `aggregation_tmp_56996040`  ORDER BY `2` ASC ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN ( `descend`.`descend.fofTreeId` + 2.0 ) AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`, (SUM(`sum__avg_descent__fofTreeId_/_2__0_`) / SUM(`cnt__avg_descent__fofTreeId_/_2__0_`)) AS `_avg_descent__fofTreeId_/_2__0_`
FROM `aggregation_tmp_10005871`  ORDER BY `2` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`)
This is the query plan for the query:
SELECT prog.*, avg(descent.fofTreeId / 2.0) FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE (descend.fofTreeId / (2.0 * descent.fofTreeId)) = 85000000000 AND prog.fofTreeId BETWEEN (descend.fofTreeId + 2.0) AND descend.lastProgId ORDER BY 2 ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`,2 AS `2` FROM MDR1.FOFMtree AS `descend` ', 'aggregation_tmp_56996040');
CALL paquExec('SELECT prog.* AS `prog.*`, COUNT(`descent`.`fofTreeId` / 2.0) AS `cnt__avg_descent__fofTreeId_/_2__0_`, SUM(`descent`.`fofTreeId` / 2.0) AS `sum__avg_descent__fofTreeId_/_2__0_` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`,`2` FROM `aggregation_tmp_56996040`  ORDER BY `2` ASC ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN ( `descend`.`descend.fofTreeId` + 2.0 ) AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_10005871');
CALL paquDropTmp('aggregation_tmp_56996040');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`, (SUM(`sum__avg_descent__fofTreeId_/_2__0_`) / SUM(`cnt__avg_descent__fofTreeId_/_2__0_`)) AS `_avg_descent__fofTreeId_/_2__0_`
FROM `aggregation_tmp_10005871`  ORDER BY `2` ASC ;
CALL paquDropTmp('aggregation_tmp_10005871');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_53117283`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_53117283`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_62225752`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   ', 'aggregation_tmp_53117283');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_53117283`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_62225752');
CALL paquDropTmp('aggregation_tmp_53117283');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_62225752`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_62225752');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_53224405`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_53224405`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_34496855`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   ', 'aggregation_tmp_53224405');
CALL paquExec('SELECT prog.* AS `prog.*`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_53224405`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_34496855');
CALL paquDropTmp('aggregation_tmp_53224405');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_34496855`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_34496855');
This is the query plan optimisation output for the query:
SELECT prog.fofTreeId FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY 1 ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`,`1`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`),
`1`=VALUES(`1`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`,1 AS `1`
FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`,`1`
FROM `aggregation_tmp_90247120`  ORDER BY `1` ASC 
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`),
`1`=VALUES(`1`)
-- INPUT SQL:
SELECT prog.fofTreeId FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY 1 ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`,`1`
FROM `aggregation_tmp_90247120`  ORDER BY `1` ASC ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.fofTreeId`
FROM `aggregation_tmp_37291488`  ORDER BY `1` ASC 
ON DUPLICATE KEY UPDATE
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.fofTreeId FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY 1 ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`,1 AS `1` FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   ', 'aggregation_tmp_90247120');
CALL paquExec('SELECT prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`,`1` FROM `aggregation_tmp_90247120`  ORDER BY `1` ASC ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_37291488');
CALL paquDropTmp('aggregation_tmp_90247120');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.fofTreeId`
FROM `aggregation_tmp_37291488`  ORDER BY `1` ASC ;
CALL paquDropTmp('aggregation_tmp_37291488');
This is the query plan optimisation output for the query:
SELECT prog.fofTreeId FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId, 1 ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_7822767`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.fofTreeId FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId, 1 ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_7822767`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.fofTreeId`
FROM `aggregation_tmp_37411640`  ORDER BY `prog.fofTreeId` ASC,`prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.fofTreeId FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId, 1 ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   ', 'aggregation_tmp_7822767');
CALL paquExec('SELECT prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_7822767`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_37411640');
CALL paquDropTmp('aggregation_tmp_7822767');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.fofTreeId`
FROM `aggregation_tmp_37411640`  ORDER BY `prog.fofTreeId` ASC,`prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_37411640');
This is the query plan optimisation output for the query:
SELECT 2.0*prog.fofTreeId FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId, 1 ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_16036187`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT 2.0*prog.fofTreeId FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId, 1 ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_2__0_*_prog__fofTreeId_`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_2__0_*_prog__fofTreeId_`=VALUES(`_2__0_*_prog__fofTreeId_`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0*prog.fofTreeId AS `_2__0_*_prog__fofTreeId_`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_16036187`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `_2__0_*_prog__fofTreeId_`,`prog.fofTreeId`
FROM `aggregation_tmp_87623626`  ORDER BY `prog.fofTreeId` ASC,`_2__0_*_prog__fofTreeId_` ASC 
ON DUPLICATE KEY UPDATE
`_2__0_*_prog__fofTreeId_`=VALUES(`_2__0_*_prog__fofTreeId_`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT 2.0*prog.fofTreeId FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId, 1 ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   ', 'aggregation_tmp_16036187');
CALL paquExec('SELECT 2.0*prog.fofTreeId AS `_2__0_*_prog__fofTreeId_`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_16036187`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_87623626');
CALL paquDropTmp('aggregation_tmp_16036187');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_2__0_*_prog__fofTreeId_`,`prog.fofTreeId`
FROM `aggregation_tmp_87623626`  ORDER BY `prog.fofTreeId` ASC,`_2__0_*_prog__fofTreeId_` ASC ;
CALL paquDropTmp('aggregation_tmp_87623626');
This is the query plan optimisation output for the query:
SELECT 2.0*prog.fofTreeId FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId, 1 ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_77764029`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT 2.0*prog.fofTreeId FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId, 1 ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_2__0_*_prog__fofTreeId_`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_2__0_*_prog__fofTreeId_`=VALUES(`_2__0_*_prog__fofTreeId_`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0*prog.fofTreeId AS `_2__0_*_prog__fofTreeId_`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_77764029`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `_2__0_*_prog__fofTreeId_`,`prog.fofTreeId`
FROM `aggregation_tmp_92909185`  ORDER BY `prog.fofTreeId` ASC,`_2__0_*_prog__fofTreeId_` ASC 
ON DUPLICATE KEY UPDATE
`_2__0_*_prog__fofTreeId_`=VALUES(`_2__0_*_prog__fofTreeId_`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT 2.0*prog.fofTreeId FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId, 1 ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   ', 'aggregation_tmp_77764029');
CALL paquExec('SELECT 2.0*prog.fofTreeId AS `_2__0_*_prog__fofTreeId_`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_77764029`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_92909185');
CALL paquDropTmp('aggregation_tmp_77764029');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_2__0_*_prog__fofTreeId_`,`prog.fofTreeId`
FROM `aggregation_tmp_92909185`  ORDER BY `prog.fofTreeId` ASC,`_2__0_*_prog__fofTreeId_` ASC ;
CALL paquDropTmp('aggregation_tmp_92909185');
This is the query plan optimisation output for the query:
SELECT 2.0*prog.fofTreeId FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId, 1 ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_88012659`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT 2.0*prog.fofTreeId FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId, 1 ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_2__0_*_prog__fofTreeId_`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_2__0_*_prog__fofTreeId_`=VALUES(`_2__0_*_prog__fofTreeId_`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0*prog.fofTreeId AS `_2__0_*_prog__fofTreeId_`,prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_88012659`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `_2__0_*_prog__fofTreeId_`,`prog.fofTreeId`
FROM `aggregation_tmp_79986083`  ORDER BY `prog.fofTreeId` ASC,`_2__0_*_prog__fofTreeId_` ASC 
ON DUPLICATE KEY UPDATE
`_2__0_*_prog__fofTreeId_`=VALUES(`_2__0_*_prog__fofTreeId_`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT 2.0*prog.fofTreeId FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId, 1 ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   ', 'aggregation_tmp_88012659');
CALL paquExec('SELECT 2.0*prog.fofTreeId AS `_2__0_*_prog__fofTreeId_`,prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_88012659`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_79986083');
CALL paquDropTmp('aggregation_tmp_88012659');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_2__0_*_prog__fofTreeId_`,`prog.fofTreeId`
FROM `aggregation_tmp_79986083`  ORDER BY `prog.fofTreeId` ASC,`_2__0_*_prog__fofTreeId_` ASC ;
CALL paquDropTmp('aggregation_tmp_79986083');
This is the query plan optimisation output for the query:
SELECT 2.0*prog.fofTreeId FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY 1 ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_19558986`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT 2.0*prog.fofTreeId FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY 1 ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_2__0_*_prog__fofTreeId_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_2__0_*_prog__fofTreeId_`=VALUES(`_2__0_*_prog__fofTreeId_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0*prog.fofTreeId AS `_2__0_*_prog__fofTreeId_`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_19558986`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `_2__0_*_prog__fofTreeId_`
FROM `aggregation_tmp_36804548`  ORDER BY `_2__0_*_prog__fofTreeId_` ASC 
ON DUPLICATE KEY UPDATE
`_2__0_*_prog__fofTreeId_`=VALUES(`_2__0_*_prog__fofTreeId_`)
This is the query plan for the query:
SELECT 2.0*prog.fofTreeId FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY 1 ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   ', 'aggregation_tmp_19558986');
CALL paquExec('SELECT 2.0*prog.fofTreeId AS `_2__0_*_prog__fofTreeId_` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_19558986`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_36804548');
CALL paquDropTmp('aggregation_tmp_19558986');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_2__0_*_prog__fofTreeId_`
FROM `aggregation_tmp_36804548`  ORDER BY `_2__0_*_prog__fofTreeId_` ASC ;
CALL paquDropTmp('aggregation_tmp_36804548');
This is the query plan optimisation output for the query:
SELECT 2.0*prog.fofTreeId FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY 1 ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_89414542`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT 2.0*prog.fofTreeId FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY 1 ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_2__0_*_prog__fofTreeId_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_2__0_*_prog__fofTreeId_`=VALUES(`_2__0_*_prog__fofTreeId_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0*prog.fofTreeId AS `_2__0_*_prog__fofTreeId_`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_89414542`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `_2__0_*_prog__fofTreeId_`
FROM `aggregation_tmp_74096021`  ORDER BY `_2__0_*_prog__fofTreeId_` ASC 
ON DUPLICATE KEY UPDATE
`_2__0_*_prog__fofTreeId_`=VALUES(`_2__0_*_prog__fofTreeId_`)
This is the query plan for the query:
SELECT 2.0*prog.fofTreeId FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY 1 ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   ', 'aggregation_tmp_89414542');
CALL paquExec('SELECT 2.0*prog.fofTreeId AS `_2__0_*_prog__fofTreeId_` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_89414542`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_74096021');
CALL paquDropTmp('aggregation_tmp_89414542');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_2__0_*_prog__fofTreeId_`
FROM `aggregation_tmp_74096021`  ORDER BY `_2__0_*_prog__fofTreeId_` ASC ;
CALL paquDropTmp('aggregation_tmp_74096021');
This is the query plan optimisation output for the query:
SELECT prog.fofTreeId FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY 1 ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_53375014`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.fofTreeId FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY 1 ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_53375014`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.fofTreeId`
FROM `aggregation_tmp_62410187`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.fofTreeId FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY 1 ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   ', 'aggregation_tmp_53375014');
CALL paquExec('SELECT prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_53375014`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_62410187');
CALL paquDropTmp('aggregation_tmp_53375014');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.fofTreeId`
FROM `aggregation_tmp_62410187`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_62410187');
This is the query plan optimisation output for the query:
SELECT prog.fofTreeId FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY 1 ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_31711078`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.fofTreeId FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY 1 ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_31711078`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.fofTreeId`
FROM `aggregation_tmp_22130573`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.fofTreeId FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY 1 ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   ', 'aggregation_tmp_31711078');
CALL paquExec('SELECT prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_31711078`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_22130573');
CALL paquDropTmp('aggregation_tmp_31711078');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.fofTreeId`
FROM `aggregation_tmp_22130573`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_22130573');
This is the query plan optimisation output for the query:
SELECT prog.fofTreeId FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY 1 ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_84721054`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.fofTreeId FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY 1 ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT prog.fofTreeId AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_84721054`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.fofTreeId`
FROM `aggregation_tmp_57018937`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.fofTreeId FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY 1 ASC

CALL paquExec('SELECT descend.fofTreeId AS `descend.fofTreeId`,descend.lastProgId AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   ', 'aggregation_tmp_84721054');
CALL paquExec('SELECT prog.fofTreeId AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_84721054`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_57018937');
CALL paquDropTmp('aggregation_tmp_84721054');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.fofTreeId`
FROM `aggregation_tmp_57018937`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_57018937');
This is the query plan optimisation output for the query:
select fofId,count(fofId) as num from MDPL.FOF2 where snapnum=19 and fofID > 400000 group by fofId having count(fofId) > 1 order by fofId desc limit 100

-- INPUT SQL:
select fofId,count(fofId) as num from MDPL.FOF2 where snapnum=19 and fofID > 400000 group by fofId having count(fofId) > 1 order by fofId desc limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`num`=`num` +  VALUES(`num`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofId AS `fofId`,COUNT(`fofId`) AS `num`
FROM MDPL.FOF2 WHERE ( `snapnum` = 19 ) and ( `fofID` > 400000 )  GROUP BY fofId ORDER BY `fofId` DESC  LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `fofId`,SUM(`num`) AS `num`
FROM `aggregation_tmp_90215285`  GROUP BY `fofId` ORDER BY `fofId` DESC  LIMIT 0,100
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`num`=`num` +  VALUES(`num`)
This is the query plan for the query:
select fofId,count(fofId) as num from MDPL.FOF2 where snapnum=19 and fofID > 400000 group by fofId having count(fofId) > 1 order by fofId desc limit 100

CALL paquExec('SELECT fofId AS `fofId`,COUNT(`fofId`) AS `num` FROM MDPL.FOF2 WHERE ( `snapnum` = 19 ) and ( `fofID` > 400000 )  GROUP BY fofId ORDER BY `fofId` DESC  LIMIT 0,100', 'aggregation_tmp_90215285');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `fofId`,SUM(`num`) AS `num`
FROM `aggregation_tmp_90215285`  GROUP BY `fofId` ORDER BY `fofId` DESC  LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_90215285');
This is the query plan optimisation output for the query:
select fofId,count(fofId) as num from MDPL.FOF2 where snapnum=19 and fofID > 400000 group by fofId having count(fofId) > 1 order by fofId desc limit 100

-- INPUT SQL:
select fofId,count(fofId) as num from MDPL.FOF2 where snapnum=19 and fofID > 400000 group by fofId having count(fofId) > 1 order by fofId desc limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`fofId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`num`=`num` +  VALUES(`num`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT fofId AS `fofId`,COUNT(`fofId`) AS `num`
FROM MDPL.FOF2 WHERE ( `snapnum` = 19 ) and ( `fofID` > 400000 )  GROUP BY fofId ORDER BY `fofId` DESC  LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `fofId`,SUM(`num`) AS `num`
FROM `aggregation_tmp_35738472`  GROUP BY `fofId` ORDER BY `fofId` DESC  LIMIT 0,100
ON DUPLICATE KEY UPDATE
`fofId`=VALUES(`fofId`),
`num`=`num` +  VALUES(`num`)
This is the query plan for the query:
select fofId,count(fofId) as num from MDPL.FOF2 where snapnum=19 and fofID > 400000 group by fofId having count(fofId) > 1 order by fofId desc limit 100

CALL paquExec('SELECT fofId AS `fofId`,COUNT(`fofId`) AS `num` FROM MDPL.FOF2 WHERE ( `snapnum` = 19 ) and ( `fofID` > 400000 )  GROUP BY fofId ORDER BY `fofId` DESC  LIMIT 0,100', 'aggregation_tmp_35738472');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `fofId`,SUM(`num`) AS `num`
FROM `aggregation_tmp_35738472`  GROUP BY `fofId` ORDER BY `fofId` DESC  LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_35738472');
This is the query plan optimisation output for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY MDR1.FOF.mass desc LIMIT 10

-- INPUT SQL:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY MDR1.FOF.mass desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`
FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY `MDR1.FOF.mass` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `*`
FROM `aggregation_tmp_99909773`  ORDER BY `MDR1.FOF.mass` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)
This is the query plan for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY MDR1.FOF.mass desc LIMIT 10

CALL paquExec('SELECT * AS `*` FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY `MDR1.FOF.mass` DESC  LIMIT 0,10', 'aggregation_tmp_99909773');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`
FROM `aggregation_tmp_99909773`  ORDER BY `MDR1.FOF.mass` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_99909773');
This is the query plan optimisation output for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY MDR1.FOF.mass desc LIMIT 10

-- INPUT SQL:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY MDR1.FOF.mass desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`,``

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
``=VALUES(``)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,MDR1.FOF.mass AS ``
FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY `MDR1.FOF.mass` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `*`,``
FROM `aggregation_tmp_64790439`  ORDER BY `MDR1.FOF.mass` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
``=VALUES(``)
This is the query plan for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY MDR1.FOF.mass desc LIMIT 10

CALL paquExec('SELECT * AS `*`,MDR1.FOF.mass AS `` FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY `MDR1.FOF.mass` DESC  LIMIT 0,10', 'aggregation_tmp_64790439');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`,``
FROM `aggregation_tmp_64790439`  ORDER BY `MDR1.FOF.mass` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_64790439');
This is the query plan optimisation output for the query:
SELECT snapnum as  FROM MDR1.FOF WHERE snapnum=85 ORDER BY  desc LIMIT 10

-- INPUT SQL:
SELECT snapnum as  FROM MDR1.FOF WHERE snapnum=85 ORDER BY  desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`snapnum`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`snapnum`=VALUES(`snapnum`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT snapnum AS `snapnum`
FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY ``   LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `snapnum`
FROM `aggregation_tmp_90198335`  ORDER BY ``   LIMIT 0,10
ON DUPLICATE KEY UPDATE
`snapnum`=VALUES(`snapnum`)
This is the query plan for the query:
SELECT snapnum as  FROM MDR1.FOF WHERE snapnum=85 ORDER BY  desc LIMIT 10

CALL paquExec('SELECT snapnum AS `snapnum` FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY ``   LIMIT 0,10', 'aggregation_tmp_90198335');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `snapnum`
FROM `aggregation_tmp_90198335`  ORDER BY ``   LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_90198335');
This is the query plan optimisation output for the query:
SELECT snapnum as  FROM MDR1.FOF WHERE snapnum=85 ORDER BY `snappi` desc LIMIT 10

-- INPUT SQL:
SELECT snapnum as  FROM MDR1.FOF WHERE snapnum=85 ORDER BY `snappi` desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`snapnum`,``snappi``

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`snapnum`=VALUES(`snapnum`),
``snappi``=VALUES(``snappi``)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT snapnum AS `snapnum`,`snappi` AS ``snappi``
FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY `snappi` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `snapnum`,``snappi``
FROM `aggregation_tmp_82582080`  ORDER BY `snappi` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`snapnum`=VALUES(`snapnum`),
``snappi``=VALUES(``snappi``)
This is the query plan for the query:
SELECT snapnum as  FROM MDR1.FOF WHERE snapnum=85 ORDER BY `snappi` desc LIMIT 10

CALL paquExec('SELECT snapnum AS `snapnum`,`snappi` AS ``snappi`` FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY `snappi` DESC  LIMIT 0,10', 'aggregation_tmp_82582080');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `snapnum`,``snappi``
FROM `aggregation_tmp_82582080`  ORDER BY `snappi` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_82582080');
This is the query plan optimisation output for the query:
SELECT snapnum as  FROM MDR1.FOF WHERE snapnum=85 ORDER BY `snappi` desc LIMIT 10

-- INPUT SQL:
SELECT snapnum as  FROM MDR1.FOF WHERE snapnum=85 ORDER BY `snappi` desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`snapnum`,``snappi``

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`snapnum`=VALUES(`snapnum`),
``snappi``=VALUES(``snappi``)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT snapnum AS `snapnum`,`snappi` AS ``snappi``
FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY `snappi` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `snapnum`,``snappi``
FROM `aggregation_tmp_87629321`  ORDER BY `snappi` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`snapnum`=VALUES(`snapnum`),
``snappi``=VALUES(``snappi``)
This is the query plan for the query:
SELECT snapnum as  FROM MDR1.FOF WHERE snapnum=85 ORDER BY `snappi` desc LIMIT 10

CALL paquExec('SELECT snapnum AS `snapnum`,`snappi` AS ``snappi`` FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY `snappi` DESC  LIMIT 0,10', 'aggregation_tmp_87629321');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `snapnum`,``snappi``
FROM `aggregation_tmp_87629321`  ORDER BY `snappi` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_87629321');
This is the query plan optimisation output for the query:
SELECT snapnum as  FROM MDR1.FOF WHERE snapnum=85 ORDER BY `snappi` desc LIMIT 10

-- INPUT SQL:
SELECT snapnum as  FROM MDR1.FOF WHERE snapnum=85 ORDER BY `snappi` desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`snapnum`,``snappi``

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`snapnum`=VALUES(`snapnum`),
``snappi``=VALUES(``snappi``)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT snapnum AS `snapnum`,`snappi` AS ``snappi``
FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY `snappi` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `snapnum`,``snappi``
FROM `aggregation_tmp_61462253`  ORDER BY `snappi` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`snapnum`=VALUES(`snapnum`),
``snappi``=VALUES(``snappi``)
This is the query plan for the query:
SELECT snapnum as  FROM MDR1.FOF WHERE snapnum=85 ORDER BY `snappi` desc LIMIT 10

CALL paquExec('SELECT snapnum AS `snapnum`,`snappi` AS ``snappi`` FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY `snappi` DESC  LIMIT 0,10', 'aggregation_tmp_61462253');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `snapnum`,``snappi``
FROM `aggregation_tmp_61462253`  ORDER BY `snappi` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_61462253');
This is the query plan optimisation output for the query:
SELECT h.snappi FROM (SELECT snapnum FROM MDR1.FOF WHERE snapnum=85 ORDER BY snapnum desc LIMIT 10) as h

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`snapnum`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`snapnum`=VALUES(`snapnum`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT snapnum AS `snapnum`
FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY `snapnum` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `snapnum`
FROM `aggregation_tmp_78431057`  ORDER BY `snapnum` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`snapnum`=VALUES(`snapnum`)
-- INPUT SQL:
SELECT h.snappi FROM (SELECT snapnum FROM MDR1.FOF WHERE snapnum=85 ORDER BY snapnum desc LIMIT 10) as h

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`h.snappi`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`h.snappi`=VALUES(`h.snappi`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT h.snappi AS `h.snappi`
FROM ( SELECT `snapnum`
FROM `aggregation_tmp_78431057`  ORDER BY `snapnum` DESC  LIMIT 0,10) AS `h` 
)


-- AGGREGATION SQL:
SELECT `h.snappi`
FROM `aggregation_tmp_7733688`   
ON DUPLICATE KEY UPDATE
`h.snappi`=VALUES(`h.snappi`)
This is the query plan for the query:
SELECT h.snappi FROM (SELECT snapnum FROM MDR1.FOF WHERE snapnum=85 ORDER BY snapnum desc LIMIT 10) as h

CALL paquExec('SELECT snapnum AS `snapnum` FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY `snapnum` DESC  LIMIT 0,10', 'aggregation_tmp_78431057');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_7733688 ENGINE=MyISAM SELECT h.snappi AS `h.snappi`
FROM ( SELECT `snapnum`
FROM `aggregation_tmp_78431057`  ORDER BY `snapnum` DESC  LIMIT 0,10) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_7733688 SELECT h.snappi AS `h.snappi`
FROM ( SELECT `snapnum`
FROM `aggregation_tmp_78431057`  ORDER BY `snapnum` DESC  LIMIT 0,10) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_7733688');
CALL paquDropTmp('aggregation_tmp_78431057');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `h.snappi`
FROM `aggregation_tmp_7733688`   ;
CALL paquDropTmp('aggregation_tmp_7733688');
This is the query plan optimisation output for the query:
SELECT h.snappi FROM (SELECT snapnum FROM MDR1.FOF WHERE snapnum=85 ORDER BY snapnum desc LIMIT 10) as h

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`snapnum`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`snapnum`=VALUES(`snapnum`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT snapnum AS `snapnum`
FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY `snapnum` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `snapnum`
FROM `aggregation_tmp_66666510`  ORDER BY `snapnum` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`snapnum`=VALUES(`snapnum`)
-- INPUT SQL:
SELECT h.snappi FROM (SELECT snapnum FROM MDR1.FOF WHERE snapnum=85 ORDER BY snapnum desc LIMIT 10) as h

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`h.snappi`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`h.snappi`=VALUES(`h.snappi`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT h.snappi AS `h.snappi`
FROM ( SELECT `snapnum`
FROM `aggregation_tmp_66666510`  ORDER BY `snapnum` DESC  LIMIT 0,10) AS `h` 
)


-- AGGREGATION SQL:
SELECT `h.snappi`
FROM `aggregation_tmp_54081293`   
ON DUPLICATE KEY UPDATE
`h.snappi`=VALUES(`h.snappi`)
This is the query plan for the query:
SELECT h.snappi FROM (SELECT snapnum FROM MDR1.FOF WHERE snapnum=85 ORDER BY snapnum desc LIMIT 10) as h

CALL paquExec('SELECT snapnum AS `snapnum` FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY `snapnum` DESC  LIMIT 0,10', 'aggregation_tmp_66666510');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_54081293 ENGINE=MyISAM SELECT h.snappi AS `h.snappi`
FROM ( SELECT `snapnum`
FROM `aggregation_tmp_66666510`  ORDER BY `snapnum` DESC  LIMIT 0,10) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_54081293 SELECT h.snappi AS `h.snappi`
FROM ( SELECT `snapnum`
FROM `aggregation_tmp_66666510`  ORDER BY `snapnum` DESC  LIMIT 0,10) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_54081293');
CALL paquDropTmp('aggregation_tmp_66666510');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `h.snappi`
FROM `aggregation_tmp_54081293`   ;
CALL paquDropTmp('aggregation_tmp_54081293');
This is the query plan optimisation output for the query:
SELECT h.snappi FROM (SELECT snapnum FROM MDR1.FOF WHERE snapnum=85 LIMIT 10) as h ORDER BY h.snapnum ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`snapnum`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`snapnum`=VALUES(`snapnum`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT snapnum AS `snapnum`
FROM MDR1.FOF WHERE ( `snapnum` = 85 )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `snapnum`
FROM `aggregation_tmp_57565982`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`snapnum`=VALUES(`snapnum`)
-- INPUT SQL:
SELECT h.snappi FROM (SELECT snapnum FROM MDR1.FOF WHERE snapnum=85 LIMIT 10) as h ORDER BY h.snapnum ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`h.snappi`,`h`.`snapnum`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`h.snappi`=VALUES(`h.snappi`),
`h`.`snapnum`=VALUES(`h`.`snapnum`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT h.snappi AS `h.snappi`,`h`.`snapnum` AS `h`.`snapnum`
FROM ( SELECT `snapnum`
FROM `aggregation_tmp_57565982`    LIMIT 0,10) AS `h` 
)


-- AGGREGATION SQL:
SELECT `h.snappi`,`h`.`snapnum`
FROM `aggregation_tmp_4548138`  ORDER BY `h.snapnum` ASC 
ON DUPLICATE KEY UPDATE
`h.snappi`=VALUES(`h.snappi`),
`h`.`snapnum`=VALUES(`h`.`snapnum`)
This is the query plan for the query:
SELECT h.snappi FROM (SELECT snapnum FROM MDR1.FOF WHERE snapnum=85 LIMIT 10) as h ORDER BY h.snapnum ASC

CALL paquExec('SELECT snapnum AS `snapnum` FROM MDR1.FOF WHERE ( `snapnum` = 85 )    LIMIT 0,10', 'aggregation_tmp_57565982');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_4548138 ENGINE=MyISAM SELECT h.snappi AS `h.snappi`,`h`.`snapnum` AS `h`.`snapnum`
FROM ( SELECT `snapnum`
FROM `aggregation_tmp_57565982`    LIMIT 0,10) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_4548138 SELECT h.snappi AS `h.snappi`,`h`.`snapnum` AS `h`.`snapnum`
FROM ( SELECT `snapnum`
FROM `aggregation_tmp_57565982`    LIMIT 0,10) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_4548138');
CALL paquDropTmp('aggregation_tmp_57565982');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `h.snappi`,`h`.`snapnum`
FROM `aggregation_tmp_4548138`  ORDER BY `h.snapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_4548138');
This is the query plan optimisation output for the query:
SELECT h.snappi FROM (SELECT snapnum as `snappi` FROM MDR1.FOF WHERE snapnum=85 LIMIT 10) as h ORDER BY h.snapnum ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`snappi`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`snappi`=VALUES(`snappi`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT snapnum AS `snappi`
FROM MDR1.FOF WHERE ( `snapnum` = 85 )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `snappi`
FROM `aggregation_tmp_11570076`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`snappi`=VALUES(`snappi`)
-- INPUT SQL:
SELECT h.snappi FROM (SELECT snapnum as `snappi` FROM MDR1.FOF WHERE snapnum=85 LIMIT 10) as h ORDER BY h.snapnum ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`h.snappi`,`h`.`snappi`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`h.snappi`=VALUES(`h.snappi`),
`h`.`snappi`=VALUES(`h`.`snappi`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT h.snappi AS `h.snappi`,`h`.`snappi` AS `h`.`snappi`
FROM ( SELECT `snappi`
FROM `aggregation_tmp_11570076`    LIMIT 0,10) AS `h` 
)


-- AGGREGATION SQL:
SELECT `h.snappi`,`h`.`snappi`
FROM `aggregation_tmp_67780683`  ORDER BY `h.snapnum` ASC 
ON DUPLICATE KEY UPDATE
`h.snappi`=VALUES(`h.snappi`),
`h`.`snappi`=VALUES(`h`.`snappi`)
This is the query plan for the query:
SELECT h.snappi FROM (SELECT snapnum as `snappi` FROM MDR1.FOF WHERE snapnum=85 LIMIT 10) as h ORDER BY h.snapnum ASC

CALL paquExec('SELECT snapnum AS `snappi` FROM MDR1.FOF WHERE ( `snapnum` = 85 )    LIMIT 0,10', 'aggregation_tmp_11570076');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_67780683 ENGINE=MyISAM SELECT h.snappi AS `h.snappi`,`h`.`snappi` AS `h`.`snappi`
FROM ( SELECT `snappi`
FROM `aggregation_tmp_11570076`    LIMIT 0,10) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_67780683 SELECT h.snappi AS `h.snappi`,`h`.`snappi` AS `h`.`snappi`
FROM ( SELECT `snappi`
FROM `aggregation_tmp_11570076`    LIMIT 0,10) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_67780683');
CALL paquDropTmp('aggregation_tmp_11570076');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `h.snappi`,`h`.`snappi`
FROM `aggregation_tmp_67780683`  ORDER BY `h.snapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_67780683');
This is the query plan optimisation output for the query:
SELECT h.snappi FROM (SELECT snapnum as `snappi` FROM MDR1.FOF WHERE snapnum=85 LIMIT 10) as h ORDER BY h.snappi ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`snappi`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`snappi`=VALUES(`snappi`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT snapnum AS `snappi`
FROM MDR1.FOF WHERE ( `snapnum` = 85 )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `snappi`
FROM `aggregation_tmp_21370986`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`snappi`=VALUES(`snappi`)
-- INPUT SQL:
SELECT h.snappi FROM (SELECT snapnum as `snappi` FROM MDR1.FOF WHERE snapnum=85 LIMIT 10) as h ORDER BY h.snappi ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`h.snappi`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`h.snappi`=VALUES(`h.snappi`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT h.snappi AS `h.snappi`
FROM ( SELECT `snappi`
FROM `aggregation_tmp_21370986`    LIMIT 0,10) AS `h` 
)


-- AGGREGATION SQL:
SELECT `h.snappi`
FROM `aggregation_tmp_31410741`  ORDER BY `h.snappi` ASC 
ON DUPLICATE KEY UPDATE
`h.snappi`=VALUES(`h.snappi`)
This is the query plan for the query:
SELECT h.snappi FROM (SELECT snapnum as `snappi` FROM MDR1.FOF WHERE snapnum=85 LIMIT 10) as h ORDER BY h.snappi ASC

CALL paquExec('SELECT snapnum AS `snappi` FROM MDR1.FOF WHERE ( `snapnum` = 85 )    LIMIT 0,10', 'aggregation_tmp_21370986');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_31410741 ENGINE=MyISAM SELECT h.snappi AS `h.snappi`
FROM ( SELECT `snappi`
FROM `aggregation_tmp_21370986`    LIMIT 0,10) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_31410741 SELECT h.snappi AS `h.snappi`
FROM ( SELECT `snappi`
FROM `aggregation_tmp_21370986`    LIMIT 0,10) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_31410741');
CALL paquDropTmp('aggregation_tmp_21370986');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `h.snappi`
FROM `aggregation_tmp_31410741`  ORDER BY `h.snappi` ASC ;
CALL paquDropTmp('aggregation_tmp_31410741');
This is the query plan optimisation output for the query:
SELECT h.snapnum FROM (SELECT snapnum FROM MDR1.FOF WHERE snapnum=85 LIMIT 10) as h ORDER BY h.snapnum ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`snapnum`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`snapnum`=VALUES(`snapnum`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT snapnum AS `snapnum`
FROM MDR1.FOF WHERE ( `snapnum` = 85 )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `snapnum`
FROM `aggregation_tmp_10000765`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`snapnum`=VALUES(`snapnum`)
-- INPUT SQL:
SELECT h.snapnum FROM (SELECT snapnum FROM MDR1.FOF WHERE snapnum=85 LIMIT 10) as h ORDER BY h.snapnum ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`h.snapnum`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`h.snapnum`=VALUES(`h.snapnum`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `h`.`snapnum` AS `h.snapnum`
FROM ( SELECT `snapnum`
FROM `aggregation_tmp_10000765`    LIMIT 0,10) AS `h` 
)


-- AGGREGATION SQL:
SELECT `h.snapnum`
FROM `aggregation_tmp_7462057`  ORDER BY `h.snapnum` ASC 
ON DUPLICATE KEY UPDATE
`h.snapnum`=VALUES(`h.snapnum`)
This is the query plan for the query:
SELECT h.snapnum FROM (SELECT snapnum FROM MDR1.FOF WHERE snapnum=85 LIMIT 10) as h ORDER BY h.snapnum ASC

CALL paquExec('SELECT snapnum AS `snapnum` FROM MDR1.FOF WHERE ( `snapnum` = 85 )    LIMIT 0,10', 'aggregation_tmp_10000765');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_7462057 ENGINE=MyISAM SELECT `h`.`snapnum` AS `h.snapnum`
FROM ( SELECT `snapnum`
FROM `aggregation_tmp_10000765`    LIMIT 0,10) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_7462057 SELECT `h`.`snapnum` AS `h.snapnum`
FROM ( SELECT `snapnum`
FROM `aggregation_tmp_10000765`    LIMIT 0,10) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_7462057');
CALL paquDropTmp('aggregation_tmp_10000765');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `h.snapnum`
FROM `aggregation_tmp_7462057`  ORDER BY `h.snapnum` ASC ;
CALL paquDropTmp('aggregation_tmp_7462057');
This is the query plan optimisation output for the query:
SELECT h.snapnum FROM (SELECT snapnum, expz FROM MDR1.FOF WHERE snapnum=85 LIMIT 10) as h ORDER BY h.expz ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`snapnum`,`expz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`snapnum`=VALUES(`snapnum`),
`expz`=VALUES(`expz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT snapnum AS `snapnum`,expz AS `expz`
FROM MDR1.FOF WHERE ( `snapnum` = 85 )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `snapnum`,`expz`
FROM `aggregation_tmp_37830282`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`snapnum`=VALUES(`snapnum`),
`expz`=VALUES(`expz`)
-- INPUT SQL:
SELECT h.snapnum FROM (SELECT snapnum, expz FROM MDR1.FOF WHERE snapnum=85 LIMIT 10) as h ORDER BY h.expz ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`h.snapnum`,`h`.`expz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`h.snapnum`=VALUES(`h.snapnum`),
`h`.`expz`=VALUES(`h`.`expz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `h`.`snapnum` AS `h.snapnum`,`h`.`expz` AS `h`.`expz`
FROM ( SELECT `snapnum`,`expz`
FROM `aggregation_tmp_37830282`    LIMIT 0,10) AS `h` 
)


-- AGGREGATION SQL:
SELECT `h.snapnum`,`h`.`expz`
FROM `aggregation_tmp_72551039`  ORDER BY `h.expz` ASC 
ON DUPLICATE KEY UPDATE
`h.snapnum`=VALUES(`h.snapnum`),
`h`.`expz`=VALUES(`h`.`expz`)
This is the query plan for the query:
SELECT h.snapnum FROM (SELECT snapnum, expz FROM MDR1.FOF WHERE snapnum=85 LIMIT 10) as h ORDER BY h.expz ASC

CALL paquExec('SELECT snapnum AS `snapnum`,expz AS `expz` FROM MDR1.FOF WHERE ( `snapnum` = 85 )    LIMIT 0,10', 'aggregation_tmp_37830282');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_72551039 ENGINE=MyISAM SELECT `h`.`snapnum` AS `h.snapnum`,`h`.`expz` AS `h`.`expz`
FROM ( SELECT `snapnum`,`expz`
FROM `aggregation_tmp_37830282`    LIMIT 0,10) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_72551039 SELECT `h`.`snapnum` AS `h.snapnum`,`h`.`expz` AS `h`.`expz`
FROM ( SELECT `snapnum`,`expz`
FROM `aggregation_tmp_37830282`    LIMIT 0,10) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_72551039');
CALL paquDropTmp('aggregation_tmp_37830282');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `h.snapnum`,`h`.`expz`
FROM `aggregation_tmp_72551039`  ORDER BY `h.expz` ASC ;
CALL paquDropTmp('aggregation_tmp_72551039');
This is the query plan optimisation output for the query:
SELECT snapnum FROM MDR1.FOF WHERE snapnum=85 LIMIT 10 order by expz

-- INPUT SQL:
SELECT snapnum FROM MDR1.FOF WHERE snapnum=85 LIMIT 10 order by expz

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`snapnum`,`expz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`snapnum`=VALUES(`snapnum`),
`expz`=VALUES(`expz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT snapnum AS `snapnum`,expz AS `expz`
FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY `expz` ASC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `snapnum`,`expz`
FROM `aggregation_tmp_34384555`  ORDER BY `expz` ASC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`snapnum`=VALUES(`snapnum`),
`expz`=VALUES(`expz`)
This is the query plan for the query:
SELECT snapnum FROM MDR1.FOF WHERE snapnum=85 LIMIT 10 order by expz

CALL paquExec('SELECT snapnum AS `snapnum`,expz AS `expz` FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY `expz` ASC  LIMIT 0,10', 'aggregation_tmp_34384555');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `snapnum`,`expz`
FROM `aggregation_tmp_34384555`  ORDER BY `expz` ASC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_34384555');
This is the query plan optimisation output for the query:
SELECT snapnum FROM MDR1.FOF WHERE snapnum=85 LIMIT 10 order by FOF.expz

-- INPUT SQL:
SELECT snapnum FROM MDR1.FOF WHERE snapnum=85 LIMIT 10 order by FOF.expz

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`snapnum`,`FOF.expz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`snapnum`=VALUES(`snapnum`),
`FOF.expz`=VALUES(`FOF.expz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT snapnum AS `snapnum`,FOF.expz AS `FOF.expz`
FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY `FOF.expz` ASC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `snapnum`,`FOF.expz`
FROM `aggregation_tmp_14034856`  ORDER BY `FOF.expz` ASC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`snapnum`=VALUES(`snapnum`),
`FOF.expz`=VALUES(`FOF.expz`)
This is the query plan for the query:
SELECT snapnum FROM MDR1.FOF WHERE snapnum=85 LIMIT 10 order by FOF.expz

CALL paquExec('SELECT snapnum AS `snapnum`,FOF.expz AS `FOF.expz` FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY `FOF.expz` ASC  LIMIT 0,10', 'aggregation_tmp_14034856');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `snapnum`,`FOF.expz`
FROM `aggregation_tmp_14034856`  ORDER BY `FOF.expz` ASC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_14034856');
This is the query plan optimisation output for the query:
SELECT snapnum FROM MDR1.FOF WHERE snapnum=85 LIMIT 10 order by FOF.expz

-- INPUT SQL:
SELECT snapnum FROM MDR1.FOF WHERE snapnum=85 LIMIT 10 order by FOF.expz

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`snapnum`,`FOF.expz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`snapnum`=VALUES(`snapnum`),
`FOF.expz`=VALUES(`FOF.expz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT snapnum AS `snapnum`,FOF.expz AS `FOF.expz`
FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY `FOF.expz` ASC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `snapnum`,`FOF.expz`
FROM `aggregation_tmp_8930800`  ORDER BY `FOF.expz` ASC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`snapnum`=VALUES(`snapnum`),
`FOF.expz`=VALUES(`FOF.expz`)
This is the query plan for the query:
SELECT snapnum FROM MDR1.FOF WHERE snapnum=85 LIMIT 10 order by FOF.expz

CALL paquExec('SELECT snapnum AS `snapnum`,FOF.expz AS `FOF.expz` FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY `FOF.expz` ASC  LIMIT 0,10', 'aggregation_tmp_8930800');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `snapnum`,`FOF.expz`
FROM `aggregation_tmp_8930800`  ORDER BY `FOF.expz` ASC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_8930800');
This is the query plan optimisation output for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY MDR1.FOF.mass desc LIMIT 10

-- INPUT SQL:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY MDR1.FOF.mass desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`,``

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
``=VALUES(``)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,MDR1.FOF.mass AS ``
FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY `MDR1.FOF.mass` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `*`,``
FROM `aggregation_tmp_18705008`  ORDER BY `MDR1.FOF.mass` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
``=VALUES(``)
This is the query plan for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY MDR1.FOF.mass desc LIMIT 10

CALL paquExec('SELECT * AS `*`,MDR1.FOF.mass AS `` FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY `MDR1.FOF.mass` DESC  LIMIT 0,10', 'aggregation_tmp_18705008');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`,``
FROM `aggregation_tmp_18705008`  ORDER BY `MDR1.FOF.mass` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_18705008');
This is the query plan optimisation output for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY MDR1.FOF.mass desc LIMIT 10

-- INPUT SQL:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY MDR1.FOF.mass desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`,``

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
``=VALUES(``)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,MDR1.FOF.mass AS ``
FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY `MDR1.FOF.mass` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `*`,``
FROM `aggregation_tmp_94564325`  ORDER BY `MDR1.FOF.mass` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
``=VALUES(``)
This is the query plan for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY MDR1.FOF.mass desc LIMIT 10

CALL paquExec('SELECT * AS `*`,MDR1.FOF.mass AS `` FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY `MDR1.FOF.mass` DESC  LIMIT 0,10', 'aggregation_tmp_94564325');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`,``
FROM `aggregation_tmp_94564325`  ORDER BY `MDR1.FOF.mass` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_94564325');
This is the query plan optimisation output for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY MDR1.FOF.mass desc LIMIT 10

-- INPUT SQL:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY MDR1.FOF.mass desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`,``

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
``=VALUES(``)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,MDR1.FOF.mass AS ``
FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY `MDR1.FOF.mass` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `*`,``
FROM `aggregation_tmp_71918703`  ORDER BY `MDR1.FOF.mass` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
``=VALUES(``)
This is the query plan for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY MDR1.FOF.mass desc LIMIT 10

CALL paquExec('SELECT * AS `*`,MDR1.FOF.mass AS `` FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY `MDR1.FOF.mass` DESC  LIMIT 0,10', 'aggregation_tmp_71918703');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`,``
FROM `aggregation_tmp_71918703`  ORDER BY `MDR1.FOF.mass` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_71918703');
This is the query plan optimisation output for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY MDR1.FOF.mass desc LIMIT 10

-- INPUT SQL:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY MDR1.FOF.mass desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`,``

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
``=VALUES(``)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,`MDR1`.`FOF`.`mass` AS ``
FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY `MDR1.FOF.mass` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `*`,``
FROM `aggregation_tmp_28829789`  ORDER BY `MDR1.FOF.mass` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
``=VALUES(``)
This is the query plan for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY MDR1.FOF.mass desc LIMIT 10

CALL paquExec('SELECT * AS `*`,`MDR1`.`FOF`.`mass` AS `` FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY `MDR1.FOF.mass` DESC  LIMIT 0,10', 'aggregation_tmp_28829789');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`,``
FROM `aggregation_tmp_28829789`  ORDER BY `MDR1.FOF.mass` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_28829789');
This is the query plan optimisation output for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY MDR1.FOF.mass desc LIMIT 10

-- INPUT SQL:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY MDR1.FOF.mass desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`,``

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
``=VALUES(``)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,`MDR1`.`FOF`.`mass` AS ``
FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY `MDR1`.`FOF`.`mass` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `*`,``
FROM `aggregation_tmp_97970754`  ORDER BY `MDR1.FOF.mass` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
``=VALUES(``)
This is the query plan for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY MDR1.FOF.mass desc LIMIT 10

CALL paquExec('SELECT * AS `*`,`MDR1`.`FOF`.`mass` AS `` FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY `MDR1`.`FOF`.`mass` DESC  LIMIT 0,10', 'aggregation_tmp_97970754');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`,``
FROM `aggregation_tmp_97970754`  ORDER BY `MDR1.FOF.mass` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_97970754');
This is the query plan optimisation output for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY MDR1.FOF.mass desc LIMIT 10

-- INPUT SQL:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY MDR1.FOF.mass desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`,`MDR1.FOF.mass`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`MDR1.FOF.mass`=VALUES(`MDR1.FOF.mass`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`,`MDR1`.`FOF`.`mass` AS `MDR1.FOF.mass`
FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY `MDR1`.`FOF`.`mass` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `*`,`MDR1.FOF.mass`
FROM `aggregation_tmp_20520253`  ORDER BY `MDR1.FOF.mass` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`),
`MDR1.FOF.mass`=VALUES(`MDR1.FOF.mass`)
This is the query plan for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY MDR1.FOF.mass desc LIMIT 10

CALL paquExec('SELECT * AS `*`,`MDR1`.`FOF`.`mass` AS `MDR1.FOF.mass` FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY `MDR1`.`FOF`.`mass` DESC  LIMIT 0,10', 'aggregation_tmp_20520253');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`,`MDR1.FOF.mass`
FROM `aggregation_tmp_20520253`  ORDER BY `MDR1.FOF.mass` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_20520253');
This is the query plan optimisation output for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY MDR1.FOF.mass desc LIMIT 10

-- INPUT SQL:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY MDR1.FOF.mass desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`*`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT * AS `*`
FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY `MDR1`.`FOF`.`mass` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `*`
FROM `aggregation_tmp_84331688`  ORDER BY `MDR1.FOF.mass` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`*`=VALUES(`*`)
This is the query plan for the query:
SELECT * FROM MDR1.FOF WHERE snapnum=85 ORDER BY MDR1.FOF.mass desc LIMIT 10

CALL paquExec('SELECT * AS `*` FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY `MDR1`.`FOF`.`mass` DESC  LIMIT 0,10', 'aggregation_tmp_84331688');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `*`
FROM `aggregation_tmp_84331688`  ORDER BY `MDR1.FOF.mass` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_84331688');
This is the query plan optimisation output for the query:
SELECT h.snapnum FROM (SELECT snapnum, expz FROM MDR1.FOF WHERE snapnum=85 LIMIT 10) as h ORDER BY h.expz ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`snapnum`,`expz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`snapnum`=VALUES(`snapnum`),
`expz`=VALUES(`expz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT snapnum AS `snapnum`,expz AS `expz`
FROM MDR1.FOF WHERE ( `snapnum` = 85 )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `snapnum`,`expz`
FROM `aggregation_tmp_33732860`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`snapnum`=VALUES(`snapnum`),
`expz`=VALUES(`expz`)
-- INPUT SQL:
SELECT h.snapnum FROM (SELECT snapnum, expz FROM MDR1.FOF WHERE snapnum=85 LIMIT 10) as h ORDER BY h.expz ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`h.snapnum`,`h.expz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`h.snapnum`=VALUES(`h.snapnum`),
`h.expz`=VALUES(`h.expz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `h`.`snapnum` AS `h.snapnum`,`h`.`expz` AS `h.expz`
FROM ( SELECT `snapnum`,`expz`
FROM `aggregation_tmp_33732860`    LIMIT 0,10) AS `h` 
)


-- AGGREGATION SQL:
SELECT `h.snapnum`,`h.expz`
FROM `aggregation_tmp_1758943`  ORDER BY `h.expz` ASC 
ON DUPLICATE KEY UPDATE
`h.snapnum`=VALUES(`h.snapnum`),
`h.expz`=VALUES(`h.expz`)
This is the query plan for the query:
SELECT h.snapnum FROM (SELECT snapnum, expz FROM MDR1.FOF WHERE snapnum=85 LIMIT 10) as h ORDER BY h.expz ASC

CALL paquExec('SELECT snapnum AS `snapnum`,expz AS `expz` FROM MDR1.FOF WHERE ( `snapnum` = 85 )    LIMIT 0,10', 'aggregation_tmp_33732860');
CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_1758943 ENGINE=MyISAM SELECT `h`.`snapnum` AS `h.snapnum`,`h`.`expz` AS `h.expz`
FROM ( SELECT `snapnum`,`expz`
FROM `aggregation_tmp_33732860`    LIMIT 0,10) AS `h`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_1758943 SELECT `h`.`snapnum` AS `h.snapnum`,`h`.`expz` AS `h.expz`
FROM ( SELECT `snapnum`,`expz`
FROM `aggregation_tmp_33732860`    LIMIT 0,10) AS `h` ;
CALL paquLinkTmp('aggregation_tmp_1758943');
CALL paquDropTmp('aggregation_tmp_33732860');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `h.snapnum`,`h.expz`
FROM `aggregation_tmp_1758943`  ORDER BY `h.expz` ASC ;
CALL paquDropTmp('aggregation_tmp_1758943');
This is the query plan optimisation output for the query:
SELECT snapnum as `snappi` FROM MDR1.FOF WHERE snapnum=85 ORDER BY `snappi` desc LIMIT 10

-- INPUT SQL:
SELECT snapnum as `snappi` FROM MDR1.FOF WHERE snapnum=85 ORDER BY `snappi` desc LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`snappi`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`snappi`=VALUES(`snappi`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT snapnum AS `snappi`
FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY `snappi` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `snappi`
FROM `aggregation_tmp_65148683`  ORDER BY `snappi` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`snappi`=VALUES(`snappi`)
This is the query plan for the query:
SELECT snapnum as `snappi` FROM MDR1.FOF WHERE snapnum=85 ORDER BY `snappi` desc LIMIT 10

CALL paquExec('SELECT snapnum AS `snappi` FROM MDR1.FOF WHERE ( `snapnum` = 85 )  ORDER BY `snappi` DESC  LIMIT 0,10', 'aggregation_tmp_65148683');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `snappi`
FROM `aggregation_tmp_65148683`  ORDER BY `snappi` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_65148683');
This is the query plan optimisation output for the query:
SELECT t1.name, t2.salary FROM employee t1 INNER JOIN info t2 ON t1.name = t2.name

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t2.salary`,`t2.`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t2.salary`=VALUES(`t2.salary`),
`t2.`=VALUES(`t2.`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t2.salary AS `t2.salary`,t2. AS `t2.`
FROM info AS `t2` 
)


-- AGGREGATION SQL:
SELECT `t2.salary`,`t2.`
FROM `aggregation_tmp_78096644`   
ON DUPLICATE KEY UPDATE
`t2.salary`=VALUES(`t2.salary`),
`t2.`=VALUES(`t2.`)
-- INPUT SQL:
SELECT t1.name, t2.salary FROM employee t1 INNER JOIN info t2 ON t1.name = t2.name

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1.name`,`t2.salary`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1.name`=VALUES(`t1.name`),
`t2.salary`=VALUES(`t2.salary`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1.name AS `t1.name`,`t2`.`t2.salary` AS `t2.salary`
FROM employee AS `t1` JOIN ( SELECT `t2.salary`,`t2.`
FROM `aggregation_tmp_78096644`   ) AS `t2`  
)


-- AGGREGATION SQL:
SELECT `t1.name`,`t2.salary`
FROM `aggregation_tmp_61842458`   
ON DUPLICATE KEY UPDATE
`t1.name`=VALUES(`t1.name`),
`t2.salary`=VALUES(`t2.salary`)
This is the query plan for the query:
SELECT t1.name, t2.salary FROM employee t1 INNER JOIN info t2 ON t1.name = t2.name

CALL paquExec('SELECT t2.salary AS `t2.salary`,t2. AS `t2.` FROM info AS `t2` ', 'aggregation_tmp_78096644');
CALL paquExec('SELECT t1.name AS `t1.name`,`t2`.`t2.salary` AS `t2.salary` FROM employee AS `t1` JOIN ( SELECT `t2.salary`,`t2.` FROM `aggregation_tmp_78096644`   ) AS `t2`  ', 'aggregation_tmp_61842458');
CALL paquDropTmp('aggregation_tmp_78096644');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `t1.name`,`t2.salary`
FROM `aggregation_tmp_61842458`   ;
CALL paquDropTmp('aggregation_tmp_61842458');
This is the query plan optimisation output for the query:
SELECT t1.name, t2.salary FROM employee t1 INNER JOIN info t2 ON t1.name = t2.name

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t2.salary`,`t1`.`name`,`t2`.`name`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t2.salary`=VALUES(`t2.salary`),
`t1`.`name`=VALUES(`t1`.`name`),
`t2`.`name`=VALUES(`t2`.`name`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t2.salary AS `t2.salary`,t1.name AS `t1`.`name`,t2.name AS `t2`.`name`
FROM info AS `t2` 
)


-- AGGREGATION SQL:
SELECT `t2.salary`,`t1`.`name`,`t2`.`name`
FROM `aggregation_tmp_30397489`   
ON DUPLICATE KEY UPDATE
`t2.salary`=VALUES(`t2.salary`),
`t1`.`name`=VALUES(`t1`.`name`),
`t2`.`name`=VALUES(`t2`.`name`)
-- INPUT SQL:
SELECT t1.name, t2.salary FROM employee t1 INNER JOIN info t2 ON t1.name = t2.name

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1.name`,`t2.salary`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1.name`=VALUES(`t1.name`),
`t2.salary`=VALUES(`t2.salary`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1.name AS `t1.name`,`t2`.`t2.salary` AS `t2.salary`
FROM employee AS `t1` JOIN ( SELECT `t2.salary`,`t1`.`name`,`t2`.`name`
FROM `aggregation_tmp_30397489`   ) AS `t2`  
)


-- AGGREGATION SQL:
SELECT `t1.name`,`t2.salary`
FROM `aggregation_tmp_78742581`   
ON DUPLICATE KEY UPDATE
`t1.name`=VALUES(`t1.name`),
`t2.salary`=VALUES(`t2.salary`)
This is the query plan for the query:
SELECT t1.name, t2.salary FROM employee t1 INNER JOIN info t2 ON t1.name = t2.name

CALL paquExec('SELECT t2.salary AS `t2.salary`,t1.name AS `t1`.`name`,t2.name AS `t2`.`name` FROM info AS `t2` ', 'aggregation_tmp_30397489');
CALL paquExec('SELECT t1.name AS `t1.name`,`t2`.`t2.salary` AS `t2.salary` FROM employee AS `t1` JOIN ( SELECT `t2.salary`,`t1`.`name`,`t2`.`name` FROM `aggregation_tmp_30397489`   ) AS `t2`  ', 'aggregation_tmp_78742581');
CALL paquDropTmp('aggregation_tmp_30397489');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `t1.name`,`t2.salary`
FROM `aggregation_tmp_78742581`   ;
CALL paquDropTmp('aggregation_tmp_78742581');
This is the query plan optimisation output for the query:
SELECT t1.name, t2.salary FROM employee t1 INNER JOIN info t2 ON t1.name = t2.name

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t2.salary`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t2.salary`=VALUES(`t2.salary`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t2.salary AS `t2.salary`
FROM info AS `t2` 
)


-- AGGREGATION SQL:
SELECT `t2.salary`
FROM `aggregation_tmp_39544950`   
ON DUPLICATE KEY UPDATE
`t2.salary`=VALUES(`t2.salary`)
-- INPUT SQL:
SELECT t1.name, t2.salary FROM employee t1 INNER JOIN info t2 ON t1.name = t2.name

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1.name`,`t2.salary`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1.name`=VALUES(`t1.name`),
`t2.salary`=VALUES(`t2.salary`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1.name AS `t1.name`,`t2`.`t2.salary` AS `t2.salary`
FROM employee AS `t1` JOIN ( SELECT `t2.salary`
FROM `aggregation_tmp_39544950`   ) AS `t2`  
)


-- AGGREGATION SQL:
SELECT `t1.name`,`t2.salary`
FROM `aggregation_tmp_76586640`   
ON DUPLICATE KEY UPDATE
`t1.name`=VALUES(`t1.name`),
`t2.salary`=VALUES(`t2.salary`)
This is the query plan for the query:
SELECT t1.name, t2.salary FROM employee t1 INNER JOIN info t2 ON t1.name = t2.name

CALL paquExec('SELECT t2.salary AS `t2.salary` FROM info AS `t2` ', 'aggregation_tmp_39544950');
CALL paquExec('SELECT t1.name AS `t1.name`,`t2`.`t2.salary` AS `t2.salary` FROM employee AS `t1` JOIN ( SELECT `t2.salary` FROM `aggregation_tmp_39544950`   ) AS `t2`  ', 'aggregation_tmp_76586640');
CALL paquDropTmp('aggregation_tmp_39544950');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `t1.name`,`t2.salary`
FROM `aggregation_tmp_76586640`   ;
CALL paquDropTmp('aggregation_tmp_76586640');
This is the query plan optimisation output for the query:
SELECT t1.name, t2.salary FROM employee t1 INNER JOIN info t2 ON t1.name = t2.name

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t2.salary`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t2.salary`=VALUES(`t2.salary`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t2.salary AS `t2.salary`
FROM info AS `t2` 
)


-- AGGREGATION SQL:
SELECT `t2.salary`
FROM `aggregation_tmp_87000757`   
ON DUPLICATE KEY UPDATE
`t2.salary`=VALUES(`t2.salary`)
-- INPUT SQL:
SELECT t1.name, t2.salary FROM employee t1 INNER JOIN info t2 ON t1.name = t2.name

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1.name`,`t2.salary`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1.name`=VALUES(`t1.name`),
`t2.salary`=VALUES(`t2.salary`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1.name AS `t1.name`,`t2`.`t2.salary` AS `t2.salary`
FROM employee AS `t1` JOIN ( SELECT `t2.salary`
FROM `aggregation_tmp_87000757`   ) AS `t2`  
)


-- AGGREGATION SQL:
SELECT `t1.name`,`t2.salary`
FROM `aggregation_tmp_95319107`   
ON DUPLICATE KEY UPDATE
`t1.name`=VALUES(`t1.name`),
`t2.salary`=VALUES(`t2.salary`)
This is the query plan for the query:
SELECT t1.name, t2.salary FROM employee t1 INNER JOIN info t2 ON t1.name = t2.name

CALL paquExec('SELECT t2.salary AS `t2.salary` FROM info AS `t2` ', 'aggregation_tmp_87000757');
CALL paquExec('SELECT t1.name AS `t1.name`,`t2`.`t2.salary` AS `t2.salary` FROM employee AS `t1` JOIN ( SELECT `t2.salary` FROM `aggregation_tmp_87000757`   ) AS `t2`  ', 'aggregation_tmp_95319107');
CALL paquDropTmp('aggregation_tmp_87000757');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `t1.name`,`t2.salary`
FROM `aggregation_tmp_95319107`   ;
CALL paquDropTmp('aggregation_tmp_95319107');
This is the query plan optimisation output for the query:
SELECT t1.name, t2.salary FROM employee t1 INNER JOIN info t2 ON t1.name = t2.name

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t2.salary`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t2.salary`=VALUES(`t2.salary`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t2.salary AS `t2.salary`
FROM info AS `t2` 
)


-- AGGREGATION SQL:
SELECT `t2.salary`
FROM `aggregation_tmp_36892932`   
ON DUPLICATE KEY UPDATE
`t2.salary`=VALUES(`t2.salary`)
-- INPUT SQL:
SELECT t1.name, t2.salary FROM employee t1 INNER JOIN info t2 ON t1.name = t2.name

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1.name`,`t2.salary`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1.name`=VALUES(`t1.name`),
`t2.salary`=VALUES(`t2.salary`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1.name AS `t1.name`,`t2`.`t2.salary` AS `t2.salary`
FROM employee AS `t1` JOIN ( SELECT `t2.salary`
FROM `aggregation_tmp_36892932`   ) AS `t2`  
)


-- AGGREGATION SQL:
SELECT `t1.name`,`t2.salary`
FROM `aggregation_tmp_53239589`   
ON DUPLICATE KEY UPDATE
`t1.name`=VALUES(`t1.name`),
`t2.salary`=VALUES(`t2.salary`)
This is the query plan for the query:
SELECT t1.name, t2.salary FROM employee t1 INNER JOIN info t2 ON t1.name = t2.name

CALL paquExec('SELECT t2.salary AS `t2.salary` FROM info AS `t2` ', 'aggregation_tmp_36892932');
CALL paquExec('SELECT t1.name AS `t1.name`,`t2`.`t2.salary` AS `t2.salary` FROM employee AS `t1` JOIN ( SELECT `t2.salary` FROM `aggregation_tmp_36892932`   ) AS `t2`  ', 'aggregation_tmp_53239589');
CALL paquDropTmp('aggregation_tmp_36892932');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `t1.name`,`t2.salary`
FROM `aggregation_tmp_53239589`   ;
CALL paquDropTmp('aggregation_tmp_53239589');
This is the query plan optimisation output for the query:
SELECT t1.name, t2.salary FROM employee t1 INNER JOIN info t2 ON t1.name = t2.name

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t2.salary`,`t2`.`name`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t2.salary`=VALUES(`t2.salary`),
`t2`.`name`=VALUES(`t2`.`name`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t2.salary AS `t2.salary`,t2.name AS `t2`.`name`
FROM info AS `t2` 
)


-- AGGREGATION SQL:
SELECT `t2.salary`,`t2`.`name`
FROM `aggregation_tmp_49798099`   
ON DUPLICATE KEY UPDATE
`t2.salary`=VALUES(`t2.salary`),
`t2`.`name`=VALUES(`t2`.`name`)
-- INPUT SQL:
SELECT t1.name, t2.salary FROM employee t1 INNER JOIN info t2 ON t1.name = t2.name

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1.name`,`t2.salary`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1.name`=VALUES(`t1.name`),
`t2.salary`=VALUES(`t2.salary`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1.name AS `t1.name`,`t2`.`t2.salary` AS `t2.salary`
FROM employee AS `t1` JOIN ( SELECT `t2.salary`,`t2`.`name`
FROM `aggregation_tmp_49798099`   ) AS `t2`  
)


-- AGGREGATION SQL:
SELECT `t1.name`,`t2.salary`
FROM `aggregation_tmp_37704697`   
ON DUPLICATE KEY UPDATE
`t1.name`=VALUES(`t1.name`),
`t2.salary`=VALUES(`t2.salary`)
This is the query plan for the query:
SELECT t1.name, t2.salary FROM employee t1 INNER JOIN info t2 ON t1.name = t2.name

CALL paquExec('SELECT t2.salary AS `t2.salary`,t2.name AS `t2`.`name` FROM info AS `t2` ', 'aggregation_tmp_49798099');
CALL paquExec('SELECT t1.name AS `t1.name`,`t2`.`t2.salary` AS `t2.salary` FROM employee AS `t1` JOIN ( SELECT `t2.salary`,`t2`.`name` FROM `aggregation_tmp_49798099`   ) AS `t2`  ', 'aggregation_tmp_37704697');
CALL paquDropTmp('aggregation_tmp_49798099');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `t1.name`,`t2.salary`
FROM `aggregation_tmp_37704697`   ;
CALL paquDropTmp('aggregation_tmp_37704697');
This is the query plan optimisation output for the query:
SELECT t1.name, t2.salary FROM employee t1 INNER JOIN info t2 ON t1.name = t2.name

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t2.salary`,`t2`.`name`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t2.salary`=VALUES(`t2.salary`),
`t2`.`name`=VALUES(`t2`.`name`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t2.salary AS `t2.salary`,t2.name AS `t2`.`name`
FROM info AS `t2` 
)


-- AGGREGATION SQL:
SELECT `t2.salary`,`t2`.`name`
FROM `aggregation_tmp_16581810`   
ON DUPLICATE KEY UPDATE
`t2.salary`=VALUES(`t2.salary`),
`t2`.`name`=VALUES(`t2`.`name`)
-- INPUT SQL:
SELECT t1.name, t2.salary FROM employee t1 INNER JOIN info t2 ON t1.name = t2.name

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1.name`,`t2.salary`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1.name`=VALUES(`t1.name`),
`t2.salary`=VALUES(`t2.salary`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1.name AS `t1.name`,`t2`.`t2.salary` AS `t2.salary`
FROM employee AS `t1` JOIN ( SELECT `t2.salary`,`t2`.`name`
FROM `aggregation_tmp_16581810`   ) AS `t2`  
)


-- AGGREGATION SQL:
SELECT `t1.name`,`t2.salary`
FROM `aggregation_tmp_19247940`   
ON DUPLICATE KEY UPDATE
`t1.name`=VALUES(`t1.name`),
`t2.salary`=VALUES(`t2.salary`)
This is the query plan for the query:
SELECT t1.name, t2.salary FROM employee t1 INNER JOIN info t2 ON t1.name = t2.name

CALL paquExec('SELECT t2.salary AS `t2.salary`,t2.name AS `t2`.`name` FROM info AS `t2` ', 'aggregation_tmp_16581810');
CALL paquExec('SELECT t1.name AS `t1.name`,`t2`.`t2.salary` AS `t2.salary` FROM employee AS `t1` JOIN ( SELECT `t2.salary`,`t2`.`name` FROM `aggregation_tmp_16581810`   ) AS `t2`  ', 'aggregation_tmp_19247940');
CALL paquDropTmp('aggregation_tmp_16581810');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `t1.name`,`t2.salary`
FROM `aggregation_tmp_19247940`   ;
CALL paquDropTmp('aggregation_tmp_19247940');
This is the query plan optimisation output for the query:
SELECT t1.name, t2.salary FROM employee t1 INNER JOIN info t2 ON t1.nameId = t2.nameId

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t2.salary`,`t2`.`nameId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t2.salary`=VALUES(`t2.salary`),
`t2`.`nameId`=VALUES(`t2`.`nameId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t2.salary AS `t2.salary`,t2.nameId AS `t2`.`nameId`
FROM info AS `t2` 
)


-- AGGREGATION SQL:
SELECT `t2.salary`,`t2`.`nameId`
FROM `aggregation_tmp_71400552`   
ON DUPLICATE KEY UPDATE
`t2.salary`=VALUES(`t2.salary`),
`t2`.`nameId`=VALUES(`t2`.`nameId`)
-- INPUT SQL:
SELECT t1.name, t2.salary FROM employee t1 INNER JOIN info t2 ON t1.nameId = t2.nameId

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1.name`,`t2.salary`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1.name`=VALUES(`t1.name`),
`t2.salary`=VALUES(`t2.salary`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1.name AS `t1.name`,`t2`.`t2.salary` AS `t2.salary`
FROM employee AS `t1` JOIN ( SELECT `t2.salary`,`t2`.`nameId`
FROM `aggregation_tmp_71400552`   ) AS `t2`  
)


-- AGGREGATION SQL:
SELECT `t1.name`,`t2.salary`
FROM `aggregation_tmp_35590247`   
ON DUPLICATE KEY UPDATE
`t1.name`=VALUES(`t1.name`),
`t2.salary`=VALUES(`t2.salary`)
This is the query plan for the query:
SELECT t1.name, t2.salary FROM employee t1 INNER JOIN info t2 ON t1.nameId = t2.nameId

CALL paquExec('SELECT t2.salary AS `t2.salary`,t2.nameId AS `t2`.`nameId` FROM info AS `t2` ', 'aggregation_tmp_71400552');
CALL paquExec('SELECT t1.name AS `t1.name`,`t2`.`t2.salary` AS `t2.salary` FROM employee AS `t1` JOIN ( SELECT `t2.salary`,`t2`.`nameId` FROM `aggregation_tmp_71400552`   ) AS `t2`  ', 'aggregation_tmp_35590247');
CALL paquDropTmp('aggregation_tmp_71400552');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `t1.name`,`t2.salary`
FROM `aggregation_tmp_35590247`   ;
CALL paquDropTmp('aggregation_tmp_35590247');
This is the query plan optimisation output for the query:
SELECT b.x,b.y,b.z,b.phkey FROM MDPL.BDMW b WHERE b.snapnum=88 ORDER BY b.Mvir DESC LIMIT 10

-- INPUT SQL:
SELECT b.x,b.y,b.z,b.phkey FROM MDPL.BDMW b WHERE b.snapnum=88 ORDER BY b.Mvir DESC LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`b.phkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,`b`.`Mvir` AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 )  ORDER BY `b`.`Mvir` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`b.phkey`,`b.Mvir`
FROM `aggregation_tmp_52835147`  ORDER BY `b.Mvir` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`b.Mvir`=VALUES(`b.Mvir`)
This is the query plan for the query:
SELECT b.x,b.y,b.z,b.phkey FROM MDPL.BDMW b WHERE b.snapnum=88 ORDER BY b.Mvir DESC LIMIT 10

CALL paquExec('SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,`b`.`Mvir` AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 )  ORDER BY `b`.`Mvir` DESC  LIMIT 0,10', 'aggregation_tmp_52835147');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `b.x`,`b.y`,`b.z`,`b.phkey`,`b.Mvir`
FROM `aggregation_tmp_52835147`  ORDER BY `b.Mvir` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_52835147');
This is the query plan optimisation output for the query:
SELECT b.x,b.y,b.z,b.phkey FROM MDPL.BDMW b WHERE b.snapnum=88 ORDER BY b.Mvir DESC LIMIT 10

-- INPUT SQL:
SELECT b.x,b.y,b.z,b.phkey FROM MDPL.BDMW b WHERE b.snapnum=88 ORDER BY b.Mvir DESC LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`b.phkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,`b`.`Mvir` AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 )  ORDER BY `b`.`Mvir` DESC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`b.phkey`,`b.Mvir`
FROM `aggregation_tmp_66962284`  ORDER BY `b.Mvir` DESC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`b.Mvir`=VALUES(`b.Mvir`)
This is the query plan for the query:
SELECT b.x,b.y,b.z,b.phkey FROM MDPL.BDMW b WHERE b.snapnum=88 ORDER BY b.Mvir DESC LIMIT 10

CALL paquExec('SELECT b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,`b`.`Mvir` AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 )  ORDER BY `b`.`Mvir` DESC  LIMIT 0,10', 'aggregation_tmp_66962284');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `b.x`,`b.y`,`b.z`,`b.phkey`,`b.Mvir`
FROM `aggregation_tmp_66962284`  ORDER BY `b.Mvir` DESC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_66962284');
This is the query plan optimisation output for the query:
SELECT b.bdmId, b.snapnum, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir 1.e14 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.bdmId`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.bdmId`=VALUES(`b.bdmId`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.bdmId AS `b.bdmId`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,b.Mvir AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` 1.e14 )   
)


-- AGGREGATION SQL:
SELECT `b.bdmId`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`b.Mvir`
FROM `aggregation_tmp_30920918`   
ON DUPLICATE KEY UPDATE
`b.bdmId`=VALUES(`b.bdmId`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`b.Mvir`=VALUES(`b.Mvir`)
-- INPUT SQL:
SELECT b.bdmId, b.snapnum, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir 1.e14 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`r.zred`,`xyzphkey`,`b.bdmId`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`r.zred`=VALUES(`r.zred`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.bdmId`=VALUES(`b.bdmId`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT r.zred AS `r.zred`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,`b`.`b.bdmId` AS `b.bdmId`,`b`.`b.snapnum` AS `b.snapnum`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT `b.bdmId`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`b.Mvir`
FROM `aggregation_tmp_30920918`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `r.zred`,`xyzphkey`,`b.bdmId`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`
FROM `aggregation_tmp_96511644`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`r.zred`=VALUES(`r.zred`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.bdmId`=VALUES(`b.bdmId`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`)
This is the query plan for the query:
SELECT b.bdmId, b.snapnum, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir 1.e14 LIMIT 10

CALL paquExec('SELECT b.bdmId AS `b.bdmId`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,b.Mvir AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` 1.e14 )   ', 'aggregation_tmp_30920918');
CALL paquExec('SELECT r.zred AS `r.zred`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,`b`.`b.bdmId` AS `b.bdmId`,`b`.`b.snapnum` AS `b.snapnum`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT `b.bdmId`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`b.Mvir` FROM `aggregation_tmp_30920918`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10', 'aggregation_tmp_96511644');
CALL paquDropTmp('aggregation_tmp_30920918');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `r.zred`,`xyzphkey`,`b.bdmId`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`
FROM `aggregation_tmp_96511644`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_96511644');
This is the query plan optimisation output for the query:
SELECT b.bdmId, b.snapnum, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir 1.e14 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.bdmId`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.bdmId`=VALUES(`b.bdmId`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.bdmId AS `b.bdmId`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,b.Mvir AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` 1.e14 )   
)


-- AGGREGATION SQL:
SELECT `b.bdmId`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`b.Mvir`
FROM `aggregation_tmp_72154434`   
ON DUPLICATE KEY UPDATE
`b.bdmId`=VALUES(`b.bdmId`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`b.Mvir`=VALUES(`b.Mvir`)
-- INPUT SQL:
SELECT b.bdmId, b.snapnum, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir 1.e14 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`r.zred`,`xyzphkey`,`b.bdmId`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`r.zred`=VALUES(`r.zred`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.bdmId`=VALUES(`b.bdmId`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT r.zred AS `r.zred`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,`b`.`b.bdmId` AS `b.bdmId`,`b`.`b.snapnum` AS `b.snapnum`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT `b.bdmId`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`b.Mvir`
FROM `aggregation_tmp_72154434`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `r.zred`,`xyzphkey`,`b.bdmId`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`
FROM `aggregation_tmp_49808940`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`r.zred`=VALUES(`r.zred`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.bdmId`=VALUES(`b.bdmId`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`)
This is the query plan for the query:
SELECT b.bdmId, b.snapnum, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir 1.e14 LIMIT 10

CALL paquExec('SELECT b.bdmId AS `b.bdmId`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,b.Mvir AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` 1.e14 )   ', 'aggregation_tmp_72154434');
CALL paquExec('SELECT r.zred AS `r.zred`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,`b`.`b.bdmId` AS `b.bdmId`,`b`.`b.snapnum` AS `b.snapnum`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT `b.bdmId`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`b.Mvir` FROM `aggregation_tmp_72154434`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10', 'aggregation_tmp_49808940');
CALL paquDropTmp('aggregation_tmp_72154434');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `r.zred`,`xyzphkey`,`b.bdmId`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`
FROM `aggregation_tmp_49808940`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_49808940');
This is the query plan optimisation output for the query:
SELECT b.bdmId, b.snapnum, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir 1.e14 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.bdmId`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.bdmId`=VALUES(`b.bdmId`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.bdmId AS `b.bdmId`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,b.Mvir AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` 1.e14 )   
)


-- AGGREGATION SQL:
SELECT `b.bdmId`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`b.Mvir`
FROM `aggregation_tmp_32024467`   
ON DUPLICATE KEY UPDATE
`b.bdmId`=VALUES(`b.bdmId`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`b.Mvir`=VALUES(`b.Mvir`)
-- INPUT SQL:
SELECT b.bdmId, b.snapnum, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir 1.e14 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`r.zred`,`xyzphkey`,`b.bdmId`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`r.zred`=VALUES(`r.zred`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.bdmId`=VALUES(`b.bdmId`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT r.zred AS `r.zred`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,`b`.`b.bdmId` AS `b.bdmId`,`b`.`b.snapnum` AS `b.snapnum`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT `b.bdmId`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`b.Mvir`
FROM `aggregation_tmp_32024467`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `r.zred`,`xyzphkey`,`b.bdmId`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`
FROM `aggregation_tmp_90471271`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`r.zred`=VALUES(`r.zred`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.bdmId`=VALUES(`b.bdmId`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`)
This is the query plan for the query:
SELECT b.bdmId, b.snapnum, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir 1.e14 LIMIT 10

CALL paquExec('SELECT b.bdmId AS `b.bdmId`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,b.Mvir AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` 1.e14 )   ', 'aggregation_tmp_32024467');
CALL paquExec('SELECT r.zred AS `r.zred`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,`b`.`b.bdmId` AS `b.bdmId`,`b`.`b.snapnum` AS `b.snapnum`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT `b.bdmId`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`b.Mvir` FROM `aggregation_tmp_32024467`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10', 'aggregation_tmp_90471271');
CALL paquDropTmp('aggregation_tmp_32024467');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `r.zred`,`xyzphkey`,`b.bdmId`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`
FROM `aggregation_tmp_90471271`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_90471271');
This is the query plan optimisation output for the query:
SELECT b.bdmId, b.snapnum, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir 1.e14 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.bdmId`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.bdmId`=VALUES(`b.bdmId`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.bdmId AS `b.bdmId`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,b.Mvir AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` 1.e14 )   
)


-- AGGREGATION SQL:
SELECT `b.bdmId`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`b.Mvir`
FROM `aggregation_tmp_66820131`   
ON DUPLICATE KEY UPDATE
`b.bdmId`=VALUES(`b.bdmId`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`b.Mvir`=VALUES(`b.Mvir`)
-- INPUT SQL:
SELECT b.bdmId, b.snapnum, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir 1.e14 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`r.zred`,`xyzphkey`,`b.bdmId`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`r.zred`=VALUES(`r.zred`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.bdmId`=VALUES(`b.bdmId`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT r.zred AS `r.zred`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,`b`.`b.bdmId` AS `b.bdmId`,`b`.`b.snapnum` AS `b.snapnum`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT `b.bdmId`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`b.Mvir`
FROM `aggregation_tmp_66820131`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `r.zred`,`xyzphkey`,`b.bdmId`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`
FROM `aggregation_tmp_54903720`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`r.zred`=VALUES(`r.zred`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.bdmId`=VALUES(`b.bdmId`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`)
This is the query plan for the query:
SELECT b.bdmId, b.snapnum, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir 1.e14 LIMIT 10

CALL paquExec('SELECT b.bdmId AS `b.bdmId`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,b.Mvir AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` 1.e14 )   ', 'aggregation_tmp_66820131');
CALL paquExec('SELECT r.zred AS `r.zred`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,`b`.`b.bdmId` AS `b.bdmId`,`b`.`b.snapnum` AS `b.snapnum`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT `b.bdmId`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`b.Mvir` FROM `aggregation_tmp_66820131`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10', 'aggregation_tmp_54903720');
CALL paquDropTmp('aggregation_tmp_66820131');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `r.zred`,`xyzphkey`,`b.bdmId`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`
FROM `aggregation_tmp_54903720`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_54903720');
This is the query plan optimisation output for the query:
SELECT b.bdmId, b.snapnum, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir 1.e14 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.bdmId`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.bdmId`=VALUES(`b.bdmId`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.bdmId AS `b.bdmId`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,b.Mvir AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` 1.e14 )   
)


-- AGGREGATION SQL:
SELECT `b.bdmId`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`b.Mvir`
FROM `aggregation_tmp_686801`   
ON DUPLICATE KEY UPDATE
`b.bdmId`=VALUES(`b.bdmId`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`b.Mvir`=VALUES(`b.Mvir`)
-- INPUT SQL:
SELECT b.bdmId, b.snapnum, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir 1.e14 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`r.zred`,`xyzphkey`,`b.bdmId`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`r.zred`=VALUES(`r.zred`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.bdmId`=VALUES(`b.bdmId`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT r.zred AS `r.zred`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,`b`.`b.bdmId` AS `b.bdmId`,`b`.`b.snapnum` AS `b.snapnum`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT `b.bdmId`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`b.Mvir`
FROM `aggregation_tmp_686801`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `r.zred`,`xyzphkey`,`b.bdmId`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`
FROM `aggregation_tmp_90858460`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`r.zred`=VALUES(`r.zred`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.bdmId`=VALUES(`b.bdmId`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`)
This is the query plan for the query:
SELECT b.bdmId, b.snapnum, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir 1.e14 LIMIT 10

CALL paquExec('SELECT b.bdmId AS `b.bdmId`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,b.Mvir AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` 1.e14 )   ', 'aggregation_tmp_686801');
CALL paquExec('SELECT r.zred AS `r.zred`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,`b`.`b.bdmId` AS `b.bdmId`,`b`.`b.snapnum` AS `b.snapnum`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT `b.bdmId`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`b.Mvir` FROM `aggregation_tmp_686801`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10', 'aggregation_tmp_90858460');
CALL paquDropTmp('aggregation_tmp_686801');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `r.zred`,`xyzphkey`,`b.bdmId`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`
FROM `aggregation_tmp_90858460`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_90858460');
This is the query plan optimisation output for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
``,`b.x`,`b.y`,`b.z`,`b.phkey`,`b.snapnum`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
``=VALUES(``),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0 + b.bdmId AS ``,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,b.snapnum AS `b.snapnum`,b.Mvir AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   
)


-- AGGREGATION SQL:
SELECT ``,`b.x`,`b.y`,`b.z`,`b.phkey`,`b.snapnum`,`b.Mvir`
FROM `aggregation_tmp_88490532`   
ON DUPLICATE KEY UPDATE
``=VALUES(``),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.Mvir`=VALUES(`b.Mvir`)
-- INPUT SQL:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_b__snapnum_/_r__zred_`,`r.zred`,`xyzphkey`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`xyzphkey`=VALUES(`xyzphkey`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.snapnum / r.zred AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,2.0 + `b`.`bdmId` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT ``,`b.x`,`b.y`,`b.z`,`b.phkey`,`b.snapnum`,`b.Mvir`
FROM `aggregation_tmp_88490532`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`xyzphkey`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`
FROM `aggregation_tmp_80263359`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`xyzphkey`=VALUES(`xyzphkey`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`)
This is the query plan for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

CALL paquExec('SELECT 2.0 + b.bdmId AS ``,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,b.snapnum AS `b.snapnum`,b.Mvir AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   ', 'aggregation_tmp_88490532');
CALL paquExec('SELECT b.snapnum / r.zred AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,2.0 + `b`.`bdmId` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT ``,`b.x`,`b.y`,`b.z`,`b.phkey`,`b.snapnum`,`b.Mvir` FROM `aggregation_tmp_88490532`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10', 'aggregation_tmp_80263359');
CALL paquDropTmp('aggregation_tmp_88490532');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`xyzphkey`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`
FROM `aggregation_tmp_80263359`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_80263359');
This is the query plan optimisation output for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
``,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
``=VALUES(``),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0 + b.bdmId AS ``,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   
)


-- AGGREGATION SQL:
SELECT ``,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_8703763`   
ON DUPLICATE KEY UPDATE
``=VALUES(``),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)
-- INPUT SQL:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`r.zred`,`r.zred`,`_b__snapnum_/_r__zred_`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`r.zred`=VALUES(`r.zred`),
`r.zred`=VALUES(`r.zred`),
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT r.zred AS `r.zred`,r.zred AS `r.zred`,b.snapnum / r.zred AS `_b__snapnum_/_r__zred_`,2.0 + `b`.`bdmId` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT ``,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_8703763`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `r.zred`,`r.zred`,`_b__snapnum_/_r__zred_`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_19715111`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`r.zred`=VALUES(`r.zred`),
`r.zred`=VALUES(`r.zred`),
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)
This is the query plan for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

CALL paquExec('SELECT 2.0 + b.bdmId AS ``,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   ', 'aggregation_tmp_8703763');
CALL paquExec('SELECT r.zred AS `r.zred`,r.zred AS `r.zred`,b.snapnum / r.zred AS `_b__snapnum_/_r__zred_`,2.0 + `b`.`bdmId` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT ``,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir` FROM `aggregation_tmp_8703763`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10', 'aggregation_tmp_19715111');
CALL paquDropTmp('aggregation_tmp_8703763');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `r.zred`,`r.zred`,`_b__snapnum_/_r__zred_`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_19715111`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_19715111');
This is the query plan optimisation output for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
``,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
``=VALUES(``),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0 + b.bdmId AS ``,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   
)


-- AGGREGATION SQL:
SELECT ``,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_18021256`   
ON DUPLICATE KEY UPDATE
``=VALUES(``),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)
-- INPUT SQL:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`r.zred`,`r.zred`,`_b__snapnum_/_r__zred_`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`r.zred`=VALUES(`r.zred`),
`r.zred`=VALUES(`r.zred`),
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT r.zred AS `r.zred`,r.zred AS `r.zred`,b.snapnum / r.zred AS `_b__snapnum_/_r__zred_`,2.0 + `b`.`bdmId` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT ``,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_18021256`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `r.zred`,`r.zred`,`_b__snapnum_/_r__zred_`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_580608`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`r.zred`=VALUES(`r.zred`),
`r.zred`=VALUES(`r.zred`),
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)
This is the query plan for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

CALL paquExec('SELECT 2.0 + b.bdmId AS ``,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   ', 'aggregation_tmp_18021256');
CALL paquExec('SELECT r.zred AS `r.zred`,r.zred AS `r.zred`,b.snapnum / r.zred AS `_b__snapnum_/_r__zred_`,2.0 + `b`.`bdmId` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT ``,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir` FROM `aggregation_tmp_18021256`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10', 'aggregation_tmp_580608');
CALL paquDropTmp('aggregation_tmp_18021256');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `r.zred`,`r.zred`,`_b__snapnum_/_r__zred_`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_580608`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_580608');
This is the query plan optimisation output for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
``,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
``=VALUES(``),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0 + b.bdmId AS ``,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   
)


-- AGGREGATION SQL:
SELECT ``,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_50941084`   
ON DUPLICATE KEY UPDATE
``=VALUES(``),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)
-- INPUT SQL:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`r.zred`,`r.zred`,`_b__snapnum_/_r__zred_`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`r.zred`=VALUES(`r.zred`),
`r.zred`=VALUES(`r.zred`),
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT r.zred AS `r.zred`,r.zred AS `r.zred`,b.snapnum / r.zred AS `_b__snapnum_/_r__zred_`,2.0 + `b`.`bdmId` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT ``,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_50941084`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `r.zred`,`r.zred`,`_b__snapnum_/_r__zred_`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_35557935`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`r.zred`=VALUES(`r.zred`),
`r.zred`=VALUES(`r.zred`),
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)
This is the query plan for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

CALL paquExec('SELECT 2.0 + b.bdmId AS ``,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   ', 'aggregation_tmp_50941084');
CALL paquExec('SELECT r.zred AS `r.zred`,r.zred AS `r.zred`,b.snapnum / r.zred AS `_b__snapnum_/_r__zred_`,2.0 + `b`.`bdmId` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT ``,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir` FROM `aggregation_tmp_50941084`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10', 'aggregation_tmp_35557935');
CALL paquDropTmp('aggregation_tmp_50941084');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `r.zred`,`r.zred`,`_b__snapnum_/_r__zred_`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_35557935`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_35557935');
This is the query plan optimisation output for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
``,`b`.`snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
``=VALUES(``),
`b`.`snapnum`=VALUES(`b`.`snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0 + b.bdmId AS ``,b.snapnum AS `b`.`snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   
)


-- AGGREGATION SQL:
SELECT ``,`b`.`snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_40247513`   
ON DUPLICATE KEY UPDATE
``=VALUES(``),
`b`.`snapnum`=VALUES(`b`.`snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)
-- INPUT SQL:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`r`.`zred`,`r.zred`,`_b__snapnum_/_r__zred_`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`r`.`zred`=VALUES(`r`.`zred`),
`r.zred`=VALUES(`r.zred`),
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT r.zred AS `r`.`zred`,r.zred AS `r.zred`,b.snapnum / r.zred AS `_b__snapnum_/_r__zred_`,2.0 + `b`.`bdmId` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT ``,`b`.`snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_40247513`   ) AS `b`  WHERE ( `b`.`snapnum` = `r`.`snapnum` )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `r`.`zred`,`r.zred`,`_b__snapnum_/_r__zred_`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_23698851`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`r`.`zred`=VALUES(`r`.`zred`),
`r.zred`=VALUES(`r.zred`),
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)
This is the query plan for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

CALL paquExec('SELECT 2.0 + b.bdmId AS ``,b.snapnum AS `b`.`snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   ', 'aggregation_tmp_40247513');
CALL paquExec('SELECT r.zred AS `r`.`zred`,r.zred AS `r.zred`,b.snapnum / r.zred AS `_b__snapnum_/_r__zred_`,2.0 + `b`.`bdmId` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT ``,`b`.`snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir` FROM `aggregation_tmp_40247513`   ) AS `b`  WHERE ( `b`.`snapnum` = `r`.`snapnum` )    LIMIT 0,10', 'aggregation_tmp_23698851');
CALL paquDropTmp('aggregation_tmp_40247513');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `r`.`zred`,`r.zred`,`_b__snapnum_/_r__zred_`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_23698851`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_23698851');
This is the query plan optimisation output for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
``,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
``=VALUES(``),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0 + b.bdmId AS ``,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   
)


-- AGGREGATION SQL:
SELECT ``,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_64733007`   
ON DUPLICATE KEY UPDATE
``=VALUES(``),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)
-- INPUT SQL:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`r.zred`,`r.zred`,`_b__snapnum_/_r__zred_`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`r.zred`=VALUES(`r.zred`),
`r.zred`=VALUES(`r.zred`),
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT r.zred AS `r.zred`,r.zred AS `r.zred`,b.snapnum / r.zred AS `_b__snapnum_/_r__zred_`,2.0 + `b`.`bdmId` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT ``,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_64733007`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `r.zred`,`r.zred`,`_b__snapnum_/_r__zred_`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_43940673`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`r.zred`=VALUES(`r.zred`),
`r.zred`=VALUES(`r.zred`),
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)
This is the query plan for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

CALL paquExec('SELECT 2.0 + b.bdmId AS ``,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   ', 'aggregation_tmp_64733007');
CALL paquExec('SELECT r.zred AS `r.zred`,r.zred AS `r.zred`,b.snapnum / r.zred AS `_b__snapnum_/_r__zred_`,2.0 + `b`.`bdmId` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT ``,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir` FROM `aggregation_tmp_64733007`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10', 'aggregation_tmp_43940673');
CALL paquDropTmp('aggregation_tmp_64733007');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `r.zred`,`r.zred`,`_b__snapnum_/_r__zred_`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_43940673`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_43940673');
This is the query plan optimisation output for the query:
SELECT t1.a, count(t1.a) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`id`=VALUES(`id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `id` AS `id`
FROM t3 
)


-- AGGREGATION SQL:
SELECT `id`
FROM `aggregation_tmp_41255217`   
ON DUPLICATE KEY UPDATE
`id`=VALUES(`id`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1_id`,`date_id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `t1_id` AS `t1_id`,`date_id` AS `date_id`
FROM t2 JOIN ( SELECT `id`
FROM `aggregation_tmp_41255217`   ) AS `t3`  WHERE ( `t3`.`id` = `t2`.`date_id` )   
)


-- AGGREGATION SQL:
SELECT `t1_id`,`date_id`
FROM `aggregation_tmp_81860634`   
ON DUPLICATE KEY UPDATE
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)
-- INPUT SQL:
SELECT t1.a, count(t1.a) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1.a`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_t1__a_`=`_count_t1__a_` +  VALUES(`_count_t1__a_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1.a AS `t1.a`,COUNT(`t1`.`a`) AS `_count_t1__a_`
FROM t1 JOIN ( SELECT `t1_id`,`date_id`
FROM `aggregation_tmp_81860634`   ) AS `t2`  WHERE ( `t1`.`id` = `t2`.`t1_id` )  GROUP BY t1.a  
)


-- AGGREGATION SQL:
SELECT `t1.a`,SUM(`_count_t1__a_`) AS `_count_t1__a_`
FROM `aggregation_tmp_71321803`  GROUP BY `t1.a`  
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_t1__a_`=`_count_t1__a_` +  VALUES(`_count_t1__a_`)
This is the query plan for the query:
SELECT t1.a, count(t1.a) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

CALL paquExec('SELECT `id` AS `id` FROM t3 ', 'aggregation_tmp_41255217');
CALL paquExec('SELECT `t1_id` AS `t1_id`,`date_id` AS `date_id` FROM t2 JOIN ( SELECT `id` FROM `aggregation_tmp_41255217`   ) AS `t3`  WHERE ( `t3`.`id` = `t2`.`date_id` )   ', 'aggregation_tmp_81860634');
CALL paquExec('SELECT t1.a AS `t1.a`,COUNT(`t1`.`a`) AS `_count_t1__a_` FROM t1 JOIN ( SELECT `t1_id`,`date_id` FROM `aggregation_tmp_81860634`   ) AS `t2`  WHERE ( `t1`.`id` = `t2`.`t1_id` )  GROUP BY t1.a  ', 'aggregation_tmp_71321803');
CALL paquDropTmp('aggregation_tmp_41255217');
CALL paquDropTmp('aggregation_tmp_81860634');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `t1.a`,SUM(`_count_t1__a_`) AS `_count_t1__a_`
FROM `aggregation_tmp_71321803`  GROUP BY `t1.a`  ;
CALL paquDropTmp('aggregation_tmp_71321803');
This is the query plan optimisation output for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
``,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
``=VALUES(``),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0 + b.bdmId AS ``,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   
)


-- AGGREGATION SQL:
SELECT ``,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_31794586`   
ON DUPLICATE KEY UPDATE
``=VALUES(``),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)
-- INPUT SQL:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`r.zred`,`r.zred`,`_b__snapnum_/_r__zred_`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`r.zred`=VALUES(`r.zred`),
`r.zred`=VALUES(`r.zred`),
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT r.zred AS `r.zred`,r.zred AS `r.zred`,b.snapnum / r.zred AS `_b__snapnum_/_r__zred_`,2.0 + `b`.`bdmId` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT ``,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_31794586`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `r.zred`,`r.zred`,`_b__snapnum_/_r__zred_`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_78811238`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`r.zred`=VALUES(`r.zred`),
`r.zred`=VALUES(`r.zred`),
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)
This is the query plan for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

CALL paquExec('SELECT 2.0 + b.bdmId AS ``,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   ', 'aggregation_tmp_31794586');
CALL paquExec('SELECT r.zred AS `r.zred`,r.zred AS `r.zred`,b.snapnum / r.zred AS `_b__snapnum_/_r__zred_`,2.0 + `b`.`bdmId` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT ``,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir` FROM `aggregation_tmp_31794586`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10', 'aggregation_tmp_78811238');
CALL paquDropTmp('aggregation_tmp_31794586');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `r.zred`,`r.zred`,`_b__snapnum_/_r__zred_`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_78811238`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_78811238');
This is the query plan optimisation output for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
``,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
``=VALUES(``),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0 + b.bdmId AS ``,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   
)


-- AGGREGATION SQL:
SELECT ``,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_54425506`   
ON DUPLICATE KEY UPDATE
``=VALUES(``),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)
-- INPUT SQL:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`r.zred`,`r.zred`,`_b__snapnum_/_r__zred_`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`r.zred`=VALUES(`r.zred`),
`r.zred`=VALUES(`r.zred`),
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT r.zred AS `r.zred`,r.zred AS `r.zred`,b.snapnum / r.zred AS `_b__snapnum_/_r__zred_`,2.0 + `b`.`bdmId` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT ``,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_54425506`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `r.zred`,`r.zred`,`_b__snapnum_/_r__zred_`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_16599309`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`r.zred`=VALUES(`r.zred`),
`r.zred`=VALUES(`r.zred`),
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)
This is the query plan for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

CALL paquExec('SELECT 2.0 + b.bdmId AS ``,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   ', 'aggregation_tmp_54425506');
CALL paquExec('SELECT r.zred AS `r.zred`,r.zred AS `r.zred`,b.snapnum / r.zred AS `_b__snapnum_/_r__zred_`,2.0 + `b`.`bdmId` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT ``,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir` FROM `aggregation_tmp_54425506`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10', 'aggregation_tmp_16599309');
CALL paquDropTmp('aggregation_tmp_54425506');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `r.zred`,`r.zred`,`_b__snapnum_/_r__zred_`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_16599309`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_16599309');
This is the query plan optimisation output for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
``,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
``=VALUES(``),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0 + b.bdmId AS ``,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   
)


-- AGGREGATION SQL:
SELECT ``,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_77864020`   
ON DUPLICATE KEY UPDATE
``=VALUES(``),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)
-- INPUT SQL:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`r.zred`,`r.zred`,`_b__snapnum_/_r__zred_`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`r.zred`=VALUES(`r.zred`),
`r.zred`=VALUES(`r.zred`),
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT r.zred AS `r.zred`,r.zred AS `r.zred`,b.snapnum / r.zred AS `_b__snapnum_/_r__zred_`,2.0 + `b`.`bdmId` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT ``,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_77864020`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `r.zred`,`r.zred`,`_b__snapnum_/_r__zred_`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_80429685`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`r.zred`=VALUES(`r.zred`),
`r.zred`=VALUES(`r.zred`),
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)
This is the query plan for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

CALL paquExec('SELECT 2.0 + b.bdmId AS ``,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   ', 'aggregation_tmp_77864020');
CALL paquExec('SELECT r.zred AS `r.zred`,r.zred AS `r.zred`,b.snapnum / r.zred AS `_b__snapnum_/_r__zred_`,2.0 + `b`.`bdmId` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT ``,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir` FROM `aggregation_tmp_77864020`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10', 'aggregation_tmp_80429685');
CALL paquDropTmp('aggregation_tmp_77864020');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `r.zred`,`r.zred`,`_b__snapnum_/_r__zred_`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_80429685`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_80429685');
This is the query plan optimisation output for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
``,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
``=VALUES(``),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0 + b.bdmId AS ``,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   
)


-- AGGREGATION SQL:
SELECT ``,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_1378163`   
ON DUPLICATE KEY UPDATE
``=VALUES(``),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)
-- INPUT SQL:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`r.zred`,`r.zred`,`_b__snapnum_/_r__zred_`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`r.zred`=VALUES(`r.zred`),
`r.zred`=VALUES(`r.zred`),
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT r.zred AS `r.zred`,r.zred AS `r.zred`,b.snapnum / r.zred AS `_b__snapnum_/_r__zred_`,2.0 + `b`.`bdmId` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT ``,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_1378163`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `r.zred`,`r.zred`,`_b__snapnum_/_r__zred_`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_87346287`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`r.zred`=VALUES(`r.zred`),
`r.zred`=VALUES(`r.zred`),
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)
This is the query plan for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

CALL paquExec('SELECT 2.0 + b.bdmId AS ``,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   ', 'aggregation_tmp_1378163');
CALL paquExec('SELECT r.zred AS `r.zred`,r.zred AS `r.zred`,b.snapnum / r.zred AS `_b__snapnum_/_r__zred_`,2.0 + `b`.`bdmId` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT ``,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir` FROM `aggregation_tmp_1378163`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10', 'aggregation_tmp_87346287');
CALL paquDropTmp('aggregation_tmp_1378163');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `r.zred`,`r.zred`,`_b__snapnum_/_r__zred_`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_87346287`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_87346287');
This is the query plan optimisation output for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
``,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
``=VALUES(``),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0 + b.bdmId AS ``,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   
)


-- AGGREGATION SQL:
SELECT ``,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_75814342`   
ON DUPLICATE KEY UPDATE
``=VALUES(``),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)
-- INPUT SQL:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`r.zred`,`r.zred`,`_b__snapnum_/_r__zred_`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`r.zred`=VALUES(`r.zred`),
`r.zred`=VALUES(`r.zred`),
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT r.zred AS `r.zred`,r.zred AS `r.zred`,b.snapnum / r.zred AS `_b__snapnum_/_r__zred_`,2.0 + `b`.`bdmId` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT ``,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_75814342`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `r.zred`,`r.zred`,`_b__snapnum_/_r__zred_`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_97518378`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`r.zred`=VALUES(`r.zred`),
`r.zred`=VALUES(`r.zred`),
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)
This is the query plan for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

CALL paquExec('SELECT 2.0 + b.bdmId AS ``,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   ', 'aggregation_tmp_75814342');
CALL paquExec('SELECT r.zred AS `r.zred`,r.zred AS `r.zred`,b.snapnum / r.zred AS `_b__snapnum_/_r__zred_`,2.0 + `b`.`bdmId` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT ``,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir` FROM `aggregation_tmp_75814342`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10', 'aggregation_tmp_97518378');
CALL paquDropTmp('aggregation_tmp_75814342');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `r.zred`,`r.zred`,`_b__snapnum_/_r__zred_`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_97518378`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_97518378');
This is the query plan optimisation output for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   
)


-- AGGREGATION SQL:
SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_56120301`   
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)
-- INPUT SQL:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`r.zred`,`r,zred`,`_b__snapnum_/_r__zred_`,`xyzphkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`r.zred`=VALUES(`r.zred`),
`r,zred`=VALUES(`r,zred`),
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`xyzphkey`=VALUES(`xyzphkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT r.zred AS `r.zred`,r.zred AS `r,zred`,b.snapnum / r.zred AS `_b__snapnum_/_r__zred_`,`b`.`xyzphkey` AS `xyzphkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_56120301`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `r.zred`,`r,zred`,`_b__snapnum_/_r__zred_`,`xyzphkey`
FROM `aggregation_tmp_12884099`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`r.zred`=VALUES(`r.zred`),
`r,zred`=VALUES(`r,zred`),
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`xyzphkey`=VALUES(`xyzphkey`)
This is the query plan for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

CALL paquExec('SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   ', 'aggregation_tmp_56120301');
CALL paquExec('SELECT r.zred AS `r.zred`,r.zred AS `r,zred`,b.snapnum / r.zred AS `_b__snapnum_/_r__zred_`,`b`.`xyzphkey` AS `xyzphkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir` FROM `aggregation_tmp_56120301`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10', 'aggregation_tmp_12884099');
CALL paquDropTmp('aggregation_tmp_56120301');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `r.zred`,`r,zred`,`_b__snapnum_/_r__zred_`,`xyzphkey`
FROM `aggregation_tmp_12884099`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_12884099');
This is the query plan optimisation output for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z`
FROM MDR1.FOF AS `f` 
)


-- AGGREGATION SQL:
SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_28432493`   
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
-- INPUT SQL:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b,x`,`b,y`,`bz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b,x`=VALUES(`b,x`),
`b,y`=VALUES(`b,y`),
`bz`=VALUES(`bz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.x AS `b,x`,b.y AS `b,y`,b.z AS `bz`
FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_28432493`   ) AS `f`  WHERE ( POWER( `b`.`x` - `f`.`f,x`, 2 ) < 1000 )    LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `b,x`,`b,y`,`bz`
FROM `aggregation_tmp_68529531`    LIMIT 0,1
ON DUPLICATE KEY UPDATE
`b,x`=VALUES(`b,x`),
`b,y`=VALUES(`b,y`),
`bz`=VALUES(`bz`)
This is the query plan for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

CALL paquExec('SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z` FROM MDR1.FOF AS `f` ', 'aggregation_tmp_28432493');
CALL paquExec('SELECT b.x AS `b,x`,b.y AS `b,y`,b.z AS `bz` FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z` FROM `aggregation_tmp_28432493`   ) AS `f`  WHERE ( POWER( `b`.`x` - `f`.`f,x`, 2 ) < 1000 )    LIMIT 0,1', 'aggregation_tmp_68529531');
CALL paquDropTmp('aggregation_tmp_28432493');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `b,x`,`b,y`,`bz`
FROM `aggregation_tmp_68529531`    LIMIT 0,1;
CALL paquDropTmp('aggregation_tmp_68529531');
This is the query plan optimisation output for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z`
FROM MDR1.FOF AS `f` 
)


-- AGGREGATION SQL:
SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_52895465`   
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
-- INPUT SQL:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b,x`,`b,y`,`bz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b,x`=VALUES(`b,x`),
`b,y`=VALUES(`b,y`),
`bz`=VALUES(`bz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.x AS `b,x`,b.y AS `b,y`,b.z AS `bz`
FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_52895465`   ) AS `f`  WHERE ( POWER( `b`.`x` - `f`.`f,x`, 2 ) < 1000 )    LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `b,x`,`b,y`,`bz`
FROM `aggregation_tmp_93584307`    LIMIT 0,1
ON DUPLICATE KEY UPDATE
`b,x`=VALUES(`b,x`),
`b,y`=VALUES(`b,y`),
`bz`=VALUES(`bz`)
This is the query plan for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

CALL paquExec('SELECT f.x AS `f.x`,f.y AS `f.y`,f.z AS `f.z` FROM MDR1.FOF AS `f` ', 'aggregation_tmp_52895465');
CALL paquExec('SELECT b.x AS `b,x`,b.y AS `b,y`,b.z AS `bz` FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z` FROM `aggregation_tmp_52895465`   ) AS `f`  WHERE ( POWER( `b`.`x` - `f`.`f,x`, 2 ) < 1000 )    LIMIT 0,1', 'aggregation_tmp_93584307');
CALL paquDropTmp('aggregation_tmp_52895465');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `b,x`,`b,y`,`bz`
FROM `aggregation_tmp_93584307`    LIMIT 0,1;
CALL paquDropTmp('aggregation_tmp_93584307');
This is the query plan optimisation output for the query:
SELECT sprng_make_seed(), count(abs(*));

-- INPUT SQL:
SELECT sprng_make_seed(), count(abs(*));

--PARALLEL OPTIMIZATIONS:


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT COUNT(abs( *)) AS `_count_abs_*_`,COUNT(abs( *)) AS `_count_abs_*_` 
)


-- AGGREGATION SQL:
SELECT SUM(`_count_abs_*_`) AS `_count_abs_*_`,SUM(`_count_abs_*_`) AS `_count_abs_*_`
FROM `aggregation_tmp_31500926`   
This is the query plan for the query:
SELECT sprng_make_seed(), count(abs(*));

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_31500926 ENGINE=MyISAM SELECT COUNT(abs( *)) AS `_count_abs_*_`,COUNT(abs( *)) AS `_count_abs_*_`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_31500926 SELECT COUNT(abs( *)) AS `_count_abs_*_`,COUNT(abs( *)) AS `_count_abs_*_` ;
CALL paquLinkTmp('aggregation_tmp_31500926');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT SUM(`_count_abs_*_`) AS `_count_abs_*_`,SUM(`_count_abs_*_`) AS `_count_abs_*_`
FROM `aggregation_tmp_31500926`   ;
CALL paquDropTmp('aggregation_tmp_31500926');
This is the query plan optimisation output for the query:
SELECT sprng_make_seed(), count(abs(*));

-- INPUT SQL:
SELECT sprng_make_seed(), count(abs(*));

--PARALLEL OPTIMIZATIONS:


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT COUNT(abs( *)) AS `_count_abs_*_`,COUNT(abs( *)) AS `_count_abs_*_` 
)


-- AGGREGATION SQL:
SELECT SUM(`_count_abs_*_`) AS `_count_abs_*_`,SUM(`_count_abs_*_`) AS `_count_abs_*_`
FROM `aggregation_tmp_51523433`   
This is the query plan for the query:
SELECT sprng_make_seed(), count(abs(*));

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_51523433 ENGINE=MyISAM SELECT COUNT(abs( *)) AS `_count_abs_*_`,COUNT(abs( *)) AS `_count_abs_*_`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_51523433 SELECT COUNT(abs( *)) AS `_count_abs_*_`,COUNT(abs( *)) AS `_count_abs_*_` ;
CALL paquLinkTmp('aggregation_tmp_51523433');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT SUM(`_count_abs_*_`) AS `_count_abs_*_`,SUM(`_count_abs_*_`) AS `_count_abs_*_`
FROM `aggregation_tmp_51523433`   ;
CALL paquDropTmp('aggregation_tmp_51523433');
This is the query plan optimisation output for the query:
SELECT sprng_make_seed(), count(abs(*));

-- INPUT SQL:
SELECT sprng_make_seed(), count(abs(*));

--PARALLEL OPTIMIZATIONS:


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT COUNT(abs( *)) AS `_count_abs_*_`,COUNT(abs( *)) AS `_count_abs_*_` 
)


-- AGGREGATION SQL:
SELECT SUM(`_count_abs_*_`) AS `_count_abs_*_`,SUM(`_count_abs_*_`) AS `_count_abs_*_`
FROM `aggregation_tmp_93563371`   
This is the query plan for the query:
SELECT sprng_make_seed(), count(abs(*));

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_93563371 ENGINE=MyISAM SELECT COUNT(abs( *)) AS `_count_abs_*_`,COUNT(abs( *)) AS `_count_abs_*_`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_93563371 SELECT COUNT(abs( *)) AS `_count_abs_*_`,COUNT(abs( *)) AS `_count_abs_*_` ;
CALL paquLinkTmp('aggregation_tmp_93563371');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT SUM(`_count_abs_*_`) AS `_count_abs_*_`,SUM(`_count_abs_*_`) AS `_count_abs_*_`
FROM `aggregation_tmp_93563371`   ;
CALL paquDropTmp('aggregation_tmp_93563371');
This is the query plan optimisation output for the query:
SELECT sprng_make_seed(), count(abs(*));

-- INPUT SQL:
SELECT sprng_make_seed(), count(abs(*));

--PARALLEL OPTIMIZATIONS:


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT COUNT(abs( *)) AS `_count_abs_*_`,COUNT(abs( *)) AS `_count_abs_*_` 
)


-- AGGREGATION SQL:
SELECT SUM(`_count_abs_*_`) AS `_count_abs_*_`,SUM(`_count_abs_*_`) AS `_count_abs_*_`
FROM `aggregation_tmp_65446034`   
This is the query plan for the query:
SELECT sprng_make_seed(), count(abs(*));

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_65446034 ENGINE=MyISAM SELECT COUNT(abs( *)) AS `_count_abs_*_`,COUNT(abs( *)) AS `_count_abs_*_`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_65446034 SELECT COUNT(abs( *)) AS `_count_abs_*_`,COUNT(abs( *)) AS `_count_abs_*_` ;
CALL paquLinkTmp('aggregation_tmp_65446034');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT SUM(`_count_abs_*_`) AS `_count_abs_*_`,SUM(`_count_abs_*_`) AS `_count_abs_*_`
FROM `aggregation_tmp_65446034`   ;
CALL paquDropTmp('aggregation_tmp_65446034');
This is the query plan optimisation output for the query:
SELECT sprng_make_seed(), count(abs(*));

-- INPUT SQL:
SELECT sprng_make_seed(), count(abs(*));

--PARALLEL OPTIMIZATIONS:


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT COUNT(abs( *)) AS `_count_abs_*_`,COUNT(abs( *)) AS `_count_abs_*_` 
)


-- AGGREGATION SQL:
SELECT SUM(`_count_abs_*_`) AS `_count_abs_*_`,SUM(`_count_abs_*_`) AS `_count_abs_*_`
FROM `aggregation_tmp_60858329`   
This is the query plan for the query:
SELECT sprng_make_seed(), count(abs(*));

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_60858329 ENGINE=MyISAM SELECT COUNT(abs( *)) AS `_count_abs_*_`,COUNT(abs( *)) AS `_count_abs_*_`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_60858329 SELECT COUNT(abs( *)) AS `_count_abs_*_`,COUNT(abs( *)) AS `_count_abs_*_` ;
CALL paquLinkTmp('aggregation_tmp_60858329');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT SUM(`_count_abs_*_`) AS `_count_abs_*_`,SUM(`_count_abs_*_`) AS `_count_abs_*_`
FROM `aggregation_tmp_60858329`   ;
CALL paquDropTmp('aggregation_tmp_60858329');
This is the query plan optimisation output for the query:
SELECT sprng_make_seed(), count(abs(*));

-- INPUT SQL:
SELECT sprng_make_seed(), count(abs(*));

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_sprng_make_seed_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_sprng_make_seed_`=VALUES(`_sprng_make_seed_`),
`_count_abs_*_`=`_count_abs_*_` +  VALUES(`_count_abs_*_`),
`_count_abs_*_`=`_count_abs_*_` +  VALUES(`_count_abs_*_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT sprng_make_seed(  ) AS `_sprng_make_seed_`,COUNT(abs( *)) AS `_count_abs_*_`,COUNT(abs( *)) AS `_count_abs_*_` 
)


-- AGGREGATION SQL:
SELECT `_sprng_make_seed_`,SUM(`_count_abs_*_`) AS `_count_abs_*_`,SUM(`_count_abs_*_`) AS `_count_abs_*_`
FROM `aggregation_tmp_85915259`   
ON DUPLICATE KEY UPDATE
`_sprng_make_seed_`=VALUES(`_sprng_make_seed_`),
`_count_abs_*_`=`_count_abs_*_` +  VALUES(`_count_abs_*_`),
`_count_abs_*_`=`_count_abs_*_` +  VALUES(`_count_abs_*_`)
This is the query plan for the query:
SELECT sprng_make_seed(), count(abs(*));

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_85915259 ENGINE=MyISAM SELECT sprng_make_seed(  ) AS `_sprng_make_seed_`,COUNT(abs( *)) AS `_count_abs_*_`,COUNT(abs( *)) AS `_count_abs_*_`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_85915259 SELECT sprng_make_seed(  ) AS `_sprng_make_seed_`,COUNT(abs( *)) AS `_count_abs_*_`,COUNT(abs( *)) AS `_count_abs_*_` ;
CALL paquLinkTmp('aggregation_tmp_85915259');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_sprng_make_seed_`,SUM(`_count_abs_*_`) AS `_count_abs_*_`,SUM(`_count_abs_*_`) AS `_count_abs_*_`
FROM `aggregation_tmp_85915259`   ;
CALL paquDropTmp('aggregation_tmp_85915259');
This is the query plan optimisation output for the query:
SELECT sprng_make_seed(), count(abs(*));

-- INPUT SQL:
SELECT sprng_make_seed(), count(abs(*));

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_sprng_make_seed_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_sprng_make_seed_`=VALUES(`_sprng_make_seed_`),
`_count_abs_*_`=`_count_abs_*_` +  VALUES(`_count_abs_*_`),
`_count_abs_*_`=`_count_abs_*_` +  VALUES(`_count_abs_*_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT sprng_make_seed(  ) AS `_sprng_make_seed_`,COUNT(abs( *)) AS `_count_abs_*_`,COUNT(abs( *)) AS `_count_abs_*_` 
)


-- AGGREGATION SQL:
SELECT `_sprng_make_seed_`,SUM(`_count_abs_*_`) AS `_count_abs_*_`,SUM(`_count_abs_*_`) AS `_count_abs_*_`
FROM `aggregation_tmp_53797967`   
ON DUPLICATE KEY UPDATE
`_sprng_make_seed_`=VALUES(`_sprng_make_seed_`),
`_count_abs_*_`=`_count_abs_*_` +  VALUES(`_count_abs_*_`),
`_count_abs_*_`=`_count_abs_*_` +  VALUES(`_count_abs_*_`)
This is the query plan for the query:
SELECT sprng_make_seed(), count(abs(*));

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_53797967 ENGINE=MyISAM SELECT sprng_make_seed(  ) AS `_sprng_make_seed_`,COUNT(abs( *)) AS `_count_abs_*_`,COUNT(abs( *)) AS `_count_abs_*_`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_53797967 SELECT sprng_make_seed(  ) AS `_sprng_make_seed_`,COUNT(abs( *)) AS `_count_abs_*_`,COUNT(abs( *)) AS `_count_abs_*_` ;
CALL paquLinkTmp('aggregation_tmp_53797967');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_sprng_make_seed_`,SUM(`_count_abs_*_`) AS `_count_abs_*_`,SUM(`_count_abs_*_`) AS `_count_abs_*_`
FROM `aggregation_tmp_53797967`   ;
CALL paquDropTmp('aggregation_tmp_53797967');
This is the query plan optimisation output for the query:
SELECT sprng_make_seed(), count(abs(*));

-- INPUT SQL:
SELECT sprng_make_seed(), count(abs(*));

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_sprng_make_seed_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_sprng_make_seed_`=VALUES(`_sprng_make_seed_`),
`_count_abs_*_`=`_count_abs_*_` +  VALUES(`_count_abs_*_`),
`_count_abs_*_`=`_count_abs_*_` +  VALUES(`_count_abs_*_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT sprng_make_seed(  ) AS `_sprng_make_seed_`,COUNT(abs( *)) AS `_count_abs_*_`,COUNT(abs( *)) AS `_count_abs_*_` 
)


-- AGGREGATION SQL:
SELECT `_sprng_make_seed_`,SUM(`_count_abs_*_`) AS `_count_abs_*_`,SUM(`_count_abs_*_`) AS `_count_abs_*_`
FROM `aggregation_tmp_7105688`   
ON DUPLICATE KEY UPDATE
`_sprng_make_seed_`=VALUES(`_sprng_make_seed_`),
`_count_abs_*_`=`_count_abs_*_` +  VALUES(`_count_abs_*_`),
`_count_abs_*_`=`_count_abs_*_` +  VALUES(`_count_abs_*_`)
This is the query plan for the query:
SELECT sprng_make_seed(), count(abs(*));

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_7105688 ENGINE=MyISAM SELECT sprng_make_seed(  ) AS `_sprng_make_seed_`,COUNT(abs( *)) AS `_count_abs_*_`,COUNT(abs( *)) AS `_count_abs_*_`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_7105688 SELECT sprng_make_seed(  ) AS `_sprng_make_seed_`,COUNT(abs( *)) AS `_count_abs_*_`,COUNT(abs( *)) AS `_count_abs_*_` ;
CALL paquLinkTmp('aggregation_tmp_7105688');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_sprng_make_seed_`,SUM(`_count_abs_*_`) AS `_count_abs_*_`,SUM(`_count_abs_*_`) AS `_count_abs_*_`
FROM `aggregation_tmp_7105688`   ;
CALL paquDropTmp('aggregation_tmp_7105688');
This is the query plan optimisation output for the query:
SELECT sprng_make_seed(), count(abs(*));

-- INPUT SQL:
SELECT sprng_make_seed(), count(abs(*));

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_sprng_make_seed_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_sprng_make_seed_`=VALUES(`_sprng_make_seed_`),
`_count_abs_*_`=`_count_abs_*_` +  VALUES(`_count_abs_*_`),
`_count_abs_*_`=`_count_abs_*_` +  VALUES(`_count_abs_*_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT sprng_make_seed(  ) AS `_sprng_make_seed_`,COUNT(abs( *)) AS `_count_abs_*_`,COUNT(abs( *)) AS `_count_abs_*_` 
)


-- AGGREGATION SQL:
SELECT `_sprng_make_seed_`,SUM(`_count_abs_*_`) AS `_count_abs_*_`,SUM(`_count_abs_*_`) AS `_count_abs_*_`
FROM `aggregation_tmp_93740323`   
ON DUPLICATE KEY UPDATE
`_sprng_make_seed_`=VALUES(`_sprng_make_seed_`),
`_count_abs_*_`=`_count_abs_*_` +  VALUES(`_count_abs_*_`),
`_count_abs_*_`=`_count_abs_*_` +  VALUES(`_count_abs_*_`)
This is the query plan for the query:
SELECT sprng_make_seed(), count(abs(*));

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_93740323 ENGINE=MyISAM SELECT sprng_make_seed(  ) AS `_sprng_make_seed_`,COUNT(abs( *)) AS `_count_abs_*_`,COUNT(abs( *)) AS `_count_abs_*_`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_93740323 SELECT sprng_make_seed(  ) AS `_sprng_make_seed_`,COUNT(abs( *)) AS `_count_abs_*_`,COUNT(abs( *)) AS `_count_abs_*_` ;
CALL paquLinkTmp('aggregation_tmp_93740323');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_sprng_make_seed_`,SUM(`_count_abs_*_`) AS `_count_abs_*_`,SUM(`_count_abs_*_`) AS `_count_abs_*_`
FROM `aggregation_tmp_93740323`   ;
CALL paquDropTmp('aggregation_tmp_93740323');
This is the query plan optimisation output for the query:
SELECT sprng_make_seed(), count(abs(*));

-- INPUT SQL:
SELECT sprng_make_seed(), count(abs(*));

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_sprng_make_seed_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_sprng_make_seed_`=VALUES(`_sprng_make_seed_`),
`_count_abs_*_`=`_count_abs_*_` +  VALUES(`_count_abs_*_`),
`_count_abs_*_`=`_count_abs_*_` +  VALUES(`_count_abs_*_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT sprng_make_seed(  ) AS `_sprng_make_seed_`,COUNT(abs( *)) AS `_count_abs_*_`,COUNT(abs( *)) AS `_count_abs_*_` 
)


-- AGGREGATION SQL:
SELECT `_sprng_make_seed_`,SUM(`_count_abs_*_`) AS `_count_abs_*_`,SUM(`_count_abs_*_`) AS `_count_abs_*_`
FROM `aggregation_tmp_62618262`   
ON DUPLICATE KEY UPDATE
`_sprng_make_seed_`=VALUES(`_sprng_make_seed_`),
`_count_abs_*_`=`_count_abs_*_` +  VALUES(`_count_abs_*_`),
`_count_abs_*_`=`_count_abs_*_` +  VALUES(`_count_abs_*_`)
This is the query plan for the query:
SELECT sprng_make_seed(), count(abs(*));

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_62618262 ENGINE=MyISAM SELECT sprng_make_seed(  ) AS `_sprng_make_seed_`,COUNT(abs( *)) AS `_count_abs_*_`,COUNT(abs( *)) AS `_count_abs_*_`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_62618262 SELECT sprng_make_seed(  ) AS `_sprng_make_seed_`,COUNT(abs( *)) AS `_count_abs_*_`,COUNT(abs( *)) AS `_count_abs_*_` ;
CALL paquLinkTmp('aggregation_tmp_62618262');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_sprng_make_seed_`,SUM(`_count_abs_*_`) AS `_count_abs_*_`,SUM(`_count_abs_*_`) AS `_count_abs_*_`
FROM `aggregation_tmp_62618262`   ;
CALL paquDropTmp('aggregation_tmp_62618262');
This is the query plan optimisation output for the query:
SELECT sprng_make_seed(), count(abs(*));

-- INPUT SQL:
SELECT sprng_make_seed(), count(abs(*));

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_sprng_make_seed_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_sprng_make_seed_`=VALUES(`_sprng_make_seed_`),
`_count_abs_*_`=`_count_abs_*_` +  VALUES(`_count_abs_*_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT sprng_make_seed(  ) AS `_sprng_make_seed_`,COUNT(abs( *)) AS `_count_abs_*_` 
)


-- AGGREGATION SQL:
SELECT `_sprng_make_seed_`,SUM(`_count_abs_*_`) AS `_count_abs_*_`
FROM `aggregation_tmp_45260395`   
ON DUPLICATE KEY UPDATE
`_sprng_make_seed_`=VALUES(`_sprng_make_seed_`),
`_count_abs_*_`=`_count_abs_*_` +  VALUES(`_count_abs_*_`)
This is the query plan for the query:
SELECT sprng_make_seed(), count(abs(*));

CREATE DATABASE IF NOT EXISTS spider_tmp_shard; USE spider_tmp_shard; CREATE TABLE spider_tmp_shard.aggregation_tmp_45260395 ENGINE=MyISAM SELECT sprng_make_seed(  ) AS `_sprng_make_seed_`,COUNT(abs( *)) AS `_count_abs_*_`  LIMIT 0;
USE spider_tmp_shard; INSERT INTO spider_tmp_shard.aggregation_tmp_45260395 SELECT sprng_make_seed(  ) AS `_sprng_make_seed_`,COUNT(abs( *)) AS `_count_abs_*_` ;
CALL paquLinkTmp('aggregation_tmp_45260395');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_sprng_make_seed_`,SUM(`_count_abs_*_`) AS `_count_abs_*_`
FROM `aggregation_tmp_45260395`   ;
CALL paquDropTmp('aggregation_tmp_45260395');
This is the query plan optimisation output for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   
)


-- AGGREGATION SQL:
SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_1947785`   
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)
-- INPUT SQL:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`r.zred`,`r.zred`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`r.zred`=VALUES(`r.zred`),
`r.zred`=VALUES(`r.zred`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT r.zred AS `r.zred`,r.zred AS `r.zred`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_1947785`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `r.zred`,`r.zred`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_59114452`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`r.zred`=VALUES(`r.zred`),
`r.zred`=VALUES(`r.zred`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)
This is the query plan for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

CALL paquExec('SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   ', 'aggregation_tmp_1947785');
CALL paquExec('SELECT r.zred AS `r.zred`,r.zred AS `r.zred`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir` FROM `aggregation_tmp_1947785`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10', 'aggregation_tmp_59114452');
CALL paquDropTmp('aggregation_tmp_1947785');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `r.zred`,`r.zred`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_59114452`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_59114452');
This is the query plan optimisation output for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   
)


-- AGGREGATION SQL:
SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_15473767`   
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)
-- INPUT SQL:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`r.zred`,`r.zred`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`r.zred`=VALUES(`r.zred`),
`r.zred`=VALUES(`r.zred`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT r.zred AS `r.zred`,r.zred AS `r.zred`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_15473767`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `r.zred`,`r.zred`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_6021903`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`r.zred`=VALUES(`r.zred`),
`r.zred`=VALUES(`r.zred`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)
This is the query plan for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

CALL paquExec('SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   ', 'aggregation_tmp_15473767');
CALL paquExec('SELECT r.zred AS `r.zred`,r.zred AS `r.zred`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir` FROM `aggregation_tmp_15473767`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10', 'aggregation_tmp_6021903');
CALL paquDropTmp('aggregation_tmp_15473767');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `r.zred`,`r.zred`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_6021903`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_6021903');
This is the query plan optimisation output for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   
)


-- AGGREGATION SQL:
SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_77685717`   
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)
-- INPUT SQL:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`r.zred`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`r.zred`=VALUES(`r.zred`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT r.zred AS `r.zred`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_77685717`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `r.zred`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_33160362`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`r.zred`=VALUES(`r.zred`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)
This is the query plan for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

CALL paquExec('SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   ', 'aggregation_tmp_77685717');
CALL paquExec('SELECT r.zred AS `r.zred`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir` FROM `aggregation_tmp_77685717`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10', 'aggregation_tmp_33160362');
CALL paquDropTmp('aggregation_tmp_77685717');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `r.zred`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_33160362`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_33160362');
This is the query plan optimisation output for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   
)


-- AGGREGATION SQL:
SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_86914771`   
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)
-- INPUT SQL:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.snapnum / r.zred AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_86914771`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_19980356`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)
This is the query plan for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

CALL paquExec('SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   ', 'aggregation_tmp_86914771');
CALL paquExec('SELECT b.snapnum / r.zred AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir` FROM `aggregation_tmp_86914771`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10', 'aggregation_tmp_19980356');
CALL paquDropTmp('aggregation_tmp_86914771');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_19980356`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_19980356');
This is the query plan optimisation output for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   
)


-- AGGREGATION SQL:
SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_23813021`   
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)
-- INPUT SQL:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.snapnum / r.zred AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_23813021`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_38507194`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)
This is the query plan for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

CALL paquExec('SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   ', 'aggregation_tmp_23813021');
CALL paquExec('SELECT b.snapnum / r.zred AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir` FROM `aggregation_tmp_23813021`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10', 'aggregation_tmp_38507194');
CALL paquDropTmp('aggregation_tmp_23813021');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_38507194`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_38507194');
This is the query plan optimisation output for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, ``.`x`, ``.`y`, ``.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   
)


-- AGGREGATION SQL:
SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_60664595`   
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)
-- INPUT SQL:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_b__snapnum_/_r__zred_`,`r.zred`,`xyzphkey`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`xyzphkey`=VALUES(`xyzphkey`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.snapnum / r.zred AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_60664595`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`xyzphkey`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_58033113`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`xyzphkey`=VALUES(`xyzphkey`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)
This is the query plan for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

CALL paquExec('SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, ``.`x`, ``.`y`, ``.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   ', 'aggregation_tmp_60664595');
CALL paquExec('SELECT b.snapnum / r.zred AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir` FROM `aggregation_tmp_60664595`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10', 'aggregation_tmp_58033113');
CALL paquDropTmp('aggregation_tmp_60664595');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`xyzphkey`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_58033113`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_58033113');
This is the query plan optimisation output for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   
)


-- AGGREGATION SQL:
SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_50441965`   
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)
-- INPUT SQL:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.snapnum / r.zred AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_50441965`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_32089612`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)
This is the query plan for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

CALL paquExec('SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   ', 'aggregation_tmp_50441965');
CALL paquExec('SELECT b.snapnum / r.zred AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir` FROM `aggregation_tmp_50441965`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10', 'aggregation_tmp_32089612');
CALL paquDropTmp('aggregation_tmp_50441965');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_32089612`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_32089612');
This is the query plan optimisation output for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   
)


-- AGGREGATION SQL:
SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_27836784`   
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)
-- INPUT SQL:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.snapnum / r.zred AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_27836784`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_32708479`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)
This is the query plan for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

CALL paquExec('SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   ', 'aggregation_tmp_27836784');
CALL paquExec('SELECT b.snapnum / r.zred AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir` FROM `aggregation_tmp_27836784`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10', 'aggregation_tmp_32708479');
CALL paquDropTmp('aggregation_tmp_27836784');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_32708479`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_32708479');
This is the query plan optimisation output for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   
)


-- AGGREGATION SQL:
SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_48416638`   
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)
-- INPUT SQL:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT b.snapnum / r.zred AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_48416638`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_24784911`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)
This is the query plan for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

CALL paquExec('SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   ', 'aggregation_tmp_48416638');
CALL paquExec('SELECT b.snapnum / r.zred AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir` FROM `aggregation_tmp_48416638`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10', 'aggregation_tmp_24784911');
CALL paquDropTmp('aggregation_tmp_48416638');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_24784911`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_24784911');
This is the query plan optimisation output for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   
)


-- AGGREGATION SQL:
SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_4462566`   
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)
-- INPUT SQL:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `b`.`b.snapnum` / `b`.`r.zred` AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_4462566`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_17708091`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)
This is the query plan for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

CALL paquExec('SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   ', 'aggregation_tmp_4462566');
CALL paquExec('SELECT `b`.`b.snapnum` / `b`.`r.zred` AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir` FROM `aggregation_tmp_4462566`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10', 'aggregation_tmp_17708091');
CALL paquDropTmp('aggregation_tmp_4462566');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_17708091`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_17708091');
This is the query plan optimisation output for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   
)


-- AGGREGATION SQL:
SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_11604134`   
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)
-- INPUT SQL:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `b`.`b.snapnum` / `b`.`r.zred` AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_11604134`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_42875122`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)
This is the query plan for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

CALL paquExec('SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   ', 'aggregation_tmp_11604134');
CALL paquExec('SELECT `b`.`b.snapnum` / `b`.`r.zred` AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir` FROM `aggregation_tmp_11604134`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10', 'aggregation_tmp_42875122');
CALL paquDropTmp('aggregation_tmp_11604134');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_42875122`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_42875122');
This is the query plan optimisation output for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   
)


-- AGGREGATION SQL:
SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_31200533`   
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)
-- INPUT SQL:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `b`.`b.snapnum` / `b`.`r.zred` AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_31200533`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_6886713`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)
This is the query plan for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

CALL paquExec('SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   ', 'aggregation_tmp_31200533');
CALL paquExec('SELECT `b`.`b.snapnum` / `b`.`r.zred` AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir` FROM `aggregation_tmp_31200533`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10', 'aggregation_tmp_6886713');
CALL paquDropTmp('aggregation_tmp_31200533');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_6886713`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_6886713');
This is the query plan optimisation output for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   
)


-- AGGREGATION SQL:
SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_49492769`   
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)
-- INPUT SQL:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `b`.`b.snapnum` / `b`.`r.zred` AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_49492769`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_88704503`    LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)
This is the query plan for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 LIMIT 10

CALL paquExec('SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   ', 'aggregation_tmp_49492769');
CALL paquExec('SELECT `b`.`b.snapnum` / `b`.`r.zred` AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir` FROM `aggregation_tmp_49492769`   ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )    LIMIT 0,10', 'aggregation_tmp_88704503');
CALL paquDropTmp('aggregation_tmp_49492769');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_88704503`    LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_88704503');
This is the query plan optimisation output for the query:
SELECT t1.a, count(t1.a) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`id`=VALUES(`id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `id` AS `id`
FROM t3 
)


-- AGGREGATION SQL:
SELECT `id`
FROM `aggregation_tmp_759111`   
ON DUPLICATE KEY UPDATE
`id`=VALUES(`id`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1_id`,`date_id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `t1_id` AS `t1_id`,`date_id` AS `date_id`
FROM t2 JOIN ( SELECT `id`
FROM `aggregation_tmp_759111`   ) AS `t3`  WHERE ( `t3`.`id` = `t2`.`date_id` )   
)


-- AGGREGATION SQL:
SELECT `t1_id`,`date_id`
FROM `aggregation_tmp_53966823`   
ON DUPLICATE KEY UPDATE
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)
-- INPUT SQL:
SELECT t1.a, count(t1.a) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1.a`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_t1__a_`=`_count_t1__a_` +  VALUES(`_count_t1__a_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1.a AS `t1.a`,COUNT(`t2`.`t1.a`) AS `_count_t1__a_`
FROM t1 JOIN ( SELECT `t1_id`,`date_id`
FROM `aggregation_tmp_53966823`   ) AS `t2`  WHERE ( `t1`.`id` = `t2`.`t1_id` )  GROUP BY t1.a  
)


-- AGGREGATION SQL:
SELECT `t1.a`,SUM(`_count_t1__a_`) AS `_count_t1__a_`
FROM `aggregation_tmp_16626271`  GROUP BY `t1.a`  
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_t1__a_`=`_count_t1__a_` +  VALUES(`_count_t1__a_`)
This is the query plan for the query:
SELECT t1.a, count(t1.a) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

CALL paquExec('SELECT `id` AS `id` FROM t3 ', 'aggregation_tmp_759111');
CALL paquExec('SELECT `t1_id` AS `t1_id`,`date_id` AS `date_id` FROM t2 JOIN ( SELECT `id` FROM `aggregation_tmp_759111`   ) AS `t3`  WHERE ( `t3`.`id` = `t2`.`date_id` )   ', 'aggregation_tmp_53966823');
CALL paquExec('SELECT t1.a AS `t1.a`,COUNT(`t2`.`t1.a`) AS `_count_t1__a_` FROM t1 JOIN ( SELECT `t1_id`,`date_id` FROM `aggregation_tmp_53966823`   ) AS `t2`  WHERE ( `t1`.`id` = `t2`.`t1_id` )  GROUP BY t1.a  ', 'aggregation_tmp_16626271');
CALL paquDropTmp('aggregation_tmp_759111');
CALL paquDropTmp('aggregation_tmp_53966823');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `t1.a`,SUM(`_count_t1__a_`) AS `_count_t1__a_`
FROM `aggregation_tmp_16626271`  GROUP BY `t1.a`  ;
CALL paquDropTmp('aggregation_tmp_16626271');
This is the query plan optimisation output for the query:
SELECT t1.a, count(t1.a) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`id`=VALUES(`id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `id` AS `id`
FROM t3 
)


-- AGGREGATION SQL:
SELECT `id`
FROM `aggregation_tmp_89640999`   
ON DUPLICATE KEY UPDATE
`id`=VALUES(`id`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1_id`,`date_id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `t1_id` AS `t1_id`,`date_id` AS `date_id`
FROM t2 JOIN ( SELECT `id`
FROM `aggregation_tmp_89640999`   ) AS `t3`  WHERE ( `t3`.`id` = `t2`.`date_id` )   
)


-- AGGREGATION SQL:
SELECT `t1_id`,`date_id`
FROM `aggregation_tmp_32955101`   
ON DUPLICATE KEY UPDATE
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)
-- INPUT SQL:
SELECT t1.a, count(t1.a) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1.a`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_t1__a_`=`_count_t1__a_` +  VALUES(`_count_t1__a_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1.a AS `t1.a`,COUNT(`t2`.`t1.a`) AS `_count_t1__a_`
FROM t1 JOIN ( SELECT `t1_id`,`date_id`
FROM `aggregation_tmp_32955101`   ) AS `t2`  WHERE ( `t1`.`id` = `t2`.`t1_id` )  GROUP BY t1.a  
)


-- AGGREGATION SQL:
SELECT `t1.a`,SUM(`_count_t1__a_`) AS `_count_t1__a_`
FROM `aggregation_tmp_57486900`  GROUP BY `t1.a`  
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_t1__a_`=`_count_t1__a_` +  VALUES(`_count_t1__a_`)
This is the query plan for the query:
SELECT t1.a, count(t1.a) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

CALL paquExec('SELECT `id` AS `id` FROM t3 ', 'aggregation_tmp_89640999');
CALL paquExec('SELECT `t1_id` AS `t1_id`,`date_id` AS `date_id` FROM t2 JOIN ( SELECT `id` FROM `aggregation_tmp_89640999`   ) AS `t3`  WHERE ( `t3`.`id` = `t2`.`date_id` )   ', 'aggregation_tmp_32955101');
CALL paquExec('SELECT t1.a AS `t1.a`,COUNT(`t2`.`t1.a`) AS `_count_t1__a_` FROM t1 JOIN ( SELECT `t1_id`,`date_id` FROM `aggregation_tmp_32955101`   ) AS `t2`  WHERE ( `t1`.`id` = `t2`.`t1_id` )  GROUP BY t1.a  ', 'aggregation_tmp_57486900');
CALL paquDropTmp('aggregation_tmp_89640999');
CALL paquDropTmp('aggregation_tmp_32955101');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `t1.a`,SUM(`_count_t1__a_`) AS `_count_t1__a_`
FROM `aggregation_tmp_57486900`  GROUP BY `t1.a`  ;
CALL paquDropTmp('aggregation_tmp_57486900');
This is the query plan optimisation output for the query:
SELECT t1.a, count(t1.a) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`id`=VALUES(`id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `id` AS `id`
FROM t3 
)


-- AGGREGATION SQL:
SELECT `id`
FROM `aggregation_tmp_65131312`   
ON DUPLICATE KEY UPDATE
`id`=VALUES(`id`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1_id`,`date_id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `t1_id` AS `t1_id`,`date_id` AS `date_id`
FROM t2 JOIN ( SELECT `id`
FROM `aggregation_tmp_65131312`   ) AS `t3`  WHERE ( `t3`.`id` = `t2`.`date_id` )   
)


-- AGGREGATION SQL:
SELECT `t1_id`,`date_id`
FROM `aggregation_tmp_67465573`   
ON DUPLICATE KEY UPDATE
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)
-- INPUT SQL:
SELECT t1.a, count(t1.a) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1.a`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_t1__a_`=`_count_t1__a_` +  VALUES(`_count_t1__a_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1.a AS `t1.a`,COUNT(`t2`.`t1.a`) AS `_count_t1__a_`
FROM t1 JOIN ( SELECT `t1_id`,`date_id`
FROM `aggregation_tmp_67465573`   ) AS `t2`  WHERE ( `t1`.`id` = `t2`.`t1_id` )  GROUP BY t1.a  
)


-- AGGREGATION SQL:
SELECT `t1.a`,SUM(`_count_t1__a_`) AS `_count_t1__a_`
FROM `aggregation_tmp_49070273`  GROUP BY `t1.a`  
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_t1__a_`=`_count_t1__a_` +  VALUES(`_count_t1__a_`)
This is the query plan for the query:
SELECT t1.a, count(t1.a) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

CALL paquExec('SELECT `id` AS `id` FROM t3 ', 'aggregation_tmp_65131312');
CALL paquExec('SELECT `t1_id` AS `t1_id`,`date_id` AS `date_id` FROM t2 JOIN ( SELECT `id` FROM `aggregation_tmp_65131312`   ) AS `t3`  WHERE ( `t3`.`id` = `t2`.`date_id` )   ', 'aggregation_tmp_67465573');
CALL paquExec('SELECT t1.a AS `t1.a`,COUNT(`t2`.`t1.a`) AS `_count_t1__a_` FROM t1 JOIN ( SELECT `t1_id`,`date_id` FROM `aggregation_tmp_67465573`   ) AS `t2`  WHERE ( `t1`.`id` = `t2`.`t1_id` )  GROUP BY t1.a  ', 'aggregation_tmp_49070273');
CALL paquDropTmp('aggregation_tmp_65131312');
CALL paquDropTmp('aggregation_tmp_67465573');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `t1.a`,SUM(`_count_t1__a_`) AS `_count_t1__a_`
FROM `aggregation_tmp_49070273`  GROUP BY `t1.a`  ;
CALL paquDropTmp('aggregation_tmp_49070273');
This is the query plan optimisation output for the query:
SELECT t1.a, count(t1.a) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`id`=VALUES(`id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `id` AS `id`
FROM t3 
)


-- AGGREGATION SQL:
SELECT `id`
FROM `aggregation_tmp_46242562`   
ON DUPLICATE KEY UPDATE
`id`=VALUES(`id`)
-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1_id`,`date_id`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `t1_id` AS `t1_id`,`date_id` AS `date_id`
FROM t2 JOIN ( SELECT `id`
FROM `aggregation_tmp_46242562`   ) AS `t3`  WHERE ( `t3`.`id` = `t2`.`date_id` )   
)


-- AGGREGATION SQL:
SELECT `t1_id`,`date_id`
FROM `aggregation_tmp_65467316`   
ON DUPLICATE KEY UPDATE
`t1_id`=VALUES(`t1_id`),
`date_id`=VALUES(`date_id`)
-- INPUT SQL:
SELECT t1.a, count(t1.a) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`t1.a`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_t1__a_`=`_count_t1__a_` +  VALUES(`_count_t1__a_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT t1.a AS `t1.a`,COUNT(`t1`.`a`) AS `_count_t1__a_`
FROM t1 JOIN ( SELECT `t1_id`,`date_id`
FROM `aggregation_tmp_65467316`   ) AS `t2`  WHERE ( `t1`.`id` = `t2`.`t1_id` )  GROUP BY t1.a  
)


-- AGGREGATION SQL:
SELECT `t1.a`,SUM(`_count_t1__a_`) AS `_count_t1__a_`
FROM `aggregation_tmp_7347446`  GROUP BY `t1.a`  
ON DUPLICATE KEY UPDATE
`t1.a`=VALUES(`t1.a`),
`_count_t1__a_`=`_count_t1__a_` +  VALUES(`_count_t1__a_`)
This is the query plan for the query:
SELECT t1.a, count(t1.a) from t1, t2, t3 where t1.id = t2.t1_id and t3.id = t2.date_id group by t1.a

CALL paquExec('SELECT `id` AS `id` FROM t3 ', 'aggregation_tmp_46242562');
CALL paquExec('SELECT `t1_id` AS `t1_id`,`date_id` AS `date_id` FROM t2 JOIN ( SELECT `id` FROM `aggregation_tmp_46242562`   ) AS `t3`  WHERE ( `t3`.`id` = `t2`.`date_id` )   ', 'aggregation_tmp_65467316');
CALL paquExec('SELECT t1.a AS `t1.a`,COUNT(`t1`.`a`) AS `_count_t1__a_` FROM t1 JOIN ( SELECT `t1_id`,`date_id` FROM `aggregation_tmp_65467316`   ) AS `t2`  WHERE ( `t1`.`id` = `t2`.`t1_id` )  GROUP BY t1.a  ', 'aggregation_tmp_7347446');
CALL paquDropTmp('aggregation_tmp_46242562');
CALL paquDropTmp('aggregation_tmp_65467316');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `t1.a`,SUM(`_count_t1__a_`) AS `_count_t1__a_`
FROM `aggregation_tmp_7347446`  GROUP BY `t1.a`  ;
CALL paquDropTmp('aggregation_tmp_7347446');
This is the query plan optimisation output for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 ORDER BY 8 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   
)


-- AGGREGATION SQL:
SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_3787229`  ORDER BY `_hilbertKey_10_1000__0_3_b__x_b__y_b__z_` ASC 
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)
-- INPUT SQL:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 ORDER BY 8 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `b`.`b.snapnum` / `r`.`zred` AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_3787229`  ORDER BY `_hilbertKey_10_1000__0_3_b__x_b__y_b__z_` ASC ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )  ORDER BY `hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` )` ASC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_8595456`  ORDER BY `_hilbertKey_10_1000__0_3_b__x_b__y_b__z_` ASC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)
This is the query plan for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 ORDER BY 8 LIMIT 10

CALL paquExec('SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   ', 'aggregation_tmp_3787229');
CALL paquExec('SELECT `b`.`b.snapnum` / `r`.`zred` AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir` FROM `aggregation_tmp_3787229`  ORDER BY `_hilbertKey_10_1000__0_3_b__x_b__y_b__z_` ASC ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )  ORDER BY `hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` )` ASC  LIMIT 0,10', 'aggregation_tmp_8595456');
CALL paquDropTmp('aggregation_tmp_3787229');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_8595456`  ORDER BY `_hilbertKey_10_1000__0_3_b__x_b__y_b__z_` ASC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_8595456');
This is the query plan optimisation output for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 ORDER BY 8 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   
)


-- AGGREGATION SQL:
SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_81816794`  ORDER BY `___10_1000__0_3_b__x_b__y_b__z_` ASC 
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)
-- INPUT SQL:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 ORDER BY 8 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `b`.`b.snapnum` / `r`.`zred` AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_81816794`  ORDER BY `___10_1000__0_3_b__x_b__y_b__z_` ASC ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )  ORDER BY `_( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` )` ASC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_28164452`  ORDER BY `___10_1000__0_3_b__x_b__y_b__z_` ASC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)
This is the query plan for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 ORDER BY 8 LIMIT 10

CALL paquExec('SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   ', 'aggregation_tmp_81816794');
CALL paquExec('SELECT `b`.`b.snapnum` / `r`.`zred` AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir` FROM `aggregation_tmp_81816794`  ORDER BY `___10_1000__0_3_b__x_b__y_b__z_` ASC ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )  ORDER BY `_( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` )` ASC  LIMIT 0,10', 'aggregation_tmp_28164452');
CALL paquDropTmp('aggregation_tmp_81816794');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_28164452`  ORDER BY `___10_1000__0_3_b__x_b__y_b__z_` ASC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_28164452');
This is the query plan optimisation output for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 ORDER BY 8 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   
)


-- AGGREGATION SQL:
SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_96936400`  ORDER BY `__f_as xyzphkey_h____10_1000__0_3_b__x_b__y_b__z_` ASC 
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)
-- INPUT SQL:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 ORDER BY 8 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `b`.`b.snapnum` / `r`.`zred` AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_96936400`  ORDER BY `__f_as xyzphkey_h____10_1000__0_3_b__x_b__y_b__z_` ASC ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )  ORDER BY `_f_as xyzphkey_h___( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` )` ASC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_26625339`  ORDER BY `__f_as xyzphkey_h____10_1000__0_3_b__x_b__y_b__z_` ASC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)
This is the query plan for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 ORDER BY 8 LIMIT 10

CALL paquExec('SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   ', 'aggregation_tmp_96936400');
CALL paquExec('SELECT `b`.`b.snapnum` / `r`.`zred` AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir` FROM `aggregation_tmp_96936400`  ORDER BY `__f_as xyzphkey_h____10_1000__0_3_b__x_b__y_b__z_` ASC ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )  ORDER BY `_f_as xyzphkey_h___( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` )` ASC  LIMIT 0,10', 'aggregation_tmp_26625339');
CALL paquDropTmp('aggregation_tmp_96936400');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_26625339`  ORDER BY `__f_as xyzphkey_h____10_1000__0_3_b__x_b__y_b__z_` ASC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_26625339');
This is the query plan optimisation output for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 ORDER BY 8 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   
)


-- AGGREGATION SQL:
SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_56038325`  ORDER BY `__hilbertKey_10_1000__0_3_b__x_b__y_b__z__10_1000__0_3_b__x_b__y_b__z_` ASC 
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)
-- INPUT SQL:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 ORDER BY 8 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `b`.`b.snapnum` / `r`.`zred` AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_56038325`  ORDER BY `__hilbertKey_10_1000__0_3_b__x_b__y_b__z__10_1000__0_3_b__x_b__y_b__z_` ASC ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )  ORDER BY `_hilbertKey_10_1000__0_3_b__x_b__y_b__z_( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` )` ASC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_342676`  ORDER BY `__hilbertKey_10_1000__0_3_b__x_b__y_b__z__10_1000__0_3_b__x_b__y_b__z_` ASC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)
This is the query plan for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 ORDER BY 8 LIMIT 10

CALL paquExec('SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   ', 'aggregation_tmp_56038325');
CALL paquExec('SELECT `b`.`b.snapnum` / `r`.`zred` AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir` FROM `aggregation_tmp_56038325`  ORDER BY `__hilbertKey_10_1000__0_3_b__x_b__y_b__z__10_1000__0_3_b__x_b__y_b__z_` ASC ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )  ORDER BY `_hilbertKey_10_1000__0_3_b__x_b__y_b__z_( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` )` ASC  LIMIT 0,10', 'aggregation_tmp_342676');
CALL paquDropTmp('aggregation_tmp_56038325');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_342676`  ORDER BY `__hilbertKey_10_1000__0_3_b__x_b__y_b__z__10_1000__0_3_b__x_b__y_b__z_` ASC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_342676');
This is the query plan optimisation output for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 ORDER BY 8 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   
)


-- AGGREGATION SQL:
SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_68909486`  ORDER BY `__hilbertKey_10_1000__0_3_b__x_b__y_b__z__10_1000__0_3_b__x_b__y_b__z_` ASC 
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)
-- INPUT SQL:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 ORDER BY 8 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `b`.`b.snapnum` / `r`.`zred` AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_68909486`  ORDER BY `__hilbertKey_10_1000__0_3_b__x_b__y_b__z__10_1000__0_3_b__x_b__y_b__z_` ASC ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )  ORDER BY `_hilbertKey_10_1000__0_3_b__x_b__y_b__z_( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` )` ASC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_72485284`  ORDER BY `__hilbertKey_10_1000__0_3_b__x_b__y_b__z__10_1000__0_3_b__x_b__y_b__z_` ASC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)
This is the query plan for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 ORDER BY 8 LIMIT 10

CALL paquExec('SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   ', 'aggregation_tmp_68909486');
CALL paquExec('SELECT `b`.`b.snapnum` / `r`.`zred` AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir` FROM `aggregation_tmp_68909486`  ORDER BY `__hilbertKey_10_1000__0_3_b__x_b__y_b__z__10_1000__0_3_b__x_b__y_b__z_` ASC ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )  ORDER BY `_hilbertKey_10_1000__0_3_b__x_b__y_b__z_( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` )` ASC  LIMIT 0,10', 'aggregation_tmp_72485284');
CALL paquDropTmp('aggregation_tmp_68909486');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_72485284`  ORDER BY `__hilbertKey_10_1000__0_3_b__x_b__y_b__z__10_1000__0_3_b__x_b__y_b__z_` ASC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_72485284');
This is the query plan optimisation output for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 ORDER BY 8 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   
)


-- AGGREGATION SQL:
SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_75271835`  ORDER BY `_hilbertKey_10_1000__0_3_b__x_b__y_b__z_(  )` ASC 
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`)
-- INPUT SQL:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 ORDER BY 8 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `b`.`b.snapnum` / `r`.`zred` AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`
FROM `aggregation_tmp_75271835`  ORDER BY `_hilbertKey_10_1000__0_3_b__x_b__y_b__z_(  )` ASC ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )  ORDER BY `_hilbertKey_10_1000__0_3_b__x_b__y_b__z_(  )` ASC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_17895816`  ORDER BY `_hilbertKey_10_1000__0_3_b__x_b__y_b__z_(  )` ASC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)
This is the query plan for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 ORDER BY 8 LIMIT 10

CALL paquExec('SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   ', 'aggregation_tmp_75271835');
CALL paquExec('SELECT `b`.`b.snapnum` / `r`.`zred` AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir` FROM `aggregation_tmp_75271835`  ORDER BY `_hilbertKey_10_1000__0_3_b__x_b__y_b__z_(  )` ASC ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )  ORDER BY `_hilbertKey_10_1000__0_3_b__x_b__y_b__z_(  )` ASC  LIMIT 0,10', 'aggregation_tmp_17895816');
CALL paquDropTmp('aggregation_tmp_75271835');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_17895816`  ORDER BY `_hilbertKey_10_1000__0_3_b__x_b__y_b__z_(  )` ASC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_17895816');
This is the query plan optimisation output for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 ORDER BY 8 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`,``

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`),
``=VALUES(``)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`, AS ``
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   
)


-- AGGREGATION SQL:
SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`,``
FROM `aggregation_tmp_27033747`  ORDER BY `` ASC 
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`),
``=VALUES(``)
-- INPUT SQL:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 ORDER BY 8 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `b`.`b.snapnum` / `r`.`zred` AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`,``
FROM `aggregation_tmp_27033747`  ORDER BY `` ASC ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )  ORDER BY `` ASC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_11811883`  ORDER BY `` ASC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)
This is the query plan for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 ORDER BY 8 LIMIT 10

CALL paquExec('SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`, AS `` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   ', 'aggregation_tmp_27033747');
CALL paquExec('SELECT `b`.`b.snapnum` / `r`.`zred` AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`,`` FROM `aggregation_tmp_27033747`  ORDER BY `` ASC ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )  ORDER BY `` ASC  LIMIT 0,10', 'aggregation_tmp_11811883');
CALL paquDropTmp('aggregation_tmp_27033747');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_11811883`  ORDER BY `` ASC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_11811883');
This is the query plan optimisation output for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 ORDER BY 8 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`,``

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`),
``=VALUES(``)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`, AS ``
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   
)


-- AGGREGATION SQL:
SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`,``
FROM `aggregation_tmp_62586455`  ORDER BY `` ASC 
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`),
``=VALUES(``)
-- INPUT SQL:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 ORDER BY 8 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `b`.`b.snapnum` / `r`.`zred` AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`,``
FROM `aggregation_tmp_62586455`  ORDER BY `` ASC ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )  ORDER BY `` ASC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_33497914`  ORDER BY `` ASC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)
This is the query plan for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 ORDER BY 8 LIMIT 10

CALL paquExec('SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`, AS `` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   ', 'aggregation_tmp_62586455');
CALL paquExec('SELECT `b`.`b.snapnum` / `r`.`zred` AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`,`` FROM `aggregation_tmp_62586455`  ORDER BY `` ASC ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )  ORDER BY `` ASC  LIMIT 0,10', 'aggregation_tmp_33497914');
CALL paquDropTmp('aggregation_tmp_62586455');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_33497914`  ORDER BY `` ASC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_33497914');
This is the query plan optimisation output for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 ORDER BY 8 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`,`_hilbertKey_10_1000__0_3_b__x_b__y_b__z_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`),
`_hilbertKey_10_1000__0_3_b__x_b__y_b__z_`=VALUES(`_hilbertKey_10_1000__0_3_b__x_b__y_b__z_`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`,`_hilbertKey_10_1000__0_3_b__x_b__y_b__z_` AS `_hilbertKey_10_1000__0_3_b__x_b__y_b__z_`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   
)


-- AGGREGATION SQL:
SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`,`_hilbertKey_10_1000__0_3_b__x_b__y_b__z_`
FROM `aggregation_tmp_91543565`  ORDER BY `_hilbertKey_10_1000__0_3_b__x_b__y_b__z_` ASC 
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`),
`_hilbertKey_10_1000__0_3_b__x_b__y_b__z_`=VALUES(`_hilbertKey_10_1000__0_3_b__x_b__y_b__z_`)
-- INPUT SQL:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 ORDER BY 8 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `b`.`b.snapnum` / `r`.`zred` AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`,`_hilbertKey_10_1000__0_3_b__x_b__y_b__z_`
FROM `aggregation_tmp_91543565`  ORDER BY `_hilbertKey_10_1000__0_3_b__x_b__y_b__z_` ASC ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )  ORDER BY `_hilbertKey_10_1000__0_3_b__x_b__y_b__z_` ASC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_79395753`  ORDER BY `_hilbertKey_10_1000__0_3_b__x_b__y_b__z_` ASC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)
This is the query plan for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 ORDER BY 8 LIMIT 10

CALL paquExec('SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`,`_hilbertKey_10_1000__0_3_b__x_b__y_b__z_` AS `_hilbertKey_10_1000__0_3_b__x_b__y_b__z_` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   ', 'aggregation_tmp_91543565');
CALL paquExec('SELECT `b`.`b.snapnum` / `r`.`zred` AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`,`_hilbertKey_10_1000__0_3_b__x_b__y_b__z_` FROM `aggregation_tmp_91543565`  ORDER BY `_hilbertKey_10_1000__0_3_b__x_b__y_b__z_` ASC ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )  ORDER BY `_hilbertKey_10_1000__0_3_b__x_b__y_b__z_` ASC  LIMIT 0,10', 'aggregation_tmp_79395753');
CALL paquDropTmp('aggregation_tmp_91543565');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_79395753`  ORDER BY `_hilbertKey_10_1000__0_3_b__x_b__y_b__z_` ASC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_79395753');
This is the query plan optimisation output for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 ORDER BY 8 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`,``

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`),
``=VALUES(``)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`,`` AS ``
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   
)


-- AGGREGATION SQL:
SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`,``
FROM `aggregation_tmp_51596492`  ORDER BY `` ASC 
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`),
``=VALUES(``)
-- INPUT SQL:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 ORDER BY 8 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `b`.`b.snapnum` / `r`.`zred` AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`,``
FROM `aggregation_tmp_51596492`  ORDER BY `` ASC ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )  ORDER BY `` ASC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_15850486`  ORDER BY `` ASC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)
This is the query plan for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 ORDER BY 8 LIMIT 10

CALL paquExec('SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`,`` AS `` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   ', 'aggregation_tmp_51596492');
CALL paquExec('SELECT `b`.`b.snapnum` / `r`.`zred` AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`,`` FROM `aggregation_tmp_51596492`  ORDER BY `` ASC ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )  ORDER BY `` ASC  LIMIT 0,10', 'aggregation_tmp_15850486');
CALL paquDropTmp('aggregation_tmp_51596492');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_15850486`  ORDER BY `` ASC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_15850486');
This is the query plan optimisation output for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 ORDER BY 8 LIMIT 10

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`,`xyzphkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`),
`xyzphkey`=VALUES(`xyzphkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`,`xyzphkey` AS `xyzphkey`
FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   
)


-- AGGREGATION SQL:
SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`,`xyzphkey`
FROM `aggregation_tmp_94749708`  ORDER BY `xyzphkey` ASC 
ON DUPLICATE KEY UPDATE
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.snapnum`=VALUES(`b.snapnum`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`),
`b.Mvir`=VALUES(`b.Mvir`),
`xyzphkey`=VALUES(`xyzphkey`)
-- INPUT SQL:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 ORDER BY 8 LIMIT 10

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `b`.`b.snapnum` / `r`.`zred` AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey`
FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`,`xyzphkey`
FROM `aggregation_tmp_94749708`  ORDER BY `xyzphkey` ASC ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )  ORDER BY `xyzphkey` ASC  LIMIT 0,10
)


-- AGGREGATION SQL:
SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_64325811`  ORDER BY `xyzphkey` ASC  LIMIT 0,10
ON DUPLICATE KEY UPDATE
`_b__snapnum_/_r__zred_`=VALUES(`_b__snapnum_/_r__zred_`),
`r.zred`=VALUES(`r.zred`),
`_2__0_+_b__bdmId_`=VALUES(`_2__0_+_b__bdmId_`),
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`b.phkey`=VALUES(`b.phkey`),
`xyzphkey`=VALUES(`xyzphkey`)
This is the query plan for the query:
SELECT 2.0 + b.bdmId, b.snapnum / r.zred, r.zred, b.x,b.y,b.z,b.phkey, hilbertKey(10,1000.0,3,b.x,b.y,b.z) as xyzphkey FROM MDPL.BDMW b, MDPL.Redshifts r WHERE b.snapnum=88 AND b.snapnum = r.snapnum AND b.Mvir > 1.e14 ORDER BY 8 LIMIT 10

CALL paquExec('SELECT 2.0 + b.bdmId AS `_2__0_+_b__bdmId_`,b.snapnum AS `b.snapnum`,b.x AS `b.x`,b.y AS `b.y`,b.z AS `b.z`,b.phkey AS `b.phkey`,hilbertKey( 10, 1000.0, 3, `b`.`x`, `b`.`y`, `b`.`z` ) AS `xyzphkey`,b.Mvir AS `b.Mvir`,`xyzphkey` AS `xyzphkey` FROM MDPL.BDMW AS `b` WHERE ( `b`.`snapnum` = 88 ) AND ( `b`.`Mvir` > 1.e14 )   ', 'aggregation_tmp_94749708');
CALL paquExec('SELECT `b`.`b.snapnum` / `r`.`zred` AS `_b__snapnum_/_r__zred_`,r.zred AS `r.zred`,`b`.`_2__0_+_b__bdmId_` AS `_2__0_+_b__bdmId_`,`b`.`b.x` AS `b.x`,`b`.`b.y` AS `b.y`,`b`.`b.z` AS `b.z`,`b`.`b.phkey` AS `b.phkey`,`b`.`xyzphkey` AS `xyzphkey` FROM MDPL.Redshifts AS `r` JOIN ( SELECT `_2__0_+_b__bdmId_`,`b.snapnum`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`,`b.Mvir`,`xyzphkey` FROM `aggregation_tmp_94749708`  ORDER BY `xyzphkey` ASC ) AS `b`  WHERE ( `b`.`b.snapnum` = `r`.`snapnum` )  ORDER BY `xyzphkey` ASC  LIMIT 0,10', 'aggregation_tmp_64325811');
CALL paquDropTmp('aggregation_tmp_94749708');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `_b__snapnum_/_r__zred_`,`r.zred`,`_2__0_+_b__bdmId_`,`b.x`,`b.y`,`b.z`,`b.phkey`,`xyzphkey`
FROM `aggregation_tmp_64325811`  ORDER BY `xyzphkey` ASC  LIMIT 0,10;
CALL paquDropTmp('aggregation_tmp_64325811');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass AS `log_mass`,COUNT(*) AS `num`,FLOOR( LOG10( `Mvir` ) / 0.25 ) AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE ( `snapnum` = 85 )  GROUP BY FLOOR( LOG10( Mvir ) / 0.25 )  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_47060112`  GROUP BY `_FLOOR_LOG10_Mvir_/_0__25_` ORDER BY `_FLOOR_LOG10_Mvir_/_0__25_` ASC 
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass AS `log_mass`,COUNT(*) AS `num`,FLOOR( LOG10( `Mvir` ) / 0.25 ) AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE ( `snapnum` = 85 )  GROUP BY FLOOR( LOG10( Mvir ) / 0.25 )  ', 'aggregation_tmp_47060112');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_47060112`  GROUP BY `_FLOOR_LOG10_Mvir_/_0__25_` ORDER BY `_FLOOR_LOG10_Mvir_/_0__25_` ASC ;
CALL paquDropTmp('aggregation_tmp_47060112');
This is the query plan optimisation output for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

-- INPUT SQL:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`log_mass`,`_FLOOR_LOG10_Mvir_/_0__25_`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT 0.25 * ( 0.5 + FLOOR ) AS `log_mass`,COUNT(*) AS `num`,FLOOR AS `_FLOOR_LOG10_Mvir_/_0__25_`
FROM MDR1.BDMV WHERE ( `snapnum` = 85 )  GROUP BY FLOOR  
)


-- AGGREGATION SQL:
SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_99150877`  GROUP BY `_FLOOR_LOG10_Mvir_/_0__25_` ORDER BY `_FLOOR_LOG10_Mvir_/_0__25_` ASC 
ON DUPLICATE KEY UPDATE
`log_mass`=VALUES(`log_mass`),
`num`=`num` +  VALUES(`num`)
This is the query plan for the query:
SELECT 0.25*(0.5+FLOOR(LOG10(Mvir)/0.25)) AS log_mass, COUNT(*) AS num FROM MDR1.BDMV WHERE snapnum=85 GROUP BY FLOOR(LOG10(Mvir)/0.25) ORDER BY FLOOR(LOG10(Mvir)/0.25)

CALL paquExec('SELECT 0.25 * ( 0.5 + FLOOR ) AS `log_mass`,COUNT(*) AS `num`,FLOOR AS `_FLOOR_LOG10_Mvir_/_0__25_` FROM MDR1.BDMV WHERE ( `snapnum` = 85 )  GROUP BY FLOOR  ', 'aggregation_tmp_99150877');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `log_mass`,SUM(`num`) AS `num`
FROM `aggregation_tmp_99150877`  GROUP BY `_FLOOR_LOG10_Mvir_/_0__25_` ORDER BY `_FLOOR_LOG10_Mvir_/_0__25_` ASC ;
CALL paquDropTmp('aggregation_tmp_99150877');
This is the query plan optimisation output for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

-- INPUT SQL:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `particleId` AS `particleId`,`x` AS `x`,`y` AS `y`,`z` AS `z`,`vx` AS `vx`,`vy` AS `vy`,`vz` AS `vz`
FROM MDR1.Particles62 WHERE ( rand(  ) <= 0.0006 )    LIMIT 0,100
)


-- AGGREGATION SQL:
SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_40806989`    LIMIT 0,100
ON DUPLICATE KEY UPDATE
`particleId`=VALUES(`particleId`),
`x`=VALUES(`x`),
`y`=VALUES(`y`),
`z`=VALUES(`z`),
`vx`=VALUES(`vx`),
`vy`=VALUES(`vy`),
`vz`=VALUES(`vz`)
This is the query plan for the query:
select particleId,x,y,z,vx,vy,vz from MDR1.Particles62 where rand() <= 0.0006 limit 100

CALL paquExec('SELECT `particleId` AS `particleId`,`x` AS `x`,`y` AS `y`,`z` AS `z`,`vx` AS `vx`,`vy` AS `vy`,`vz` AS `vz` FROM MDR1.Particles62 WHERE ( rand(  ) <= 0.0006 )    LIMIT 0,100', 'aggregation_tmp_40806989');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `particleId`,`x`,`y`,`z`,`vx`,`vy`,`vz`
FROM `aggregation_tmp_40806989`    LIMIT 0,100;
CALL paquDropTmp('aggregation_tmp_40806989');
This is the query plan optimisation output for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f`.`x`,`f`.`y`,`f`.`z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f`.`x`=VALUES(`f`.`x`),
`f`.`y`=VALUES(`f`.`y`),
`f`.`z`=VALUES(`f`.`z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `f`.`x` AS `f`.`x`,`f`.`y` AS `f`.`y`,`f`.`z` AS `f`.`z`
FROM MDR1.FOF AS `f` 
)


-- AGGREGATION SQL:
SELECT `f`.`x`,`f`.`y`,`f`.`z`
FROM `aggregation_tmp_90417267`   
ON DUPLICATE KEY UPDATE
`f`.`x`=VALUES(`f`.`x`),
`f`.`y`=VALUES(`f`.`y`),
`f`.`z`=VALUES(`f`.`z`)
-- INPUT SQL:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `b`.`x` AS `b.x`,`b`.`y` AS `b.y`,`b`.`z` AS `b.z`,`f`.`f.x` AS `f.x`,`f`.`f.y` AS `f.y`,`f`.`f.z` AS `f.z`
FROM MDR1.BDMV AS `b` JOIN ( SELECT `f`.`x`,`f`.`y`,`f`.`z`
FROM `aggregation_tmp_90417267`   ) AS `f`  WHERE ( POWER( `b`.`x` - `f`.`f.x`, 2 ) < 1000 )    LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_6378996`    LIMIT 0,1
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
This is the query plan for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

CALL paquExec('SELECT `f`.`x` AS `f`.`x`,`f`.`y` AS `f`.`y`,`f`.`z` AS `f`.`z` FROM MDR1.FOF AS `f` ', 'aggregation_tmp_90417267');
CALL paquExec('SELECT `b`.`x` AS `b.x`,`b`.`y` AS `b.y`,`b`.`z` AS `b.z`,`f`.`f.x` AS `f.x`,`f`.`f.y` AS `f.y`,`f`.`f.z` AS `f.z` FROM MDR1.BDMV AS `b` JOIN ( SELECT `f`.`x`,`f`.`y`,`f`.`z` FROM `aggregation_tmp_90417267`   ) AS `f`  WHERE ( POWER( `b`.`x` - `f`.`f.x`, 2 ) < 1000 )    LIMIT 0,1', 'aggregation_tmp_6378996');
CALL paquDropTmp('aggregation_tmp_90417267');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_6378996`    LIMIT 0,1;
CALL paquDropTmp('aggregation_tmp_6378996');
This is the query plan optimisation output for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `f`.`x` AS `f.x`,`f`.`y` AS `f.y`,`f`.`z` AS `f.z`
FROM MDR1.FOF AS `f` 
)


-- AGGREGATION SQL:
SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_24433240`   
ON DUPLICATE KEY UPDATE
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
-- INPUT SQL:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `b`.`x` AS `b.x`,`b`.`y` AS `b.y`,`b`.`z` AS `b.z`,`f`.`f.x` AS `f.x`,`f`.`f.y` AS `f.y`,`f`.`f.z` AS `f.z`
FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_24433240`   ) AS `f`  WHERE ( POWER( `b`.`x` - `f`.`f.x`, 2 ) < 1000 )    LIMIT 0,1
)


-- AGGREGATION SQL:
SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_68261178`    LIMIT 0,1
ON DUPLICATE KEY UPDATE
`b.x`=VALUES(`b.x`),
`b.y`=VALUES(`b.y`),
`b.z`=VALUES(`b.z`),
`f.x`=VALUES(`f.x`),
`f.y`=VALUES(`f.y`),
`f.z`=VALUES(`f.z`)
This is the query plan for the query:
SELECT f.x,f.y,f.z, b.x,b.y,b.z FROM MDR1.FOF AS f, MDR1.BDMV AS b WHERE POWER(b.x-f.x,2) < 1000 limit 1

CALL paquExec('SELECT `f`.`x` AS `f.x`,`f`.`y` AS `f.y`,`f`.`z` AS `f.z` FROM MDR1.FOF AS `f` ', 'aggregation_tmp_24433240');
CALL paquExec('SELECT `b`.`x` AS `b.x`,`b`.`y` AS `b.y`,`b`.`z` AS `b.z`,`f`.`f.x` AS `f.x`,`f`.`f.y` AS `f.y`,`f`.`f.z` AS `f.z` FROM MDR1.BDMV AS `b` JOIN ( SELECT `f.x`,`f.y`,`f.z` FROM `aggregation_tmp_24433240`   ) AS `f`  WHERE ( POWER( `b`.`x` - `f`.`f.x`, 2 ) < 1000 )    LIMIT 0,1', 'aggregation_tmp_68261178');
CALL paquDropTmp('aggregation_tmp_24433240');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `b.x`,`b.y`,`b.z`,`f.x`,`f.y`,`f.z`
FROM `aggregation_tmp_68261178`    LIMIT 0,1;
CALL paquDropTmp('aggregation_tmp_68261178');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `descend`.`fofTreeId` AS `descend.fofTreeId`,`descend`.`lastProgId` AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_13797898`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.* AS `prog.*`,`prog`.`fofTreeId` AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_13797898`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_69635317`   
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT `descend`.`fofTreeId` AS `descend.fofTreeId`,`descend`.`lastProgId` AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   ', 'aggregation_tmp_13797898');
CALL paquExec('SELECT `prog`.* AS `prog.*`,`prog`.`fofTreeId` AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_13797898`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_69635317');
CALL paquDropTmp('aggregation_tmp_13797898');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_69635317`   ;
CALL paquDropTmp('aggregation_tmp_69635317');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `descend`.`fofTreeId` AS `descend.fofTreeId`,`descend`.`lastProgId` AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_60130544`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.* AS `prog.*`,`prog`.`fofTreeId` AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_60130544`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_8924714`   
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT `descend`.`fofTreeId` AS `descend.fofTreeId`,`descend`.`lastProgId` AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   ', 'aggregation_tmp_60130544');
CALL paquExec('SELECT `prog`.* AS `prog.*`,`prog`.`fofTreeId` AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_60130544`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_8924714');
CALL paquDropTmp('aggregation_tmp_60130544');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_8924714`   ;
CALL paquDropTmp('aggregation_tmp_8924714');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `descend`.`fofTreeId` AS `descend.fofTreeId`,`descend`.`lastProgId` AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_92290277`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.* AS `prog.*`,`prog`.`fofTreeId` AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_92290277`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_94707915`   
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT `descend`.`fofTreeId` AS `descend.fofTreeId`,`descend`.`lastProgId` AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   ', 'aggregation_tmp_92290277');
CALL paquExec('SELECT `prog`.* AS `prog.*`,`prog`.`fofTreeId` AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_92290277`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_94707915');
CALL paquDropTmp('aggregation_tmp_92290277');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_94707915`   ;
CALL paquDropTmp('aggregation_tmp_94707915');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `descend`.`fofTreeId` AS `descend.fofTreeId`,`descend`.`lastProgId` AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_64967277`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.* AS `prog.*`,`prog`.`fofTreeId` AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_64967277`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_59212695`   
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT `descend`.`fofTreeId` AS `descend.fofTreeId`,`descend`.`lastProgId` AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   ', 'aggregation_tmp_64967277');
CALL paquExec('SELECT `prog`.* AS `prog.*`,`prog`.`fofTreeId` AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_64967277`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_59212695');
CALL paquDropTmp('aggregation_tmp_64967277');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_59212695`   ;
CALL paquDropTmp('aggregation_tmp_59212695');
This is the query plan optimisation output for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `descend`.`fofTreeId` AS `descend.fofTreeId`,`descend`.`lastProgId` AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_82932581`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog.*`,`prog.fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.* AS `prog.*`,`prog`.`fofTreeId` AS `prog.fofTreeId`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_82932581`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_68059394`  ORDER BY `prog.fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog.*`=VALUES(`prog.*`),
`prog.fofTreeId`=VALUES(`prog.fofTreeId`)
This is the query plan for the query:
SELECT prog.* FROM MDR1.FOFMtree prog, MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY prog.fofTreeId ASC

CALL paquExec('SELECT `descend`.`fofTreeId` AS `descend.fofTreeId`,`descend`.`lastProgId` AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   ', 'aggregation_tmp_82932581');
CALL paquExec('SELECT `prog`.* AS `prog.*`,`prog`.`fofTreeId` AS `prog.fofTreeId` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_82932581`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_68059394');
CALL paquDropTmp('aggregation_tmp_82932581');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog.*`,`prog.fofTreeId`
FROM `aggregation_tmp_68059394`  ORDER BY `prog.fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_68059394');
This is the query plan optimisation output for the query:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`,`prog__fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`),
`prog__fofTreeId`=VALUES(`prog__fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `descend`.`fofTreeId` AS `descend.fofTreeId`,`descend`.`lastProgId` AS `descend.lastProgId`,`prog__fofTreeId` AS `prog__fofTreeId`
FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`,`prog__fofTreeId`
FROM `aggregation_tmp_26167533`  ORDER BY `prog__fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`),
`prog__fofTreeId`=VALUES(`prog__fofTreeId`)
-- INPUT SQL:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog__fofTreeId`=VALUES(`prog__fofTreeId`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.`fofTreeId` AS `prog__fofTreeId`,`prog`.`fofId` AS `prog__fofId`,`prog`.`treeSnapnum` AS `prog__treeSnapnum`,`prog`.`descendantId` AS `prog__descendantId`,`prog`.`lastProgId` AS `prog__lastProgId`,`prog`.`mainLeafId` AS `prog__mainLeafId`,`prog`.`treeRootId` AS `prog__treeRootId`,`prog`.`x` AS `prog__x`,`prog`.`y` AS `prog__y`,`prog`.`z` AS `prog__z`,`prog`.`vx` AS `prog__vx`,`prog`.`vy` AS `prog__vy`,`prog`.`vz` AS `prog__vz`,`prog`.`np` AS `prog__np`,`prog`.`mass` AS `prog__mass`,`prog`.`size` AS `prog__size`,`prog`.`spin` AS `prog__spin`,`prog`.`ix` AS `prog__ix`,`prog`.`iy` AS `prog__iy`,`prog`.`iz` AS `prog__iz`,`prog`.`phkey` AS `prog__phkey`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`,`prog__fofTreeId`
FROM `aggregation_tmp_26167533`  ORDER BY `prog__fofTreeId` ASC ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_52594957`  ORDER BY `prog__fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog__fofTreeId`=VALUES(`prog__fofTreeId`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)
This is the query plan for the query:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

CALL paquExec('SELECT `descend`.`fofTreeId` AS `descend.fofTreeId`,`descend`.`lastProgId` AS `descend.lastProgId`,`prog__fofTreeId` AS `prog__fofTreeId` FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   ', 'aggregation_tmp_26167533');
CALL paquExec('SELECT `prog`.`fofTreeId` AS `prog__fofTreeId`,`prog`.`fofId` AS `prog__fofId`,`prog`.`treeSnapnum` AS `prog__treeSnapnum`,`prog`.`descendantId` AS `prog__descendantId`,`prog`.`lastProgId` AS `prog__lastProgId`,`prog`.`mainLeafId` AS `prog__mainLeafId`,`prog`.`treeRootId` AS `prog__treeRootId`,`prog`.`x` AS `prog__x`,`prog`.`y` AS `prog__y`,`prog`.`z` AS `prog__z`,`prog`.`vx` AS `prog__vx`,`prog`.`vy` AS `prog__vy`,`prog`.`vz` AS `prog__vz`,`prog`.`np` AS `prog__np`,`prog`.`mass` AS `prog__mass`,`prog`.`size` AS `prog__size`,`prog`.`spin` AS `prog__spin`,`prog`.`ix` AS `prog__ix`,`prog`.`iy` AS `prog__iy`,`prog`.`iz` AS `prog__iz`,`prog`.`phkey` AS `prog__phkey` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`,`prog__fofTreeId` FROM `aggregation_tmp_26167533`  ORDER BY `prog__fofTreeId` ASC ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_52594957');
CALL paquDropTmp('aggregation_tmp_26167533');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_52594957`  ORDER BY `prog__fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_52594957');
This is the query plan optimisation output for the query:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`,`prog__fofTreeId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`),
`prog__fofTreeId`=VALUES(`prog__fofTreeId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `descend`.`fofTreeId` AS `descend.fofTreeId`,`descend`.`lastProgId` AS `descend.lastProgId`,`prog__fofTreeId` AS `prog__fofTreeId`
FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`,`prog__fofTreeId`
FROM `aggregation_tmp_8135462`  ORDER BY `prog__fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`),
`prog__fofTreeId`=VALUES(`prog__fofTreeId`)
-- INPUT SQL:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog__fofTreeId`=VALUES(`prog__fofTreeId`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.`fofTreeId` AS `prog__fofTreeId`,`prog`.`fofId` AS `prog__fofId`,`prog`.`treeSnapnum` AS `prog__treeSnapnum`,`prog`.`descendantId` AS `prog__descendantId`,`prog`.`lastProgId` AS `prog__lastProgId`,`prog`.`mainLeafId` AS `prog__mainLeafId`,`prog`.`treeRootId` AS `prog__treeRootId`,`prog`.`x` AS `prog__x`,`prog`.`y` AS `prog__y`,`prog`.`z` AS `prog__z`,`prog`.`vx` AS `prog__vx`,`prog`.`vy` AS `prog__vy`,`prog`.`vz` AS `prog__vz`,`prog`.`np` AS `prog__np`,`prog`.`mass` AS `prog__mass`,`prog`.`size` AS `prog__size`,`prog`.`spin` AS `prog__spin`,`prog`.`ix` AS `prog__ix`,`prog`.`iy` AS `prog__iy`,`prog`.`iz` AS `prog__iz`,`prog`.`phkey` AS `prog__phkey`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`,`prog__fofTreeId`
FROM `aggregation_tmp_8135462`  ORDER BY `prog__fofTreeId` ASC ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_92864312`  ORDER BY `prog__fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog__fofTreeId`=VALUES(`prog__fofTreeId`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)
This is the query plan for the query:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

CALL paquExec('SELECT `descend`.`fofTreeId` AS `descend.fofTreeId`,`descend`.`lastProgId` AS `descend.lastProgId`,`prog__fofTreeId` AS `prog__fofTreeId` FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   ', 'aggregation_tmp_8135462');
CALL paquExec('SELECT `prog`.`fofTreeId` AS `prog__fofTreeId`,`prog`.`fofId` AS `prog__fofId`,`prog`.`treeSnapnum` AS `prog__treeSnapnum`,`prog`.`descendantId` AS `prog__descendantId`,`prog`.`lastProgId` AS `prog__lastProgId`,`prog`.`mainLeafId` AS `prog__mainLeafId`,`prog`.`treeRootId` AS `prog__treeRootId`,`prog`.`x` AS `prog__x`,`prog`.`y` AS `prog__y`,`prog`.`z` AS `prog__z`,`prog`.`vx` AS `prog__vx`,`prog`.`vy` AS `prog__vy`,`prog`.`vz` AS `prog__vz`,`prog`.`np` AS `prog__np`,`prog`.`mass` AS `prog__mass`,`prog`.`size` AS `prog__size`,`prog`.`spin` AS `prog__spin`,`prog`.`ix` AS `prog__ix`,`prog`.`iy` AS `prog__iy`,`prog`.`iz` AS `prog__iz`,`prog`.`phkey` AS `prog__phkey` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`,`prog__fofTreeId` FROM `aggregation_tmp_8135462`  ORDER BY `prog__fofTreeId` ASC ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_92864312');
CALL paquDropTmp('aggregation_tmp_8135462');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_92864312`  ORDER BY `prog__fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_92864312');
This is the query plan optimisation output for the query:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

-- INPUT SQL:
Array

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`descend.fofTreeId`,`descend.lastProgId`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `descend`.`fofTreeId` AS `descend.fofTreeId`,`descend`.`lastProgId` AS `descend.lastProgId`
FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   
)


-- AGGREGATION SQL:
SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_78246355`   
ON DUPLICATE KEY UPDATE
`descend.fofTreeId`=VALUES(`descend.fofTreeId`),
`descend.lastProgId`=VALUES(`descend.lastProgId`)
-- INPUT SQL:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

--PARALLEL OPTIMIZATIONS:

* The following projections were selected for a UNIQUE CHECK on the storage node operation:
`prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`

* storage node result set merge optimization enabled:
ON DUPLICATE KEY UPDATE
`prog__fofTreeId`=VALUES(`prog__fofTreeId`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)


-- SQL TO SEND TO SHARDS:
Array
(
    [0] => SELECT `prog`.`fofTreeId` AS `prog__fofTreeId`,`prog`.`fofId` AS `prog__fofId`,`prog`.`treeSnapnum` AS `prog__treeSnapnum`,`prog`.`descendantId` AS `prog__descendantId`,`prog`.`lastProgId` AS `prog__lastProgId`,`prog`.`mainLeafId` AS `prog__mainLeafId`,`prog`.`treeRootId` AS `prog__treeRootId`,`prog`.`x` AS `prog__x`,`prog`.`y` AS `prog__y`,`prog`.`z` AS `prog__z`,`prog`.`vx` AS `prog__vx`,`prog`.`vy` AS `prog__vy`,`prog`.`vz` AS `prog__vz`,`prog`.`np` AS `prog__np`,`prog`.`mass` AS `prog__mass`,`prog`.`size` AS `prog__size`,`prog`.`spin` AS `prog__spin`,`prog`.`ix` AS `prog__ix`,`prog`.`iy` AS `prog__iy`,`prog`.`iz` AS `prog__iz`,`prog`.`phkey` AS `prog__phkey`
FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId`
FROM `aggregation_tmp_78246355`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   
)


-- AGGREGATION SQL:
SELECT `prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_93666276`  ORDER BY `prog__fofTreeId` ASC 
ON DUPLICATE KEY UPDATE
`prog__fofTreeId`=VALUES(`prog__fofTreeId`),
`prog__fofId`=VALUES(`prog__fofId`),
`prog__treeSnapnum`=VALUES(`prog__treeSnapnum`),
`prog__descendantId`=VALUES(`prog__descendantId`),
`prog__lastProgId`=VALUES(`prog__lastProgId`),
`prog__mainLeafId`=VALUES(`prog__mainLeafId`),
`prog__treeRootId`=VALUES(`prog__treeRootId`),
`prog__x`=VALUES(`prog__x`),
`prog__y`=VALUES(`prog__y`),
`prog__z`=VALUES(`prog__z`),
`prog__vx`=VALUES(`prog__vx`),
`prog__vy`=VALUES(`prog__vy`),
`prog__vz`=VALUES(`prog__vz`),
`prog__np`=VALUES(`prog__np`),
`prog__mass`=VALUES(`prog__mass`),
`prog__size`=VALUES(`prog__size`),
`prog__spin`=VALUES(`prog__spin`),
`prog__ix`=VALUES(`prog__ix`),
`prog__iy`=VALUES(`prog__iy`),
`prog__iz`=VALUES(`prog__iz`),
`prog__phkey`=VALUES(`prog__phkey`)
This is the query plan for the query:
SELECT `prog`.fofTreeId as `prog__fofTreeId`,`prog`.fofId as `prog__fofId`,`prog`.treeSnapnum as `prog__treeSnapnum`,`prog`.descendantId as `prog__descendantId`,`prog`.lastProgId as `prog__lastProgId`,`prog`.mainLeafId as `prog__mainLeafId`,`prog`.treeRootId as `prog__treeRootId`,`prog`.x as `prog__x`,`prog`.y as `prog__y`,`prog`.z as `prog__z`,`prog`.vx as `prog__vx`,`prog`.vy as `prog__vy`,`prog`.vz as `prog__vz`,`prog`.np as `prog__np`,`prog`.mass as `prog__mass`,`prog`.size as `prog__size`,`prog`.spin as `prog__spin`,`prog`.ix as `prog__ix`,`prog`.iy as `prog__iy`,`prog`.iz as `prog__iz`,`prog`.phkey as `prog__phkey` FROM MDR1.FOFMtree prog , MDR1.FOFMtree descend WHERE descend.fofTreeId = 85000000000 AND prog.fofTreeId BETWEEN descend.fofTreeId AND descend.lastProgId ORDER BY `prog__fofTreeId` ASC

CALL paquExec('SELECT `descend`.`fofTreeId` AS `descend.fofTreeId`,`descend`.`lastProgId` AS `descend.lastProgId` FROM MDR1.FOFMtree AS `descend` WHERE ( `descend`.`fofTreeId` = 85000000000 )   ', 'aggregation_tmp_78246355');
CALL paquExec('SELECT `prog`.`fofTreeId` AS `prog__fofTreeId`,`prog`.`fofId` AS `prog__fofId`,`prog`.`treeSnapnum` AS `prog__treeSnapnum`,`prog`.`descendantId` AS `prog__descendantId`,`prog`.`lastProgId` AS `prog__lastProgId`,`prog`.`mainLeafId` AS `prog__mainLeafId`,`prog`.`treeRootId` AS `prog__treeRootId`,`prog`.`x` AS `prog__x`,`prog`.`y` AS `prog__y`,`prog`.`z` AS `prog__z`,`prog`.`vx` AS `prog__vx`,`prog`.`vy` AS `prog__vy`,`prog`.`vz` AS `prog__vz`,`prog`.`np` AS `prog__np`,`prog`.`mass` AS `prog__mass`,`prog`.`size` AS `prog__size`,`prog`.`spin` AS `prog__spin`,`prog`.`ix` AS `prog__ix`,`prog`.`iy` AS `prog__iy`,`prog`.`iz` AS `prog__iz`,`prog`.`phkey` AS `prog__phkey` FROM MDR1.FOFMtree AS `prog` JOIN ( SELECT `descend.fofTreeId`,`descend.lastProgId` FROM `aggregation_tmp_78246355`   ) AS `descend`  WHERE ( `prog`.`fofTreeId` BETWEEN `descend`.`descend.fofTreeId` AND `descend`.`descend.lastProgId` )   ', 'aggregation_tmp_93666276');
CALL paquDropTmp('aggregation_tmp_78246355');
USE spider_tmp_shard; CREATE TABLE TEST.TEST ENGINE=MyISAM SELECT `prog__fofTreeId`,`prog__fofId`,`prog__treeSnapnum`,`prog__descendantId`,`prog__lastProgId`,`prog__mainLeafId`,`prog__treeRootId`,`prog__x`,`prog__y`,`prog__z`,`prog__vx`,`prog__vy`,`prog__vz`,`prog__np`,`prog__mass`,`prog__size`,`prog__spin`,`prog__ix`,`prog__iy`,`prog__iz`,`prog__phkey`
FROM `aggregation_tmp_93666276`  ORDER BY `prog__fofTreeId` ASC ;
CALL paquDropTmp('aggregation_tmp_93666276');
